Attaching to ozone_datanode_1, ozone_scm_1, ozone_datanode_3, ozone_datanode_2, ozone_recon_1, ozone_om_1, ozone_s3g_1
datanode_1  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2020-04-20 12:17:05,771 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = 69674aa52266/172.21.0.8
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 3.2.0
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1  | STARTUP_MSG:   java = 11.0.6
datanode_1  | ************************************************************/
datanode_1  | 2020-04-20 12:17:05,816 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2020-04-20 12:17:07,512 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2020-04-20 12:17:07,990 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2020-04-20 12:17:08,985 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2020-04-20 12:17:08,985 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2020-04-20 12:17:09,778 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:69674aa52266 ip:172.21.0.8
datanode_1  | 2020-04-20 12:17:10,203 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2020-04-20 12:17:10,220 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1  | 2020-04-20 12:17:10,223 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2020-04-20 12:17:10,242 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2020-04-20 12:17:10,324 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2020-04-20 12:17:15,284 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2020-04-20 12:17:15,529 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1  | 2020-04-20 12:17:15,827 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1  | 2020-04-20 12:17:15,833 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  | 2020-04-20 12:17:15,837 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-20 12:17:15,838 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1  | 2020-04-20 12:17:15,839 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2020-04-20 12:17:17,063 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-04-20 12:17:17,907 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2020-04-20 12:17:17,987 [main] INFO util.log: Logging initialized @17129ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2020-04-20 12:17:18,564 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2020-04-20 12:17:18,618 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2020-04-20 12:17:18,646 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2020-04-20 12:17:18,670 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1  | 2020-04-20 12:17:18,677 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1  | 2020-04-20 12:17:18,677 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1  | 2020-04-20 12:17:18,916 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2020-04-20 12:17:18,922 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1  | 2020-04-20 12:17:19,044 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  | 2020-04-20 12:17:19,054 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2020-04-20 12:17:19,056 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_1  | 2020-04-20 12:17:19,090 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f76c2cc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2020-04-20 12:17:19,101 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@441b8382{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2020-04-20 12:17:19,643 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@673c4f6e{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-15819496388296280298.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1  | 2020-04-20 12:17:19,687 [main] INFO server.AbstractConnector: Started ServerConnector@1491344a{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1  | 2020-04-20 12:17:19,690 [main] INFO server.Server: Started @18832ms
datanode_1  | 2020-04-20 12:17:19,713 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2020-04-20 12:17:19,713 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2020-04-20 12:17:19,723 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1  | 2020-04-20 12:17:19,778 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4da37cbc] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2020-04-20 12:17:20,229 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.21.0.5:9891
datanode_1  | 2020-04-20 12:17:20,571 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1  | 2020-04-20 12:17:22,986 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-04-20 12:17:22,994 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_1  | java.net.SocketTimeoutException: Call From 69674aa52266/172.21.0.8 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.8:48162 remote=recon/172.21.0.5:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_1  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.8:48162 remote=recon/172.21.0.5:9891]
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_1  | 2020-04-20 12:17:23,924 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 2020-04-20 12:17:23,926 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1  | 2020-04-20 12:17:23,931 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis bb3db77a-6a57-4c4e-bdc7-ea39008446e6 at port 9858
datanode_1  | 2020-04-20 12:17:24,090 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start RPC server
datanode_1  | 2020-04-20 12:17:24,341 [Datanode State Machine Thread - 1] INFO server.GrpcService: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1  | 2020-04-20 12:17:28,890 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: addNew group-32D803F54E3F:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858] returns group-32D803F54E3F:java.util.concurrent.CompletableFuture@52ebd720[Not completed]
datanode_1  | 2020-04-20 12:17:29,142 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: new RaftServerImpl for group-32D803F54E3F:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-04-20 12:17:29,161 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-04-20 12:17:29,162 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-04-20 12:17:29,162 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-04-20 12:17:29,162 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-04-20 12:17:29,163 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-04-20 12:17:29,189 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-04-20 12:17:29,197 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-04-20 12:17:29,223 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-04-20 12:17:29,231 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e57c404d-293c-4d1e-85dd-32d803f54e3f does not exist. Creating ...
datanode_1  | 2020-04-20 12:17:29,271 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e57c404d-293c-4d1e-85dd-32d803f54e3f/in_use.lock acquired by nodename 6@69674aa52266
datanode_1  | 2020-04-20 12:17:29,283 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e57c404d-293c-4d1e-85dd-32d803f54e3f has been successfully formatted.
datanode_1  | 2020-04-20 12:17:29,286 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-32D803F54E3F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-04-20 12:17:29,293 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-04-20 12:17:29,320 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-04-20 12:17:29,331 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-04-20 12:17:29,338 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-20 12:17:29,340 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-20 12:17:29,384 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:17:29,483 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-04-20 12:17:29,520 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/e57c404d-293c-4d1e-85dd-32d803f54e3f
datanode_1  | 2020-04-20 12:17:29,534 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-04-20 12:17:29,534 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-04-20 12:17:29,539 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-20 12:17:29,540 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-04-20 12:17:29,540 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-04-20 12:17:29,561 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-04-20 12:17:29,564 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-04-20 12:17:29,564 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-04-20 12:17:29,564 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-04-20 12:17:29,646 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-04-20 12:17:29,668 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-04-20 12:17:29,704 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-04-20 12:17:29,711 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-04-20 12:17:29,713 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-04-20 12:17:29,717 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-04-20 12:17:29,768 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F
datanode_1  | 2020-04-20 12:17:29,781 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F
datanode_1  | 2020-04-20 12:17:29,786 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858], old=null
datanode_1  | 2020-04-20 12:17:29,786 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-04-20 12:17:29,788 [pool-69-thread-1] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start FollowerState
datanode_1  | 2020-04-20 12:17:29,815 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-32D803F54E3F,id=bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:17:29,823 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F
datanode_1  | 2020-04-20 12:17:29,887 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "e57c404d-293c-4d1e-85dd-32d803f54e3f"
datanode_1  | .
datanode_1  | 2020-04-20 12:17:29,894 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: addNew group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-59C4E3B5DF2B:java.util.concurrent.CompletableFuture@4c3b2a19[Not completed]
datanode_1  | 2020-04-20 12:17:29,896 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: new RaftServerImpl for group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-04-20 12:17:29,900 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-04-20 12:17:29,916 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-04-20 12:17:29,921 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-04-20 12:17:29,921 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-04-20 12:17:29,921 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-04-20 12:17:29,921 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-04-20 12:17:29,922 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-04-20 12:17:29,922 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-04-20 12:17:29,922 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/99e9249b-6272-4da5-81f6-59c4e3b5df2b does not exist. Creating ...
datanode_1  | 2020-04-20 12:17:29,929 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/99e9249b-6272-4da5-81f6-59c4e3b5df2b/in_use.lock acquired by nodename 6@69674aa52266
datanode_1  | 2020-04-20 12:17:29,931 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/99e9249b-6272-4da5-81f6-59c4e3b5df2b has been successfully formatted.
datanode_1  | 2020-04-20 12:17:29,932 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-59C4E3B5DF2B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-04-20 12:17:29,932 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-04-20 12:17:29,932 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-04-20 12:17:29,932 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-04-20 12:17:29,933 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-20 12:17:29,933 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-20 12:17:29,933 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-04-20 12:17:29,933 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/99e9249b-6272-4da5-81f6-59c4e3b5df2b
datanode_1  | 2020-04-20 12:17:29,947 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-04-20 12:17:29,950 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-04-20 12:17:29,951 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-20 12:17:29,951 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-04-20 12:17:29,957 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2020-04-20 12:17:00,533 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = f98376242d82/172.21.0.3
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 3.2.0
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_2  | STARTUP_MSG:   java = 11.0.6
datanode_2  | ************************************************************/
datanode_2  | 2020-04-20 12:17:00,565 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2020-04-20 12:17:02,271 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2020-04-20 12:17:03,001 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2020-04-20 12:17:04,133 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2020-04-20 12:17:04,133 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2020-04-20 12:17:05,077 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:f98376242d82 ip:172.21.0.3
datanode_2  | 2020-04-20 12:17:05,640 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2  | 2020-04-20 12:17:05,653 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2  | 2020-04-20 12:17:05,658 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2020-04-20 12:17:05,697 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2  | 2020-04-20 12:17:05,798 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2020-04-20 12:17:10,702 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-04-20 12:17:11,013 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2020-04-20 12:17:11,358 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2  | 2020-04-20 12:17:11,372 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2  | 2020-04-20 12:17:11,378 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-20 12:17:11,384 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2  | 2020-04-20 12:17:11,389 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-04-20 12:17:13,200 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-20 12:17:13,740 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 2020-04-20 12:17:13,844 [main] INFO util.log: Logging initialized @15482ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | 2020-04-20 12:17:14,303 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2020-04-20 12:17:14,310 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2020-04-20 12:17:14,347 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2020-04-20 12:17:14,349 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2  | 2020-04-20 12:17:14,360 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2  | 2020-04-20 12:17:14,362 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2  | 2020-04-20 12:17:14,493 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2020-04-20 12:17:14,498 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2  | 2020-04-20 12:17:14,595 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2020-04-20 12:17:14,596 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2020-04-20 12:17:14,600 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2  | 2020-04-20 12:17:14,635 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f76c2cc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2020-04-20 12:17:14,644 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@441b8382{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2020-04-20 12:17:15,319 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@673c4f6e{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-764523688427506416.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 2020-04-20 12:17:15,349 [main] INFO server.AbstractConnector: Started ServerConnector@1491344a{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2  | 2020-04-20 12:17:15,350 [main] INFO server.Server: Started @16988ms
datanode_2  | 2020-04-20 12:17:15,357 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2020-04-20 12:17:15,357 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2020-04-20 12:17:15,365 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2020-04-20 12:17:15,522 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@266b1f23] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2020-04-20 12:17:16,018 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.21.0.5:9891
datanode_2  | 2020-04-20 12:17:16,297 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2  | 2020-04-20 12:17:18,753 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-04-20 12:17:19,753 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-04-20 12:17:20,754 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-04-20 12:17:21,755 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-04-20 12:17:22,756 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-04-20 12:17:23,756 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-04-20 12:17:23,970 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2020-04-20 12:17:23,972 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2  | 2020-04-20 12:17:23,973 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 175c1ce4-a4bc-4858-9a69-a6ac92762c21 at port 9858
datanode_2  | 2020-04-20 12:17:24,082 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start RPC server
datanode_2  | 2020-04-20 12:17:24,402 [Datanode State Machine Thread - 1] INFO server.GrpcService: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2  | 2020-04-20 12:17:28,654 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: addNew group-40413D362A41:[175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858] returns group-40413D362A41:java.util.concurrent.CompletableFuture@56c8a6f8[Not completed]
datanode_2  | 2020-04-20 12:17:28,740 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: new RaftServerImpl for group-40413D362A41:[175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-04-20 12:17:28,752 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-04-20 12:17:28,753 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-04-20 12:17:28,753 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-04-20 12:17:28,754 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-04-20 12:17:28,755 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-04-20 12:17:28,774 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41: ConfigurationManager, init=-1: [175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-04-20 12:17:28,774 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-20 12:17:28,791 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-04-20 12:17:28,800 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a860a08d-a8b9-4b50-90bb-40413d362a41 does not exist. Creating ...
datanode_2  | 2020-04-20 12:17:28,849 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a860a08d-a8b9-4b50-90bb-40413d362a41/in_use.lock acquired by nodename 6@f98376242d82
datanode_2  | 2020-04-20 12:17:28,862 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a860a08d-a8b9-4b50-90bb-40413d362a41 has been successfully formatted.
datanode_2  | 2020-04-20 12:17:28,888 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-40413D362A41: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-04-20 12:17:28,889 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-04-20 12:17:28,892 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-04-20 12:17:28,902 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-04-20 12:17:28,904 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-20 12:17:28,906 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-20 12:17:28,923 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:17:28,969 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-04-20 12:17:28,987 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/a860a08d-a8b9-4b50-90bb-40413d362a41
datanode_2  | 2020-04-20 12:17:28,993 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-04-20 12:17:28,993 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-04-20 12:17:28,996 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-20 12:17:28,997 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-04-20 12:17:29,005 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-04-20 12:17:29,006 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-04-20 12:17:29,007 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-04-20 12:17:29,013 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-04-20 12:17:29,013 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-04-20 12:17:29,101 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-04-20 12:17:29,131 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-04-20 12:17:29,167 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-04-20 12:17:29,167 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-04-20 12:17:29,173 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-04-20 12:17:29,173 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-04-20 12:17:29,289 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41
datanode_2  | 2020-04-20 12:17:29,305 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41
datanode_2  | 2020-04-20 12:17:29,307 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41: start as a follower, conf=-1: [175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858], old=null
datanode_2  | 2020-04-20 12:17:29,312 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-04-20 12:17:29,324 [pool-69-thread-1] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start FollowerState
datanode_2  | 2020-04-20 12:17:29,377 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-40413D362A41,id=175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:17:29,379 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41
datanode_2  | 2020-04-20 12:17:29,422 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "a860a08d-a8b9-4b50-90bb-40413d362a41"
datanode_2  | .
datanode_2  | 2020-04-20 12:17:29,433 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: addNew group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-59C4E3B5DF2B:java.util.concurrent.CompletableFuture@df45572[Not completed]
datanode_2  | 2020-04-20 12:17:29,442 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: new RaftServerImpl for group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-04-20 12:17:29,453 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-04-20 12:17:29,453 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-04-20 12:17:29,453 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-04-20 12:17:29,453 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-04-20 12:17:29,453 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-04-20 12:17:29,961 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-04-20 12:17:29,961 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-04-20 12:17:29,961 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-04-20 12:17:29,969 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-04-20 12:17:29,969 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-04-20 12:17:29,970 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-04-20 12:17:29,979 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-04-20 12:17:29,981 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-04-20 12:17:29,981 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-04-20 12:17:29,981 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-04-20 12:17:29,985 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B
datanode_1  | 2020-04-20 12:17:29,985 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B
datanode_1  | 2020-04-20 12:17:29,987 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_1  | 2020-04-20 12:17:29,993 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-04-20 12:17:29,993 [pool-69-thread-1] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start FollowerState
datanode_1  | 2020-04-20 12:17:29,997 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-59C4E3B5DF2B,id=bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:17:30,004 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B
datanode_1  | 2020-04-20 12:17:31,505 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_1  | .
datanode_1  | 2020-04-20 12:17:31,550 [grpc-default-executor-0] WARN impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed groupAdd* GroupManagementRequest:client-3B9FB1A3FA76->bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B, cid=1, seq=0, RW, null, Add:group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 	... 13 more
datanode_1  | 2020-04-20 12:17:31,565 [grpc-default-executor-1] WARN impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed groupAdd* GroupManagementRequest:client-CCA7226330CA->bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B, cid=1, seq=0, RW, null, Add:group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 2020-04-20 12:17:29,454 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-04-20 12:17:29,454 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-20 12:17:29,454 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-04-20 12:17:29,455 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/99e9249b-6272-4da5-81f6-59c4e3b5df2b does not exist. Creating ...
datanode_2  | 2020-04-20 12:17:29,462 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/99e9249b-6272-4da5-81f6-59c4e3b5df2b/in_use.lock acquired by nodename 6@f98376242d82
datanode_2  | 2020-04-20 12:17:29,464 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/99e9249b-6272-4da5-81f6-59c4e3b5df2b has been successfully formatted.
datanode_2  | 2020-04-20 12:17:29,465 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-59C4E3B5DF2B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-04-20 12:17:29,465 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-04-20 12:17:29,465 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-04-20 12:17:29,466 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-04-20 12:17:29,467 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-20 12:17:29,467 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-20 12:17:29,467 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-04-20 12:17:29,467 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/99e9249b-6272-4da5-81f6-59c4e3b5df2b
datanode_2  | 2020-04-20 12:17:29,468 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-04-20 12:17:29,468 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-04-20 12:17:29,468 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-20 12:17:29,469 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-04-20 12:17:29,469 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-04-20 12:17:29,470 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-04-20 12:17:29,470 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-04-20 12:17:29,470 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-04-20 12:17:29,474 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-04-20 12:17:29,475 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-04-20 12:17:29,476 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-04-20 12:17:29,500 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-04-20 12:17:29,517 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-04-20 12:17:29,519 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-04-20 12:17:29,523 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-04-20 12:17:29,523 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B
datanode_2  | 2020-04-20 12:17:29,524 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B
datanode_2  | 2020-04-20 12:17:29,524 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_2  | 2020-04-20 12:17:29,530 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-04-20 12:17:29,530 [pool-69-thread-1] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start FollowerState
datanode_2  | 2020-04-20 12:17:29,537 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-59C4E3B5DF2B,id=175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:17:29,537 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B
datanode_2  | 2020-04-20 12:17:31,045 [grpc-default-executor-0] WARN impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed groupAdd* GroupManagementRequest:client-2F2DED101CF3->175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B, cid=0, seq=0, RW, null, Add:group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2  | 	... 13 more
datanode_2  | 2020-04-20 12:17:31,434 [grpc-default-executor-0] WARN impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed groupAdd* GroupManagementRequest:client-FD9D91D3D862->175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B, cid=1, seq=0, RW, null, Add:group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2  | 	... 13 more
datanode_2  | 2020-04-20 12:17:31,619 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_2  | .
datanode_2  | 2020-04-20 12:17:34,451 [grpc-default-executor-0] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_2  | 2020-04-20 12:17:34,452 [grpc-default-executor-0] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown FollowerState
datanode_2  | 2020-04-20 12:17:34,452 [Thread-26] INFO impl.FollowerState: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2  | 2020-04-20 12:17:34,452 [grpc-default-executor-0] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start FollowerState
datanode_2  | 2020-04-20 12:17:34,479 [Thread-24] INFO impl.FollowerState: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-FollowerState: change to CANDIDATE, lastRpcTime:5155ms, electionTimeout:5110ms
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 	... 13 more
datanode_1  | 2020-04-20 12:17:34,439 [grpc-default-executor-0] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | 2020-04-20 12:17:34,440 [grpc-default-executor-0] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown FollowerState
datanode_1  | 2020-04-20 12:17:34,441 [Thread-27] INFO impl.FollowerState: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1  | 2020-04-20 12:17:34,441 [grpc-default-executor-0] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start FollowerState
datanode_2  | 2020-04-20 12:17:34,481 [Thread-24] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown FollowerState
datanode_2  | 2020-04-20 12:17:34,484 [Thread-24] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-04-20 12:17:34,486 [Thread-24] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start LeaderElection
datanode_2  | 2020-04-20 12:17:34,505 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO impl.LeaderElection: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1: begin an election at term 1 for -1: [175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858], old=null
datanode_2  | 2020-04-20 12:17:34,506 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown LeaderElection
datanode_2  | 2020-04-20 12:17:34,506 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-04-20 12:17:34,507 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-40413D362A41 with new leaderId: 175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:17:34,508 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41: change Leader from null to 175c1ce4-a4bc-4858-9a69-a6ac92762c21 at term 1 for becomeLeader, leader elected after 5618ms
datanode_2  | 2020-04-20 12:17:34,517 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-04-20 12:17:34,517 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2020-04-20 12:17:34,529 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41
datanode_2  | 2020-04-20 12:17:34,534 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2020-04-20 12:17:34,534 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-04-20 12:17:34,561 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-04-20 12:17:34,561 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-04-20 12:17:34,564 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2020-04-20 12:17:34,590 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start LeaderState
datanode_2  | 2020-04-20 12:17:34,619 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-59C4E3B5DF2B with new leaderId: 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_2  | 2020-04-20 12:17:34,619 [grpc-default-executor-0] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B: change Leader from null to 258ceeb5-4c9c-49bf-b393-79534db322e4 at term 1 for appendEntries, leader elected after 5153ms
datanode_2  | 2020-04-20 12:17:34,626 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-04-20 12:17:34,743 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-LeaderElection1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41: set configuration 0: [175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858], old=null at 0
datanode_2  | 2020-04-20 12:17:34,750 [grpc-default-executor-0] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_2  | 2020-04-20 12:17:34,750 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-04-20 12:17:34,904 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-40413D362A41-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a860a08d-a8b9-4b50-90bb-40413d362a41/current/log_inprogress_0
datanode_2  | 2020-04-20 12:17:34,910 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/99e9249b-6272-4da5-81f6-59c4e3b5df2b/current/log_inprogress_0
datanode_2  | 2020-04-20 12:17:42,400 [ChunkWriter-19-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: e7e3361cefa2c31a:7318f7b560aa1975:e7e3361cefa2c31a:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_2  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=1045446656 B) is less than the container size (=1073741824 B).
datanode_1  | 2020-04-20 12:17:34,667 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-59C4E3B5DF2B with new leaderId: 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | 2020-04-20 12:17:34,667 [grpc-default-executor-0] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B: change Leader from null to 258ceeb5-4c9c-49bf-b393-79534db322e4 at term 1 for appendEntries, leader elected after 4734ms
datanode_1  | 2020-04-20 12:17:34,711 [grpc-default-executor-0] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_1  | 2020-04-20 12:17:34,723 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-04-20 12:17:34,861 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/99e9249b-6272-4da5-81f6-59c4e3b5df2b/current/log_inprogress_0
datanode_1  | 2020-04-20 12:17:35,022 [Thread-25] INFO impl.FollowerState: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-FollowerState: change to CANDIDATE, lastRpcTime:5234ms, electionTimeout:5198ms
datanode_1  | 2020-04-20 12:17:35,023 [Thread-25] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown FollowerState
datanode_1  | 2020-04-20 12:17:35,024 [Thread-25] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2020-04-20 12:17:35,025 [Thread-25] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start LeaderElection
datanode_1  | 2020-04-20 12:17:35,033 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO impl.LeaderElection: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1: begin an election at term 1 for -1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858], old=null
datanode_1  | 2020-04-20 12:17:35,034 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown LeaderElection
datanode_1  | 2020-04-20 12:17:35,034 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2020-04-20 12:17:35,034 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-32D803F54E3F with new leaderId: bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:17:35,034 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F: change Leader from null to bb3db77a-6a57-4c4e-bdc7-ea39008446e6 at term 1 for becomeLeader, leader elected after 5748ms
datanode_1  | 2020-04-20 12:17:35,037 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2020-04-20 12:17:35,037 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2020-04-20 12:17:35,049 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F
datanode_1  | 2020-04-20 12:17:35,054 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2020-04-20 12:17:35,055 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1  | 2020-04-20 12:17:35,059 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2020-04-20 12:17:35,059 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2020-04-20 12:17:35,060 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2020-04-20 12:17:35,073 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start LeaderState
datanode_1  | 2020-04-20 12:17:35,076 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-04-20 12:17:35,077 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-LeaderElection1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858], old=null at 0
datanode_1  | 2020-04-20 12:17:35,078 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-32D803F54E3F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e57c404d-293c-4d1e-85dd-32d803f54e3f/current/log_inprogress_0
datanode_1  | 2020-04-20 12:17:42,373 [ChunkWriter-20-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: e7e3361cefa2c31a:7318f7b560aa1975:e7e3361cefa2c31a:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
recon_1     | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1     | WARNING: An illegal reflective access operation has occurred
recon_1     | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
recon_1     | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | WARNING: All illegal access operations will be denied in a future release
recon_1     | 2020-04-20 12:17:02,737 [main] INFO recon.ReconRestServletModule: rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1     | 2020-04-20 12:17:04,273 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1     | 2020-04-20 12:17:07,913 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1     | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
recon_1     | 2020-04-20 12:17:11,569 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1     | 2020-04-20 12:17:11,668 [main] INFO util.log: Logging initialized @13205ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1     | 2020-04-20 12:17:12,290 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1     | 2020-04-20 12:17:12,347 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1     | 2020-04-20 12:17:12,385 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1     | 2020-04-20 12:17:12,396 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context recon
recon_1     | 2020-04-20 12:17:12,396 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
recon_1     | 2020-04-20 12:17:12,403 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
recon_1     | 2020-04-20 12:17:13,261 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1     | 2020-04-20 12:17:14,772 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1     | 2020-04-20 12:17:16,957 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-20 12:17:16,957 [main] INFO Configuration.deprecation: No unit for recon.om.connection.request.timeout(5000) assuming MILLISECONDS
recon_1     | 2020-04-20 12:17:17,855 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-20 12:17:17,896 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@1dcedc93
recon_1     | 2020-04-20 12:17:17,907 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1     | 2020-04-20 12:17:18,192 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1     | 2020-04-20 12:17:18,216 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-20 12:17:18,269 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1     | 2020-04-20 12:17:18,353 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1     | 2020-04-20 12:17:18,453 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1     | 2020-04-20 12:17:18,544 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-20 12:17:18,604 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
recon_1     | 2020-04-20 12:17:18,611 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-20 12:17:19,038 [main] INFO scm.ReconScmTask: Registered MissingContainerTask task 
recon_1     | 2020-04-20 12:17:19,045 [main] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1     | 2020-04-20 12:17:19,046 [main] INFO recon.ReconServer: Recon server initialized successfully!
recon_1     | 2020-04-20 12:17:19,046 [main] INFO recon.ReconServer: Starting Recon server
recon_1     | 2020-04-20 12:17:19,282 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1     | 2020-04-20 12:17:19,416 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1     | 2020-04-20 12:17:19,416 [main] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1     | 2020-04-20 12:17:20,187 [main] INFO http.HttpServer2: Jetty bound to port 9888
recon_1     | 2020-04-20 12:17:20,188 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
recon_1     | 2020-04-20 12:17:20,259 [main] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1     | 2020-04-20 12:17:20,259 [main] INFO server.session: No SessionScavenger set, using defaults
recon_1     | 2020-04-20 12:17:20,260 [main] INFO server.session: node0 Scavenging every 660000ms
recon_1     | 2020-04-20 12:17:20,342 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@23f3dbf0{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1     | 2020-04-20 12:17:20,362 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@20a05b32{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1     | 2020-04-20 12:17:22,619 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@d949bc4{recon,/,file:///tmp/jetty-0_0_0_0-9888-hadoop-ozone-recon-0_6_0-SNAPSHOT_jar-_-any-7495652361128630358.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar!/webapps/recon}
recon_1     | 2020-04-20 12:17:22,633 [main] INFO server.AbstractConnector: Started ServerConnector@46a953cf{HTTP/1.1,[http/1.1]}{0.0.0.0:9888}
recon_1     | 2020-04-20 12:17:22,634 [main] INFO server.Server: Started @24171ms
recon_1     | 2020-04-20 12:17:22,636 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1     | 2020-04-20 12:17:22,636 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1     | 2020-04-20 12:17:22,640 [main] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1     | 2020-04-20 12:17:22,640 [main] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1     | 2020-04-20 12:17:22,652 [main] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
datanode_3  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2020-04-20 12:17:04,180 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = 78409bf0b6e2/172.21.0.2
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 3.2.0
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_3  | STARTUP_MSG:   java = 11.0.6
datanode_3  | ************************************************************/
datanode_3  | 2020-04-20 12:17:04,234 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2020-04-20 12:17:05,642 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2020-04-20 12:17:06,083 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2020-04-20 12:17:07,252 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2020-04-20 12:17:07,256 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2020-04-20 12:17:08,161 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:78409bf0b6e2 ip:172.21.0.2
datanode_3  | 2020-04-20 12:17:08,529 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3  | 2020-04-20 12:17:08,548 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3  | 2020-04-20 12:17:08,550 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2020-04-20 12:17:08,578 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2020-04-20 12:17:08,669 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2020-04-20 12:17:13,275 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-04-20 12:17:13,498 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3  | 2020-04-20 12:17:13,777 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3  | 2020-04-20 12:17:13,785 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3  | 2020-04-20 12:17:13,788 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-20 12:17:13,789 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3  | 2020-04-20 12:17:13,795 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-04-20 12:17:14,947 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-20 12:17:15,697 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2020-04-20 12:17:15,799 [main] INFO util.log: Logging initialized @16001ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2020-04-20 12:17:16,388 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2020-04-20 12:17:16,406 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2020-04-20 12:17:16,424 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2020-04-20 12:17:16,454 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3  | 2020-04-20 12:17:16,472 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3  | 2020-04-20 12:17:16,473 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3  | 2020-04-20 12:17:16,677 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2020-04-20 12:17:16,678 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3  | 2020-04-20 12:17:16,843 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2020-04-20 12:17:16,845 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 2020-04-20 12:17:16,846 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_3  | 2020-04-20 12:17:16,901 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d7cac8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2020-04-20 12:17:16,913 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5349b246{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2020-04-20 12:17:17,301 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3f36e8d1{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-13356571491661803502.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2020-04-20 12:17:17,355 [main] INFO server.AbstractConnector: Started ServerConnector@1386313f{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3  | 2020-04-20 12:17:17,356 [main] INFO server.Server: Started @17557ms
datanode_3  | 2020-04-20 12:17:17,377 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2020-04-20 12:17:17,377 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2020-04-20 12:17:17,389 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3  | 2020-04-20 12:17:17,510 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7947f3d6] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2020-04-20 12:17:17,905 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.21.0.5:9891
datanode_3  | 2020-04-20 12:17:18,054 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3  | 2020-04-20 12:17:20,591 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-04-20 12:17:20,630 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_3  | java.net.SocketTimeoutException: Call From 78409bf0b6e2/172.21.0.2 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.2:53982 remote=recon/172.21.0.5:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_3  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
recon_1     | 2020-04-20 12:17:22,673 [main] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1     | 2020-04-20 12:17:22,673 [main] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1     | 2020-04-20 12:17:22,673 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-20 12:17:22,676 [main] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1     | 2020-04-20 12:17:22,684 [main] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1     | 2020-04-20 12:17:23,790 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9860. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
recon_1     | 2020-04-20 12:17:23,983 [main] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1     | 2020-04-20 12:17:23,983 [main] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2020-04-20 12:17:23,983 [main] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1     | 2020-04-20 12:17:24,004 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1     | 2020-04-20 12:17:23,989 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1     | 2020-04-20 12:17:24,078 [main] INFO scm.ReconScmTask: Starting MissingContainerTask Thread.
recon_1     | 2020-04-20 12:17:24,372 [main] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1     | 2020-04-20 12:17:24,429 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2020-04-20 12:17:24,441 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 56 milliseconds.
recon_1     | 2020-04-20 12:17:24,808 [IPC Server handler 3 on 9891] WARN ipc.Server: IPC Server handler 3 on 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.21.0.2:53982: output error
recon_1     | 2020-04-20 12:17:24,809 [IPC Server handler 4 on 9891] WARN ipc.Server: IPC Server handler 4 on 9891, call Call#3 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.21.0.2:54050: output error
recon_1     | 2020-04-20 12:17:24,809 [IPC Server handler 5 on 9891] WARN ipc.Server: IPC Server handler 5 on 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.21.0.2:54012: output error
recon_1     | 2020-04-20 12:17:24,827 [IPC Server handler 2 on 9891] WARN ipc.Server: IPC Server handler 2 on 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.21.0.8:48162: output error
recon_1     | 2020-04-20 12:17:24,828 [IPC Server handler 3 on 9891] INFO ipc.Server: IPC Server handler 3 on 9891 caught an exception
recon_1     | java.nio.channels.AsynchronousCloseException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1     | 2020-04-20 12:17:24,829 [IPC Server handler 5 on 9891] INFO ipc.Server: IPC Server handler 5 on 9891 caught an exception
recon_1     | java.nio.channels.AsynchronousCloseException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1     | 2020-04-20 12:17:24,829 [IPC Server handler 4 on 9891] INFO ipc.Server: IPC Server handler 4 on 9891 caught an exception
recon_1     | java.nio.channels.AsynchronousCloseException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1     | 2020-04-20 12:17:24,831 [IPC Server handler 2 on 9891] INFO ipc.Server: IPC Server handler 2 on 9891 caught an exception
recon_1     | java.nio.channels.AsynchronousCloseException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_3  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.2:53982 remote=recon/172.21.0.5:9891]
datanode_3  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_3  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_3  | 2020-04-20 12:17:21,592 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-04-20 12:17:22,592 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-04-20 12:17:23,593 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-04-20 12:17:23,925 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3  | 2020-04-20 12:17:23,927 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3  | 2020-04-20 12:17:23,932 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 258ceeb5-4c9c-49bf-b393-79534db322e4 at port 9858
datanode_3  | 2020-04-20 12:17:24,028 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: start RPC server
datanode_3  | 2020-04-20 12:17:24,462 [Datanode State Machine Thread - 1] INFO server.GrpcService: 258ceeb5-4c9c-49bf-b393-79534db322e4: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3  | 2020-04-20 12:17:28,551 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: addNew group-A48AB5D471DA:[258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-A48AB5D471DA:java.util.concurrent.CompletableFuture@56c8a6f8[Not completed]
datanode_3  | 2020-04-20 12:17:28,604 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4: new RaftServerImpl for group-A48AB5D471DA:[258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-04-20 12:17:28,606 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-04-20 12:17:28,606 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-04-20 12:17:28,606 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-04-20 12:17:28,607 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-04-20 12:17:28,608 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-20 12:17:28,634 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA: ConfigurationManager, init=-1: [258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-04-20 12:17:28,635 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-20 12:17:28,645 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-04-20 12:17:28,646 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/58833d14-bfe3-48b3-983c-a48ab5d471da does not exist. Creating ...
datanode_3  | 2020-04-20 12:17:28,661 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/58833d14-bfe3-48b3-983c-a48ab5d471da/in_use.lock acquired by nodename 6@78409bf0b6e2
datanode_3  | 2020-04-20 12:17:28,669 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/58833d14-bfe3-48b3-983c-a48ab5d471da has been successfully formatted.
datanode_3  | 2020-04-20 12:17:28,679 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-A48AB5D471DA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-04-20 12:17:28,699 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-04-20 12:17:28,734 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-04-20 12:17:28,746 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-04-20 12:17:28,749 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-20 12:17:28,751 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-20 12:17:28,781 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:17:28,817 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-04-20 12:17:28,827 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/58833d14-bfe3-48b3-983c-a48ab5d471da
datanode_3  | 2020-04-20 12:17:28,830 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-04-20 12:17:28,833 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-04-20 12:17:28,834 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-20 12:17:28,839 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-04-20 12:17:28,840 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-04-20 12:17:28,840 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-04-20 12:17:28,851 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-04-20 12:17:28,851 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-04-20 12:17:28,852 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-04-20 12:17:28,958 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-04-20 12:17:29,028 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-04-20 12:17:29,042 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-04-20 12:17:29,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-04-20 12:17:29,058 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-04-20 12:17:29,059 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-04-20 12:17:29,115 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA
datanode_3  | 2020-04-20 12:17:29,119 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA
datanode_3  | 2020-04-20 12:17:29,133 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA: start as a follower, conf=-1: [258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 2020-04-20 12:17:29,134 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-04-20 12:17:29,140 [pool-69-thread-1] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start FollowerState
datanode_3  | 2020-04-20 12:17:29,157 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A48AB5D471DA,id=258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:17:29,158 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA
datanode_3  | 2020-04-20 12:17:29,181 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "58833d14-bfe3-48b3-983c-a48ab5d471da"
datanode_3  | .
datanode_3  | 2020-04-20 12:17:29,182 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: addNew group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-59C4E3B5DF2B:java.util.concurrent.CompletableFuture@7fda81ec[Not completed]
datanode_3  | 2020-04-20 12:17:29,184 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4: new RaftServerImpl for group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-04-20 12:17:29,199 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-04-20 12:17:29,199 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-04-20 12:17:29,200 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-04-20 12:17:29,200 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-04-20 12:17:29,200 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-20 12:17:29,200 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-04-20 12:17:29,200 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-20 12:17:29,201 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-04-20 12:17:29,201 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/99e9249b-6272-4da5-81f6-59c4e3b5df2b does not exist. Creating ...
datanode_3  | 2020-04-20 12:17:29,203 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/99e9249b-6272-4da5-81f6-59c4e3b5df2b/in_use.lock acquired by nodename 6@78409bf0b6e2
datanode_3  | 2020-04-20 12:17:29,207 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/99e9249b-6272-4da5-81f6-59c4e3b5df2b has been successfully formatted.
datanode_3  | 2020-04-20 12:17:29,207 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-59C4E3B5DF2B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-04-20 12:17:29,210 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-04-20 12:17:29,210 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-04-20 12:17:29,211 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-04-20 12:17:29,211 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-20 12:17:29,211 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-20 12:17:29,212 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-04-20 12:17:29,213 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/99e9249b-6272-4da5-81f6-59c4e3b5df2b
datanode_2  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_2  | 	... 13 more
datanode_2  | 2020-04-20 12:17:42,454 [ChunkWriter-19-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: e7e3361cefa2c31a:7318f7b560aa1975:e7e3361cefa2c31a:0 , Message: ContainerID 1 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_2  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 1 creation failed
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:17:42,483 [ChunkWriter-19-0] ERROR ratis.ContainerStateMachine: group-59C4E3B5DF2B: writeChunk writeStateMachineData failed: blockIdcontainerID: 1
datanode_2  | localID: 104030867351994368
datanode_2  | blockCommitSequenceId: 0
datanode_2  |  logIndex 1 chunkName 104030867351994368_chunk_1 Error message: ContainerID 1 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_2  | 2020-04-20 12:17:42,491 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b.Reason : ContainerID 1 creation failed
datanode_2  | 2020-04-20 12:17:42,607 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2F5EC9472277, cid=1
datanode_2  | 	 State Machine: cmdType: WriteChunk traceID: "e7e3361cefa2c31a:7318f7b560aa1975:e7e3361cefa2c31a:0" containerID: 1 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "99e9249b-6272-4da5-81f6-59c4e3b5df2b" writeChunk { blockID { containerID: 1 localID: 104030867351994368 blockCommitSequenceId: 0 } chunkData { chunkName: "104030867351994368_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "\246rN\213" } } }, container path=nonexistent
datanode_2  | 2020-04-20 12:18:00,467 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #1 does not exist in datanode. Container close failed.
datanode_2  | 2020-04-20 12:18:17,752 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: recon/172.21.0.5:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=60000 MILLISECONDS)
datanode_2  | 2020-04-20 12:19:13,482 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Completed APPEND_ENTRIES, lastRequest: 258ceeb5-4c9c-49bf-b393-79534db322e4->175c1ce4-a4bc-4858-9a69-a6ac92762c21#5-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-2F5EC9472277, cid=2
datanode_2  | 2020-04-20 12:19:13,558 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: new RaftServerImpl for group-AFBDFEF81D7E:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-04-20 12:19:13,559 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-04-20 12:19:13,559 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-04-20 12:19:13,559 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-04-20 12:19:13,560 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-04-20 12:19:13,560 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-04-20 12:19:13,561 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-04-20 12:19:13,562 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-20 12:19:13,563 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-04-20 12:19:13,563 [grpc-default-executor-0] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: addNew group-AFBDFEF81D7E:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-AFBDFEF81D7E:java.util.concurrent.CompletableFuture@26b6a41a[Not completed]
datanode_2  | 2020-04-20 12:19:13,563 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d762918c-eef0-4ec1-86d1-afbdfef81d7e does not exist. Creating ...
datanode_2  | 2020-04-20 12:19:13,564 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d762918c-eef0-4ec1-86d1-afbdfef81d7e/in_use.lock acquired by nodename 6@f98376242d82
datanode_2  | 2020-04-20 12:19:13,565 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d762918c-eef0-4ec1-86d1-afbdfef81d7e has been successfully formatted.
datanode_2  | 2020-04-20 12:19:13,566 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-AFBDFEF81D7E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-04-20 12:19:13,566 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-04-20 12:19:13,566 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-04-20 12:19:13,566 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-04-20 12:19:13,566 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-20 12:19:13,566 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-20 12:19:13,567 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1     | 2020-04-20 12:17:25,463 [MissingContainerTask] INFO fsck.MissingContainerTask: Missing Container task Thread took 1091 milliseconds for processing 0 containers.
recon_1     | 2020-04-20 12:17:25,891 [IPC Server handler 7 on 9891] INFO net.NetworkTopology: Added a new node: /default-rack/bb3db77a-6a57-4c4e-bdc7-ea39008446e6
recon_1     | 2020-04-20 12:17:25,893 [IPC Server handler 7 on 9891] INFO node.SCMNodeManager: Registered Data node : bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:17:25,915 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node bb3db77a-6a57-4c4e-bdc7-ea39008446e6 to Node DB.
recon_1     | 2020-04-20 12:17:27,523 [IPC Server handler 5 on 9891] INFO net.NetworkTopology: Added a new node: /default-rack/258ceeb5-4c9c-49bf-b393-79534db322e4
recon_1     | 2020-04-20 12:17:27,524 [IPC Server handler 5 on 9891] INFO node.SCMNodeManager: Registered Data node : 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:17:27,525 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 258ceeb5-4c9c-49bf-b393-79534db322e4 to Node DB.
recon_1     | 2020-04-20 12:17:29,029 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=58833d14-bfe3-48b3-983c-a48ab5d471da. Trying to get from SCM.
recon_1     | 2020-04-20 12:17:29,037 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 58833d14-bfe3-48b3-983c-a48ab5d471da, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:17:25.615Z] to Recon pipeline metadata.
recon_1     | 2020-04-20 12:17:29,069 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 58833d14-bfe3-48b3-983c-a48ab5d471da, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:17:25.615Z]
recon_1     | 2020-04-20 12:17:29,073 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline ONE PipelineID=58833d14-bfe3-48b3-983c-a48ab5d471da reported by 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:17:29,075 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 58833d14-bfe3-48b3-983c-a48ab5d471da, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.615Z] moved to OPEN state
recon_1     | 2020-04-20 12:17:29,211 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b. Trying to get from SCM.
recon_1     | 2020-04-20 12:17:29,220 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:17:25.891Z] to Recon pipeline metadata.
recon_1     | 2020-04-20 12:17:29,220 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:17:25.891Z]
recon_1     | 2020-04-20 12:17:29,221 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b reported by 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:17:29,760 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=e57c404d-293c-4d1e-85dd-32d803f54e3f. Trying to get from SCM.
recon_1     | 2020-04-20 12:17:29,857 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: e57c404d-293c-4d1e-85dd-32d803f54e3f, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:17:25.879Z] to Recon pipeline metadata.
recon_1     | 2020-04-20 12:17:29,858 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e57c404d-293c-4d1e-85dd-32d803f54e3f, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:17:25.879Z]
recon_1     | 2020-04-20 12:17:29,950 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b reported by bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:17:34,313 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b reported by 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_3  | 2020-04-20 12:17:29,213 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-04-20 12:17:29,213 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-04-20 12:17:29,217 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-20 12:17:29,217 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-04-20 12:17:29,219 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-04-20 12:17:29,221 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-04-20 12:17:29,221 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-04-20 12:17:29,221 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-04-20 12:17:29,224 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-04-20 12:17:29,225 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-04-20 12:17:29,229 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-04-20 12:17:29,229 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-04-20 12:17:29,230 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-04-20 12:17:29,230 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-04-20 12:17:29,231 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-04-20 12:17:29,231 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B
datanode_3  | 2020-04-20 12:17:29,237 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B
datanode_3  | 2020-04-20 12:17:29,244 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 2020-04-20 12:17:29,247 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-04-20 12:17:29,247 [pool-69-thread-1] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start FollowerState
datanode_3  | 2020-04-20 12:17:29,248 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-59C4E3B5DF2B,id=258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:17:29,248 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B
datanode_3  | 2020-04-20 12:17:31,040 [grpc-default-executor-0] WARN impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed groupAdd* GroupManagementRequest:client-587A665F29B4->258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B, cid=0, seq=0, RW, null, Add:group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3  | 	... 13 more
datanode_3  | 2020-04-20 12:17:31,050 [grpc-default-executor-1] WARN impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed groupAdd* GroupManagementRequest:client-CF13BE0E4754->258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B, cid=0, seq=0, RW, null, Add:group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=1045454848 B) is less than the container size (=1073741824 B).
datanode_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_1  | 	... 13 more
datanode_1  | 2020-04-20 12:17:42,416 [ChunkWriter-20-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: e7e3361cefa2c31a:7318f7b560aa1975:e7e3361cefa2c31a:0 , Message: ContainerID 1 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 1 creation failed
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:17:42,434 [ChunkWriter-20-0] ERROR ratis.ContainerStateMachine: group-59C4E3B5DF2B: writeChunk writeStateMachineData failed: blockIdcontainerID: 1
datanode_1  | localID: 104030867351994368
datanode_1  | blockCommitSequenceId: 0
datanode_1  |  logIndex 1 chunkName 104030867351994368_chunk_1 Error message: ContainerID 1 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_1  | 2020-04-20 12:17:42,458 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b.Reason : ContainerID 1 creation failed
datanode_1  | 2020-04-20 12:17:42,589 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2F5EC9472277, cid=1
datanode_1  | 	 State Machine: cmdType: WriteChunk traceID: "e7e3361cefa2c31a:7318f7b560aa1975:e7e3361cefa2c31a:0" containerID: 1 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "99e9249b-6272-4da5-81f6-59c4e3b5df2b" writeChunk { blockID { containerID: 1 localID: 104030867351994368 blockCommitSequenceId: 0 } chunkData { chunkName: "104030867351994368_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "\246rN\213" } } }, container path=nonexistent
datanode_1  | 2020-04-20 12:18:00,932 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #1 does not exist in datanode. Container close failed.
datanode_1  | 2020-04-20 12:19:13,477 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Completed APPEND_ENTRIES, lastRequest: 258ceeb5-4c9c-49bf-b393-79534db322e4->bb3db77a-6a57-4c4e-bdc7-ea39008446e6#5-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-2F5EC9472277, cid=2
datanode_1  | 2020-04-20 12:19:13,591 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove  FOLLOWER bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B:t1, leader=258ceeb5-4c9c-49bf-b393-79534db322e4, voted=258ceeb5-4c9c-49bf-b393-79534db322e4, raftlog=bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
datanode_1  | 2020-04-20 12:19:13,600 [Command processor thread] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B: shutdown
datanode_1  | 2020-04-20 12:19:13,600 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-59C4E3B5DF2B,id=bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:19:13,600 [Command processor thread] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown FollowerState
datanode_1  | 2020-04-20 12:19:13,601 [Thread-30] INFO impl.FollowerState: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1  | 2020-04-20 12:19:13,601 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-59C4E3B5DF2B as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | 2020-04-20 12:19:13,601 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-StateMachineUpdater] ERROR impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-StateMachineUpdater: Failed to take snapshot
datanode_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-59C4E3B5DF2B as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:19:13,602 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-59C4E3B5DF2B as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | 2020-04-20 12:19:13,602 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-StateMachineUpdater] ERROR impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-StateMachineUpdater: Failed to take snapshot
datanode_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-59C4E3B5DF2B as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:17:34,524 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b reported by 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:17:35,037 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b reported by bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:17:42,364 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : ContainerID 1 creation failed
recon_1     | 2020-04-20 12:17:42,365 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891Z]
recon_1     | 2020-04-20 12:17:42,366 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891Z] moved to CLOSED state
recon_1     | 2020-04-20 12:17:42,452 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : ContainerID 1 creation failed
recon_1     | 2020-04-20 12:17:42,452 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891Z]
recon_1     | 2020-04-20 12:17:42,478 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2F5EC9472277, cid=1
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "e7e3361cefa2c31a:7318f7b560aa1975:e7e3361cefa2c31a:0" containerID: 1 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "99e9249b-6272-4da5-81f6-59c4e3b5df2b" writeChunk { blockID { containerID: 1 localID: 104030867351994368 blockCommitSequenceId: 0 } chunkData { chunkName: "104030867351994368_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "\246rN\213" } } }, container path=nonexistent
recon_1     | 2020-04-20 12:17:42,478 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891Z]
recon_1     | 2020-04-20 12:17:42,592 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2F5EC9472277, cid=1
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "e7e3361cefa2c31a:7318f7b560aa1975:e7e3361cefa2c31a:0" containerID: 1 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "99e9249b-6272-4da5-81f6-59c4e3b5df2b" writeChunk { blockID { containerID: 1 localID: 104030867351994368 blockCommitSequenceId: 0 } chunkData { chunkName: "104030867351994368_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "\246rN\213" } } }, container path=nonexistent
recon_1     | 2020-04-20 12:17:42,592 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891Z]
recon_1     | 2020-04-20 12:18:22,677 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-20 12:18:22,678 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1     | 2020-04-20 12:18:22,822 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1587385102678
recon_1     | 2020-04-20 12:18:22,850 [pool-8-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1587385102678.
recon_1     | 2020-04-20 12:18:22,865 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
recon_1     | 2020-04-20 12:18:22,869 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1     | 2020-04-20 12:18:22,911 [pool-9-thread-1] INFO impl.ContainerDBServiceProviderImpl: Creating new Recon Container DB at /data/metadata/recon/recon-container-key.db_1587385102877
recon_1     | 2020-04-20 12:18:22,912 [pool-9-thread-1] INFO impl.ContainerDBServiceProviderImpl: Cleaning up old Recon Container DB at /data/metadata/recon/recon-container-key.db_1587385025102.
recon_1     | 2020-04-20 12:18:22,927 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
recon_1     | 2020-04-20 12:18:22,928 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.05 seconds to process 0 keys.
datanode_2  | 2020-04-20 12:19:13,567 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/d762918c-eef0-4ec1-86d1-afbdfef81d7e
datanode_2  | 2020-04-20 12:19:13,569 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-04-20 12:19:13,569 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-04-20 12:19:13,569 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-20 12:19:13,569 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-04-20 12:19:13,569 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-04-20 12:19:13,570 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-04-20 12:19:13,570 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-04-20 12:19:13,570 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-04-20 12:19:13,570 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-04-20 12:19:13,571 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-04-20 12:19:13,571 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-04-20 12:19:13,576 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-04-20 12:19:13,577 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-04-20 12:19:13,578 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-04-20 12:19:13,578 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-04-20 12:19:13,578 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E
datanode_2  | 2020-04-20 12:19:13,579 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E
datanode_2  | 2020-04-20 12:19:13,579 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_2  | 2020-04-20 12:19:13,580 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-04-20 12:19:13,580 [pool-69-thread-1] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start FollowerState
datanode_2  | 2020-04-20 12:19:13,580 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AFBDFEF81D7E,id=175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:19:13,581 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E
datanode_2  | 2020-04-20 12:19:13,610 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove  FOLLOWER 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B:t1, leader=258ceeb5-4c9c-49bf-b393-79534db322e4, voted=258ceeb5-4c9c-49bf-b393-79534db322e4, raftlog=175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
datanode_2  | 2020-04-20 12:19:13,615 [Command processor thread] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B: shutdown
datanode_2  | 2020-04-20 12:19:13,616 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-59C4E3B5DF2B,id=175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:19:13,624 [Command processor thread] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown FollowerState
datanode_2  | 2020-04-20 12:19:13,624 [Thread-29] INFO impl.FollowerState: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2  | 2020-04-20 12:19:13,625 [Command processor thread] INFO impl.StateMachineUpdater: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-StateMachineUpdater: set stopIndex = 0
datanode_2  | 2020-04-20 12:19:13,625 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-59C4E3B5DF2B as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 2020-04-20 12:19:13,625 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-StateMachineUpdater] ERROR impl.StateMachineUpdater: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-StateMachineUpdater: Failed to take snapshot
datanode_2  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-59C4E3B5DF2B as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:19:13,635 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-59C4E3B5DF2B as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 2020-04-20 12:19:13,635 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-StateMachineUpdater] ERROR impl.StateMachineUpdater: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-StateMachineUpdater: Failed to take snapshot
datanode_2  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-59C4E3B5DF2B as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:19:13,644 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B
recon_1     | 2020-04-20 12:18:23,100 [pool-9-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
recon_1     | 2020-04-20 12:18:42,612 [IPC Server handler 6 on 9891] INFO net.NetworkTopology: Added a new node: /default-rack/175c1ce4-a4bc-4858-9a69-a6ac92762c21
recon_1     | 2020-04-20 12:18:42,613 [IPC Server handler 6 on 9891] INFO node.SCMNodeManager: Registered Data node : 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:18:42,612 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 175c1ce4-a4bc-4858-9a69-a6ac92762c21 to Node DB.
recon_1     | 2020-04-20 12:18:42,614 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=a860a08d-a8b9-4b50-90bb-40413d362a41. Trying to get from SCM.
recon_1     | 2020-04-20 12:18:42,621 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: a860a08d-a8b9-4b50-90bb-40413d362a41, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:17:25.633Z] to Recon pipeline metadata.
recon_1     | 2020-04-20 12:18:42,621 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: a860a08d-a8b9-4b50-90bb-40413d362a41, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:17:25.633Z]
recon_1     | 2020-04-20 12:18:48,371 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891Z] removed from db
recon_1     | 2020-04-20 12:18:48,453 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891Z]
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:18:48,479 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891Z]
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:18:48,592 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891Z]
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
datanode_2  | 2020-04-20 12:19:13,652 [Command processor thread] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B: closes. applyIndex: 0
datanode_2  | 2020-04-20 12:19:13,653 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_2  | 2020-04-20 12:19:13,655 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B-SegmentedRaftLogWorker close()
datanode_2  | 2020-04-20 12:19:13,656 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:19:13,656 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B
datanode_2  | 2020-04-20 12:19:13,657 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-59C4E3B5DF2B
datanode_2  | 2020-04-20 12:19:13,662 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_2  |  command on datanode #175c1ce4-a4bc-4858-9a69-a6ac92762c21.
datanode_2  | 2020-04-20 12:19:13,663 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-59C4E3B5DF2B:null
datanode_2  | 2020-04-20 12:19:13,664 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_2  | 
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-59C4E3B5DF2B not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-59C4E3B5DF2B not found.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 	... 4 more
datanode_2  | 2020-04-20 12:19:13,665 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-59C4E3B5DF2B:null
datanode_2  | 2020-04-20 12:19:13,667 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_2  | 
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-59C4E3B5DF2B not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-59C4E3B5DF2B not found.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 	... 4 more
datanode_2  | 2020-04-20 12:19:13,668 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-59C4E3B5DF2B:null
datanode_2  | 2020-04-20 12:19:13,668 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_2  | 
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-59C4E3B5DF2B not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-59C4E3B5DF2B not found.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 	... 4 more
datanode_2  | 2020-04-20 12:19:13,668 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-59C4E3B5DF2B:null
datanode_2  | 2020-04-20 12:19:13,669 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_2  | 
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-59C4E3B5DF2B not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-59C4E3B5DF2B not found.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 	... 4 more
datanode_2  | 2020-04-20 12:19:13,671 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-59C4E3B5DF2B:null
datanode_2  | 2020-04-20 12:19:13,672 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_2  | 
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-59C4E3B5DF2B not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-59C4E3B5DF2B not found.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 	... 4 more
datanode_2  | 2020-04-20 12:19:13,717 [grpc-default-executor-0] WARN impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed groupAdd* GroupManagementRequest:client-8EB413F00B8F->175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E, cid=3, seq=0, RW, null, Add:group-AFBDFEF81D7E:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-AFBDFEF81D7E:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-AFBDFEF81D7E:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2  | 	... 13 more
datanode_2  | 2020-04-20 12:19:18,611 [Thread-81] INFO impl.FollowerState: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-FollowerState: change to CANDIDATE, lastRpcTime:5031ms, electionTimeout:5030ms
datanode_2  | 2020-04-20 12:19:18,612 [Thread-81] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown FollowerState
datanode_1  | 2020-04-20 12:19:13,603 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B
datanode_1  | 2020-04-20 12:19:13,601 [Command processor thread] INFO impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-StateMachineUpdater: set stopIndex = 0
datanode_1  | 2020-04-20 12:19:13,603 [Command processor thread] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B: closes. applyIndex: 0
datanode_1  | 2020-04-20 12:19:13,604 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_1  | 2020-04-20 12:19:13,605 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B-SegmentedRaftLogWorker close()
datanode_1  | 2020-04-20 12:19:13,605 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:19:13,606 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B
datanode_1  | 2020-04-20 12:19:13,606 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-59C4E3B5DF2B
datanode_1  | 2020-04-20 12:19:13,608 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_1  |  command on datanode #bb3db77a-6a57-4c4e-bdc7-ea39008446e6.
datanode_1  | 2020-04-20 12:19:13,610 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: new RaftServerImpl for group-AFBDFEF81D7E:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-04-20 12:19:13,610 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-04-20 12:19:13,610 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-04-20 12:19:13,610 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-04-20 12:19:13,610 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-04-20 12:19:13,610 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-04-20 12:19:13,611 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-04-20 12:19:13,611 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-04-20 12:19:13,611 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-04-20 12:19:13,611 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d762918c-eef0-4ec1-86d1-afbdfef81d7e does not exist. Creating ...
datanode_1  | 2020-04-20 12:19:13,613 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d762918c-eef0-4ec1-86d1-afbdfef81d7e/in_use.lock acquired by nodename 6@69674aa52266
datanode_1  | 2020-04-20 12:19:13,614 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: addNew group-AFBDFEF81D7E:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-AFBDFEF81D7E:java.util.concurrent.CompletableFuture@395512b8[Not completed]
datanode_1  | 2020-04-20 12:19:13,615 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d762918c-eef0-4ec1-86d1-afbdfef81d7e has been successfully formatted.
datanode_1  | 2020-04-20 12:19:13,615 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-AFBDFEF81D7E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-04-20 12:19:13,615 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-04-20 12:19:13,615 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-04-20 12:19:13,615 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-04-20 12:19:13,616 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-20 12:19:13,616 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-20 12:19:13,616 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:19:13,616 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-04-20 12:19:13,616 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/d762918c-eef0-4ec1-86d1-afbdfef81d7e
datanode_1  | 2020-04-20 12:19:13,616 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-04-20 12:19:13,616 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-04-20 12:19:13,617 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-20 12:19:13,617 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-04-20 12:19:13,617 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-04-20 12:19:13,617 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-04-20 12:19:13,617 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-04-20 12:19:13,617 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-04-20 12:19:13,617 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-04-20 12:19:13,618 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-04-20 12:19:13,632 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-04-20 12:19:13,638 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-04-20 12:19:13,644 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-04-20 12:19:13,644 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-59C4E3B5DF2B:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3  | 	... 13 more
datanode_3  | 2020-04-20 12:17:31,640 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_3  | .
datanode_3  | 2020-04-20 12:17:34,268 [Thread-27] INFO impl.FollowerState: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-FollowerState: change to CANDIDATE, lastRpcTime:5128ms, electionTimeout:5119ms
datanode_3  | 2020-04-20 12:17:34,270 [Thread-27] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown FollowerState
datanode_3  | 2020-04-20 12:17:34,272 [Thread-27] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2020-04-20 12:17:34,278 [Thread-27] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start LeaderElection
datanode_3  | 2020-04-20 12:17:34,293 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO impl.LeaderElection: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1: begin an election at term 1 for -1: [258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 2020-04-20 12:17:34,294 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown LeaderElection
datanode_3  | 2020-04-20 12:17:34,295 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-04-20 12:17:34,295 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A48AB5D471DA with new leaderId: 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:17:34,296 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA: change Leader from null to 258ceeb5-4c9c-49bf-b393-79534db322e4 at term 1 for becomeLeader, leader elected after 5616ms
datanode_3  | 2020-04-20 12:17:34,299 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-04-20 12:17:34,302 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-04-20 12:17:34,308 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA
datanode_3  | 2020-04-20 12:17:34,320 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-04-20 12:17:34,321 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-04-20 12:17:34,317 [Thread-29] INFO impl.FollowerState: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-FollowerState: change to CANDIDATE, lastRpcTime:5069ms, electionTimeout:5059ms
datanode_3  | 2020-04-20 12:17:34,327 [Thread-29] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown FollowerState
datanode_3  | 2020-04-20 12:17:34,327 [Thread-29] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2020-04-20 12:17:34,327 [Thread-29] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start LeaderElection
datanode_3  | 2020-04-20 12:17:34,335 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-04-20 12:17:34,335 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-04-20 12:17:34,336 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-04-20 12:17:34,343 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO impl.LeaderElection: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2: begin an election at term 1 for -1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 2020-04-20 12:17:34,378 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start LeaderState
datanode_3  | 2020-04-20 12:17:34,453 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-04-20 12:17:34,493 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-LeaderElection1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA: set configuration 0: [258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_3  | 2020-04-20 12:17:34,512 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO impl.LeaderElection: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2: Election PASSED; received 1 response(s) [258ceeb5-4c9c-49bf-b393-79534db322e4<-bb3db77a-6a57-4c4e-bdc7-ea39008446e6#0:OK-t1] and 0 exception(s); 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B:t1, leader=null, voted=258ceeb5-4c9c-49bf-b393-79534db322e4, raftlog=258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 2020-04-20 12:17:34,513 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown LeaderElection
datanode_3  | 2020-04-20 12:17:34,513 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-04-20 12:17:34,513 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-59C4E3B5DF2B with new leaderId: 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:17:34,514 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B: change Leader from null to 258ceeb5-4c9c-49bf-b393-79534db322e4 at term 1 for becomeLeader, leader elected after 5305ms
datanode_3  | 2020-04-20 12:17:34,514 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-04-20 12:17:34,514 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-04-20 12:17:34,514 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B
datanode_3  | 2020-04-20 12:17:34,515 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-04-20 12:17:34,515 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-04-20 12:17:34,516 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-04-20 12:17:34,516 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-04-20 12:17:34,516 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-04-20 12:17:34,528 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2020-04-20 12:17:34,528 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-20 12:17:34,529 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 2020-04-20 12:17:34,538 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2020-04-20 12:17:34,547 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-04-20 12:17:34,547 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-20 12:17:34,551 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2020-04-20 12:17:34,559 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-20 12:17:34,560 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 2020-04-20 12:17:34,561 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2020-04-20 12:17:34,561 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-04-20 12:17:34,562 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-20 12:17:34,564 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start LeaderState
datanode_3  | 2020-04-20 12:17:34,569 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-04-20 12:17:34,588 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-LeaderElection2] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_3  | 2020-04-20 12:17:34,885 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/99e9249b-6272-4da5-81f6-59c4e3b5df2b/current/log_inprogress_0
datanode_3  | 2020-04-20 12:17:34,904 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-A48AB5D471DA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/58833d14-bfe3-48b3-983c-a48ab5d471da/current/log_inprogress_0
datanode_3  | 2020-04-20 12:17:42,267 [ChunkWriter-0-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: e7e3361cefa2c31a:7318f7b560aa1975:e7e3361cefa2c31a:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=1045467136 B) is less than the container size (=1073741824 B).
datanode_3  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_3  | 	... 13 more
datanode_3  | 2020-04-20 12:17:42,310 [ChunkWriter-0-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: e7e3361cefa2c31a:7318f7b560aa1975:e7e3361cefa2c31a:0 , Message: ContainerID 1 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 1 creation failed
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:17:42,328 [ChunkWriter-0-0] ERROR ratis.ContainerStateMachine: group-59C4E3B5DF2B: writeChunk writeStateMachineData failed: blockIdcontainerID: 1
datanode_3  | localID: 104030867351994368
datanode_3  | blockCommitSequenceId: 0
datanode_3  |  logIndex 1 chunkName 104030867351994368_chunk_1 Error message: ContainerID 1 creation failed Container Result: DISK_OUT_OF_SPACE
scm_1       | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-04-20 12:17:10,812 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = 003f04fa6a61/172.21.0.6
scm_1       | STARTUP_MSG:   args = [--init]
scm_1       | STARTUP_MSG:   version = 3.2.0
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-04-20 12:17:10,900 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-04-20 12:17:11,430 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-20 12:17:11,734 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-d50825b9-c1ac-4532-9c54-8d2cfff4dc07
scm_1       | 2020-04-20 12:17:11,877 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at 003f04fa6a61/172.21.0.6
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-04-20 12:17:20,769 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = 003f04fa6a61/172.21.0.6
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 3.2.0
datanode_1  | 2020-04-20 12:19:13,644 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-04-20 12:19:13,644 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E
datanode_1  | 2020-04-20 12:19:13,644 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E
datanode_1  | 2020-04-20 12:19:13,645 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_1  | 2020-04-20 12:19:13,645 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-04-20 12:19:13,645 [pool-69-thread-1] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start FollowerState
datanode_1  | 2020-04-20 12:19:13,649 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AFBDFEF81D7E,id=bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:19:13,649 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E
datanode_1  | 2020-04-20 12:19:13,669 [grpc-default-executor-0] WARN impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed groupAdd* GroupManagementRequest:client-91B211E69FC8->bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E, cid=3, seq=0, RW, null, Add:group-AFBDFEF81D7E:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-AFBDFEF81D7E:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-AFBDFEF81D7E:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 	... 13 more
datanode_1  | 2020-04-20 12:19:13,736 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_1  | .
datanode_1  | 2020-04-20 12:19:13,736 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-59C4E3B5DF2B:null
datanode_1  | 2020-04-20 12:19:13,737 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_1  | 
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-59C4E3B5DF2B not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-59C4E3B5DF2B not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_1  | 2020-04-20 12:19:13,737 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-59C4E3B5DF2B:null
datanode_1  | 2020-04-20 12:19:13,737 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_1  | 
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-59C4E3B5DF2B not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-04-20 12:17:20,783 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-04-20 12:17:20,978 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-20 12:17:20,993 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-20 12:17:21,422 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@3336e6b6
scm_1       | 2020-04-20 12:17:21,424 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1       | 2020-04-20 12:17:21,620 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1       | 2020-04-20 12:17:21,914 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       | 2020-04-20 12:17:21,919 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-20 12:17:21,947 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1       | 2020-04-20 12:17:21,949 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-20 12:17:22,044 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2020-04-20 12:17:22,046 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1       | 2020-04-20 12:17:22,100 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1       | 2020-04-20 12:17:22,790 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-04-20 12:17:22,807 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2020-04-20 12:17:22,837 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-04-20 12:17:22,838 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1       | 2020-04-20 12:17:22,846 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-04-20 12:17:22,847 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1       | 2020-04-20 12:17:22,868 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1       | 2020-04-20 12:17:22,883 [main] INFO util.log: Logging initialized @10017ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       | 2020-04-20 12:17:23,020 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2020-04-20 12:17:23,035 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1       | 2020-04-20 12:17:23,048 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       | 2020-04-20 12:17:23,051 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1       | 2020-04-20 12:17:23,051 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
scm_1       | 2020-04-20 12:17:23,051 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1       | 2020-04-20 12:17:23,085 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1       | 2020-04-20 12:17:23,173 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | 2020-04-20 12:17:23,217 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1       | 2020-04-20 12:17:23,217 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1       | 2020-04-20 12:17:23,391 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1       | 2020-04-20 12:17:23,392 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-04-20 12:17:23,397 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1       | 2020-04-20 12:17:23,489 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1       | 2020-04-20 12:17:23,490 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1       | 2020-04-20 12:17:23,491 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-04-20 12:17:23,492 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1       | 2020-04-20 12:17:23,556 [main] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1       | 2020-04-20 12:17:23,556 [main] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1       | 2020-04-20 12:17:23,558 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-04-20 12:17:23,559 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1       | 2020-04-20 12:17:23,668 [main] INFO http.HttpServer2: Jetty bound to port 9876
om_1        | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-04-20 12:17:07,645 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = c049d2d9a44c/172.21.0.4
om_1        | STARTUP_MSG:   args = [--init]
om_1        | STARTUP_MSG:   version = 3.2.0
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-04-20 12:17:07,679 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-04-20 12:17:11,761 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-04-20 12:17:11,971 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.21.0.4:9862
om_1        | 2020-04-20 12:17:11,971 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-04-20 12:17:12,016 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-20 12:17:14,359 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-20 12:17:15,360 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-20 12:17:16,361 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-20 12:17:17,362 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-20 12:17:18,363 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-20 12:17:19,364 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-20 12:17:20,391 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-20 12:17:21,396 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-20 12:17:22,397 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-20 12:17:23,398 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.6:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-d50825b9-c1ac-4532-9c54-8d2cfff4dc07
om_1        | 2020-04-20 12:17:23,789 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1        | /************************************************************
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at c049d2d9a44c/172.21.0.4
om_1        | ************************************************************/
om_1        | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-04-20 12:17:25,692 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = c049d2d9a44c/172.21.0.4
om_1        | STARTUP_MSG:   args = []
om_1        | STARTUP_MSG:   version = 3.2.0
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-04-20 12:17:25,698 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-04-20 12:17:26,515 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-04-20 12:17:26,571 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.21.0.4:9862
om_1        | 2020-04-20 12:17:26,572 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-04-20 12:17:26,580 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-20 12:17:26,730 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-20 12:17:27,907 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-20 12:17:28,362 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2020-04-20 12:17:28,392 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1        | 2020-04-20 12:17:28,810 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | 2020-04-20 12:17:29,167 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2020-04-20 12:17:29,167 [main] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1        | 2020-04-20 12:17:29,438 [main] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.21.0.4:9862
datanode_3  | 2020-04-20 12:17:42,351 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b.Reason : ContainerID 1 creation failed
datanode_3  | 2020-04-20 12:17:42,469 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2F5EC9472277, cid=1
datanode_3  | 	 State Machine: cmdType: WriteChunk traceID: "e7e3361cefa2c31a:7318f7b560aa1975:e7e3361cefa2c31a:0" containerID: 1 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "99e9249b-6272-4da5-81f6-59c4e3b5df2b" writeChunk { blockID { containerID: 1 localID: 104030867351994368 blockCommitSequenceId: 0 } chunkData { chunkName: "104030867351994368_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "\246rN\213" } } }, container path=nonexistent
datanode_3  | 2020-04-20 12:18:00,208 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #1 does not exist in datanode. Container close failed.
datanode_3  | 2020-04-20 12:18:42,174 [java.util.concurrent.ThreadPoolExecutor$Worker@4c1e53a9[State = -1, empty queue]] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B->175c1ce4-a4bc-4858-9a69-a6ac92762c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4,entriesCount=1,lastEntry=(t:1, i:1)
datanode_3  | 2020-04-20 12:18:42,256 [java.util.concurrent.ThreadPoolExecutor$Worker@4c1e53a9[State = -1, empty queue]] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4,entriesCount=1,lastEntry=(t:1, i:1)
datanode_3  | 2020-04-20 12:18:42,257 [java.util.concurrent.ThreadPoolExecutor$Worker@4c1e53a9[State = -1, empty queue]] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B->175c1ce4-a4bc-4858-9a69-a6ac92762c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5,entriesCount=1,lastEntry=(t:1, i:2)
datanode_3  | 2020-04-20 12:18:42,269 [java.util.concurrent.ThreadPoolExecutor$Worker@4c1e53a9[State = -1, empty queue]] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5,entriesCount=1,lastEntry=(t:1, i:2)
datanode_3  | 2020-04-20 12:19:13,471 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove    LEADER 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B:t1, leader=258ceeb5-4c9c-49bf-b393-79534db322e4, voted=258ceeb5-4c9c-49bf-b393-79534db322e4, raftlog=258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
datanode_3  | 2020-04-20 12:19:13,473 [Command processor thread] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B: shutdown
datanode_3  | 2020-04-20 12:19:13,473 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-59C4E3B5DF2B,id=258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:19:13,473 [Command processor thread] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown LeaderState
datanode_3  | 2020-04-20 12:19:13,474 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$443/0x0000000840592040@3fbd7ee1] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-59C4E3B5DF2B not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_1  | 2020-04-20 12:19:13,738 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-59C4E3B5DF2B:null
datanode_1  | 2020-04-20 12:19:13,738 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_1  | 
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-59C4E3B5DF2B not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-59C4E3B5DF2B not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_1  | 2020-04-20 12:19:13,738 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-59C4E3B5DF2B:null
datanode_1  | 2020-04-20 12:19:13,738 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_1  | 
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-59C4E3B5DF2B not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-59C4E3B5DF2B not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_1  | 2020-04-20 12:19:13,739 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-59C4E3B5DF2B:null
datanode_1  | 2020-04-20 12:19:13,739 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_1  | 
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-59C4E3B5DF2B not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-59C4E3B5DF2B not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_1  | 2020-04-20 12:19:13,739 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-59C4E3B5DF2B:null
datanode_1  | 2020-04-20 12:19:13,739 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_1  | 
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-59C4E3B5DF2B not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-59C4E3B5DF2B not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_1  | 2020-04-20 12:19:18,648 [grpc-default-executor-2] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | 2020-04-20 12:19:18,649 [grpc-default-executor-2] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown FollowerState
datanode_1  | 2020-04-20 12:19:18,649 [grpc-default-executor-2] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start FollowerState
datanode_1  | 2020-04-20 12:19:18,649 [Thread-84] INFO impl.FollowerState: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1  | 2020-04-20 12:19:18,694 [grpc-default-executor-2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-AFBDFEF81D7E with new leaderId: 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | 2020-04-20 12:19:18,695 [grpc-default-executor-2] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E: change Leader from null to 258ceeb5-4c9c-49bf-b393-79534db322e4 at term 1 for appendEntries, leader elected after 5079ms
datanode_1  | 2020-04-20 12:19:18,699 [grpc-default-executor-2] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_1  | 2020-04-20 12:19:18,699 [grpc-default-executor-2] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-04-20 12:19:18,701 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d762918c-eef0-4ec1-86d1-afbdfef81d7e/current/log_inprogress_0
datanode_1  | 2020-04-20 12:19:35,004 [ChunkWriter-50-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: 4342c3eb64c113e5:36736dca5ee5156:4342c3eb64c113e5:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
om_1        | 2020-04-20 12:17:29,527 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1        | 2020-04-20 12:17:29,524 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1        | 2020-04-20 12:17:29,989 [main] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1        | 2020-04-20 12:17:30,274 [main] INFO util.log: Logging initialized @6199ms to org.eclipse.jetty.util.log.Slf4jLog
om_1        | 2020-04-20 12:17:30,663 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1        | 2020-04-20 12:17:30,674 [main] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1        | 2020-04-20 12:17:30,701 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1        | 2020-04-20 12:17:30,715 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1        | 2020-04-20 12:17:30,716 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
om_1        | 2020-04-20 12:17:30,716 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
om_1        | 2020-04-20 12:17:30,903 [main] INFO http.HttpServer2: Jetty bound to port 9874
om_1        | 2020-04-20 12:17:30,905 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1        | 2020-04-20 12:17:30,991 [main] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 2020-04-20 12:17:30,991 [main] INFO server.session: No SessionScavenger set, using defaults
om_1        | 2020-04-20 12:17:30,996 [main] INFO server.session: node0 Scavenging every 660000ms
om_1        | 2020-04-20 12:17:31,022 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@d5556bf{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 2020-04-20 12:17:31,026 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@18f55704{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | 2020-04-20 12:17:31,502 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3e0fbeb5{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-16775081048961500945.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1        | 2020-04-20 12:17:31,544 [main] INFO server.AbstractConnector: Started ServerConnector@6468a7b6{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1        | 2020-04-20 12:17:31,545 [main] INFO server.Server: Started @7470ms
om_1        | 2020-04-20 12:17:31,546 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2020-04-20 12:17:31,547 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 2020-04-20 12:17:31,551 [main] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1        | 2020-04-20 12:17:40,638 [IPC Server handler 1 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-57086 for user:hadoop
om_1        | 2020-04-20 12:17:40,671 [IPC Server handler 3 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-31314 for user:hadoop
om_1        | 2020-04-20 12:17:40,681 [IPC Server handler 35 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-25315 for user:hadoop
om_1        | 2020-04-20 12:17:40,688 [IPC Server handler 37 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-43351 for user:hadoop
om_1        | 2020-04-20 12:17:40,695 [IPC Server handler 49 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-15276 for user:hadoop
om_1        | 2020-04-20 12:18:22,745 [qtp2045143855-136] INFO om.OMDBCheckpointServlet: Received request to obtain OM DB checkpoint snapshot
om_1        | 2020-04-20 12:18:22,766 [qtp2045143855-136] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1587385102746 in 19 milliseconds
om_1        | 2020-04-20 12:18:22,783 [qtp2045143855-136] INFO om.OMDBCheckpointServlet: Time taken to write the checkpoint to response output stream: 15 milliseconds
om_1        | 2020-04-20 12:18:22,785 [qtp2045143855-136] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1587385102746
om_1        | 2020-04-20 12:19:19,309 [IPC Server handler 2 on 9862] INFO volume.OMVolumeCreateRequest: created volume:03092-rpcwoport for user:hadoop
om_1        | 2020-04-20 12:21:09,042 [IPC Server handler 5 on 9862] INFO volume.OMVolumeCreateRequest: created volume:03092-rpcwoport2 for user:hadoop
om_1        | 2020-04-20 12:21:26,100 [IPC Server handler 7 on 9862] ERROR acl.OMBucketAddAclRequest: Add acl [user:superuser1:rwxy[ACCESS]] to path /03092-rpcwoport2/bb1 failed, because acl already exist
om_1        | 2020-04-20 12:23:13,425 [IPC Server handler 10 on 9862] INFO volume.OMVolumeCreateRequest: created volume:03092-rpcwport for user:hadoop
om_1        | 2020-04-20 12:25:04,669 [IPC Server handler 11 on 9862] INFO volume.OMVolumeCreateRequest: created volume:03092-rpcwoscheme for user:hadoop
s3g_1       | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
s3g_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1       | 2020-04-20 12:17:07,602 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1       | 2020-04-20 12:17:07,726 [main] INFO util.log: Logging initialized @6996ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1       | 2020-04-20 12:17:08,316 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 2020-04-20 12:17:08,514 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1       | 2020-04-20 12:17:08,580 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1       | 2020-04-20 12:17:08,590 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g_1       | 2020-04-20 12:17:08,609 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1       | 2020-04-20 12:17:08,609 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1       | 2020-04-20 12:17:08,795 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1       | 2020-04-20 12:17:08,834 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1       | 2020-04-20 12:17:08,858 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
s3g_1       | 2020-04-20 12:17:09,071 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1       | 2020-04-20 12:17:09,072 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1       | 2020-04-20 12:17:09,094 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1       | 2020-04-20 12:17:09,161 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3af0a9da{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 2020-04-20 12:17:09,162 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@54eb2b70{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
s3g_1       | WARNING: An illegal reflective access operation has occurred
s3g_1       | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1       | WARNING: All illegal access operations will be denied in a future release
s3g_1       | Apr 20, 2020 12:17:21 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1       | 
s3g_1       | 2020-04-20 12:17:21,672 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1142d377{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-0_6_0-SNAPSHOT_jar-_-any-2365124934363160747.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1       | 2020-04-20 12:17:21,700 [main] INFO server.AbstractConnector: Started ServerConnector@1869fbd2{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
s3g_1       | 2020-04-20 12:17:21,701 [main] INFO server.Server: Started @20971ms
s3g_1       | 2020-04-20 12:17:21,712 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:19:12,478 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b. Trying to get from SCM.
recon_1     | 2020-04-20 12:19:12,496 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
recon_1     |   id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
recon_1     | }
recon_1     | isLeader: true
recon_1     | bytesWritten: 0
recon_1     |  from dn=258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null} {}
recon_1     | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException): PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
recon_1     | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
recon_1     | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1     | 
recon_1     | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
recon_1     | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:123)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:114)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.getPipeline(StorageContainerLocationProtocolClientSideTranslatorPB.java:347)
recon_1     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
recon_1     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
recon_1     | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
recon_1     | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
recon_1     | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:71)
recon_1     | 	at com.sun.proxy.$Proxy42.getPipeline(Unknown Source)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getPipeline(StorageContainerServiceProviderImpl.java:55)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineReportHandler.processPipelineReport(ReconPipelineReportHandler.java:65)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:84)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:47)
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:19:12,601 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b. Trying to get from SCM.
recon_1     | 2020-04-20 12:19:12,604 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
recon_1     |   id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
recon_1     | }
recon_1     | isLeader: false
recon_1     | bytesWritten: 0
recon_1     |  from dn=bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null} {}
recon_1     | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException): PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
recon_1     | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
recon_1     | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
datanode_2  | 2020-04-20 12:19:18,612 [Thread-81] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-04-20 12:19:18,612 [Thread-81] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start LeaderElection
datanode_2  | 2020-04-20 12:19:18,620 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-LeaderElection2] INFO impl.LeaderElection: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-LeaderElection2: begin an election at term 1 for -1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_2  | 2020-04-20 12:19:18,694 [grpc-default-executor-0] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E: changes role from CANDIDATE to FOLLOWER at term 1 for appendEntries
datanode_2  | 2020-04-20 12:19:18,702 [grpc-default-executor-0] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown LeaderElection
datanode_2  | 2020-04-20 12:19:18,702 [grpc-default-executor-0] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start FollowerState
datanode_2  | 2020-04-20 12:19:18,702 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-AFBDFEF81D7E with new leaderId: 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_2  | 2020-04-20 12:19:18,703 [grpc-default-executor-0] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E: change Leader from null to 258ceeb5-4c9c-49bf-b393-79534db322e4 at term 1 for appendEntries, leader elected after 5136ms
datanode_2  | 2020-04-20 12:19:18,719 [grpc-default-executor-0] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_2  | 2020-04-20 12:19:18,720 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-SegmentedRaftLogWorker: Starting segment from index:0
scm_1       | 2020-04-20 12:17:23,669 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1       | 2020-04-20 12:17:23,789 [main] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1       | 2020-04-20 12:17:23,790 [main] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2020-04-20 12:17:23,805 [main] INFO server.session: node0 Scavenging every 660000ms
scm_1       | 2020-04-20 12:17:23,893 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@486bc9a4{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1       | 2020-04-20 12:17:23,903 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1237e0be{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | 2020-04-20 12:17:24,769 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4d21c56e{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-12004731159777870255.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
scm_1       | 2020-04-20 12:17:24,791 [main] INFO server.AbstractConnector: Started ServerConnector@4992613f{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1       | 2020-04-20 12:17:24,805 [main] INFO server.Server: Started @11939ms
scm_1       | 2020-04-20 12:17:24,829 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | 2020-04-20 12:17:24,829 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1       | 2020-04-20 12:17:24,834 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1       | 2020-04-20 12:17:24,857 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@43af351a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2020-04-20 12:17:25,553 [IPC Server handler 1 on 9861] INFO net.NetworkTopology: Added a new node: /default-rack/258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:17:25,556 [IPC Server handler 1 on 9861] INFO node.SCMNodeManager: Registered Data node : 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-04-20 12:17:25,576 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1       | 2020-04-20 12:17:25,581 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-04-20 12:17:25,590 [IPC Server handler 30 on 9861] INFO net.NetworkTopology: Added a new node: /default-rack/175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:17:25,609 [IPC Server handler 30 on 9861] INFO node.SCMNodeManager: Registered Data node : 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-04-20 12:17:25,609 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1       | 2020-04-20 12:17:25,613 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-04-20 12:17:25,617 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=58833d14-bfe3-48b3-983c-a48ab5d471da to datanode:258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:17:25,626 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 58833d14-bfe3-48b3-983c-a48ab5d471da, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:17:25.615876Z]
scm_1       | 2020-04-20 12:17:25,633 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a860a08d-a8b9-4b50-90bb-40413d362a41 to datanode:175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:17:25,633 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: a860a08d-a8b9-4b50-90bb-40413d362a41, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:17:25.633424Z]
scm_1       | 2020-04-20 12:17:25,634 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
scm_1       | 2020-04-20 12:17:25,877 [IPC Server handler 3 on 9861] INFO net.NetworkTopology: Added a new node: /default-rack/bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:17:25,877 [IPC Server handler 3 on 9861] INFO node.SCMNodeManager: Registered Data node : bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-04-20 12:17:25,878 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1       | 2020-04-20 12:17:25,879 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-04-20 12:17:25,879 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e57c404d-293c-4d1e-85dd-32d803f54e3f to datanode:bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:17:25,880 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e57c404d-293c-4d1e-85dd-32d803f54e3f, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:17:25.879513Z]
scm_1       | 2020-04-20 12:17:25,881 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2020-04-20 12:17:25,881 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1       | 2020-04-20 12:17:25,882 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-20 12:17:25,891 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b to datanode:258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:17:25,892 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b to datanode:175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:17:25,892 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b to datanode:bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:17:25,892 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:17:25.891905Z]
scm_1       | 2020-04-20 12:17:25,893 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-20 12:17:29,113 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 58833d14-bfe3-48b3-983c-a48ab5d471da, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.615876Z] moved to OPEN state
scm_1       | 2020-04-20 12:17:29,120 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-04-20 12:17:29,149 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-04-20 12:17:29,435 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: a860a08d-a8b9-4b50-90bb-40413d362a41, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:17:25.633424Z] moved to OPEN state
scm_1       | 2020-04-20 12:17:29,435 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-04-20 12:17:29,437 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-04-20 12:17:29,757 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: e57c404d-293c-4d1e-85dd-32d803f54e3f, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:17:25.879513Z] moved to OPEN state
scm_1       | 2020-04-20 12:17:29,758 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-04-20 12:17:29,758 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-04-20 12:17:34,526 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891905Z] moved to OPEN state
scm_1       | 2020-04-20 12:17:34,526 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1       | 2020-04-20 12:17:34,526 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1       | 2020-04-20 12:17:34,526 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1       | 2020-04-20 12:17:34,526 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1       | 2020-04-20 12:17:42,362 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : ContainerID 1 creation failed
scm_1       | 2020-04-20 12:17:42,364 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891905Z]
scm_1       | 2020-04-20 12:17:42,364 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891905Z] moved to CLOSED state
scm_1       | 2020-04-20 12:17:42,366 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1
scm_1       | 2020-04-20 12:17:42,457 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : ContainerID 1 creation failed
scm_1       | 2020-04-20 12:17:42,458 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891905Z]
recon_1     | 
recon_1     | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
recon_1     | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:123)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:114)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.getPipeline(StorageContainerLocationProtocolClientSideTranslatorPB.java:347)
recon_1     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
recon_1     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
recon_1     | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
recon_1     | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
recon_1     | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:71)
recon_1     | 	at com.sun.proxy.$Proxy42.getPipeline(Unknown Source)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getPipeline(StorageContainerServiceProviderImpl.java:55)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineReportHandler.processPipelineReport(ReconPipelineReportHandler.java:65)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:84)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:47)
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:19:12,622 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : ContainerID 1 creation failed
recon_1     | 2020-04-20 12:19:12,622 [EventQueue-PipelineActionsForPipelineActionHandler] WARN pipeline.PipelineActionHandler: Pipeline action CLOSE received for unknown pipeline PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b, firing close pipeline event.
recon_1     | 2020-04-20 12:19:12,623 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b. Trying to get from SCM.
recon_1     | 2020-04-20 12:19:12,624 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2F5EC9472277, cid=1
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "e7e3361cefa2c31a:7318f7b560aa1975:e7e3361cefa2c31a:0" containerID: 1 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "99e9249b-6272-4da5-81f6-59c4e3b5df2b" writeChunk { blockID { containerID: 1 localID: 104030867351994368 blockCommitSequenceId: 0 } chunkData { chunkName: "104030867351994368_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "\246rN\213" } } }, container path=nonexistent
recon_1     | 2020-04-20 12:19:12,624 [EventQueue-PipelineActionsForPipelineActionHandler] WARN pipeline.PipelineActionHandler: Pipeline action CLOSE received for unknown pipeline PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b, firing close pipeline event.
recon_1     | 2020-04-20 12:19:12,631 [EventQueue-DatanodeCommandForReconNodeManager] INFO scm.ReconNodeManager: Ignoring unsupported command closePipelineCommand for Datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21.
recon_1     | 2020-04-20 12:19:12,631 [EventQueue-DatanodeCommandForReconNodeManager] INFO scm.ReconNodeManager: Ignoring unsupported command closePipelineCommand for Datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21.
recon_1     | 2020-04-20 12:19:12,655 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
recon_1     |   id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
recon_1     | }
recon_1     | isLeader: false
recon_1     | bytesWritten: 0
recon_1     |  from dn=175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null} {}
recon_1     | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException): PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
recon_1     | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=892698624 B) is less than the container size (=1073741824 B).
datanode_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_1  | 	... 13 more
datanode_1  | 2020-04-20 12:19:35,009 [ChunkWriter-50-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: 4342c3eb64c113e5:36736dca5ee5156:4342c3eb64c113e5:0 , Message: ContainerID 2 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 creation failed
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:19:35,011 [ChunkWriter-50-0] ERROR ratis.ContainerStateMachine: group-AFBDFEF81D7E: writeChunk writeStateMachineData failed: blockIdcontainerID: 2
datanode_1  | localID: 104030874748977153
datanode_1  | blockCommitSequenceId: 0
datanode_1  |  logIndex 1 chunkName 104030874748977153_chunk_1 Error message: ContainerID 2 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_1  | 2020-04-20 12:19:35,011 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e.Reason : ContainerID 2 creation failed
datanode_1  | 2020-04-20 12:19:35,044 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2C9E6EB1600C, cid=1
datanode_1  | 	 State Machine: cmdType: WriteChunk traceID: "4342c3eb64c113e5:36736dca5ee5156:4342c3eb64c113e5:0" containerID: 2 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "d762918c-eef0-4ec1-86d1-afbdfef81d7e" writeChunk { blockID { containerID: 2 localID: 104030874748977153 blockCommitSequenceId: 0 } chunkData { chunkName: "104030874748977153_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 2020-04-20 12:19:44,616 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #2 does not exist in datanode. Container close failed.
datanode_1  | 2020-04-20 12:21:06,028 [grpc-default-executor-2] INFO server.GrpcServerProtocolService: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Completed APPEND_ENTRIES, lastRequest: 258ceeb5-4c9c-49bf-b393-79534db322e4->bb3db77a-6a57-4c4e-bdc7-ea39008446e6#9-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-2C9E6EB1600C, cid=2
datanode_2  | 2020-04-20 12:19:18,728 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d762918c-eef0-4ec1-86d1-afbdfef81d7e/current/log_inprogress_0
datanode_2  | 2020-04-20 12:19:18,730 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-LeaderElection2] INFO impl.LeaderElection: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-LeaderElection2: Election REJECTED; received 2 response(s) [175c1ce4-a4bc-4858-9a69-a6ac92762c21<-bb3db77a-6a57-4c4e-bdc7-ea39008446e6#0:FAIL-t1, 175c1ce4-a4bc-4858-9a69-a6ac92762c21<-258ceeb5-4c9c-49bf-b393-79534db322e4#0:FAIL-t1] and 0 exception(s); 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E:t1, leader=258ceeb5-4c9c-49bf-b393-79534db322e4, voted=175c1ce4-a4bc-4858-9a69-a6ac92762c21, raftlog=175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-SegmentedRaftLog:OPENED:c-1,f0,i0, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_2  | 2020-04-20 12:19:35,007 [ChunkWriter-11-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: 4342c3eb64c113e5:36736dca5ee5156:4342c3eb64c113e5:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_2  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=892698624 B) is less than the container size (=1073741824 B).
datanode_2  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_2  | 	... 13 more
datanode_2  | 2020-04-20 12:19:35,010 [ChunkWriter-11-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: 4342c3eb64c113e5:36736dca5ee5156:4342c3eb64c113e5:0 , Message: ContainerID 2 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_2  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 creation failed
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:19:35,013 [ChunkWriter-11-0] ERROR ratis.ContainerStateMachine: group-AFBDFEF81D7E: writeChunk writeStateMachineData failed: blockIdcontainerID: 2
datanode_2  | localID: 104030874748977153
datanode_2  | blockCommitSequenceId: 0
datanode_2  |  logIndex 1 chunkName 104030874748977153_chunk_1 Error message: ContainerID 2 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_2  | 2020-04-20 12:19:35,018 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e.Reason : ContainerID 2 creation failed
datanode_2  | 2020-04-20 12:19:35,041 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2C9E6EB1600C, cid=1
datanode_2  | 	 State Machine: cmdType: WriteChunk traceID: "4342c3eb64c113e5:36736dca5ee5156:4342c3eb64c113e5:0" containerID: 2 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "d762918c-eef0-4ec1-86d1-afbdfef81d7e" writeChunk { blockID { containerID: 2 localID: 104030874748977153 blockCommitSequenceId: 0 } chunkData { chunkName: "104030874748977153_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_2  | 2020-04-20 12:19:44,566 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-59C4E3B5DF2B:null
datanode_2  | 2020-04-20 12:19:44,566 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_2  | 
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-59C4E3B5DF2B not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-59C4E3B5DF2B not found.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1       | 2020-04-20 12:17:42,480 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2F5EC9472277, cid=1
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "e7e3361cefa2c31a:7318f7b560aa1975:e7e3361cefa2c31a:0" containerID: 1 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "99e9249b-6272-4da5-81f6-59c4e3b5df2b" writeChunk { blockID { containerID: 1 localID: 104030867351994368 blockCommitSequenceId: 0 } chunkData { chunkName: "104030867351994368_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "\246rN\213" } } }, container path=nonexistent
scm_1       | 2020-04-20 12:17:42,481 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891905Z]
scm_1       | 2020-04-20 12:17:42,521 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : ContainerID 1 creation failed
scm_1       | 2020-04-20 12:17:42,522 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891905Z]
scm_1       | 2020-04-20 12:17:42,600 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2F5EC9472277, cid=1
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "e7e3361cefa2c31a:7318f7b560aa1975:e7e3361cefa2c31a:0" containerID: 1 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "99e9249b-6272-4da5-81f6-59c4e3b5df2b" writeChunk { blockID { containerID: 1 localID: 104030867351994368 blockCommitSequenceId: 0 } chunkData { chunkName: "104030867351994368_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "\246rN\213" } } }, container path=nonexistent
scm_1       | 2020-04-20 12:17:42,601 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891905Z]
scm_1       | 2020-04-20 12:17:42,626 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2F5EC9472277, cid=1
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "e7e3361cefa2c31a:7318f7b560aa1975:e7e3361cefa2c31a:0" containerID: 1 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "99e9249b-6272-4da5-81f6-59c4e3b5df2b" writeChunk { blockID { containerID: 1 localID: 104030867351994368 blockCommitSequenceId: 0 } chunkData { chunkName: "104030867351994368_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "\246rN\213" } } }, container path=nonexistent
scm_1       | 2020-04-20 12:17:42,627 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891905Z]
scm_1       | 2020-04-20 12:18:48,366 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:18:48,367 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:18:48,368 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:18:48,368 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891905Z] removed from db
scm_1       | 2020-04-20 12:18:48,369 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-20 12:18:48,369 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e to datanode:258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:18:48,369 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e to datanode:175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:18:48,370 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e to datanode:bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:18:48,370 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:18:48.369739Z]
scm_1       | 2020-04-20 12:18:48,370 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-20 12:18:48,459 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:18:48,459 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:18:48,459 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:18:48,460 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891905Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:18:48,481 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:18:48,481 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:18:48,481 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:18:48,482 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891905Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:18:48,525 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:18:48,525 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:18:48,525 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 	... 4 more
datanode_2  | 2020-04-20 12:19:44,567 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #2 does not exist in datanode. Container close failed.
datanode_2  | 2020-04-20 12:21:06,030 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Completed APPEND_ENTRIES, lastRequest: 258ceeb5-4c9c-49bf-b393-79534db322e4->175c1ce4-a4bc-4858-9a69-a6ac92762c21#9-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-2C9E6EB1600C, cid=2
datanode_2  | 2020-04-20 12:21:06,042 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove  FOLLOWER 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E:t1, leader=258ceeb5-4c9c-49bf-b393-79534db322e4, voted=175c1ce4-a4bc-4858-9a69-a6ac92762c21, raftlog=175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
datanode_2  | 2020-04-20 12:21:06,043 [Command processor thread] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E: shutdown
datanode_2  | 2020-04-20 12:21:06,043 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AFBDFEF81D7E,id=175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:21:06,043 [Command processor thread] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown FollowerState
datanode_2  | 2020-04-20 12:21:06,043 [Thread-87] INFO impl.FollowerState: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2  | 2020-04-20 12:21:06,043 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-AFBDFEF81D7E as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 2020-04-20 12:21:06,043 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-StateMachineUpdater] ERROR impl.StateMachineUpdater: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-StateMachineUpdater: Failed to take snapshot
datanode_2  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-AFBDFEF81D7E as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:21:06,044 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-AFBDFEF81D7E as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 2020-04-20 12:21:06,044 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-StateMachineUpdater] ERROR impl.StateMachineUpdater: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-StateMachineUpdater: Failed to take snapshot
datanode_2  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-AFBDFEF81D7E as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:21:06,044 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E
datanode_2  | 2020-04-20 12:21:06,043 [Command processor thread] INFO impl.StateMachineUpdater: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-StateMachineUpdater: set stopIndex = 0
datanode_2  | 2020-04-20 12:21:06,045 [Command processor thread] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E: closes. applyIndex: 0
datanode_2  | 2020-04-20 12:21:06,046 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_2  | 2020-04-20 12:21:06,050 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E-SegmentedRaftLogWorker close()
datanode_2  | 2020-04-20 12:21:06,051 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:21:06,051 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E
datanode_2  | 2020-04-20 12:21:06,051 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-AFBDFEF81D7E
datanode_2  | 2020-04-20 12:21:06,052 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_2  |  command on datanode #175c1ce4-a4bc-4858-9a69-a6ac92762c21.
datanode_2  | 2020-04-20 12:21:06,054 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: addNew group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-CF9DF1472EEF:java.util.concurrent.CompletableFuture@37571a48[Not completed]
datanode_2  | 2020-04-20 12:21:06,056 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: new RaftServerImpl for group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-04-20 12:21:06,056 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-04-20 12:21:06,056 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-04-20 12:21:06,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-04-20 12:21:06,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
recon_1     | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1     | 
recon_1     | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
recon_1     | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:123)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:114)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.getPipeline(StorageContainerLocationProtocolClientSideTranslatorPB.java:347)
recon_1     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
recon_1     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
recon_1     | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
recon_1     | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
recon_1     | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:71)
recon_1     | 	at com.sun.proxy.$Proxy42.getPipeline(Unknown Source)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getPipeline(StorageContainerServiceProviderImpl.java:55)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineReportHandler.processPipelineReport(ReconPipelineReportHandler.java:65)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:84)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:47)
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:19:13,531 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e. Trying to get from SCM.
recon_1     | 2020-04-20 12:19:13,536 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:18:48.369Z] to Recon pipeline metadata.
recon_1     | 2020-04-20 12:19:13,537 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:18:48.369Z]
recon_1     | 2020-04-20 12:19:13,537 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e reported by 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:19:13,577 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e reported by 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:19:13,578 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b. Trying to get from SCM.
recon_1     | 2020-04-20 12:19:13,583 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
recon_1     |   id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
recon_1     | }
recon_1     | isLeader: false
recon_1     | bytesWritten: 0
recon_1     |  from dn=175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null} {}
recon_1     | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException): PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
recon_1     | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
scm_1       | 2020-04-20 12:18:48,525 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891905Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:18:48,602 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:18:48,602 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:18:48,602 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:18:48,602 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891905Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:18:48,627 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:18:48,627 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:18:48,627 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:18:48,628 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 99e9249b-6272-4da5-81f6-59c4e3b5df2b, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:17:25.891905Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:19:13,475 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$443/0x0000000840592040@23b46c26] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B->175c1ce4-a4bc-4858-9a69-a6ac92762c21-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_3  | 2020-04-20 12:19:13,475 [Command processor thread] INFO impl.PendingRequests: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-PendingRequests: sendNotLeaderResponses
datanode_3  | 2020-04-20 12:19:13,481 [grpc-default-executor-2] INFO server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_3  | 2020-04-20 12:19:13,484 [grpc-default-executor-1] INFO server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B->175c1ce4-a4bc-4858-9a69-a6ac92762c21-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_3  | 2020-04-20 12:19:13,489 [grpc-default-executor-2] INFO impl.FollowerInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B->bb3db77a-6a57-4c4e-bdc7-ea39008446e6: nextIndex: updateUnconditionally 3 -> 1
datanode_3  | 2020-04-20 12:19:13,489 [grpc-default-executor-1] INFO impl.FollowerInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B->175c1ce4-a4bc-4858-9a69-a6ac92762c21: nextIndex: updateUnconditionally 3 -> 1
datanode_3  | 2020-04-20 12:19:13,503 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B
datanode_3  | 2020-04-20 12:19:13,507 [Command processor thread] INFO impl.StateMachineUpdater: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-StateMachineUpdater: set stopIndex = 0
datanode_3  | 2020-04-20 12:19:13,511 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-59C4E3B5DF2B as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_3  | 2020-04-20 12:19:13,511 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-StateMachineUpdater] ERROR impl.StateMachineUpdater: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-StateMachineUpdater: Failed to take snapshot
datanode_3  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-59C4E3B5DF2B as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:19:13,512 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-59C4E3B5DF2B as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_3  | 2020-04-20 12:19:13,512 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-StateMachineUpdater] ERROR impl.StateMachineUpdater: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-StateMachineUpdater: Failed to take snapshot
datanode_3  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-59C4E3B5DF2B as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:19:13,512 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B
datanode_3  | 2020-04-20 12:19:13,513 [Command processor thread] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B: closes. applyIndex: 0
datanode_3  | 2020-04-20 12:19:13,514 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_3  | 2020-04-20 12:19:13,514 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B-SegmentedRaftLogWorker close()
datanode_3  | 2020-04-20 12:19:13,515 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:19:13,515 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B
datanode_3  | 2020-04-20 12:19:13,515 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.258ceeb5-4c9c-49bf-b393-79534db322e4@group-59C4E3B5DF2B
datanode_3  | Apr 20, 2020 12:19:13 PM org.apache.ratis.thirdparty.io.grpc.netty.NettyServerHandler onStreamError
datanode_3  | WARNING: Stream Error
datanode_3  | org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2Exception$StreamException: Received DATA frame for an unknown stream 3
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2Exception.streamError(Http2Exception.java:147)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder$FrameReadListener.shouldIgnoreHeadersOrDataFrame(DefaultHttp2ConnectionDecoder.java:591)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder$FrameReadListener.onDataRead(DefaultHttp2ConnectionDecoder.java:239)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2InboundFrameLogger$1.onDataRead(Http2InboundFrameLogger.java:48)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2FrameReader.readDataFrame(DefaultHttp2FrameReader.java:422)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2FrameReader.processPayloadState(DefaultHttp2FrameReader.java:251)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2FrameReader.readFrame(DefaultHttp2FrameReader.java:160)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2InboundFrameLogger.readFrame(Http2InboundFrameLogger.java:41)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder.decodeFrame(DefaultHttp2ConnectionDecoder.java:174)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2ConnectionHandler$FrameDecoder.decode(Http2ConnectionHandler.java:378)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2ConnectionHandler.decode(Http2ConnectionHandler.java:438)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:505)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:444)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:283)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
datanode_1  | 2020-04-20 12:21:06,046 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove  FOLLOWER bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E:t1, leader=258ceeb5-4c9c-49bf-b393-79534db322e4, voted=258ceeb5-4c9c-49bf-b393-79534db322e4, raftlog=bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
datanode_1  | 2020-04-20 12:21:06,046 [Command processor thread] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E: shutdown
datanode_1  | 2020-04-20 12:21:06,046 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AFBDFEF81D7E,id=bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:21:06,046 [Command processor thread] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown FollowerState
datanode_1  | 2020-04-20 12:21:06,046 [Command processor thread] INFO impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-StateMachineUpdater: set stopIndex = 0
datanode_1  | 2020-04-20 12:21:06,046 [Thread-86] INFO impl.FollowerState: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1  | 2020-04-20 12:21:06,047 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-AFBDFEF81D7E as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | 2020-04-20 12:21:06,048 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-StateMachineUpdater] ERROR impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-StateMachineUpdater: Failed to take snapshot
datanode_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-AFBDFEF81D7E as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:21:06,048 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-AFBDFEF81D7E as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | 2020-04-20 12:21:06,048 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-StateMachineUpdater] ERROR impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-StateMachineUpdater: Failed to take snapshot
datanode_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-AFBDFEF81D7E as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:21:06,048 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E
datanode_1  | 2020-04-20 12:21:06,049 [Command processor thread] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E: closes. applyIndex: 0
datanode_1  | 2020-04-20 12:21:06,049 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_1  | 2020-04-20 12:21:06,050 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E-SegmentedRaftLogWorker close()
datanode_1  | 2020-04-20 12:21:06,052 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:21:06,052 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E
datanode_1  | 2020-04-20 12:21:06,052 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-AFBDFEF81D7E
datanode_1  | 2020-04-20 12:21:06,055 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_1  |  command on datanode #bb3db77a-6a57-4c4e-bdc7-ea39008446e6.
datanode_1  | 2020-04-20 12:21:06,067 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: new RaftServerImpl for group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-04-20 12:21:06,069 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-04-20 12:21:06,069 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-04-20 12:21:06,069 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-04-20 12:21:06,069 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: addNew group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-CF9DF1472EEF:java.util.concurrent.CompletableFuture@72bfe4c[Not completed]
datanode_1  | 2020-04-20 12:21:06,069 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-04-20 12:21:06,070 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-04-20 12:21:06,070 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-04-20 12:21:06,072 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-04-20 12:21:06,073 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-04-20 12:21:06,073 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/cc7b5d95-9851-4876-8726-cf9df1472eef does not exist. Creating ...
datanode_1  | 2020-04-20 12:21:06,083 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cc7b5d95-9851-4876-8726-cf9df1472eef/in_use.lock acquired by nodename 6@69674aa52266
datanode_1  | 2020-04-20 12:21:06,084 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/cc7b5d95-9851-4876-8726-cf9df1472eef has been successfully formatted.
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1421)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 
datanode_3  | 2020-04-20 12:19:13,521 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_3  |  command on datanode #258ceeb5-4c9c-49bf-b393-79534db322e4.
datanode_3  | 2020-04-20 12:19:13,522 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: addNew group-AFBDFEF81D7E:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-AFBDFEF81D7E:java.util.concurrent.CompletableFuture@53d277cc[Not completed]
datanode_3  | 2020-04-20 12:19:13,523 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4: new RaftServerImpl for group-AFBDFEF81D7E:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-04-20 12:19:13,524 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-04-20 12:19:13,524 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-04-20 12:19:13,524 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-04-20 12:19:13,524 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-04-20 12:19:13,525 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-20 12:19:13,525 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-04-20 12:19:13,525 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-20 12:19:13,525 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-04-20 12:19:13,525 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d762918c-eef0-4ec1-86d1-afbdfef81d7e does not exist. Creating ...
datanode_3  | 2020-04-20 12:19:13,527 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d762918c-eef0-4ec1-86d1-afbdfef81d7e/in_use.lock acquired by nodename 6@78409bf0b6e2
datanode_3  | 2020-04-20 12:19:13,528 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d762918c-eef0-4ec1-86d1-afbdfef81d7e has been successfully formatted.
datanode_3  | 2020-04-20 12:19:13,528 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-AFBDFEF81D7E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-04-20 12:19:13,530 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-04-20 12:19:13,531 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-04-20 12:19:13,531 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-04-20 12:19:13,531 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-20 12:19:13,531 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-20 12:19:13,532 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:19:13,532 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-04-20 12:19:13,532 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/d762918c-eef0-4ec1-86d1-afbdfef81d7e
datanode_3  | 2020-04-20 12:19:13,532 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-04-20 12:19:13,532 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-04-20 12:19:13,532 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-20 12:19:13,532 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-04-20 12:19:13,532 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-04-20 12:19:13,532 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-04-20 12:19:13,532 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-04-20 12:19:13,532 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-04-20 12:19:13,532 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-04-20 12:19:13,536 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-04-20 12:19:13,536 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
recon_1     | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1     | 
recon_1     | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
recon_1     | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:123)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:114)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.getPipeline(StorageContainerLocationProtocolClientSideTranslatorPB.java:347)
recon_1     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
recon_1     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
recon_1     | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
recon_1     | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
recon_1     | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:71)
recon_1     | 	at com.sun.proxy.$Proxy42.getPipeline(Unknown Source)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getPipeline(StorageContainerServiceProviderImpl.java:55)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineReportHandler.processPipelineReport(ReconPipelineReportHandler.java:65)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:84)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:47)
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:19:13,634 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e reported by bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:19:18,670 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e reported by 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:19:18,670 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369Z] moved to OPEN state
recon_1     | 2020-04-20 12:19:23,105 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-20 12:19:23,106 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-20 12:19:23,221 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 1
recon_1     | 2020-04-20 12:19:23,251 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2020-04-20 12:19:23,405 [pool-9-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-20 12:19:35,026 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : ContainerID 2 creation failed
recon_1     | 2020-04-20 12:19:35,026 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369Z]
recon_1     | 2020-04-20 12:19:35,028 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369Z] moved to CLOSED state
recon_1     | 2020-04-20 12:19:35,031 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2C9E6EB1600C, cid=1
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "4342c3eb64c113e5:36736dca5ee5156:4342c3eb64c113e5:0" containerID: 2 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "d762918c-eef0-4ec1-86d1-afbdfef81d7e" writeChunk { blockID { containerID: 2 localID: 104030874748977153 blockCommitSequenceId: 0 } chunkData { chunkName: "104030874748977153_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
recon_1     | 2020-04-20 12:19:35,031 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369Z]
recon_1     | 2020-04-20 12:19:35,048 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : ContainerID 2 creation failed
recon_1     | 2020-04-20 12:19:35,048 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369Z]
recon_1     | 2020-04-20 12:19:35,060 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : ContainerID 2 creation failed
recon_1     | 2020-04-20 12:19:35,061 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369Z]
recon_1     | 2020-04-20 12:19:35,067 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2C9E6EB1600C, cid=1
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "4342c3eb64c113e5:36736dca5ee5156:4342c3eb64c113e5:0" containerID: 2 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "d762918c-eef0-4ec1-86d1-afbdfef81d7e" writeChunk { blockID { containerID: 2 localID: 104030874748977153 blockCommitSequenceId: 0 } chunkData { chunkName: "104030874748977153_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
recon_1     | 2020-04-20 12:19:35,067 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369Z]
recon_1     | 2020-04-20 12:19:35,071 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2C9E6EB1600C, cid=1
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "4342c3eb64c113e5:36736dca5ee5156:4342c3eb64c113e5:0" containerID: 2 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "d762918c-eef0-4ec1-86d1-afbdfef81d7e" writeChunk { blockID { containerID: 2 localID: 104030874748977153 blockCommitSequenceId: 0 } chunkData { chunkName: "104030874748977153_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
recon_1     | 2020-04-20 12:19:35,071 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369Z]
recon_1     | 2020-04-20 12:20:23,417 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-20 12:20:23,418 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-20 12:20:23,424 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 3
recon_1     | 2020-04-20 12:20:23,427 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2020-04-20 12:20:23,496 [pool-9-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-20 12:20:41,029 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369Z] removed from db
recon_1     | 2020-04-20 12:20:41,032 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369Z]
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:20:41,049 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369Z]
datanode_2  | 2020-04-20 12:21:06,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-04-20 12:21:06,057 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-04-20 12:21:06,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-20 12:21:06,058 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-04-20 12:21:06,058 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/cc7b5d95-9851-4876-8726-cf9df1472eef does not exist. Creating ...
datanode_2  | 2020-04-20 12:21:06,061 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cc7b5d95-9851-4876-8726-cf9df1472eef/in_use.lock acquired by nodename 6@f98376242d82
datanode_2  | 2020-04-20 12:21:06,063 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/cc7b5d95-9851-4876-8726-cf9df1472eef has been successfully formatted.
datanode_2  | 2020-04-20 12:21:06,064 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-CF9DF1472EEF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-04-20 12:21:06,064 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-04-20 12:21:06,064 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-04-20 12:21:06,064 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-04-20 12:21:06,064 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-20 12:21:06,064 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-20 12:21:06,064 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:21:06,065 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-04-20 12:21:06,065 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/cc7b5d95-9851-4876-8726-cf9df1472eef
datanode_2  | 2020-04-20 12:21:06,065 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-04-20 12:21:06,065 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-04-20 12:21:06,065 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-20 12:21:06,065 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-04-20 12:21:06,065 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-04-20 12:21:06,065 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-04-20 12:21:06,065 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-04-20 12:21:06,065 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-04-20 12:21:06,065 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-04-20 12:21:06,069 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-04-20 12:21:06,069 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-04-20 12:21:06,085 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-04-20 12:21:06,085 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-04-20 12:21:06,085 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-04-20 12:21:06,085 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-04-20 12:21:06,085 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF
datanode_2  | 2020-04-20 12:21:06,088 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF
datanode_2  | 2020-04-20 12:21:06,088 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_2  | 2020-04-20 12:21:06,088 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-04-20 12:21:06,088 [pool-69-thread-1] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start FollowerState
datanode_2  | 2020-04-20 12:21:06,106 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CF9DF1472EEF,id=175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:21:06,106 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF
datanode_2  | 2020-04-20 12:21:06,157 [grpc-default-executor-0] WARN impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed groupAdd* GroupManagementRequest:client-0394D77BD6E4->175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF, cid=4, seq=0, RW, null, Add:group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 2020-04-20 12:19:13,539 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-04-20 12:19:13,539 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-04-20 12:19:13,540 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-04-20 12:19:13,540 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-04-20 12:19:13,540 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E
datanode_3  | 2020-04-20 12:19:13,540 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E
datanode_3  | 2020-04-20 12:19:13,541 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 2020-04-20 12:19:13,541 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-04-20 12:19:13,541 [pool-69-thread-1] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start FollowerState
datanode_3  | 2020-04-20 12:19:13,543 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AFBDFEF81D7E,id=258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:19:13,543 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E
datanode_3  | 2020-04-20 12:19:13,680 [grpc-default-executor-1] WARN impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed groupAdd* GroupManagementRequest:client-19EDAC2F3356->258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E, cid=2, seq=0, RW, null, Add:group-AFBDFEF81D7E:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-AFBDFEF81D7E:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-AFBDFEF81D7E:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3  | 	... 13 more
datanode_3  | 2020-04-20 12:19:13,696 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_3  | .
datanode_3  | 2020-04-20 12:19:13,696 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-59C4E3B5DF2B:null
datanode_3  | 2020-04-20 12:19:13,696 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_3  | 
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-59C4E3B5DF2B not found.
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-59C4E3B5DF2B not found.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 	... 4 more
datanode_3  | 2020-04-20 12:19:13,697 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-59C4E3B5DF2B:null
datanode_3  | 2020-04-20 12:19:13,697 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_3  | 
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-59C4E3B5DF2B not found.
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1       | 2020-04-20 12:19:12,482 [IPC Server handler 63 on 9860] INFO ipc.Server: IPC Server handler 63 on 9860, call Call#6 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.21.0.5:55816
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1       | 2020-04-20 12:19:12,602 [IPC Server handler 0 on 9860] INFO ipc.Server: IPC Server handler 0 on 9860, call Call#7 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.21.0.5:55816
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1       | 2020-04-20 12:19:12,653 [IPC Server handler 1 on 9860] INFO ipc.Server: IPC Server handler 1 on 9860, call Call#8 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.21.0.5:55816
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1       | 2020-04-20 12:19:13,579 [IPC Server handler 1 on 9860] INFO ipc.Server: IPC Server handler 1 on 9860, call Call#10 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.21.0.5:55816
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=99e9249b-6272-4da5-81f6-59c4e3b5df2b not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-59C4E3B5DF2B not found.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 	... 4 more
datanode_3  | 2020-04-20 12:19:13,697 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-59C4E3B5DF2B:null
datanode_3  | 2020-04-20 12:19:13,697 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_3  | 
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-59C4E3B5DF2B not found.
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-59C4E3B5DF2B not found.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 	... 4 more
datanode_3  | 2020-04-20 12:19:13,698 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-59C4E3B5DF2B:null
datanode_3  | 2020-04-20 12:19:13,698 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_3  | 
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-59C4E3B5DF2B not found.
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-59C4E3B5DF2B not found.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 	... 4 more
datanode_3  | 2020-04-20 12:19:13,698 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-59C4E3B5DF2B:null
datanode_3  | 2020-04-20 12:19:13,698 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_3  | 
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-59C4E3B5DF2B not found.
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-59C4E3B5DF2B not found.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 	... 4 more
datanode_3  | 2020-04-20 12:19:13,698 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-59C4E3B5DF2B:null
datanode_3  | 2020-04-20 12:19:13,698 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "99e9249b-6272-4da5-81f6-59c4e3b5df2b"
datanode_3  | 
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-59C4E3B5DF2B not found.
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-59C4E3B5DF2B not found.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 	... 4 more
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1       | 2020-04-20 12:19:14,578 [IPC Server handler 81 on 9863] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-20 12:19:14,578 [IPC Server handler 81 on 9863] WARN block.BlockManagerImpl: Pipeline creation failed for type:RATIS factor:THREE. Datanodes may be used up.
scm_1       | org.apache.hadoop.hdds.scm.exceptions.SCMException: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:173)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:196)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:116)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:63)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:232)
scm_1       | 	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:200)
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:190)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:161)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:119)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:100)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1       | 2020-04-20 12:19:14,579 [IPC Server handler 81 on 9863] ERROR block.BlockManagerImpl: Unable to allocate a block for the size: 268435456, type: RATIS, factor: THREE
scm_1       | 2020-04-20 12:19:18,681 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369739Z] moved to OPEN state
scm_1       | 2020-04-20 12:19:22,109 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-20 12:19:22,110 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-20 12:19:35,034 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : ContainerID 2 creation failed
scm_1       | 2020-04-20 12:19:35,038 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369739Z]
scm_1       | 2020-04-20 12:19:35,048 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369739Z] moved to CLOSED state
scm_1       | 2020-04-20 12:19:35,048 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2
datanode_1  | 2020-04-20 12:21:06,085 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-CF9DF1472EEF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-04-20 12:21:06,085 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-04-20 12:21:06,086 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-04-20 12:21:06,086 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-04-20 12:21:06,087 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-20 12:21:06,092 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-20 12:21:06,092 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:21:06,104 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-04-20 12:21:06,109 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/cc7b5d95-9851-4876-8726-cf9df1472eef
datanode_1  | 2020-04-20 12:21:06,110 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-04-20 12:21:06,110 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-04-20 12:21:06,110 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-20 12:21:06,110 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-04-20 12:21:06,111 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-04-20 12:21:06,111 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-04-20 12:21:06,111 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-04-20 12:21:06,111 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-04-20 12:21:06,111 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-04-20 12:21:06,112 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-04-20 12:21:06,114 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-04-20 12:21:06,119 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-04-20 12:21:06,119 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-04-20 12:21:06,120 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-04-20 12:21:06,120 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-04-20 12:21:06,121 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF
datanode_1  | 2020-04-20 12:21:06,123 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF
datanode_1  | 2020-04-20 12:21:06,124 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_1  | 2020-04-20 12:21:06,124 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-04-20 12:21:06,124 [pool-69-thread-1] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start FollowerState
datanode_1  | 2020-04-20 12:21:06,126 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CF9DF1472EEF,id=bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:21:06,126 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF
datanode_1  | 2020-04-20 12:21:06,158 [grpc-default-executor-2] WARN impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed groupAdd* GroupManagementRequest:client-CB54724C6A39->bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF, cid=2, seq=0, RW, null, Add:group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 	... 13 more
datanode_1  | 2020-04-20 12:21:06,184 [grpc-default-executor-2] WARN impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed groupAdd* GroupManagementRequest:client-B38C7A78104D->bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF, cid=4, seq=0, RW, null, Add:group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
scm_1       | 2020-04-20 12:19:35,049 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2C9E6EB1600C, cid=1
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "4342c3eb64c113e5:36736dca5ee5156:4342c3eb64c113e5:0" containerID: 2 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "d762918c-eef0-4ec1-86d1-afbdfef81d7e" writeChunk { blockID { containerID: 2 localID: 104030874748977153 blockCommitSequenceId: 0 } chunkData { chunkName: "104030874748977153_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
scm_1       | 2020-04-20 12:19:35,056 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369739Z]
scm_1       | 2020-04-20 12:19:35,057 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : ContainerID 2 creation failed
scm_1       | 2020-04-20 12:19:35,057 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369739Z]
scm_1       | 2020-04-20 12:19:35,069 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : ContainerID 2 creation failed
scm_1       | 2020-04-20 12:19:35,069 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369739Z]
scm_1       | 2020-04-20 12:19:35,070 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2C9E6EB1600C, cid=1
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "4342c3eb64c113e5:36736dca5ee5156:4342c3eb64c113e5:0" containerID: 2 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "d762918c-eef0-4ec1-86d1-afbdfef81d7e" writeChunk { blockID { containerID: 2 localID: 104030874748977153 blockCommitSequenceId: 0 } chunkData { chunkName: "104030874748977153_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
scm_1       | 2020-04-20 12:19:35,070 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369739Z]
scm_1       | 2020-04-20 12:19:35,075 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2C9E6EB1600C, cid=1
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "4342c3eb64c113e5:36736dca5ee5156:4342c3eb64c113e5:0" containerID: 2 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "d762918c-eef0-4ec1-86d1-afbdfef81d7e" writeChunk { blockID { containerID: 2 localID: 104030874748977153 blockCommitSequenceId: 0 } chunkData { chunkName: "104030874748977153_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
scm_1       | 2020-04-20 12:19:35,075 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369739Z]
scm_1       | 2020-04-20 12:20:41,049 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:20:41,054 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:20:41,054 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_3  | 2020-04-20 12:19:18,613 [Thread-52] INFO impl.FollowerState: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-FollowerState: change to CANDIDATE, lastRpcTime:5071ms, electionTimeout:5069ms
datanode_3  | 2020-04-20 12:19:18,613 [Thread-52] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown FollowerState
datanode_3  | 2020-04-20 12:19:18,613 [Thread-52] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2020-04-20 12:19:18,614 [Thread-52] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start LeaderElection
datanode_3  | 2020-04-20 12:19:18,623 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO impl.LeaderElection: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3: begin an election at term 1 for -1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 2020-04-20 12:19:18,658 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO impl.LeaderElection: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3: Election PASSED; received 1 response(s) [258ceeb5-4c9c-49bf-b393-79534db322e4<-bb3db77a-6a57-4c4e-bdc7-ea39008446e6#0:OK-t1] and 0 exception(s); 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E:t1, leader=null, voted=258ceeb5-4c9c-49bf-b393-79534db322e4, raftlog=258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 2020-04-20 12:19:18,659 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown LeaderElection
datanode_3  | 2020-04-20 12:19:18,659 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-04-20 12:19:18,659 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-AFBDFEF81D7E with new leaderId: 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:19:18,659 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E: change Leader from null to 258ceeb5-4c9c-49bf-b393-79534db322e4 at term 1 for becomeLeader, leader elected after 5130ms
datanode_3  | 2020-04-20 12:19:18,660 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-04-20 12:19:18,660 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-04-20 12:19:18,660 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E
datanode_3  | 2020-04-20 12:19:18,661 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-04-20 12:19:18,661 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-04-20 12:19:18,661 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-04-20 12:19:18,661 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-04-20 12:19:18,665 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-04-20 12:19:18,665 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2020-04-20 12:19:18,665 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-20 12:19:18,665 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 2020-04-20 12:19:18,666 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2020-04-20 12:19:18,666 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-04-20 12:19:18,666 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-20 12:19:18,668 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2020-04-20 12:19:18,669 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-20 12:19:18,672 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 2020-04-20 12:19:18,673 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2020-04-20 12:19:18,673 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-04-20 12:19:18,673 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-20 12:19:18,674 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start LeaderState
datanode_3  | 2020-04-20 12:19:18,674 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-04-20 12:19:18,678 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d762918c-eef0-4ec1-86d1-afbdfef81d7e/current/log_inprogress_0
datanode_3  | 2020-04-20 12:19:18,685 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-LeaderElection3] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:20:41,061 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369Z]
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:20:41,067 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369Z]
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1       | 2020-04-20 12:20:41,054 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369739Z] removed from db
scm_1       | 2020-04-20 12:20:41,055 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-20 12:20:41,056 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef to datanode:bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:20:41,056 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef to datanode:175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:20:41,056 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef to datanode:258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:20:41,056 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:20:41.056088Z]
scm_1       | 2020-04-20 12:20:41,057 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-20 12:20:41,057 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:20:41,057 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:20:41,057 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:20:41,058 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369739Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:20:41,058 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:20:41,058 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:20:41,058 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:20:41,059 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369739Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 	... 13 more
datanode_1  | 2020-04-20 12:21:06,264 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_1  | .
datanode_1  | 2020-04-20 12:21:06,265 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-AFBDFEF81D7E:null
datanode_1  | 2020-04-20 12:21:06,265 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_1  | 
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-AFBDFEF81D7E not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-AFBDFEF81D7E not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_1  | 2020-04-20 12:21:06,265 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-AFBDFEF81D7E:null
datanode_1  | 2020-04-20 12:21:06,266 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_1  | 
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-AFBDFEF81D7E not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-AFBDFEF81D7E not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_1  | 2020-04-20 12:21:06,266 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-AFBDFEF81D7E:null
datanode_1  | 2020-04-20 12:21:06,267 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_1  | 
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-AFBDFEF81D7E not found.
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2  | 	... 13 more
datanode_2  | 2020-04-20 12:21:06,242 [grpc-default-executor-0] WARN impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed groupAdd* GroupManagementRequest:client-77B0CA4AEB17->175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF, cid=5, seq=0, RW, null, Add:group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2  | 	... 13 more
datanode_2  | 2020-04-20 12:21:06,260 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_2  | .
datanode_2  | 2020-04-20 12:21:06,260 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-AFBDFEF81D7E:null
datanode_2  | 2020-04-20 12:21:06,260 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_2  | 
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-AFBDFEF81D7E not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-AFBDFEF81D7E not found.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 	... 4 more
datanode_2  | 2020-04-20 12:21:06,261 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-AFBDFEF81D7E:null
datanode_2  | 2020-04-20 12:21:06,261 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_2  | 
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-AFBDFEF81D7E not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:20:41,072 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369Z]
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:21:06,088 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef. Trying to get from SCM.
recon_1     | 2020-04-20 12:21:06,106 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:20:41.056Z] to Recon pipeline metadata.
recon_1     | 2020-04-20 12:21:06,107 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:20:41.056Z]
recon_1     | 2020-04-20 12:21:06,107 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef reported by bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:21:06,113 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef reported by 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:21:06,123 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef reported by 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:21:11,250 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef reported by 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:21:11,250 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056Z] moved to OPEN state
recon_1     | 2020-04-20 12:21:23,503 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-20 12:21:23,503 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-20 12:21:23,518 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5
recon_1     | 2020-04-20 12:21:23,523 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2020-04-20 12:21:23,597 [pool-9-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-20 12:21:37,863 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : ContainerID 3 creation failed
datanode_3  | 2020-04-20 12:19:18,721 [grpc-default-executor-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-   LEADER: Withhold vote from candidate 175c1ce4-a4bc-4858-9a69-a6ac92762c21 with term 1. State: leader=258ceeb5-4c9c-49bf-b393-79534db322e4, term=1, lastRpcElapsed=null
datanode_3  | 2020-04-20 12:19:35,000 [ChunkWriter-30-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: 4342c3eb64c113e5:36736dca5ee5156:4342c3eb64c113e5:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=892702720 B) is less than the container size (=1073741824 B).
datanode_3  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_3  | 	... 13 more
datanode_3  | 2020-04-20 12:19:35,001 [ChunkWriter-30-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: 4342c3eb64c113e5:36736dca5ee5156:4342c3eb64c113e5:0 , Message: ContainerID 2 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 creation failed
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:19:35,008 [ChunkWriter-30-0] ERROR ratis.ContainerStateMachine: group-AFBDFEF81D7E: writeChunk writeStateMachineData failed: blockIdcontainerID: 2
datanode_3  | localID: 104030874748977153
datanode_3  | blockCommitSequenceId: 0
datanode_3  |  logIndex 1 chunkName 104030874748977153_chunk_1 Error message: ContainerID 2 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_3  | 2020-04-20 12:19:35,012 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e.Reason : ContainerID 2 creation failed
datanode_3  | 2020-04-20 12:19:35,025 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-2C9E6EB1600C, cid=1
datanode_3  | 	 State Machine: cmdType: WriteChunk traceID: "4342c3eb64c113e5:36736dca5ee5156:4342c3eb64c113e5:0" containerID: 2 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "d762918c-eef0-4ec1-86d1-afbdfef81d7e" writeChunk { blockID { containerID: 2 localID: 104030874748977153 blockCommitSequenceId: 0 } chunkData { chunkName: "104030874748977153_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_3  | 2020-04-20 12:20:06,026 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #2 does not exist in datanode. Container close failed.
datanode_3  | 2020-04-20 12:20:18,691 [java.util.concurrent.ThreadPoolExecutor$Worker@60596d7f[State = -1, empty queue]] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender: HEARTBEAT appendEntries Timeout, request=AppendEntriesRequest:cid=0,entriesCount=0,lastEntry=null
datanode_3  | 2020-04-20 12:20:35,000 [java.util.concurrent.ThreadPoolExecutor$Worker@60596d7f[State = -1, empty queue]] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=8,entriesCount=1,lastEntry=(t:1, i:1)
datanode_3  | 2020-04-20 12:20:35,002 [java.util.concurrent.ThreadPoolExecutor$Worker@60596d7f[State = -1, empty queue]] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E->175c1ce4-a4bc-4858-9a69-a6ac92762c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=8,entriesCount=1,lastEntry=(t:1, i:1)
datanode_3  | 2020-04-20 12:20:35,026 [java.util.concurrent.ThreadPoolExecutor$Worker@60596d7f[State = -1, empty queue]] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E->175c1ce4-a4bc-4858-9a69-a6ac92762c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=9,entriesCount=1,lastEntry=(t:1, i:2)
datanode_3  | 2020-04-20 12:20:35,029 [java.util.concurrent.ThreadPoolExecutor$Worker@60596d7f[State = -1, empty queue]] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=9,entriesCount=1,lastEntry=(t:1, i:2)
datanode_3  | 2020-04-20 12:21:06,025 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove    LEADER 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E:t1, leader=258ceeb5-4c9c-49bf-b393-79534db322e4, voted=258ceeb5-4c9c-49bf-b393-79534db322e4, raftlog=258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
datanode_3  | 2020-04-20 12:21:06,026 [Command processor thread] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E: shutdown
datanode_3  | 2020-04-20 12:21:06,026 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AFBDFEF81D7E,id=258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:21:06,026 [Command processor thread] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown LeaderState
datanode_3  | 2020-04-20 12:21:06,026 [Command processor thread] INFO impl.PendingRequests: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-PendingRequests: sendNotLeaderResponses
datanode_3  | 2020-04-20 12:21:06,026 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$443/0x0000000840592040@74aea13f] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_3  | 2020-04-20 12:21:06,026 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$443/0x0000000840592040@45901437] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E->175c1ce4-a4bc-4858-9a69-a6ac92762c21-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_3  | 2020-04-20 12:21:06,036 [grpc-default-executor-2] INFO server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_3  | 2020-04-20 12:21:06,036 [grpc-default-executor-1] INFO server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E->175c1ce4-a4bc-4858-9a69-a6ac92762c21-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_3  | 2020-04-20 12:21:06,038 [grpc-default-executor-2] INFO impl.FollowerInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E->bb3db77a-6a57-4c4e-bdc7-ea39008446e6: nextIndex: updateUnconditionally 3 -> 1
datanode_3  | 2020-04-20 12:21:06,043 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E
datanode_3  | 2020-04-20 12:21:06,043 [Command processor thread] INFO impl.StateMachineUpdater: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-StateMachineUpdater: set stopIndex = 0
datanode_3  | 2020-04-20 12:21:06,044 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-AFBDFEF81D7E as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_3  | 2020-04-20 12:21:06,047 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-StateMachineUpdater] ERROR impl.StateMachineUpdater: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-StateMachineUpdater: Failed to take snapshot
datanode_3  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-AFBDFEF81D7E as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
scm_1       | 2020-04-20 12:20:41,069 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:20:41,070 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:20:41,070 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:20:41,070 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369739Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:20:41,071 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:20:41,071 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:20:41,071 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:20:41,072 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369739Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:20:41,081 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:20:41,081 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:20:41,081 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:20:41,082 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: d762918c-eef0-4ec1-86d1-afbdfef81d7e, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:18:48.369739Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=d762918c-eef0-4ec1-86d1-afbdfef81d7e not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-AFBDFEF81D7E not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_1  | 2020-04-20 12:21:06,268 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-AFBDFEF81D7E:null
datanode_1  | 2020-04-20 12:21:06,269 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_1  | 
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-AFBDFEF81D7E not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-AFBDFEF81D7E not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_1  | 2020-04-20 12:21:06,271 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-AFBDFEF81D7E:null
datanode_1  | 2020-04-20 12:21:06,271 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_1  | 
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-AFBDFEF81D7E not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-AFBDFEF81D7E not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_1  | 2020-04-20 12:21:11,224 [grpc-default-executor-2] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | 2020-04-20 12:21:11,224 [grpc-default-executor-2] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown FollowerState
datanode_1  | 2020-04-20 12:21:11,224 [Thread-145] INFO impl.FollowerState: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1  | 2020-04-20 12:21:11,224 [grpc-default-executor-2] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start FollowerState
datanode_1  | 2020-04-20 12:21:11,261 [grpc-default-executor-2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CF9DF1472EEF with new leaderId: 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | 2020-04-20 12:21:11,261 [grpc-default-executor-2] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF: change Leader from null to 258ceeb5-4c9c-49bf-b393-79534db322e4 at term 1 for appendEntries, leader elected after 5175ms
datanode_1  | 2020-04-20 12:21:11,276 [grpc-default-executor-2] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_1  | 2020-04-20 12:21:11,276 [grpc-default-executor-2] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-04-20 12:21:11,279 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cc7b5d95-9851-4876-8726-cf9df1472eef/current/log_inprogress_0
datanode_1  | 2020-04-20 12:21:37,847 [ChunkWriter-44-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: b40afd923a12cac5:7105a950cb9a80b:b40afd923a12cac5:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
recon_1     | 2020-04-20 12:21:37,863 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056Z]
recon_1     | 2020-04-20 12:21:37,863 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056Z] moved to CLOSED state
recon_1     | 2020-04-20 12:21:37,865 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : ContainerID 3 creation failed
recon_1     | 2020-04-20 12:21:37,865 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056Z]
recon_1     | 2020-04-20 12:21:37,873 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : ContainerID 3 creation failed
recon_1     | 2020-04-20 12:21:37,874 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056Z]
recon_1     | 2020-04-20 12:21:37,884 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-C1B291565344, cid=1
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "b40afd923a12cac5:7105a950cb9a80b:b40afd923a12cac5:0" containerID: 3 datanodeUuid: "bb3db77a-6a57-4c4e-bdc7-ea39008446e6" pipelineID: "cc7b5d95-9851-4876-8726-cf9df1472eef" writeChunk { blockID { containerID: 3 localID: 104030882799943682 blockCommitSequenceId: 0 } chunkData { chunkName: "104030882799943682_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
recon_1     | 2020-04-20 12:21:37,884 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056Z]
recon_1     | 2020-04-20 12:21:37,891 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-C1B291565344, cid=1
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "b40afd923a12cac5:7105a950cb9a80b:b40afd923a12cac5:0" containerID: 3 datanodeUuid: "bb3db77a-6a57-4c4e-bdc7-ea39008446e6" pipelineID: "cc7b5d95-9851-4876-8726-cf9df1472eef" writeChunk { blockID { containerID: 3 localID: 104030882799943682 blockCommitSequenceId: 0 } chunkData { chunkName: "104030882799943682_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
recon_1     | 2020-04-20 12:21:37,891 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056Z]
recon_1     | 2020-04-20 12:21:37,896 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-C1B291565344, cid=1
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "b40afd923a12cac5:7105a950cb9a80b:b40afd923a12cac5:0" containerID: 3 datanodeUuid: "bb3db77a-6a57-4c4e-bdc7-ea39008446e6" pipelineID: "cc7b5d95-9851-4876-8726-cf9df1472eef" writeChunk { blockID { containerID: 3 localID: 104030882799943682 blockCommitSequenceId: 0 } chunkData { chunkName: "104030882799943682_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:21:07,123 [IPC Server handler 8 on 9863] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-20 12:21:07,123 [IPC Server handler 8 on 9863] WARN block.BlockManagerImpl: Pipeline creation failed for type:RATIS factor:THREE. Datanodes may be used up.
scm_1       | org.apache.hadoop.hdds.scm.exceptions.SCMException: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:173)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:196)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:116)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:63)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:232)
scm_1       | 	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:200)
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:190)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:161)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:119)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:100)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1       | 2020-04-20 12:21:07,124 [IPC Server handler 8 on 9863] ERROR block.BlockManagerImpl: Unable to allocate a block for the size: 268435456, type: RATIS, factor: THREE
scm_1       | 2020-04-20 12:21:11,252 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056088Z] moved to OPEN state
scm_1       | 2020-04-20 12:21:22,110 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-20 12:21:22,112 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-20 12:21:37,862 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : ContainerID 3 creation failed
scm_1       | 2020-04-20 12:21:37,873 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056088Z]
scm_1       | 2020-04-20 12:21:37,873 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056088Z] moved to CLOSED state
scm_1       | 2020-04-20 12:21:37,875 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #3
scm_1       | 2020-04-20 12:21:37,875 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : ContainerID 3 creation failed
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-AFBDFEF81D7E not found.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 	... 4 more
datanode_2  | 2020-04-20 12:21:06,266 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-AFBDFEF81D7E:null
datanode_2  | 2020-04-20 12:21:06,266 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_2  | 
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-AFBDFEF81D7E not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-AFBDFEF81D7E not found.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 	... 4 more
datanode_2  | 2020-04-20 12:21:06,267 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-AFBDFEF81D7E:null
datanode_2  | 2020-04-20 12:21:06,267 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_2  | 
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-AFBDFEF81D7E not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-AFBDFEF81D7E not found.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 	... 4 more
datanode_2  | 2020-04-20 12:21:06,267 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-AFBDFEF81D7E:null
datanode_2  | 2020-04-20 12:21:06,268 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_2  | 
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-AFBDFEF81D7E not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-AFBDFEF81D7E not found.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 	... 4 more
datanode_2  | 2020-04-20 12:21:11,230 [grpc-default-executor-0] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_2  | 2020-04-20 12:21:11,230 [grpc-default-executor-0] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown FollowerState
datanode_2  | 2020-04-20 12:21:11,230 [grpc-default-executor-0] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start FollowerState
datanode_2  | 2020-04-20 12:21:11,230 [Thread-145] INFO impl.FollowerState: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2  | 2020-04-20 12:21:11,267 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CF9DF1472EEF with new leaderId: 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_2  | 2020-04-20 12:21:11,267 [grpc-default-executor-0] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF: change Leader from null to 258ceeb5-4c9c-49bf-b393-79534db322e4 at term 1 for appendEntries, leader elected after 5202ms
datanode_2  | 2020-04-20 12:21:11,268 [grpc-default-executor-0] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_2  | 2020-04-20 12:21:11,271 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:21:06,047 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-AFBDFEF81D7E as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_3  | 2020-04-20 12:21:06,047 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-StateMachineUpdater] ERROR impl.StateMachineUpdater: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-StateMachineUpdater: Failed to take snapshot
datanode_3  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-AFBDFEF81D7E as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:21:06,047 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E
datanode_3  | 2020-04-20 12:21:06,073 [grpc-default-executor-1] INFO impl.FollowerInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E->175c1ce4-a4bc-4858-9a69-a6ac92762c21: nextIndex: updateUnconditionally 3 -> 1
datanode_3  | Apr 20, 2020 12:21:06 PM org.apache.ratis.thirdparty.io.grpc.netty.NettyServerHandler onStreamError
datanode_3  | WARNING: Stream Error
datanode_3  | org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2Exception$StreamException: Received DATA frame for an unknown stream 3
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2Exception.streamError(Http2Exception.java:147)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder$FrameReadListener.shouldIgnoreHeadersOrDataFrame(DefaultHttp2ConnectionDecoder.java:591)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder$FrameReadListener.onDataRead(DefaultHttp2ConnectionDecoder.java:239)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2InboundFrameLogger$1.onDataRead(Http2InboundFrameLogger.java:48)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2FrameReader.readDataFrame(DefaultHttp2FrameReader.java:422)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2FrameReader.processPayloadState(DefaultHttp2FrameReader.java:251)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2FrameReader.readFrame(DefaultHttp2FrameReader.java:160)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2InboundFrameLogger.readFrame(Http2InboundFrameLogger.java:41)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder.decodeFrame(DefaultHttp2ConnectionDecoder.java:174)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2ConnectionHandler$FrameDecoder.decode(Http2ConnectionHandler.java:378)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2ConnectionHandler.decode(Http2ConnectionHandler.java:438)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:505)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:444)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:283)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=892362752 B) is less than the container size (=1073741824 B).
datanode_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_1  | 	... 13 more
datanode_1  | 2020-04-20 12:21:37,852 [ChunkWriter-44-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: b40afd923a12cac5:7105a950cb9a80b:b40afd923a12cac5:0 , Message: ContainerID 3 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 3 creation failed
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:21:37,853 [ChunkWriter-44-0] ERROR ratis.ContainerStateMachine: group-CF9DF1472EEF: writeChunk writeStateMachineData failed: blockIdcontainerID: 3
datanode_1  | localID: 104030882799943682
datanode_1  | blockCommitSequenceId: 0
datanode_1  |  logIndex 1 chunkName 104030882799943682_chunk_1 Error message: ContainerID 3 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_1  | 2020-04-20 12:21:37,853 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef.Reason : ContainerID 3 creation failed
datanode_1  | 2020-04-20 12:21:37,887 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-C1B291565344, cid=1
datanode_1  | 	 State Machine: cmdType: WriteChunk traceID: "b40afd923a12cac5:7105a950cb9a80b:b40afd923a12cac5:0" containerID: 3 datanodeUuid: "bb3db77a-6a57-4c4e-bdc7-ea39008446e6" pipelineID: "cc7b5d95-9851-4876-8726-cf9df1472eef" writeChunk { blockID { containerID: 3 localID: 104030882799943682 blockCommitSequenceId: 0 } chunkData { chunkName: "104030882799943682_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 2020-04-20 12:22:07,085 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #3 does not exist in datanode. Container close failed.
datanode_1  | 2020-04-20 12:23:08,889 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove  FOLLOWER bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF:t1, leader=258ceeb5-4c9c-49bf-b393-79534db322e4, voted=258ceeb5-4c9c-49bf-b393-79534db322e4, raftlog=bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
datanode_1  | 2020-04-20 12:23:08,889 [Command processor thread] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF: shutdown
datanode_1  | 2020-04-20 12:23:08,889 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CF9DF1472EEF,id=bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:23:08,889 [Command processor thread] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown FollowerState
datanode_1  | 2020-04-20 12:23:08,889 [Command processor thread] INFO impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-StateMachineUpdater: set stopIndex = 0
datanode_1  | 2020-04-20 12:23:08,889 [Thread-148] INFO impl.FollowerState: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1  | 2020-04-20 12:23:08,890 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-CF9DF1472EEF as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | 2020-04-20 12:23:08,890 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-StateMachineUpdater] ERROR impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-StateMachineUpdater: Failed to take snapshot
datanode_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-CF9DF1472EEF as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:23:08,891 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-CF9DF1472EEF as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | 2020-04-20 12:23:08,891 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-StateMachineUpdater] ERROR impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-StateMachineUpdater: Failed to take snapshot
datanode_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-CF9DF1472EEF as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
recon_1     | 2020-04-20 12:21:37,897 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056Z]
recon_1     | 2020-04-20 12:22:23,603 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-20 12:22:23,604 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-20 12:22:23,608 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 4
recon_1     | 2020-04-20 12:22:23,612 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2020-04-20 12:22:23,665 [pool-9-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-20 12:22:25,468 [MissingContainerTask] INFO fsck.MissingContainerTask: Missing Container task Thread took 5 milliseconds for processing 0 containers.
recon_1     | 2020-04-20 12:22:43,863 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056Z] removed from db
recon_1     | 2020-04-20 12:22:43,866 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056Z]
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:22:43,874 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056Z]
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:22:43,884 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056Z]
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1421)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
datanode_3  | 	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 
datanode_3  | 2020-04-20 12:21:06,093 [Command processor thread] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E: closes. applyIndex: 0
datanode_3  | 2020-04-20 12:21:06,093 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_3  | 2020-04-20 12:21:06,095 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E-SegmentedRaftLogWorker close()
datanode_3  | 2020-04-20 12:21:06,098 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:21:06,098 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E
datanode_3  | 2020-04-20 12:21:06,098 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.258ceeb5-4c9c-49bf-b393-79534db322e4@group-AFBDFEF81D7E
datanode_3  | 2020-04-20 12:21:06,099 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_3  |  command on datanode #258ceeb5-4c9c-49bf-b393-79534db322e4.
datanode_3  | 2020-04-20 12:21:06,100 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: addNew group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-CF9DF1472EEF:java.util.concurrent.CompletableFuture@4bc2c819[Not completed]
datanode_3  | 2020-04-20 12:21:06,102 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4: new RaftServerImpl for group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-04-20 12:21:06,109 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-04-20 12:21:06,109 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-04-20 12:21:06,109 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-04-20 12:21:06,109 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-04-20 12:21:06,109 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-20 12:21:06,109 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-04-20 12:21:06,110 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-20 12:21:06,110 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-04-20 12:21:06,111 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/cc7b5d95-9851-4876-8726-cf9df1472eef does not exist. Creating ...
datanode_3  | 2020-04-20 12:21:06,117 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cc7b5d95-9851-4876-8726-cf9df1472eef/in_use.lock acquired by nodename 6@78409bf0b6e2
datanode_3  | 2020-04-20 12:21:06,120 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/cc7b5d95-9851-4876-8726-cf9df1472eef has been successfully formatted.
datanode_3  | 2020-04-20 12:21:06,120 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-CF9DF1472EEF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-04-20 12:21:06,120 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-04-20 12:21:06,121 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-04-20 12:21:06,121 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-04-20 12:21:06,121 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-20 12:21:06,123 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-20 12:21:06,123 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:21:06,124 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-04-20 12:21:06,124 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/cc7b5d95-9851-4876-8726-cf9df1472eef
datanode_3  | 2020-04-20 12:21:06,125 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-04-20 12:21:06,126 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-04-20 12:21:06,126 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2020-04-20 12:21:37,880 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056088Z]
scm_1       | 2020-04-20 12:21:37,881 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : ContainerID 3 creation failed
scm_1       | 2020-04-20 12:21:37,881 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056088Z]
scm_1       | 2020-04-20 12:21:37,895 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-C1B291565344, cid=1
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "b40afd923a12cac5:7105a950cb9a80b:b40afd923a12cac5:0" containerID: 3 datanodeUuid: "bb3db77a-6a57-4c4e-bdc7-ea39008446e6" pipelineID: "cc7b5d95-9851-4876-8726-cf9df1472eef" writeChunk { blockID { containerID: 3 localID: 104030882799943682 blockCommitSequenceId: 0 } chunkData { chunkName: "104030882799943682_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
scm_1       | 2020-04-20 12:21:37,895 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056088Z]
scm_1       | 2020-04-20 12:21:37,899 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-C1B291565344, cid=1
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "b40afd923a12cac5:7105a950cb9a80b:b40afd923a12cac5:0" containerID: 3 datanodeUuid: "bb3db77a-6a57-4c4e-bdc7-ea39008446e6" pipelineID: "cc7b5d95-9851-4876-8726-cf9df1472eef" writeChunk { blockID { containerID: 3 localID: 104030882799943682 blockCommitSequenceId: 0 } chunkData { chunkName: "104030882799943682_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
scm_1       | 2020-04-20 12:21:37,899 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056088Z]
scm_1       | 2020-04-20 12:21:37,899 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-C1B291565344, cid=1
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "b40afd923a12cac5:7105a950cb9a80b:b40afd923a12cac5:0" containerID: 3 datanodeUuid: "bb3db77a-6a57-4c4e-bdc7-ea39008446e6" pipelineID: "cc7b5d95-9851-4876-8726-cf9df1472eef" writeChunk { blockID { containerID: 3 localID: 104030882799943682 blockCommitSequenceId: 0 } chunkData { chunkName: "104030882799943682_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
scm_1       | 2020-04-20 12:21:37,899 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056088Z]
scm_1       | 2020-04-20 12:22:34,537 [Thread-338] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1       | 2020-04-20 12:22:34,543 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 4 milliseconds for processing 3 containers.
scm_1       | 2020-04-20 12:22:43,875 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:22:43,875 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:22:43,875 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:22:43,875 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056088Z] removed from db
scm_1       | 2020-04-20 12:22:43,876 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:22:43,892 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056Z]
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:22:43,897 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056Z]
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:23:07,910 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef. Trying to get from SCM.
recon_1     | 2020-04-20 12:23:07,923 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
recon_1     |   id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
recon_1     | }
recon_1     | isLeader: false
recon_1     | bytesWritten: 0
recon_1     |  from dn=bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null} {}
recon_1     | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException): PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
recon_1     | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
recon_1     | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1     | 
recon_1     | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:23:08,891 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF
datanode_1  | 2020-04-20 12:23:08,892 [Command processor thread] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF: closes. applyIndex: 0
datanode_1  | 2020-04-20 12:23:08,896 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_1  | 2020-04-20 12:23:08,897 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF-SegmentedRaftLogWorker close()
datanode_1  | 2020-04-20 12:23:08,898 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:23:08,898 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF
datanode_1  | 2020-04-20 12:23:08,898 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-CF9DF1472EEF
datanode_1  | 2020-04-20 12:23:08,899 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_1  |  command on datanode #bb3db77a-6a57-4c4e-bdc7-ea39008446e6.
datanode_1  | 2020-04-20 12:23:08,900 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: addNew group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-DFF8A315EADB:java.util.concurrent.CompletableFuture@db9b189[Not completed]
datanode_1  | 2020-04-20 12:23:08,904 [grpc-default-executor-2] INFO server.GrpcServerProtocolService: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Completed APPEND_ENTRIES, lastRequest: 258ceeb5-4c9c-49bf-b393-79534db322e4->bb3db77a-6a57-4c4e-bdc7-ea39008446e6#13-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-C1B291565344, cid=2
datanode_1  | 2020-04-20 12:23:08,910 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: new RaftServerImpl for group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-04-20 12:23:08,910 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-04-20 12:23:08,913 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-04-20 12:23:08,913 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-04-20 12:23:08,913 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-04-20 12:23:08,913 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-04-20 12:23:08,913 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-04-20 12:23:08,913 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-04-20 12:23:08,914 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-04-20 12:23:08,914 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b47aa9e4-1bde-4d0a-825f-dff8a315eadb does not exist. Creating ...
datanode_1  | 2020-04-20 12:23:08,915 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b47aa9e4-1bde-4d0a-825f-dff8a315eadb/in_use.lock acquired by nodename 6@69674aa52266
datanode_1  | 2020-04-20 12:23:08,918 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b47aa9e4-1bde-4d0a-825f-dff8a315eadb has been successfully formatted.
datanode_1  | 2020-04-20 12:23:08,918 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-DFF8A315EADB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-04-20 12:23:08,918 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-04-20 12:23:08,918 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-04-20 12:23:08,918 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-04-20 12:23:08,923 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-20 12:23:08,923 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-20 12:23:08,923 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:23:08,935 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-04-20 12:23:08,935 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/b47aa9e4-1bde-4d0a-825f-dff8a315eadb
datanode_1  | 2020-04-20 12:23:08,935 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-04-20 12:23:08,935 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-04-20 12:23:08,935 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-20 12:23:08,935 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-04-20 12:23:08,935 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-04-20 12:23:08,935 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-04-20 12:23:08,935 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-04-20 12:23:08,935 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-04-20 12:23:08,935 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-04-20 12:23:08,936 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-04-20 12:23:08,936 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-04-20 12:23:08,938 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-04-20 12:23:08,941 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-04-20 12:23:08,942 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-04-20 12:23:08,943 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-04-20 12:23:08,943 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
recon_1     | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:123)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:114)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.getPipeline(StorageContainerLocationProtocolClientSideTranslatorPB.java:347)
recon_1     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
recon_1     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
recon_1     | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
recon_1     | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
recon_1     | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:71)
recon_1     | 	at com.sun.proxy.$Proxy42.getPipeline(Unknown Source)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getPipeline(StorageContainerServiceProviderImpl.java:55)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineReportHandler.processPipelineReport(ReconPipelineReportHandler.java:65)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:84)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:47)
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:23:08,923 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb. Trying to get from SCM.
recon_1     | 2020-04-20 12:23:08,928 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:22:43.877Z] to Recon pipeline metadata.
recon_1     | 2020-04-20 12:23:08,929 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:22:43.877Z]
recon_1     | 2020-04-20 12:23:08,929 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb reported by bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:23:08,948 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb reported by 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:23:08,982 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb reported by 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:23:14,049 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb reported by 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-20 12:23:14,049 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877Z] moved to OPEN state
recon_1     | 2020-04-20 12:23:23,670 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-20 12:23:23,671 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-20 12:23:23,718 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 3
recon_1     | 2020-04-20 12:23:23,724 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2020-04-20 12:23:23,809 [pool-9-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-20 12:23:28,948 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : ContainerID 4 creation failed
recon_1     | 2020-04-20 12:23:28,950 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877Z]
datanode_2  | 2020-04-20 12:21:11,273 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cc7b5d95-9851-4876-8726-cf9df1472eef/current/log_inprogress_0
datanode_2  | 2020-04-20 12:21:37,845 [ChunkWriter-53-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: b40afd923a12cac5:7105a950cb9a80b:b40afd923a12cac5:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_2  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=892366848 B) is less than the container size (=1073741824 B).
datanode_2  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_2  | 	... 13 more
datanode_2  | 2020-04-20 12:21:37,845 [ChunkWriter-53-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: b40afd923a12cac5:7105a950cb9a80b:b40afd923a12cac5:0 , Message: ContainerID 3 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_2  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 3 creation failed
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:21:37,846 [ChunkWriter-53-0] ERROR ratis.ContainerStateMachine: group-CF9DF1472EEF: writeChunk writeStateMachineData failed: blockIdcontainerID: 3
datanode_2  | localID: 104030882799943682
datanode_2  | blockCommitSequenceId: 0
datanode_2  |  logIndex 1 chunkName 104030882799943682_chunk_1 Error message: ContainerID 3 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_2  | 2020-04-20 12:21:37,848 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef.Reason : ContainerID 3 creation failed
datanode_2  | 2020-04-20 12:21:37,889 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-C1B291565344, cid=1
datanode_2  | 	 State Machine: cmdType: WriteChunk traceID: "b40afd923a12cac5:7105a950cb9a80b:b40afd923a12cac5:0" containerID: 3 datanodeUuid: "bb3db77a-6a57-4c4e-bdc7-ea39008446e6" pipelineID: "cc7b5d95-9851-4876-8726-cf9df1472eef" writeChunk { blockID { containerID: 3 localID: 104030882799943682 blockCommitSequenceId: 0 } chunkData { chunkName: "104030882799943682_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_2  | 2020-04-20 12:22:07,071 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #3 does not exist in datanode. Container close failed.
datanode_2  | 2020-04-20 12:23:08,892 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove  FOLLOWER 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF:t1, leader=258ceeb5-4c9c-49bf-b393-79534db322e4, voted=258ceeb5-4c9c-49bf-b393-79534db322e4, raftlog=175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
datanode_2  | 2020-04-20 12:23:08,892 [Command processor thread] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF: shutdown
datanode_2  | 2020-04-20 12:23:08,893 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CF9DF1472EEF,id=175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:23:08,893 [Command processor thread] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown FollowerState
datanode_2  | 2020-04-20 12:23:08,893 [Thread-148] INFO impl.FollowerState: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2  | 2020-04-20 12:23:08,894 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-CF9DF1472EEF as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 2020-04-20 12:23:08,894 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-StateMachineUpdater] ERROR impl.StateMachineUpdater: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-StateMachineUpdater: Failed to take snapshot
datanode_2  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-CF9DF1472EEF as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
scm_1       | 2020-04-20 12:22:43,877 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb to datanode:258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:22:43,877 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb to datanode:175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:22:43,877 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb to datanode:bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:22:43,877 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:22:43.877043Z]
scm_1       | 2020-04-20 12:22:43,877 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-20 12:22:43,881 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:22:43,881 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:22:43,881 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:22:43,881 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056088Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:22:43,881 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:22:43,881 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:22:43,881 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:22:43,881 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056088Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:22:43,896 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:22:43,896 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:22:43,896 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:22:43,896 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056088Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:22:43,899 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:22:43,900 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:22:43,900 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:22:43,900 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056088Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 2020-04-20 12:23:28,950 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877Z] moved to CLOSED state
recon_1     | 2020-04-20 12:23:28,953 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-F1305EE27D8B, cid=1
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "ecec66793606d963:831a297635280820:ecec66793606d963:0" containerID: 4 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb" writeChunk { blockID { containerID: 4 localID: 104030890075553795 blockCommitSequenceId: 0 } chunkData { chunkName: "104030890075553795_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
recon_1     | 2020-04-20 12:23:28,954 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877Z]
recon_1     | 2020-04-20 12:23:28,958 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : ContainerID 4 creation failed
recon_1     | 2020-04-20 12:23:28,958 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877Z]
recon_1     | 2020-04-20 12:23:28,964 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : ContainerID 4 creation failed
recon_1     | 2020-04-20 12:23:28,964 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877Z]
recon_1     | 2020-04-20 12:23:28,974 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-F1305EE27D8B, cid=1
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "ecec66793606d963:831a297635280820:ecec66793606d963:0" containerID: 4 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb" writeChunk { blockID { containerID: 4 localID: 104030890075553795 blockCommitSequenceId: 0 } chunkData { chunkName: "104030890075553795_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
recon_1     | 2020-04-20 12:23:28,974 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877Z]
recon_1     | 2020-04-20 12:23:28,980 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-F1305EE27D8B, cid=1
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "ecec66793606d963:831a297635280820:ecec66793606d963:0" containerID: 4 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb" writeChunk { blockID { containerID: 4 localID: 104030890075553795 blockCommitSequenceId: 0 } chunkData { chunkName: "104030890075553795_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
recon_1     | 2020-04-20 12:23:28,981 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877Z]
recon_1     | 2020-04-20 12:24:23,815 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-20 12:24:23,816 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_3  | 2020-04-20 12:21:06,126 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-04-20 12:21:06,126 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-04-20 12:21:06,131 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-04-20 12:21:06,131 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-04-20 12:21:06,131 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-04-20 12:21:06,132 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-04-20 12:21:06,133 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-04-20 12:21:06,135 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-04-20 12:21:06,141 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-04-20 12:21:06,142 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-04-20 12:21:06,143 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-04-20 12:21:06,143 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-04-20 12:21:06,143 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF
datanode_3  | 2020-04-20 12:21:06,143 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF
datanode_3  | 2020-04-20 12:21:06,149 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 2020-04-20 12:21:06,149 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-04-20 12:21:06,149 [pool-69-thread-1] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start FollowerState
datanode_3  | 2020-04-20 12:21:06,155 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CF9DF1472EEF,id=258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:21:06,157 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF
datanode_3  | 2020-04-20 12:21:06,232 [grpc-default-executor-2] WARN impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed groupAdd* GroupManagementRequest:client-E18566A6780E->258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF, cid=3, seq=0, RW, null, Add:group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3  | 	... 13 more
datanode_3  | 2020-04-20 12:21:06,239 [grpc-default-executor-2] WARN impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed groupAdd* GroupManagementRequest:client-A99ACDB2C3EE->258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF, cid=5, seq=0, RW, null, Add:group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-CF9DF1472EEF:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3  | 	... 13 more
datanode_3  | 2020-04-20 12:21:06,255 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_3  | .
datanode_3  | 2020-04-20 12:21:06,257 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-AFBDFEF81D7E:null
datanode_3  | 2020-04-20 12:21:06,257 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_3  | 
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-AFBDFEF81D7E not found.
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:22:43,900 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:22:43,901 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:22:43,901 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:22:43,901 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: cc7b5d95-9851-4876-8726-cf9df1472eef, Nodes: bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:258ceeb5-4c9c-49bf-b393-79534db322e4, CreationTimestamp2020-04-20T12:20:41.056088Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:23:08,894 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-CF9DF1472EEF as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 2020-04-20 12:23:08,895 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-StateMachineUpdater] ERROR impl.StateMachineUpdater: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-StateMachineUpdater: Failed to take snapshot
datanode_2  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-CF9DF1472EEF as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:23:08,894 [Command processor thread] INFO impl.StateMachineUpdater: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-StateMachineUpdater: set stopIndex = 0
datanode_2  | 2020-04-20 12:23:08,897 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF
datanode_2  | 2020-04-20 12:23:08,898 [Command processor thread] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF: closes. applyIndex: 0
datanode_2  | 2020-04-20 12:23:08,901 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_2  | 2020-04-20 12:23:08,904 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Completed APPEND_ENTRIES, lastRequest: 258ceeb5-4c9c-49bf-b393-79534db322e4->175c1ce4-a4bc-4858-9a69-a6ac92762c21#13-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-C1B291565344, cid=2
datanode_2  | 2020-04-20 12:23:08,906 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF-SegmentedRaftLogWorker close()
datanode_2  | 2020-04-20 12:23:08,907 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:23:08,907 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF
datanode_2  | 2020-04-20 12:23:08,907 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-CF9DF1472EEF
datanode_2  | 2020-04-20 12:23:08,908 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_2  |  command on datanode #175c1ce4-a4bc-4858-9a69-a6ac92762c21.
datanode_2  | 2020-04-20 12:23:08,915 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: new RaftServerImpl for group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-04-20 12:23:08,916 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: addNew group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-DFF8A315EADB:java.util.concurrent.CompletableFuture@1a3709bb[Not completed]
datanode_2  | 2020-04-20 12:23:08,919 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-04-20 12:23:08,919 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-04-20 12:23:08,919 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-04-20 12:23:08,920 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-04-20 12:23:08,922 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-04-20 12:23:08,923 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-04-20 12:23:08,924 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-20 12:23:08,924 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-04-20 12:23:08,925 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b47aa9e4-1bde-4d0a-825f-dff8a315eadb does not exist. Creating ...
datanode_2  | 2020-04-20 12:23:08,933 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b47aa9e4-1bde-4d0a-825f-dff8a315eadb/in_use.lock acquired by nodename 6@f98376242d82
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:23:07,917 [IPC Server handler 8 on 9860] INFO ipc.Server: IPC Server handler 8 on 9860, call Call#16 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.21.0.5:57120
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1       | 2020-04-20 12:23:09,958 [IPC Server handler 8 on 9863] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-20 12:23:09,959 [IPC Server handler 8 on 9863] WARN block.BlockManagerImpl: Pipeline creation failed for type:RATIS factor:THREE. Datanodes may be used up.
scm_1       | org.apache.hadoop.hdds.scm.exceptions.SCMException: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:173)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:196)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:116)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:63)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:232)
scm_1       | 	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:200)
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:190)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:161)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:119)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:100)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1       | 2020-04-20 12:23:09,959 [IPC Server handler 8 on 9863] ERROR block.BlockManagerImpl: Unable to allocate a block for the size: 268435456, type: RATIS, factor: THREE
scm_1       | 2020-04-20 12:23:14,060 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877043Z] moved to OPEN state
scm_1       | 2020-04-20 12:23:22,113 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-20 12:23:22,114 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-20 12:23:28,949 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : ContainerID 4 creation failed
scm_1       | 2020-04-20 12:23:28,950 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877043Z]
scm_1       | 2020-04-20 12:23:28,950 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877043Z] moved to CLOSED state
scm_1       | 2020-04-20 12:23:28,950 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #4
scm_1       | 2020-04-20 12:23:28,955 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-F1305EE27D8B, cid=1
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "ecec66793606d963:831a297635280820:ecec66793606d963:0" containerID: 4 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb" writeChunk { blockID { containerID: 4 localID: 104030890075553795 blockCommitSequenceId: 0 } chunkData { chunkName: "104030890075553795_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
scm_1       | 2020-04-20 12:23:28,955 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877043Z]
scm_1       | 2020-04-20 12:23:28,959 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : ContainerID 4 creation failed
scm_1       | 2020-04-20 12:23:28,959 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877043Z]
scm_1       | 2020-04-20 12:23:28,974 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-F1305EE27D8B, cid=1
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "ecec66793606d963:831a297635280820:ecec66793606d963:0" containerID: 4 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb" writeChunk { blockID { containerID: 4 localID: 104030890075553795 blockCommitSequenceId: 0 } chunkData { chunkName: "104030890075553795_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
scm_1       | 2020-04-20 12:23:28,975 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877043Z]
scm_1       | 2020-04-20 12:23:28,981 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : ContainerID 4 creation failed
scm_1       | 2020-04-20 12:23:28,982 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877043Z]
scm_1       | 2020-04-20 12:23:28,984 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-F1305EE27D8B, cid=1
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "ecec66793606d963:831a297635280820:ecec66793606d963:0" containerID: 4 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb" writeChunk { blockID { containerID: 4 localID: 104030890075553795 blockCommitSequenceId: 0 } chunkData { chunkName: "104030890075553795_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
scm_1       | 2020-04-20 12:23:28,984 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877043Z]
scm_1       | 2020-04-20 12:24:34,951 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:24:34,951 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:24:34,952 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:24:34,952 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877043Z] removed from db
scm_1       | 2020-04-20 12:24:34,952 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-20 12:24:34,955 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 to datanode:258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:24:34,956 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 to datanode:bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:24:34,957 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 to datanode:175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 2020-04-20 12:24:34,957 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:24:34.955632Z]
scm_1       | 2020-04-20 12:24:34,957 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-20 12:24:34,957 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-AFBDFEF81D7E not found.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 	... 4 more
datanode_3  | 2020-04-20 12:21:06,257 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-AFBDFEF81D7E:null
datanode_3  | 2020-04-20 12:21:06,258 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_3  | 
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-AFBDFEF81D7E not found.
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-AFBDFEF81D7E not found.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 	... 4 more
datanode_3  | 2020-04-20 12:21:06,258 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-AFBDFEF81D7E:null
datanode_3  | 2020-04-20 12:21:06,258 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_3  | 
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-AFBDFEF81D7E not found.
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-AFBDFEF81D7E not found.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 	... 4 more
datanode_3  | 2020-04-20 12:21:06,258 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-AFBDFEF81D7E:null
datanode_3  | 2020-04-20 12:21:06,259 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
datanode_3  | 
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-AFBDFEF81D7E not found.
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 2020-04-20 12:23:08,936 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b47aa9e4-1bde-4d0a-825f-dff8a315eadb has been successfully formatted.
datanode_2  | 2020-04-20 12:23:08,938 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-DFF8A315EADB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-04-20 12:23:08,940 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-04-20 12:23:08,940 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-04-20 12:23:08,940 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-04-20 12:23:08,941 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-20 12:23:08,941 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-20 12:23:08,941 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:23:08,941 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-04-20 12:23:08,942 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/b47aa9e4-1bde-4d0a-825f-dff8a315eadb
datanode_2  | 2020-04-20 12:23:08,942 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-04-20 12:23:08,944 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-04-20 12:23:08,947 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-20 12:23:08,962 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-04-20 12:23:08,962 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-04-20 12:23:08,962 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-04-20 12:23:08,962 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-04-20 12:23:08,962 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-04-20 12:23:08,963 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-04-20 12:23:08,964 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-04-20 12:23:08,975 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-04-20 12:23:08,976 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-04-20 12:23:08,976 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-04-20 12:23:08,976 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-04-20 12:23:08,976 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-04-20 12:23:08,976 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB
datanode_2  | 2020-04-20 12:23:08,977 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB
datanode_2  | 2020-04-20 12:23:08,977 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_2  | 2020-04-20 12:23:08,977 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-04-20 12:23:08,977 [pool-69-thread-1] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start FollowerState
datanode_2  | 2020-04-20 12:23:08,977 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DFF8A315EADB,id=175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:23:08,978 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB
datanode_2  | 2020-04-20 12:23:09,044 [grpc-default-executor-0] WARN impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed groupAdd* GroupManagementRequest:client-8381F09D61B8->175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB, cid=6, seq=0, RW, null, Add:group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2  | 	... 13 more
datanode_2  | 2020-04-20 12:23:09,084 [grpc-default-executor-0] WARN impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed groupAdd* GroupManagementRequest:client-DAEA84FA8BF9->175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB, cid=7, seq=0, RW, null, Add:group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
scm_1       | 2020-04-20 12:24:34,958 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_1  | 2020-04-20 12:23:08,944 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
recon_1     | 2020-04-20 12:24:23,823 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 1
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
scm_1       | 2020-04-20 12:24:34,958 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:23:08,944 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
recon_1     | 2020-04-20 12:24:34,953 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877Z] removed from db
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
scm_1       | 2020-04-20 12:24:34,959 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877043Z]
datanode_1  | 2020-04-20 12:23:08,945 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
recon_1     | 2020-04-20 12:24:34,955 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877Z]
datanode_2  | 	... 13 more
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb not found
datanode_1  | 2020-04-20 12:23:08,947 [pool-69-thread-1] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start FollowerState
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb not found
datanode_2  | 2020-04-20 12:23:09,100 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_1  | 2020-04-20 12:23:08,956 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DFF8A315EADB,id=bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-AFBDFEF81D7E not found.
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_2  | .
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_1  | 2020-04-20 12:23:08,956 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_2  | 2020-04-20 12:23:09,100 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-CF9DF1472EEF:null
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_1  | 2020-04-20 12:23:09,074 [grpc-default-executor-2] WARN impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed groupAdd* GroupManagementRequest:client-EDC3F8F51EFA->bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB, cid=5, seq=0, RW, null, Add:group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_2  | 2020-04-20 12:23:09,100 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_2  | 
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-CF9DF1472EEF not found.
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | 	... 4 more
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | 2020-04-20 12:21:06,259 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-AFBDFEF81D7E:null
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 2020-04-20 12:21:06,260 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "d762918c-eef0-4ec1-86d1-afbdfef81d7e"
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-AFBDFEF81D7E not found.
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-CF9DF1472EEF not found.
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1       | 2020-04-20 12:24:34,959 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
recon_1     | 2020-04-20 12:24:34,959 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877Z]
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1       | 2020-04-20 12:24:34,959 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb not found
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1       | 2020-04-20 12:24:34,960 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-AFBDFEF81D7E not found.
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_2  | 	... 4 more
scm_1       | 2020-04-20 12:24:34,960 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877043Z]
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_2  | 2020-04-20 12:23:09,100 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-CF9DF1472EEF:null
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb not found
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_2  | 2020-04-20 12:23:09,101 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_2  | 
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-CF9DF1472EEF not found.
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	... 4 more
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 2020-04-20 12:21:11,202 [Thread-75] INFO impl.FollowerState: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-FollowerState: change to CANDIDATE, lastRpcTime:5052ms, electionTimeout:5045ms
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | 2020-04-20 12:21:11,203 [Thread-75] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown FollowerState
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3  | 2020-04-20 12:21:11,203 [Thread-75] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	... 13 more
datanode_3  | 2020-04-20 12:21:11,203 [Thread-75] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start LeaderElection
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:23:09,095 [grpc-default-executor-2] WARN impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed groupAdd* GroupManagementRequest:client-9E449CB51E0F->bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB, cid=7, seq=0, RW, null, Add:group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_3  | 2020-04-20 12:21:11,210 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO impl.LeaderElection: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4: begin an election at term 1 for -1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-CF9DF1472EEF not found.
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 2020-04-20 12:21:11,245 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO impl.LeaderElection: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4: Election PASSED; received 1 response(s) [258ceeb5-4c9c-49bf-b393-79534db322e4<-bb3db77a-6a57-4c4e-bdc7-ea39008446e6#0:OK-t1] and 0 exception(s); 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF:t1, leader=null, voted=258ceeb5-4c9c-49bf-b393-79534db322e4, raftlog=258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 2020-04-20 12:21:11,245 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown LeaderElection
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | 2020-04-20 12:21:11,245 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 2020-04-20 12:24:34,965 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877Z]
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | 2020-04-20 12:21:11,245 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CF9DF1472EEF with new leaderId: 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb not found
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 2020-04-20 12:21:11,246 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF: change Leader from null to 258ceeb5-4c9c-49bf-b393-79534db322e4 at term 1 for becomeLeader, leader elected after 5124ms
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_2  | 	... 4 more
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 2020-04-20 12:21:11,246 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_2  | 2020-04-20 12:23:09,101 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-CF9DF1472EEF:null
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | 2020-04-20 12:21:11,246 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1       | 2020-04-20 12:24:34,978 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_2  | 2020-04-20 12:23:09,101 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 2020-04-20 12:21:11,246 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF
scm_1       | 2020-04-20 12:24:34,978 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_2  | 
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3  | 2020-04-20 12:21:11,247 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
scm_1       | 2020-04-20 12:24:34,978 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-CF9DF1472EEF not found.
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3  | 2020-04-20 12:21:11,247 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
scm_1       | 2020-04-20 12:24:34,978 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877043Z]
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3  | 2020-04-20 12:21:11,247 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb not found
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 2020-04-20 12:21:11,247 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | 2020-04-20 12:21:11,247 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 2020-04-20 12:21:11,247 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:21:11,249 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-CF9DF1472EEF not found.
datanode_3  | 2020-04-20 12:21:11,249 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 2020-04-20 12:21:11,249 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:24:34,975 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877Z]
datanode_3  | 2020-04-20 12:21:11,249 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb not found
datanode_3  | 2020-04-20 12:21:11,249 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	... 4 more
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_3  | 2020-04-20 12:21:11,251 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_2  | 2020-04-20 12:23:09,101 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-CF9DF1472EEF:null
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 	... 13 more
datanode_3  | 2020-04-20 12:21:11,251 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 2020-04-20 12:23:09,096 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_2  | 2020-04-20 12:23:09,101 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_3  | 2020-04-20 12:21:11,252 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | .
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_2  | 
datanode_3  | 2020-04-20 12:21:11,252 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:23:09,096 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-CF9DF1472EEF:null
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-CF9DF1472EEF not found.
datanode_3  | 2020-04-20 12:21:11,253 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
scm_1       | 2020-04-20 12:24:34,982 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | 2020-04-20 12:23:09,096 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 2020-04-20 12:21:11,253 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 2020-04-20 12:24:34,982 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_1  | 
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 2020-04-20 12:21:11,253 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start LeaderState
scm_1       | 2020-04-20 12:24:34,982 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-CF9DF1472EEF not found.
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 2020-04-20 12:21:11,254 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-SegmentedRaftLogWorker: Starting segment from index:0
scm_1       | 2020-04-20 12:24:34,983 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877043Z]
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 2020-04-20 12:21:11,258 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-LeaderElection4] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb not found
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:21:11,258 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cc7b5d95-9851-4876-8726-cf9df1472eef/current/log_inprogress_0
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-CF9DF1472EEF not found.
datanode_3  | 2020-04-20 12:21:37,839 [ChunkWriter-12-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: b40afd923a12cac5:7105a950cb9a80b:b40afd923a12cac5:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-CF9DF1472EEF not found.
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
recon_1     | 2020-04-20 12:24:34,981 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877Z]
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb not found
datanode_2  | 	... 4 more
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_2  | 2020-04-20 12:23:09,102 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-CF9DF1472EEF:null
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_2  | 2020-04-20 12:23:09,102 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	... 4 more
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_1  | 2020-04-20 12:23:09,096 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-CF9DF1472EEF:null
datanode_2  | 
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 2020-04-20 12:23:09,097 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-CF9DF1472EEF not found.
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-CF9DF1472EEF not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2020-04-20 12:24:34,985 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2020-04-20 12:24:34,985 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2020-04-20 12:24:34,985 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1       | 2020-04-20 12:24:34,985 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: b47aa9e4-1bde-4d0a-825f-dff8a315eadb, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:22:43.877043Z]
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-CF9DF1472EEF not found.
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=892375040 B) is less than the container size (=1073741824 B).
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb not found
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-CF9DF1472EEF not found.
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
recon_1     | 2020-04-20 12:24:58,954 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb. Trying to get from SCM.
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
recon_1     | 2020-04-20 12:24:58,971 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
datanode_3  | 	... 13 more
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
recon_1     |   id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
datanode_3  | 2020-04-20 12:21:37,840 [ChunkWriter-12-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: b40afd923a12cac5:7105a950cb9a80b:b40afd923a12cac5:0 , Message: ContainerID 3 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_2  | 	... 4 more
recon_1     | }
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 3 creation failed
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_2  | 2020-04-20 12:23:14,024 [Thread-211] INFO impl.FollowerState: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-FollowerState: change to CANDIDATE, lastRpcTime:5047ms, electionTimeout:5046ms
recon_1     | isLeader: false
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_1  | 	... 4 more
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_2  | 2020-04-20 12:23:14,025 [Thread-211] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown FollowerState
recon_1     | bytesWritten: 0
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1  | 2020-04-20 12:23:09,097 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-CF9DF1472EEF:null
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_2  | 2020-04-20 12:23:14,025 [Thread-211] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
recon_1     |  from dn=bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null} {}
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1  | 2020-04-20 12:23:09,098 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 2020-04-20 12:23:14,025 [Thread-211] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start LeaderElection
recon_1     | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException): PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb not found
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1  | 
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 2020-04-20 12:23:14,033 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO impl.LeaderElection: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3: begin an election at term 1 for -1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-CF9DF1472EEF not found.
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_2  | 2020-04-20 12:23:14,042 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO impl.LeaderElection: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3: Election PASSED; received 1 response(s) [175c1ce4-a4bc-4858-9a69-a6ac92762c21<-258ceeb5-4c9c-49bf-b393-79534db322e4#0:OK-t1] and 0 exception(s); 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB:t1, leader=null, voted=175c1ce4-a4bc-4858-9a69-a6ac92762c21, raftlog=175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 2020-04-20 12:23:14,042 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown LeaderElection
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 2020-04-20 12:23:14,042 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
recon_1     | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:23:14,043 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-DFF8A315EADB with new leaderId: 175c1ce4-a4bc-4858-9a69-a6ac92762c21
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1       | 2020-04-20 12:24:58,964 [IPC Server handler 3 on 9860] INFO ipc.Server: IPC Server handler 3 on 9860, call Call#20 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.21.0.5:57716
datanode_2  | 2020-04-20 12:23:14,050 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB: change Leader from null to 175c1ce4-a4bc-4858-9a69-a6ac92762c21 at term 1 for becomeLeader, leader elected after 5102ms
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
datanode_3  | 2020-04-20 12:21:37,840 [ChunkWriter-12-0] ERROR ratis.ContainerStateMachine: group-CF9DF1472EEF: writeChunk writeStateMachineData failed: blockIdcontainerID: 3
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb not found
datanode_2  | 2020-04-20 12:23:14,055 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
recon_1     | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
datanode_3  | localID: 104030882799943682
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-CF9DF1472EEF not found.
datanode_2  | 2020-04-20 12:23:14,056 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
datanode_3  | blockCommitSequenceId: 0
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 2020-04-20 12:23:14,056 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
datanode_3  |  logIndex 1 chunkName 104030882799943682_chunk_1 Error message: ContainerID 3 creation failed Container Result: DISK_OUT_OF_SPACE
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 2020-04-20 12:23:14,056 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
datanode_3  | 2020-04-20 12:21:37,840 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef.Reason : ContainerID 3 creation failed
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 2020-04-20 12:23:14,056 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
datanode_3  | 2020-04-20 12:21:37,882 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=cc7b5d95-9851-4876-8726-cf9df1472eef.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-C1B291565344, cid=1
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 2020-04-20 12:23:14,056 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
datanode_3  | 	 State Machine: cmdType: WriteChunk traceID: "b40afd923a12cac5:7105a950cb9a80b:b40afd923a12cac5:0" containerID: 3 datanodeUuid: "bb3db77a-6a57-4c4e-bdc7-ea39008446e6" pipelineID: "cc7b5d95-9851-4876-8726-cf9df1472eef" writeChunk { blockID { containerID: 3 localID: 104030882799943682 blockCommitSequenceId: 0 } chunkData { chunkName: "104030882799943682_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 	... 4 more
datanode_2  | 2020-04-20 12:23:14,056 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
datanode_3  | 2020-04-20 12:21:42,246 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #3 does not exist in datanode. Container close failed.
datanode_1  | 2020-04-20 12:23:09,099 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-CF9DF1472EEF:null
datanode_2  | 2020-04-20 12:23:14,057 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
datanode_3  | 2020-04-20 12:22:37,839 [java.util.concurrent.ThreadPoolExecutor$Worker@331ecfe1[State = -1, empty queue]] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=12,entriesCount=1,lastEntry=(t:1, i:1)
datanode_1  | 2020-04-20 12:23:09,099 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_2  | 2020-04-20 12:23:14,062 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
datanode_3  | 2020-04-20 12:22:37,843 [java.util.concurrent.ThreadPoolExecutor$Worker@331ecfe1[State = -1, empty queue]] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF->175c1ce4-a4bc-4858-9a69-a6ac92762c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=12,entriesCount=1,lastEntry=(t:1, i:1)
datanode_1  | 
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_2  | 2020-04-20 12:23:14,062 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
datanode_3  | 2020-04-20 12:22:37,891 [java.util.concurrent.ThreadPoolExecutor$Worker@331ecfe1[State = -1, empty queue]] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF->175c1ce4-a4bc-4858-9a69-a6ac92762c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=13,entriesCount=1,lastEntry=(t:1, i:2)
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-CF9DF1472EEF not found.
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
datanode_2  | 2020-04-20 12:23:14,067 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
datanode_3  | 2020-04-20 12:22:37,891 [java.util.concurrent.ThreadPoolExecutor$Worker@331ecfe1[State = -1, empty queue]] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=13,entriesCount=1,lastEntry=(t:1, i:2)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
recon_1     | 
datanode_2  | 2020-04-20 12:23:14,071 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
datanode_3  | 2020-04-20 12:23:08,882 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove    LEADER 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF:t1, leader=258ceeb5-4c9c-49bf-b393-79534db322e4, voted=258ceeb5-4c9c-49bf-b393-79534db322e4, raftlog=258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 2020-04-20 12:23:14,077 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
datanode_3  | 2020-04-20 12:23:08,882 [Command processor thread] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF: shutdown
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
recon_1     | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
datanode_2  | 2020-04-20 12:23:14,077 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
datanode_3  | 2020-04-20 12:23:08,883 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CF9DF1472EEF,id=258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_2  | 2020-04-20 12:23:14,083 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_3  | 2020-04-20 12:23:08,883 [Command processor thread] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown LeaderState
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_2  | 2020-04-20 12:23:14,083 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-CF9DF1472EEF not found.
datanode_3  | 2020-04-20 12:23:08,883 [Command processor thread] INFO impl.PendingRequests: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-PendingRequests: sendNotLeaderResponses
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_2  | 2020-04-20 12:23:14,083 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 2020-04-20 12:23:08,883 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$443/0x0000000840592040@170fb32] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF->175c1ce4-a4bc-4858-9a69-a6ac92762c21-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_2  | 2020-04-20 12:23:14,083 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm_1       | 2020-04-20 12:24:58,973 [IPC Server handler 10 on 9860] INFO ipc.Server: IPC Server handler 10 on 9860, call Call#21 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.21.0.5:57716
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 2020-04-20 12:23:08,884 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF
recon_1     | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
datanode_2  | 2020-04-20 12:23:14,085 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb not found
datanode_3  | 2020-04-20 12:23:08,884 [Command processor thread] INFO impl.StateMachineUpdater: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-StateMachineUpdater: set stopIndex = 0
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:123)
datanode_2  | 2020-04-20 12:23:14,086 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_3  | 2020-04-20 12:23:08,883 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$443/0x0000000840592040@308aae09] WARN server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:114)
datanode_2  | 2020-04-20 12:23:14,091 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start LeaderState
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
datanode_3  | 2020-04-20 12:23:08,921 [grpc-default-executor-2] INFO server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_1  | 	... 4 more
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.getPipeline(StorageContainerLocationProtocolClientSideTranslatorPB.java:347)
datanode_2  | 2020-04-20 12:23:14,093 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-04-20 12:23:14,097 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b47aa9e4-1bde-4d0a-825f-dff8a315eadb/current/log_inprogress_0
datanode_3  | 2020-04-20 12:23:08,921 [grpc-default-executor-1] INFO server.GrpcLogAppender: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF->175c1ce4-a4bc-4858-9a69-a6ac92762c21-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_1  | 2020-04-20 12:23:09,099 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-CF9DF1472EEF:null
datanode_2  | 2020-04-20 12:23:14,106 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-LeaderElection3] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
recon_1     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
datanode_3  | 2020-04-20 12:23:08,921 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-CF9DF1472EEF as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | 2020-04-20 12:23:09,099 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_2  | 2020-04-20 12:23:28,922 [ChunkWriter-23-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: ecec66793606d963:831a297635280820:ecec66793606d963:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
recon_1     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
datanode_3  | 2020-04-20 12:23:08,921 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-StateMachineUpdater] ERROR impl.StateMachineUpdater: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-StateMachineUpdater: Failed to take snapshot
datanode_1  | 
datanode_2  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
recon_1     | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
datanode_3  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-CF9DF1472EEF as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-CF9DF1472EEF not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
recon_1     | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
recon_1     | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:71)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
recon_1     | 	at com.sun.proxy.$Proxy42.getPipeline(Unknown Source)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getPipeline(StorageContainerServiceProviderImpl.java:55)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineReportHandler.processPipelineReport(ReconPipelineReportHandler.java:65)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:84)
datanode_3  | 2020-04-20 12:23:08,934 [grpc-default-executor-2] INFO impl.FollowerInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF->bb3db77a-6a57-4c4e-bdc7-ea39008446e6: nextIndex: updateUnconditionally 3 -> 1
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-CF9DF1472EEF not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:47)
datanode_3  | 2020-04-20 12:23:08,938 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-CF9DF1472EEF as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
datanode_3  | 2020-04-20 12:23:08,938 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-StateMachineUpdater] ERROR impl.StateMachineUpdater: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-StateMachineUpdater: Failed to take snapshot
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-CF9DF1472EEF as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1  | 	... 4 more
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1     | 2020-04-20 12:24:58,972 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb. Trying to get from SCM.
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_1  | 2020-04-20 12:23:09,102 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-CF9DF1472EEF:null
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2020-04-20 12:25:01,042 [IPC Server handler 5 on 9863] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
recon_1     | 2020-04-20 12:24:58,974 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_1  | 2020-04-20 12:23:09,102 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:25:01,042 [IPC Server handler 5 on 9863] WARN block.BlockManagerImpl: Pipeline creation failed for type:RATIS factor:THREE. Datanodes may be used up.
recon_1     |   id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 
datanode_2  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=892076032 B) is less than the container size (=1073741824 B).
scm_1       | org.apache.hadoop.hdds.scm.exceptions.SCMException: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
recon_1     | }
datanode_3  | 2020-04-20 12:23:08,939 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-CF9DF1472EEF not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.filterViableNodes(PipelinePlacementPolicy.java:173)
recon_1     | isLeader: true
datanode_3  | 2020-04-20 12:23:08,939 [Command processor thread] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF: closes. applyIndex: 0
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelinePlacementPolicy.chooseDatanodes(PipelinePlacementPolicy.java:196)
recon_1     | bytesWritten: 0
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_3  | 2020-04-20 12:23:08,939 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.create(RatisPipelineProvider.java:116)
recon_1     |  from dn=175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null} {}
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	... 13 more
datanode_3  | 2020-04-20 12:23:08,940 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF-SegmentedRaftLogWorker close()
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineFactory.create(PipelineFactory.java:63)
recon_1     | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException): PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb not found
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:23:28,924 [ChunkWriter-23-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: ecec66793606d963:831a297635280820:ecec66793606d963:0 , Message: ContainerID 4 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_3  | 2020-04-20 12:23:08,942 [grpc-default-executor-1] INFO impl.FollowerInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF->175c1ce4-a4bc-4858-9a69-a6ac92762c21: nextIndex: updateUnconditionally 3 -> 1
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.createPipeline(SCMPipelineManager.java:232)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-CF9DF1472EEF not found.
datanode_2  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 4 creation failed
datanode_3  | 2020-04-20 12:23:08,943 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.allocateBlock(BlockManagerImpl.java:200)
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMBlockProtocolServer.allocateBlock(SCMBlockProtocolServer.java:190)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.allocateScmBlock(ScmBlockLocationProtocolServerSideTranslatorPB.java:161)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
datanode_3  | 2020-04-20 12:23:08,945 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.processMessage(ScmBlockLocationProtocolServerSideTranslatorPB.java:119)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
datanode_3  | 2020-04-20 12:23:08,945 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.258ceeb5-4c9c-49bf-b393-79534db322e4@group-CF9DF1472EEF
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
recon_1     | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
datanode_3  | 2020-04-20 12:23:08,946 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:100)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
datanode_3  |  command on datanode #258ceeb5-4c9c-49bf-b393-79534db322e4.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:13157)
datanode_1  | 	... 4 more
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
datanode_3  | 2020-04-20 12:23:08,953 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: addNew group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-DFF8A315EADB:java.util.concurrent.CompletableFuture@4f93fe04[Not completed]
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
datanode_1  | 2020-04-20 12:23:14,050 [grpc-default-executor-2] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:175c1ce4-a4bc-4858-9a69-a6ac92762c21
recon_1     | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
datanode_3  | 2020-04-20 12:23:08,955 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4: new RaftServerImpl for group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
datanode_1  | 2020-04-20 12:23:14,051 [grpc-default-executor-2] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown FollowerState
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
datanode_3  | 2020-04-20 12:23:08,955 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
datanode_1  | 2020-04-20 12:23:14,051 [grpc-default-executor-2] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start FollowerState
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
datanode_3  | 2020-04-20 12:23:08,955 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
datanode_1  | 2020-04-20 12:23:14,052 [Thread-210] INFO impl.FollowerState: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
datanode_3  | 2020-04-20 12:23:08,955 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 2020-04-20 12:23:14,130 [grpc-default-executor-2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-DFF8A315EADB with new leaderId: 175c1ce4-a4bc-4858-9a69-a6ac92762c21
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
datanode_3  | 2020-04-20 12:23:08,955 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-04-20 12:23:28,924 [ChunkWriter-23-0] ERROR ratis.ContainerStateMachine: group-DFF8A315EADB: writeChunk writeStateMachineData failed: blockIdcontainerID: 4
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | 2020-04-20 12:23:14,130 [grpc-default-executor-2] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB: change Leader from null to 175c1ce4-a4bc-4858-9a69-a6ac92762c21 at term 1 for appendEntries, leader elected after 5212ms
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
datanode_3  | 2020-04-20 12:23:08,957 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | localID: 104030890075553795
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_1  | 2020-04-20 12:23:14,156 [grpc-default-executor-2] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
datanode_3  | 2020-04-20 12:23:08,958 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | blockCommitSequenceId: 0
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
datanode_1  | 2020-04-20 12:23:14,157 [grpc-default-executor-2] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-SegmentedRaftLogWorker: Starting segment from index:0
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_3  | 2020-04-20 12:23:08,958 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  |  logIndex 1 chunkName 104030890075553795_chunk_1 Error message: ContainerID 4 creation failed Container Result: DISK_OUT_OF_SPACE
scm_1       | 2020-04-20 12:25:01,043 [IPC Server handler 5 on 9863] ERROR block.BlockManagerImpl: Unable to allocate a block for the size: 268435456, type: RATIS, factor: THREE
datanode_1  | 2020-04-20 12:23:14,158 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b47aa9e4-1bde-4d0a-825f-dff8a315eadb/current/log_inprogress_0
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_3  | 2020-04-20 12:23:08,959 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-04-20 12:23:28,924 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb.Reason : ContainerID 4 creation failed
scm_1       | 2020-04-20 12:25:10,312 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955632Z] moved to OPEN state
datanode_1  | 2020-04-20 12:23:28,932 [ChunkWriter-14-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: ecec66793606d963:831a297635280820:ecec66793606d963:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_3  | 2020-04-20 12:23:08,959 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b47aa9e4-1bde-4d0a-825f-dff8a315eadb does not exist. Creating ...
scm_1       | 2020-04-20 12:25:20,070 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : ContainerID 5 creation failed
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_2  | 2020-04-20 12:23:28,930 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-F1305EE27D8B, cid=1
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
datanode_3  | 2020-04-20 12:23:08,973 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b47aa9e4-1bde-4d0a-825f-dff8a315eadb/in_use.lock acquired by nodename 6@78409bf0b6e2
scm_1       | 2020-04-20 12:25:20,071 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955632Z]
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_2  | 	 State Machine: cmdType: WriteChunk traceID: "ecec66793606d963:831a297635280820:ecec66793606d963:0" containerID: 4 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb" writeChunk { blockID { containerID: 4 localID: 104030890075553795 blockCommitSequenceId: 0 } chunkData { chunkName: "104030890075553795_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
recon_1     | 
datanode_3  | 2020-04-20 12:23:08,976 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b47aa9e4-1bde-4d0a-825f-dff8a315eadb has been successfully formatted.
scm_1       | 2020-04-20 12:25:20,072 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955632Z] moved to CLOSED state
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_2  | 2020-04-20 12:23:39,942 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #4 does not exist in datanode. Container close failed.
recon_1     | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
datanode_3  | 2020-04-20 12:23:08,979 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-DFF8A315EADB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
scm_1       | 2020-04-20 12:25:20,072 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #5
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_2  | 2020-04-20 12:24:28,928 [java.util.concurrent.ThreadPoolExecutor$Worker@627a6c6e[State = -1, empty queue]] WARN server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB->258ceeb5-4c9c-49bf-b393-79534db322e4-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=7,entriesCount=1,lastEntry=(t:1, i:1)
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_3  | 2020-04-20 12:23:08,980 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm_1       | 2020-04-20 12:25:20,078 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : Log already failed at index 1 for task WriteLog:1: (t:2, i:1), STATEMACHINELOGENTRY, client-ED0225477BB7, cid=1
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_2  | 2020-04-20 12:24:28,928 [java.util.concurrent.ThreadPoolExecutor$Worker@627a6c6e[State = -1, empty queue]] WARN server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=7,entriesCount=1,lastEntry=(t:1, i:1)
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_3  | 2020-04-20 12:23:08,980 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:ebe55fbcd1c7ca13:56b24e3416ae0434:0" containerID: 5 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "008a62b9-4e5b-43f7-be42-4584cff877b4" writeChunk { blockID { containerID: 5 localID: 104030897365057540 blockCommitSequenceId: 0 } chunkData { chunkName: "104030897365057540_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_2  | 2020-04-20 12:24:28,932 [java.util.concurrent.ThreadPoolExecutor$Worker@627a6c6e[State = -1, empty queue]] WARN server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=8,entriesCount=1,lastEntry=(t:1, i:2)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_3  | 2020-04-20 12:23:08,992 [grpc-default-executor-3] WARN impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed groupAdd* GroupManagementRequest:client-EF19108565EE->258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB, cid=6, seq=0, RW, null, Add:group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
scm_1       | 2020-04-20 12:25:20,080 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955632Z]
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_2  | 2020-04-20 12:24:28,965 [java.util.concurrent.ThreadPoolExecutor$Worker@627a6c6e[State = -1, empty queue]] WARN server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB->258ceeb5-4c9c-49bf-b393-79534db322e4-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=8,entriesCount=1,lastEntry=(t:1, i:2)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
scm_1       | 2020-04-20 12:25:20,084 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : ContainerID 5 creation failed
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_2  | 2020-04-20 12:24:59,940 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove    LEADER 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB:t1, leader=175c1ce4-a4bc-4858-9a69-a6ac92762c21, voted=175c1ce4-a4bc-4858-9a69-a6ac92762c21, raftlog=175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
recon_1     | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
scm_1       | 2020-04-20 12:25:20,084 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955632Z]
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_2  | 2020-04-20 12:24:59,940 [Command processor thread] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB: shutdown
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:123)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
scm_1       | 2020-04-20 12:25:20,098 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:2, i:1), STATEMACHINELOGENTRY, client-ED0225477BB7, cid=1
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_2  | 2020-04-20 12:24:59,940 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DFF8A315EADB,id=175c1ce4-a4bc-4858-9a69-a6ac92762c21
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:114)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:ebe55fbcd1c7ca13:56b24e3416ae0434:0" containerID: 5 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "008a62b9-4e5b-43f7-be42-4584cff877b4" writeChunk { blockID { containerID: 5 localID: 104030897365057540 blockCommitSequenceId: 0 } chunkData { chunkName: "104030897365057540_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_2  | 2020-04-20 12:24:59,940 [Command processor thread] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown LeaderState
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.getPipeline(StorageContainerLocationProtocolClientSideTranslatorPB.java:347)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
scm_1       | 2020-04-20 12:25:20,098 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955632Z]
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_2  | 2020-04-20 12:24:59,941 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/0x0000000840609440@747745a7] WARN server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
recon_1     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
scm_1       | 2020-04-20 12:25:20,112 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : ContainerID 5 creation failed
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 2020-04-20 12:24:59,942 [Command processor thread] INFO impl.PendingRequests: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-PendingRequests: sendNotLeaderResponses
recon_1     | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
scm_1       | 2020-04-20 12:25:20,112 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955632Z]
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 2020-04-20 12:24:59,941 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/0x0000000840609440@7645f274] WARN server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB->258ceeb5-4c9c-49bf-b393-79534db322e4-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
recon_1     | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
scm_1       | 2020-04-20 12:25:20,118 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:2, i:1), STATEMACHINELOGENTRY, client-ED0225477BB7, cid=1
recon_1     | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:ebe55fbcd1c7ca13:56b24e3416ae0434:0" containerID: 5 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "008a62b9-4e5b-43f7-be42-4584cff877b4" writeChunk { blockID { containerID: 5 localID: 104030897365057540 blockCommitSequenceId: 0 } chunkData { chunkName: "104030897365057540_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:24:59,945 [grpc-default-executor-0] INFO server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB->258ceeb5-4c9c-49bf-b393-79534db322e4-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_2  | 2020-04-20 12:24:59,950 [grpc-default-executor-2] INFO server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
recon_1     | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:71)
scm_1       | 2020-04-20 12:25:20,119 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955632Z]
datanode_2  | 2020-04-20 12:24:59,961 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=892071936 B) is less than the container size (=1073741824 B).
recon_1     | 	at com.sun.proxy.$Proxy42.getPipeline(Unknown Source)
scm_1       | 2020-04-20 12:25:22,115 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
datanode_2  | 2020-04-20 12:24:59,961 [Command processor thread] INFO impl.StateMachineUpdater: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-StateMachineUpdater: set stopIndex = 0
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getPipeline(StorageContainerServiceProviderImpl.java:55)
scm_1       | 2020-04-20 12:25:22,116 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c to datanode:175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:24:59,962 [grpc-default-executor-0] INFO impl.FollowerInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB->258ceeb5-4c9c-49bf-b393-79534db322e4: nextIndex: updateUnconditionally 3 -> 1
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineReportHandler.processPipelineReport(ReconPipelineReportHandler.java:65)
scm_1       | 2020-04-20 12:25:22,117 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c to datanode:bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_2  | 2020-04-20 12:24:59,962 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-DFF8A315EADB as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 	... 13 more
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:84)
scm_1       | 2020-04-20 12:25:22,117 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c to datanode:258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_2  | 2020-04-20 12:24:59,962 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-StateMachineUpdater] ERROR impl.StateMachineUpdater: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-StateMachineUpdater: Failed to take snapshot
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 2020-04-20 12:23:28,934 [ChunkWriter-14-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: ecec66793606d963:831a297635280820:ecec66793606d963:0 , Message: ContainerID 4 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:47)
scm_1       | 2020-04-20 12:25:22,117 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:25:22.116778Z]
datanode_2  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-DFF8A315EADB as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 4 creation failed
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
scm_1       | 2020-04-20 12:25:22,117 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2020-04-20 12:25:56,130 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116778Z] moved to OPEN state
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2020-04-20 12:26:26,074 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:26:26,074 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
recon_1     | 2020-04-20 12:24:59,987 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4. Trying to get from SCM.
scm_1       | 2020-04-20 12:26:26,074 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
recon_1     | 2020-04-20 12:24:59,995 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:24:34.955Z] to Recon pipeline metadata.
scm_1       | 2020-04-20 12:26:26,074 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955632Z] removed from db
scm_1       | 2020-04-20 12:26:26,075 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-20 12:26:26,075 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
datanode_2  | 2020-04-20 12:24:59,962 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-DFF8A315EADB as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 2020-04-20 12:24:59,962 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-StateMachineUpdater] ERROR impl.StateMachineUpdater: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-StateMachineUpdater: Failed to take snapshot
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2020-04-20 12:26:26,081 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_2  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-DFF8A315EADB as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2020-04-20 12:26:26,081 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
scm_1       | 2020-04-20 12:26:26,081 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
recon_1     | 2020-04-20 12:24:59,995 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:24:34.955Z]
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	... 13 more
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
recon_1     | 2020-04-20 12:24:59,996 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 reported by bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_1  | 2020-04-20 12:23:28,936 [ChunkWriter-14-0] ERROR ratis.ContainerStateMachine: group-DFF8A315EADB: writeChunk writeStateMachineData failed: blockIdcontainerID: 4
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
scm_1       | 2020-04-20 12:26:26,081 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955632Z]
datanode_3  | 2020-04-20 12:23:09,001 [grpc-default-executor-1] WARN impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed groupAdd* GroupManagementRequest:client-CA0CF6F6D2BC->258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB, cid=4, seq=0, RW, null, Add:group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
recon_1     | 2020-04-20 12:25:00,006 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 reported by 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_1  | localID: 104030890075553795
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 2020-04-20 12:25:00,035 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 reported by 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_1  | blockCommitSequenceId: 0
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 2020-04-20 12:24:59,964 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB
recon_1     | 2020-04-20 12:25:10,316 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 reported by 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_1  |  logIndex 1 chunkName 104030890075553795_chunk_1 Error message: ContainerID 4 creation failed Container Result: DISK_OUT_OF_SPACE
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 2020-04-20 12:24:59,965 [Command processor thread] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB: closes. applyIndex: 0
recon_1     | 2020-04-20 12:25:10,316 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955Z] moved to OPEN state
datanode_1  | 2020-04-20 12:23:28,936 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb.Reason : ContainerID 4 creation failed
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 2020-04-20 12:24:59,965 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
recon_1     | 2020-04-20 12:25:20,071 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : ContainerID 5 creation failed
datanode_1  | 2020-04-20 12:23:28,943 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-F1305EE27D8B, cid=1
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 2020-04-20 12:24:59,981 [grpc-default-executor-2] INFO impl.FollowerInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB->bb3db77a-6a57-4c4e-bdc7-ea39008446e6: nextIndex: updateUnconditionally 3 -> 1
recon_1     | 2020-04-20 12:25:20,071 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955Z]
datanode_1  | 	 State Machine: cmdType: WriteChunk traceID: "ecec66793606d963:831a297635280820:ecec66793606d963:0" containerID: 4 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb" writeChunk { blockID { containerID: 4 localID: 104030890075553795 blockCommitSequenceId: 0 } chunkData { chunkName: "104030890075553795_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 2020-04-20 12:24:59,993 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB-SegmentedRaftLogWorker close()
recon_1     | 2020-04-20 12:25:20,072 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955Z] moved to CLOSED state
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_1  | 2020-04-20 12:23:39,918 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #4 does not exist in datanode. Container close failed.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 2020-04-20 12:25:00,007 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.175c1ce4-a4bc-4858-9a69-a6ac92762c21
recon_1     | 2020-04-20 12:25:20,074 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : Log already failed at index 1 for task WriteLog:1: (t:2, i:1), STATEMACHINELOGENTRY, client-ED0225477BB7, cid=1
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_1  | 2020-04-20 12:24:59,943 [grpc-default-executor-2] INFO server.GrpcServerProtocolService: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Completed APPEND_ENTRIES, lastRequest: 175c1ce4-a4bc-4858-9a69-a6ac92762c21->bb3db77a-6a57-4c4e-bdc7-ea39008446e6#8-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-F1305EE27D8B, cid=2
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 2020-04-20 12:25:00,007 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:ebe55fbcd1c7ca13:56b24e3416ae0434:0" containerID: 5 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "008a62b9-4e5b-43f7-be42-4584cff877b4" writeChunk { blockID { containerID: 5 localID: 104030897365057540 blockCommitSequenceId: 0 } chunkData { chunkName: "104030897365057540_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 2020-04-20 12:24:59,945 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove  FOLLOWER bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB:t1, leader=175c1ce4-a4bc-4858-9a69-a6ac92762c21, voted=175c1ce4-a4bc-4858-9a69-a6ac92762c21, raftlog=bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 2020-04-20 12:25:00,007 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-DFF8A315EADB
recon_1     | 2020-04-20 12:25:20,075 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955Z]
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 2020-04-20 12:24:59,945 [Command processor thread] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB: shutdown
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 2020-04-20 12:25:00,008 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
recon_1     | 2020-04-20 12:25:20,084 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : ContainerID 5 creation failed
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_1  | 2020-04-20 12:24:59,945 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DFF8A315EADB,id=bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  |  command on datanode #175c1ce4-a4bc-4858-9a69-a6ac92762c21.
recon_1     | 2020-04-20 12:25:20,085 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955Z]
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 2020-04-20 12:24:59,946 [Command processor thread] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown FollowerState
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 2020-04-20 12:25:00,009 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: addNew group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-4584CFF877B4:java.util.concurrent.CompletableFuture@62f929fc[Not completed]
recon_1     | 2020-04-20 12:25:20,095 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:2, i:1), STATEMACHINELOGENTRY, client-ED0225477BB7, cid=1
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2020-04-20 12:24:59,946 [Command processor thread] INFO impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-StateMachineUpdater: set stopIndex = 0
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | Apr 20, 2020 12:24:59 PM org.apache.ratis.thirdparty.io.grpc.netty.NettyServerHandler onStreamError
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:ebe55fbcd1c7ca13:56b24e3416ae0434:0" containerID: 5 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "008a62b9-4e5b-43f7-be42-4584cff877b4" writeChunk { blockID { containerID: 5 localID: 104030897365057540 blockCommitSequenceId: 0 } chunkData { chunkName: "104030897365057540_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:26:26,085 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2  | WARNING: Stream Error
datanode_1  | 2020-04-20 12:24:59,946 [Thread-213] INFO impl.FollowerState: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
scm_1       | 2020-04-20 12:26:26,085 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
recon_1     | 2020-04-20 12:25:20,096 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955Z]
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2Exception$StreamException: Received DATA frame for an unknown stream 3
datanode_1  | 2020-04-20 12:24:59,948 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-DFF8A315EADB as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
scm_1       | 2020-04-20 12:26:26,085 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
recon_1     | 2020-04-20 12:25:20,112 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : ContainerID 5 creation failed
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2020-04-20 12:26:26,085 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955632Z]
recon_1     | 2020-04-20 12:25:20,112 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955Z]
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2020-04-20 12:24:59,948 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-StateMachineUpdater] ERROR impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-StateMachineUpdater: Failed to take snapshot
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2Exception.streamError(Http2Exception.java:147)
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 not found
recon_1     | 2020-04-20 12:25:20,117 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:2, i:1), STATEMACHINELOGENTRY, client-ED0225477BB7, cid=1
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-DFF8A315EADB as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder$FrameReadListener.shouldIgnoreHeadersOrDataFrame(DefaultHttp2ConnectionDecoder.java:591)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:ebe55fbcd1c7ca13:56b24e3416ae0434:0" containerID: 5 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "008a62b9-4e5b-43f7-be42-4584cff877b4" writeChunk { blockID { containerID: 5 localID: 104030897365057540 blockCommitSequenceId: 0 } chunkData { chunkName: "104030897365057540_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-DFF8A315EADB:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder$FrameReadListener.onDataRead(DefaultHttp2ConnectionDecoder.java:239)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 2020-04-20 12:25:20,117 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955Z]
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2InboundFrameLogger$1.onDataRead(Http2InboundFrameLogger.java:48)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 2020-04-20 12:25:23,826 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2FrameReader.readDataFrame(DefaultHttp2FrameReader.java:422)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 2020-04-20 12:25:23,827 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_3  | 	... 13 more
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2FrameReader.processPayloadState(DefaultHttp2FrameReader.java:251)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
recon_1     | 2020-04-20 12:25:23,833 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 4
datanode_3  | 2020-04-20 12:23:09,000 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2FrameReader.readFrame(DefaultHttp2FrameReader.java:160)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 2020-04-20 12:25:23,836 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
datanode_3  | 2020-04-20 12:23:09,001 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-20 12:24:59,949 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-DFF8A315EADB as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2InboundFrameLogger.readFrame(Http2InboundFrameLogger.java:41)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
recon_1     | 2020-04-20 12:25:23,884 [pool-9-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_3  | 2020-04-20 12:23:09,002 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-20 12:24:59,949 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-StateMachineUpdater] ERROR impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-StateMachineUpdater: Failed to take snapshot
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.DefaultHttp2ConnectionDecoder.decodeFrame(DefaultHttp2ConnectionDecoder.java:174)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 2020-04-20 12:25:51,064 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c. Trying to get from SCM.
datanode_3  | 2020-04-20 12:23:09,002 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-DFF8A315EADB as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2ConnectionHandler$FrameDecoder.decode(Http2ConnectionHandler.java:378)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 2020-04-20 12:25:51,085 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:25:22.116Z] to Recon pipeline metadata.
datanode_3  | 2020-04-20 12:23:09,002 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.http2.Http2ConnectionHandler.decode(Http2ConnectionHandler.java:438)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 2020-04-20 12:25:51,085 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:25:22.116Z]
datanode_3  | 2020-04-20 12:23:09,002 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/b47aa9e4-1bde-4d0a-825f-dff8a315eadb
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:505)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 2020-04-20 12:25:51,085 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c reported by bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_3  | 2020-04-20 12:23:09,002 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:444)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 2020-04-20 12:25:51,086 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c reported by 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_3  | 2020-04-20 12:23:09,002 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:283)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:25:51,087 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c reported by 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_3  | 2020-04-20 12:23:09,002 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
scm_1       | 2020-04-20 12:26:26,100 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
recon_1     | 2020-04-20 12:25:56,128 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c reported by bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_3  | 2020-04-20 12:23:09,003 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-04-20 12:24:59,949 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
scm_1       | 2020-04-20 12:26:26,100 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
recon_1     | 2020-04-20 12:25:56,129 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116Z] moved to OPEN state
datanode_3  | 2020-04-20 12:23:09,003 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-04-20 12:24:59,950 [Command processor thread] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB: closes. applyIndex: 0
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
scm_1       | 2020-04-20 12:26:26,100 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
recon_1     | 2020-04-20 12:26:23,889 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_3  | 2020-04-20 12:23:09,003 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-04-20 12:24:59,950 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1421)
scm_1       | 2020-04-20 12:26:26,101 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955632Z]
recon_1     | 2020-04-20 12:26:23,890 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_3  | 2020-04-20 12:23:09,003 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-04-20 12:24:59,950 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB-SegmentedRaftLogWorker close()
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 not found
recon_1     | 2020-04-20 12:26:23,895 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0
datanode_3  | 2020-04-20 12:23:09,003 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-04-20 12:24:59,951 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 2020-04-20 12:26:26,072 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955Z] removed from db
datanode_3  | 2020-04-20 12:23:09,003 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-04-20 12:24:59,951 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:930)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 2020-04-20 12:26:26,075 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955Z]
datanode_3  | 2020-04-20 12:23:09,027 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-04-20 12:24:59,951 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-DFF8A315EADB
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 not found
datanode_3  | 2020-04-20 12:23:09,027 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-04-20 12:24:59,952 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:697)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_3  | 2020-04-20 12:23:09,027 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_1  |  command on datanode #bb3db77a-6a57-4c4e-bdc7-ea39008446e6.
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:632)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_3  | 2020-04-20 12:23:09,027 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_1  | 2020-04-20 12:24:59,952 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: addNew group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-4584CFF877B4:java.util.concurrent.CompletableFuture@639aecea[Not completed]
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:549)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_3  | 2020-04-20 12:23:09,027 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_1  | 2020-04-20 12:24:59,954 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: new RaftServerImpl for group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:511)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_3  | 2020-04-20 12:23:09,027 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_1  | 2020-04-20 12:24:59,956 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
datanode_3  | 2020-04-20 12:23:09,028 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 2020-04-20 12:24:59,956 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_3  | 2020-04-20 12:23:09,028 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 2020-04-20 12:24:59,956 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_3  | 2020-04-20 12:23:09,028 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_1  | 2020-04-20 12:24:59,956 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 2020-04-20 12:23:09,028 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 2020-04-20 12:24:59,956 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 2020-04-20 12:23:09,028 [pool-69-thread-1] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start FollowerState
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2020-04-20 12:24:59,956 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-04-20 12:25:00,015 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: new RaftServerImpl for group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-04-20 12:23:09,029 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DFF8A315EADB,id=258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:24:59,956 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-20 12:25:00,020 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_3  | 2020-04-20 12:23:09,035 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB
scm_1       | 2020-04-20 12:26:26,113 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | 2020-04-20 12:24:59,956 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-04-20 12:25:00,020 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2020-04-20 12:26:26,113 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_3  | 2020-04-20 12:23:09,110 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
datanode_1  | 2020-04-20 12:24:59,956 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/008a62b9-4e5b-43f7-be42-4584cff877b4 does not exist. Creating ...
datanode_2  | 2020-04-20 12:25:00,020 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2020-04-20 12:26:26,113 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_3  | .
datanode_1  | 2020-04-20 12:24:59,959 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/008a62b9-4e5b-43f7-be42-4584cff877b4/in_use.lock acquired by nodename 6@69674aa52266
datanode_2  | 2020-04-20 12:25:00,020 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:26:26,114 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955632Z]
datanode_3  | 2020-04-20 12:23:09,110 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-CF9DF1472EEF:null
datanode_1  | 2020-04-20 12:24:59,961 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/008a62b9-4e5b-43f7-be42-4584cff877b4 has been successfully formatted.
datanode_2  | 2020-04-20 12:25:00,021 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
recon_1     | 2020-04-20 12:26:26,086 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955Z]
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 not found
datanode_3  | 2020-04-20 12:23:09,113 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_1  | 2020-04-20 12:24:59,962 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-4584CFF877B4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-04-20 12:25:00,021 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 not found
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_3  | 
datanode_1  | 2020-04-20 12:24:59,967 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_2  | 2020-04-20 12:25:00,021 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-CF9DF1472EEF not found.
datanode_1  | 2020-04-20 12:24:59,967 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_2  | 2020-04-20 12:25:00,021 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 2020-04-20 12:24:59,967 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_2  | 2020-04-20 12:25:00,021 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/008a62b9-4e5b-43f7-be42-4584cff877b4 does not exist. Creating ...
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 2020-04-20 12:24:59,967 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_2  | 2020-04-20 12:25:00,023 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/008a62b9-4e5b-43f7-be42-4584cff877b4/in_use.lock acquired by nodename 6@f98376242d82
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 2020-04-20 12:24:59,967 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
datanode_2  | 2020-04-20 12:25:00,024 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/008a62b9-4e5b-43f7-be42-4584cff877b4 has been successfully formatted.
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 2020-04-20 12:24:59,968 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.bb3db77a-6a57-4c4e-bdc7-ea39008446e6
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_2  | 2020-04-20 12:25:00,041 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-4584CFF877B4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:24:59,968 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_2  | 2020-04-20 12:25:00,043 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 2020-04-20 12:24:59,968 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/008a62b9-4e5b-43f7-be42-4584cff877b4
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 2020-04-20 12:25:00,043 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-CF9DF1472EEF not found.
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 2020-04-20 12:25:00,043 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 2020-04-20 12:24:59,968 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_2  | 2020-04-20 12:25:00,044 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2020-04-20 12:24:59,968 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 2020-04-20 12:25:00,044 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:24:59,968 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 2020-04-20 12:25:00,044 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1       | 2020-04-20 12:26:26,119 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | 2020-04-20 12:24:59,968 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:25:00,049 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 	... 4 more
scm_1       | 2020-04-20 12:26:26,119 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:24:59,969 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
recon_1     | 2020-04-20 12:26:26,096 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955Z]
datanode_2  | 2020-04-20 12:25:00,049 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/008a62b9-4e5b-43f7-be42-4584cff877b4
datanode_3  | 2020-04-20 12:23:09,113 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-CF9DF1472EEF:null
scm_1       | 2020-04-20 12:26:26,120 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_1  | 2020-04-20 12:24:59,969 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 not found
datanode_2  | 2020-04-20 12:25:00,049 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-04-20 12:23:09,113 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
scm_1       | 2020-04-20 12:26:26,121 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955632Z]
datanode_1  | 2020-04-20 12:24:59,969 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_2  | 2020-04-20 12:25:00,049 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 not found
datanode_1  | 2020-04-20 12:24:59,969 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_2  | 2020-04-20 12:25:00,049 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-CF9DF1472EEF not found.
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_1  | 2020-04-20 12:24:59,977 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_2  | 2020-04-20 12:25:00,049 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_1  | 2020-04-20 12:24:59,989 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_2  | 2020-04-20 12:25:00,049 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_1  | 2020-04-20 12:24:59,996 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
datanode_2  | 2020-04-20 12:25:00,049 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_1  | 2020-04-20 12:24:59,996 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_2  | 2020-04-20 12:25:00,049 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_1  | 2020-04-20 12:24:59,996 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_2  | 2020-04-20 12:25:00,049 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_1  | 2020-04-20 12:24:59,996 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 2020-04-20 12:25:00,049 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-CF9DF1472EEF not found.
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_1  | 2020-04-20 12:24:59,997 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-04-20 12:24:59,998 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4
datanode_2  | 2020-04-20 12:25:00,051 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 2020-04-20 12:24:59,998 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 2020-04-20 12:25:00,053 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 2020-04-20 12:24:59,998 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_2  | 2020-04-20 12:25:00,056 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_1  | 2020-04-20 12:24:59,999 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4: changes role from      null to FOLLOWER at term 0 for startAsFollower
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 2020-04-20 12:25:00,058 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 2020-04-20 12:24:59,999 [pool-69-thread-1] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start FollowerState
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 2020-04-20 12:25:00,059 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 	... 4 more
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2020-04-20 12:24:59,999 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4584CFF877B4,id=bb3db77a-6a57-4c4e-bdc7-ea39008446e6
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:25:00,059 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-04-20 12:23:09,117 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-CF9DF1472EEF:null
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:24:59,999 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4
datanode_2  | 2020-04-20 12:25:00,059 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4
recon_1     | 2020-04-20 12:26:26,113 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955Z]
datanode_3  | 2020-04-20 12:23:09,117 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
scm_1       | 2020-04-20 12:26:53,197 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : ContainerID 6 creation failed
datanode_1  | 2020-04-20 12:25:00,057 [grpc-default-executor-2] WARN impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed groupAdd* GroupManagementRequest:client-2D0DDD11676F->bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4, cid=8, seq=0, RW, null, Add:group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_2  | 2020-04-20 12:25:00,059 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 not found
datanode_3  | 
scm_1       | 2020-04-20 12:26:53,203 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116778Z]
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 2020-04-20 12:25:00,060 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-CF9DF1472EEF not found.
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
scm_1       | 2020-04-20 12:26:53,203 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116778Z] moved to CLOSED state
datanode_2  | 2020-04-20 12:25:00,060 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4: changes role from      null to FOLLOWER at term 0 for startAsFollower
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
scm_1       | 2020-04-20 12:26:53,203 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #6
datanode_2  | 2020-04-20 12:25:00,061 [pool-69-thread-1] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start FollowerState
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
scm_1       | 2020-04-20 12:26:53,204 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : ContainerID 6 creation failed
datanode_2  | 2020-04-20 12:25:00,061 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4584CFF877B4,id=175c1ce4-a4bc-4858-9a69-a6ac92762c21
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
scm_1       | 2020-04-20 12:26:53,213 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116778Z]
datanode_2  | 2020-04-20 12:25:00,061 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
scm_1       | 2020-04-20 12:26:53,226 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : ContainerID 6 creation failed
datanode_2  | 2020-04-20 12:25:00,085 [grpc-default-executor-2] WARN impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed groupAdd* GroupManagementRequest:client-116090EFBC6E->175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4, cid=9, seq=0, RW, null, Add:group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
scm_1       | 2020-04-20 12:26:53,228 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116778Z]
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-CF9DF1472EEF not found.
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
scm_1       | 2020-04-20 12:26:53,228 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
scm_1       | 2020-04-20 12:26:53,228 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116778Z]
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
scm_1       | 2020-04-20 12:26:53,229 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	... 4 more
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
scm_1       | 2020-04-20 12:26:53,232 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116778Z]
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:23:09,118 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-CF9DF1472EEF:null
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
scm_1       | 2020-04-20 12:26:53,243 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
recon_1     | 2020-04-20 12:26:26,118 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 008a62b9-4e5b-43f7-be42-4584cff877b4, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:175c1ce4-a4bc-4858-9a69-a6ac92762c21, CreationTimestamp2020-04-20T12:24:34.955Z]
datanode_3  | 2020-04-20 12:23:09,118 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4 not found
datanode_3  | 
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
scm_1       | 2020-04-20 12:26:53,244 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116778Z]
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-CF9DF1472EEF not found.
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2020-04-20 12:27:22,118 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
scm_1       | 2020-04-20 12:27:22,119 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be to datanode:258ceeb5-4c9c-49bf-b393-79534db322e4
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:27:22,119 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be to datanode:175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
scm_1       | 2020-04-20 12:27:22,119 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be to datanode:bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
scm_1       | 2020-04-20 12:27:22,119 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:27:22.119541Z]
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
scm_1       | 2020-04-20 12:27:22,120 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-CF9DF1472EEF not found.
datanode_1  | 	... 13 more
scm_1       | 2020-04-20 12:27:29,254 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119541Z] moved to OPEN state
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 2020-04-20 12:25:00,145 [grpc-default-executor-2] WARN impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed groupAdd* GroupManagementRequest:client-447D091DF76A->bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4, cid=7, seq=0, RW, null, Add:group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
scm_1       | 2020-04-20 12:27:34,547 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 6 containers.
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
scm_1       | 2020-04-20 12:27:59,204 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
scm_1       | 2020-04-20 12:27:59,211 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
scm_1       | 2020-04-20 12:27:59,211 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	... 4 more
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
scm_1       | 2020-04-20 12:27:59,211 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116778Z] removed from db
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:23:09,118 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-CF9DF1472EEF:null
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
scm_1       | 2020-04-20 12:27:59,211 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
datanode_2  | 	... 13 more
recon_1     | 2020-04-20 12:26:53,195 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : ContainerID 6 creation failed
datanode_3  | 2020-04-20 12:23:09,118 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "cc7b5d95-9851-4876-8726-cf9df1472eef"
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
scm_1       | 2020-04-20 12:27:59,212 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
datanode_2  | 2020-04-20 12:25:00,137 [grpc-default-executor-2] WARN impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed groupAdd* GroupManagementRequest:client-47B1CACCD1AC->175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4, cid=9, seq=0, RW, null, Add:group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
recon_1     | 2020-04-20 12:26:53,196 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116Z]
datanode_3  | 
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
scm_1       | 2020-04-20 12:27:59,213 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
recon_1     | 2020-04-20 12:26:53,196 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116Z] moved to CLOSED state
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-CF9DF1472EEF not found.
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
scm_1       | 2020-04-20 12:27:59,213 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
recon_1     | 2020-04-20 12:26:53,201 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : ContainerID 6 creation failed
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
scm_1       | 2020-04-20 12:27:59,213 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
recon_1     | 2020-04-20 12:26:53,201 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116Z]
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
scm_1       | 2020-04-20 12:27:59,213 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116778Z]
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
recon_1     | 2020-04-20 12:26:53,217 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : ContainerID 6 creation failed
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c not found
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
recon_1     | 2020-04-20 12:26:53,217 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116Z]
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
recon_1     | 2020-04-20 12:26:53,219 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-CF9DF1472EEF not found.
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
recon_1     | 2020-04-20 12:26:53,219 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116Z]
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
recon_1     | 2020-04-20 12:26:53,227 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
recon_1     | 2020-04-20 12:26:53,227 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116Z]
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
recon_1     | 2020-04-20 12:26:53,240 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	... 4 more
datanode_3  | 2020-04-20 12:23:14,036 [grpc-default-executor-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_3  | 2020-04-20 12:23:14,036 [grpc-default-executor-1] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown FollowerState
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
recon_1     | 2020-04-20 12:26:53,240 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116Z]
datanode_3  | 2020-04-20 12:23:14,036 [grpc-default-executor-1] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start FollowerState
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
recon_1     | 2020-04-20 12:27:23,898 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_3  | 2020-04-20 12:23:14,036 [Thread-101] INFO impl.FollowerState: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_1  | 	... 13 more
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
recon_1     | 2020-04-20 12:27:23,898 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_3  | 2020-04-20 12:23:14,181 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-DFF8A315EADB with new leaderId: 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 2020-04-20 12:25:00,160 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 2020-04-20 12:27:23,905 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 1
datanode_3  | 2020-04-20 12:23:14,186 [grpc-default-executor-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB: change Leader from null to 175c1ce4-a4bc-4858-9a69-a6ac92762c21 at term 1 for appendEntries, leader elected after 5200ms
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 2020-04-20 12:23:14,208 [grpc-default-executor-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_1  | .
recon_1     | 2020-04-20 12:27:24,195 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be. Trying to get from SCM.
recon_1     | 2020-04-20 12:27:24,206 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:27:22.119Z] to Recon pipeline metadata.
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:23:14,208 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-04-20 12:25:00,160 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-DFF8A315EADB:null
recon_1     | 2020-04-20 12:27:24,206 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:27:22.119Z]
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 2020-04-20 12:23:14,210 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b47aa9e4-1bde-4d0a-825f-dff8a315eadb/current/log_inprogress_0
datanode_1  | 2020-04-20 12:25:00,160 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
recon_1     | 2020-04-20 12:27:24,206 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be reported by bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-04-20 12:27:59,228 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | 2020-04-20 12:23:28,930 [ChunkWriter-42-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: ecec66793606d963:831a297635280820:ecec66793606d963:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1  | 
recon_1     | 2020-04-20 12:27:24,232 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be reported by 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-04-20 12:27:59,228 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
scm_1       | 2020-04-20 12:27:59,228 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
scm_1       | 2020-04-20 12:27:59,229 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116778Z]
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-DFF8A315EADB not found.
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c not found
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
recon_1     | 2020-04-20 12:27:24,241 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be reported by 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_2  | 	... 13 more
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
recon_1     | 2020-04-20 12:27:24,474 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_2  | 2020-04-20 12:25:00,153 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
recon_1     | 2020-04-20 12:27:24,478 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 16 milliseconds.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_2  | .
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
recon_1     | 2020-04-20 12:27:25,471 [MissingContainerTask] INFO fsck.MissingContainerTask: Missing Container task Thread took 3 milliseconds for processing 0 containers.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_2  | 2020-04-20 12:25:00,154 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-DFF8A315EADB:null
recon_1     | 2020-04-20 12:27:29,274 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be reported by bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_2  | 2020-04-20 12:25:00,154 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
recon_1     | 2020-04-20 12:27:29,274 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119Z] moved to OPEN state
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-DFF8A315EADB not found.
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_2  | 
recon_1     | 2020-04-20 12:27:59,197 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116Z] removed from db
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-DFF8A315EADB not found.
recon_1     | 2020-04-20 12:27:59,202 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116Z]
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c not found
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_1  | 2020-04-20 12:25:00,161 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-DFF8A315EADB:null
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_1  | 2020-04-20 12:25:00,161 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_1  | 
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-DFF8A315EADB not found.
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-DFF8A315EADB not found.
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1       | 2020-04-20 12:27:59,229 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1       | 2020-04-20 12:27:59,229 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_3  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=892071936 B) is less than the container size (=1073741824 B).
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1       | 2020-04-20 12:27:59,229 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1       | 2020-04-20 12:27:59,229 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116778Z]
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_2  | 	... 4 more
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c not found
datanode_3  | 	... 13 more
datanode_2  | 2020-04-20 12:25:00,159 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-DFF8A315EADB:null
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-DFF8A315EADB not found.
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_3  | 2020-04-20 12:23:28,933 [ChunkWriter-42-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: ecec66793606d963:831a297635280820:ecec66793606d963:0 , Message: ContainerID 4 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_2  | 2020-04-20 12:25:00,160 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 4 creation failed
datanode_2  | 
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-DFF8A315EADB not found.
recon_1     | 2020-04-20 12:27:59,218 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116Z]
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c not found
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_1  | 	... 4 more
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_1  | 2020-04-20 12:25:00,161 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-DFF8A315EADB:null
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_1  | 2020-04-20 12:25:00,162 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_1  | 
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-DFF8A315EADB not found.
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-DFF8A315EADB not found.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 2020-04-20 12:23:28,934 [ChunkWriter-42-0] ERROR ratis.ContainerStateMachine: group-DFF8A315EADB: writeChunk writeStateMachineData failed: blockIdcontainerID: 4
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | localID: 104030890075553795
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1       | 2020-04-20 12:27:59,233 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_3  | blockCommitSequenceId: 0
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	... 4 more
scm_1       | 2020-04-20 12:27:59,233 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_3  |  logIndex 1 chunkName 104030890075553795_chunk_1 Error message: ContainerID 4 creation failed Container Result: DISK_OUT_OF_SPACE
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:25:00,160 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-DFF8A315EADB:null
scm_1       | 2020-04-20 12:27:59,233 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:23:28,934 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb.Reason : ContainerID 4 creation failed
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-DFF8A315EADB not found.
datanode_2  | 2020-04-20 12:25:00,160 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
scm_1       | 2020-04-20 12:27:59,233 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116778Z]
datanode_3  | 2020-04-20 12:23:28,967 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=b47aa9e4-1bde-4d0a-825f-dff8a315eadb.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-F1305EE27D8B, cid=1
recon_1     | 2020-04-20 12:27:59,219 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116Z]
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c not found
datanode_2  | 
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 	 State Machine: cmdType: WriteChunk traceID: "ecec66793606d963:831a297635280820:ecec66793606d963:0" containerID: 4 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb" writeChunk { blockID { containerID: 4 localID: 104030890075553795 blockCommitSequenceId: 0 } chunkData { chunkName: "104030890075553795_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-DFF8A315EADB not found.
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 2020-04-20 12:23:39,979 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #4 does not exist in datanode. Container close failed.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_3  | 2020-04-20 12:24:59,944 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 258ceeb5-4c9c-49bf-b393-79534db322e4: Completed APPEND_ENTRIES, lastRequest: 175c1ce4-a4bc-4858-9a69-a6ac92762c21->258ceeb5-4c9c-49bf-b393-79534db322e4#8-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-F1305EE27D8B, cid=2
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_3  | 2020-04-20 12:24:59,968 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove  FOLLOWER 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB:t1, leader=175c1ce4-a4bc-4858-9a69-a6ac92762c21, voted=175c1ce4-a4bc-4858-9a69-a6ac92762c21, raftlog=258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_1  | 	... 4 more
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
datanode_3  | 2020-04-20 12:24:59,968 [Command processor thread] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB: shutdown
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_1  | 2020-04-20 12:25:00,165 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-DFF8A315EADB:null
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_3  | 2020-04-20 12:24:59,969 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DFF8A315EADB,id=258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_1  | 2020-04-20 12:25:00,165 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_3  | 2020-04-20 12:24:59,969 [Command processor thread] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown FollowerState
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-DFF8A315EADB not found.
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_1  | 
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 2020-04-20 12:24:59,969 [Thread-102] INFO impl.FollowerState: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-DFF8A315EADB not found.
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 2020-04-20 12:24:59,971 [Command processor thread] INFO impl.StateMachineUpdater: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-StateMachineUpdater: set stopIndex = 0
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_3  | 2020-04-20 12:24:59,973 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-DFF8A315EADB as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 2020-04-20 12:24:59,973 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-StateMachineUpdater] ERROR impl.StateMachineUpdater: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-StateMachineUpdater: Failed to take snapshot
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-DFF8A315EADB as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 	... 4 more
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_2  | 2020-04-20 12:25:00,161 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-DFF8A315EADB:null
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:27:59,227 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116Z]
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_2  | 2020-04-20 12:25:00,161 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-DFF8A315EADB not found.
scm_1       | 2020-04-20 12:27:59,244 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c not found
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_2  | 
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1       | 2020-04-20 12:27:59,244 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-DFF8A315EADB not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1       | 2020-04-20 12:27:59,244 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c close command to datanode 258ceeb5-4c9c-49bf-b393-79534db322e4
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1       | 2020-04-20 12:27:59,245 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116778Z]
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_3  | 2020-04-20 12:24:59,975 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-DFF8A315EADB as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_3  | 2020-04-20 12:24:59,975 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-StateMachineUpdater] ERROR impl.StateMachineUpdater: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-StateMachineUpdater: Failed to take snapshot
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	... 4 more
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
datanode_3  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-DFF8A315EADB as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 2020-04-20 12:25:00,165 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-DFF8A315EADB:null
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:25:00,166 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-DFF8A315EADB not found.
datanode_1  | 
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-DFF8A315EADB not found.
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1       | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 2020-04-20 12:24:59,975 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 2020-04-20 12:24:59,975 [Command processor thread] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB: closes. applyIndex: 0
datanode_2  | 	... 4 more
scm_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:24:59,976 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_2  | 2020-04-20 12:25:00,163 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-DFF8A315EADB:null
scm_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:27:59,240 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: c86a4171-f4bc-41af-b90c-9651da6f239c, Nodes: 175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:25:22.116Z]
datanode_3  | 2020-04-20 12:24:59,976 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB-SegmentedRaftLogWorker close()
datanode_2  | 2020-04-20 12:25:00,163 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-DFF8A315EADB not found.
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c not found
datanode_3  | 2020-04-20 12:24:59,977 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_2  | 
scm_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_3  | 2020-04-20 12:24:59,977 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-DFF8A315EADB not found.
scm_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_3  | 2020-04-20 12:24:59,977 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.258ceeb5-4c9c-49bf-b393-79534db322e4@group-DFF8A315EADB
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1       | 2020-04-20 12:28:01,375 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : ContainerID 7 creation failed
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_3  | 2020-04-20 12:24:59,978 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1       | 2020-04-20 12:28:01,376 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119541Z]
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_3  |  command on datanode #258ceeb5-4c9c-49bf-b393-79534db322e4.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1       | 2020-04-20 12:28:01,377 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119541Z] moved to CLOSED state
datanode_1  | 	... 4 more
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.destroyPipeline(ReconPipelineManager.java:74)
datanode_3  | 2020-04-20 12:24:59,980 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: addNew group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-4584CFF877B4:java.util.concurrent.CompletableFuture@2d06bf7d[Not completed]
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1       | 2020-04-20 12:28:01,377 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #7
datanode_1  | 2020-04-20 12:25:00,166 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-DFF8A315EADB:null
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_3  | 2020-04-20 12:24:59,983 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4: new RaftServerImpl for group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:28:01,377 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : ContainerID 7 creation failed
datanode_1  | 2020-04-20 12:25:00,166 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
recon_1     | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_3  | 2020-04-20 12:24:59,983 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-DFF8A315EADB not found.
scm_1       | 2020-04-20 12:28:01,398 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119541Z]
datanode_1  | 
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1       | 2020-04-20 12:28:01,400 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : ContainerID 7 creation failed
datanode_3  | 2020-04-20 12:24:59,983 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
recon_1     | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-DFF8A315EADB not found.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1       | 2020-04-20 12:28:01,401 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119541Z]
datanode_3  | 2020-04-20 12:24:59,983 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
recon_1     | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1       | 2020-04-20 12:28:01,401 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-EB079894756F, cid=7
datanode_3  | 2020-04-20 12:24:59,983 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
recon_1     | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:c7410ab9656a4cae:56b24e3416ae0434:0" containerID: 7 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "ef41e815-9e34-4915-8c0b-73e797e718be" writeChunk { blockID { containerID: 7 localID: 104030908011839494 blockCommitSequenceId: 0 } chunkData { chunkName: "104030908011839494_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 2020-04-20 12:24:59,983 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	... 4 more
scm_1       | 2020-04-20 12:28:01,401 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119541Z]
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 2020-04-20 12:24:59,983 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 2020-04-20 12:25:00,164 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-DFF8A315EADB:null
scm_1       | 2020-04-20 12:28:01,409 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-EB079894756F, cid=7
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:24:59,984 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:25:00,164 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:c7410ab9656a4cae:56b24e3416ae0434:0" containerID: 7 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "ef41e815-9e34-4915-8c0b-73e797e718be" writeChunk { blockID { containerID: 7 localID: 104030908011839494 blockCommitSequenceId: 0 } chunkData { chunkName: "104030908011839494_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
recon_1     | 2020-04-20 12:28:01,367 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : ContainerID 7 creation failed
datanode_3  | 2020-04-20 12:24:59,984 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-DFF8A315EADB not found.
datanode_2  | 
scm_1       | 2020-04-20 12:28:01,410 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119541Z]
recon_1     | 2020-04-20 12:28:01,368 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119Z]
datanode_3  | 2020-04-20 12:24:59,984 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/008a62b9-4e5b-43f7-be42-4584cff877b4 does not exist. Creating ...
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-DFF8A315EADB not found.
scm_1       | 2020-04-20 12:28:01,419 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-EB079894756F, cid=7
recon_1     | 2020-04-20 12:28:01,369 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119Z] moved to CLOSED state
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:c7410ab9656a4cae:56b24e3416ae0434:0" containerID: 7 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "ef41e815-9e34-4915-8c0b-73e797e718be" writeChunk { blockID { containerID: 7 localID: 104030908011839494 blockCommitSequenceId: 0 } chunkData { chunkName: "104030908011839494_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_3  | 2020-04-20 12:24:59,987 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/008a62b9-4e5b-43f7-be42-4584cff877b4/in_use.lock acquired by nodename 6@78409bf0b6e2
recon_1     | 2020-04-20 12:28:01,370 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : ContainerID 7 creation failed
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1       | 2020-04-20 12:28:01,419 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119541Z]
datanode_3  | 2020-04-20 12:24:59,990 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/008a62b9-4e5b-43f7-be42-4584cff877b4 has been successfully formatted.
recon_1     | 2020-04-20 12:28:01,370 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119Z]
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1       | 2020-04-20 12:28:03,771 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_3  | 2020-04-20 12:24:59,990 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-4584CFF877B4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
recon_1     | 2020-04-20 12:28:01,381 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : ContainerID 7 creation failed
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_3  | 2020-04-20 12:24:59,991 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
recon_1     | 2020-04-20 12:28:01,381 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119Z]
datanode_1  | 	... 4 more
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-20 12:28:03,771 [EventQueue-PipelineActionsForPipelineActionHandler] WARN pipeline.PipelineActionHandler: Pipeline action CLOSE received for unknown pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c, firing close pipeline event.
datanode_3  | 2020-04-20 12:24:59,991 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
recon_1     | 2020-04-20 12:28:01,389 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-EB079894756F, cid=7
datanode_1  | 2020-04-20 12:25:05,136 [Thread-270] INFO impl.FollowerState: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-FollowerState: change to CANDIDATE, lastRpcTime:5137ms, electionTimeout:5136ms
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-DFF8A315EADB not found.
scm_1       | 2020-04-20 12:28:03,797 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_3  | 2020-04-20 12:24:59,991 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:c7410ab9656a4cae:56b24e3416ae0434:0" containerID: 7 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "ef41e815-9e34-4915-8c0b-73e797e718be" writeChunk { blockID { containerID: 7 localID: 104030908011839494 blockCommitSequenceId: 0 } chunkData { chunkName: "104030908011839494_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 2020-04-20 12:25:05,136 [Thread-270] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown FollowerState
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_3  | 2020-04-20 12:24:59,991 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 2020-04-20 12:28:01,389 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119Z]
datanode_1  | 2020-04-20 12:25:05,136 [Thread-270] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1       | 2020-04-20 12:28:03,797 [EventQueue-PipelineActionsForPipelineActionHandler] WARN pipeline.PipelineActionHandler: Pipeline action CLOSE received for unknown pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c, firing close pipeline event.
datanode_3  | 2020-04-20 12:24:59,991 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
recon_1     | 2020-04-20 12:28:01,390 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be from datanode bb3db77a-6a57-4c4e-bdc7-ea39008446e6. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-EB079894756F, cid=7
datanode_1  | 2020-04-20 12:25:05,136 [Thread-270] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start LeaderElection
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1       | 2020-04-20 12:28:03,797 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_3  | 2020-04-20 12:24:59,991 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.258ceeb5-4c9c-49bf-b393-79534db322e4
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:c7410ab9656a4cae:56b24e3416ae0434:0" containerID: 7 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "ef41e815-9e34-4915-8c0b-73e797e718be" writeChunk { blockID { containerID: 7 localID: 104030908011839494 blockCommitSequenceId: 0 } chunkData { chunkName: "104030908011839494_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 2020-04-20 12:25:05,143 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-LeaderElection2] INFO impl.LeaderElection: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-LeaderElection2: begin an election at term 1 for -1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_3  | 2020-04-20 12:24:59,992 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
recon_1     | 2020-04-20 12:28:01,391 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119Z]
datanode_1  | 2020-04-20 12:25:05,212 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-LeaderElection2] INFO impl.LeaderElection: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-LeaderElection2: Election REJECTED; received 2 response(s) [bb3db77a-6a57-4c4e-bdc7-ea39008446e6<-175c1ce4-a4bc-4858-9a69-a6ac92762c21#0:FAIL-t1, bb3db77a-6a57-4c4e-bdc7-ea39008446e6<-258ceeb5-4c9c-49bf-b393-79534db322e4#0:FAIL-t1] and 0 exception(s); bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4:t1, leader=null, voted=bb3db77a-6a57-4c4e-bdc7-ea39008446e6, raftlog=bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_2  | 	... 4 more
scm_1       | 2020-04-20 12:28:03,797 [EventQueue-PipelineActionsForPipelineActionHandler] WARN pipeline.PipelineActionHandler: Pipeline action CLOSE received for unknown pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c, firing close pipeline event.
datanode_3  | 2020-04-20 12:24:59,992 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/008a62b9-4e5b-43f7-be42-4584cff877b4
recon_1     | 2020-04-20 12:28:01,400 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-EB079894756F, cid=7
datanode_1  | 2020-04-20 12:25:05,213 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-LeaderElection2] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
datanode_2  | 2020-04-20 12:25:05,131 [Thread-235] INFO impl.FollowerState: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-FollowerState: change to CANDIDATE, lastRpcTime:5070ms, electionTimeout:5060ms
scm_1       | 2020-04-20 12:28:03,797 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_3  | 2020-04-20 12:24:59,992 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:c7410ab9656a4cae:56b24e3416ae0434:0" containerID: 7 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "ef41e815-9e34-4915-8c0b-73e797e718be" writeChunk { blockID { containerID: 7 localID: 104030908011839494 blockCommitSequenceId: 0 } chunkData { chunkName: "104030908011839494_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 2020-04-20 12:25:05,213 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-LeaderElection2] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown LeaderElection
datanode_2  | 2020-04-20 12:25:05,131 [Thread-235] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown FollowerState
datanode_3  | 2020-04-20 12:24:59,992 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
scm_1       | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
recon_1     | 2020-04-20 12:28:01,400 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: ef41e815-9e34-4915-8c0b-73e797e718be, Nodes: 258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}175c1ce4-a4bc-4858-9a69-a6ac92762c21{ip: 172.21.0.3, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}bb3db77a-6a57-4c4e-bdc7-ea39008446e6{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:bb3db77a-6a57-4c4e-bdc7-ea39008446e6, CreationTimestamp2020-04-20T12:27:22.119Z]
datanode_1  | 2020-04-20 12:25:05,213 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-LeaderElection2] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start FollowerState
datanode_2  | 2020-04-20 12:25:05,131 [Thread-235] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2020-04-20 12:24:59,992 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2020-04-20 12:28:03,797 [EventQueue-PipelineActionsForPipelineActionHandler] WARN pipeline.PipelineActionHandler: Pipeline action CLOSE received for unknown pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c, firing close pipeline event.
recon_1     | 2020-04-20 12:28:03,767 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_1  | 2020-04-20 12:25:10,251 [grpc-default-executor-4] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 2020-04-20 12:25:05,132 [Thread-235] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start LeaderElection
datanode_3  | 2020-04-20 12:25:00,006 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm_1       | 2020-04-20 12:28:03,804 [IPC Server handler 9 on 9860] INFO ipc.Server: IPC Server handler 9 on 9860, call Call#29 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.21.0.5:58722
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 2020-04-20 12:25:10,257 [grpc-default-executor-4] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown FollowerState
datanode_3  | 2020-04-20 12:25:00,006 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-04-20 12:25:05,141 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection4] INFO impl.LeaderElection: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection4: begin an election at term 1 for -1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
scm_1       | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c not found
recon_1     | 2020-04-20 12:28:03,768 [EventQueue-PipelineActionsForPipelineActionHandler] WARN pipeline.PipelineActionHandler: Pipeline action CLOSE received for unknown pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c, firing close pipeline event.
datanode_1  | 2020-04-20 12:25:10,257 [grpc-default-executor-4] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start FollowerState
datanode_3  | 2020-04-20 12:25:00,006 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-04-20 12:25:05,203 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection4] INFO impl.LeaderElection: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection4: Election REJECTED; received 2 response(s) [175c1ce4-a4bc-4858-9a69-a6ac92762c21<-bb3db77a-6a57-4c4e-bdc7-ea39008446e6#0:FAIL-t1, 175c1ce4-a4bc-4858-9a69-a6ac92762c21<-258ceeb5-4c9c-49bf-b393-79534db322e4#0:FAIL-t1] and 0 exception(s); 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4:t1, leader=null, voted=175c1ce4-a4bc-4858-9a69-a6ac92762c21, raftlog=175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
recon_1     | 2020-04-20 12:28:03,768 [EventQueue-DatanodeCommandForReconNodeManager] INFO scm.ReconNodeManager: Ignoring unsupported command closePipelineCommand for Datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21.
datanode_1  | 2020-04-20 12:25:10,257 [Thread-276] INFO impl.FollowerState: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3  | 2020-04-20 12:25:00,007 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-04-20 12:25:05,203 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection4] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
recon_1     | 2020-04-20 12:28:03,777 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c. Trying to get from SCM.
datanode_1  | 2020-04-20 12:25:10,287 [grpc-default-executor-4] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4584CFF877B4 with new leaderId: 175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_3  | 2020-04-20 12:25:00,007 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-04-20 12:25:05,203 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection4] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown LeaderElection
scm_1       | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
datanode_1  | 2020-04-20 12:25:10,287 [grpc-default-executor-4] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4: change Leader from null to 175c1ce4-a4bc-4858-9a69-a6ac92762c21 at term 2 for appendEntries, leader elected after 10319ms
recon_1     | 2020-04-20 12:28:03,804 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_3  | 2020-04-20 12:25:00,007 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-04-20 12:25:05,204 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection4] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start FollowerState
scm_1       | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
datanode_1  | 2020-04-20 12:25:10,318 [grpc-default-executor-4] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_3  | 2020-04-20 12:25:00,011 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-04-20 12:25:10,245 [Thread-241] INFO impl.FollowerState: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-FollowerState: change to CANDIDATE, lastRpcTime:5041ms, electionTimeout:5041ms
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
datanode_1  | 2020-04-20 12:25:10,318 [grpc-default-executor-4] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-SegmentedRaftLogWorker: Starting segment from index:0
recon_1     | 2020-04-20 12:28:03,805 [EventQueue-PipelineActionsForPipelineActionHandler] WARN pipeline.PipelineActionHandler: Pipeline action CLOSE received for unknown pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c, firing close pipeline event.
datanode_3  | 2020-04-20 12:25:00,011 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-04-20 12:25:10,246 [Thread-241] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown FollowerState
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
datanode_1  | 2020-04-20 12:25:10,320 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/008a62b9-4e5b-43f7-be42-4584cff877b4/current/log_inprogress_0
recon_1     | 2020-04-20 12:28:03,805 [EventQueue-DatanodeCommandForReconNodeManager] INFO scm.ReconNodeManager: Ignoring unsupported command closePipelineCommand for Datanode 175c1ce4-a4bc-4858-9a69-a6ac92762c21.
datanode_3  | 2020-04-20 12:25:00,013 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-04-20 12:25:10,246 [Thread-241] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
datanode_1  | 2020-04-20 12:25:20,030 [ChunkWriter-1-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: 56b24e3416ae0434:ebe55fbcd1c7ca13:56b24e3416ae0434:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
recon_1     | 2020-04-20 12:28:03,808 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_3  | 2020-04-20 12:25:00,013 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-04-20 12:25:10,246 [Thread-241] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start LeaderElection
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_3  | 2020-04-20 12:25:00,013 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-04-20 12:25:10,248 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO impl.LeaderElection: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5: begin an election at term 2 for -1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
recon_1     | 2020-04-20 12:28:03,809 [EventQueue-PipelineActionsForPipelineActionHandler] WARN pipeline.PipelineActionHandler: Pipeline action CLOSE received for unknown pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c, firing close pipeline event.
datanode_3  | 2020-04-20 12:25:00,013 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-04-20 12:25:10,265 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO impl.LeaderElection: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5: Election PASSED; received 1 response(s) [175c1ce4-a4bc-4858-9a69-a6ac92762c21<-258ceeb5-4c9c-49bf-b393-79534db322e4#0:OK-t2] and 0 exception(s); 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4:t2, leader=null, voted=175c1ce4-a4bc-4858-9a69-a6ac92762c21, raftlog=175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
recon_1     | 2020-04-20 12:28:03,810 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c from datanode 258ceeb5-4c9c-49bf-b393-79534db322e4. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_3  | 2020-04-20 12:25:00,013 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4
datanode_2  | 2020-04-20 12:25:10,265 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown LeaderElection
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
recon_1     | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_3  | 2020-04-20 12:25:00,014 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4
datanode_2  | 2020-04-20 12:25:10,265 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
recon_1     | 2020-04-20 12:28:03,810 [EventQueue-DatanodeCommandForReconNodeManager] INFO scm.ReconNodeManager: Ignoring unsupported command closePipelineCommand for Datanode 258ceeb5-4c9c-49bf-b393-79534db322e4.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_3  | 2020-04-20 12:25:00,014 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_2  | 2020-04-20 12:25:10,266 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4584CFF877B4 with new leaderId: 175c1ce4-a4bc-4858-9a69-a6ac92762c21
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1     | 2020-04-20 12:28:03,811 [EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_3  | 2020-04-20 12:25:00,014 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-04-20 12:25:10,269 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4: change Leader from null to 175c1ce4-a4bc-4858-9a69-a6ac92762c21 at term 2 for becomeLeader, leader elected after 10223ms
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     |   id: "c86a4171-f4bc-41af-b90c-9651da6f239c"
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_3  | 2020-04-20 12:25:00,014 [pool-69-thread-1] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start FollowerState
datanode_2  | 2020-04-20 12:25:10,269 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | }
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_3  | 2020-04-20 12:25:00,029 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4584CFF877B4,id=258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_2  | 2020-04-20 12:25:10,269 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | isLeader: true
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_3  | 2020-04-20 12:25:00,030 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4
datanode_2  | 2020-04-20 12:25:10,269 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1     | bytesWritten: 0
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_3  | 2020-04-20 12:25:00,042 [grpc-default-executor-1] WARN impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed groupAdd* GroupManagementRequest:client-6EAD8274C6AD->258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4, cid=8, seq=0, RW, null, Add:group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_2  | 2020-04-20 12:25:10,270 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
recon_1     |  from dn=258ceeb5-4c9c-49bf-b393-79534db322e4{ip: 172.21.0.2, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null} {}
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 2020-04-20 12:25:10,270 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
recon_1     | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException): PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c not found
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 2020-04-20 12:25:10,270 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 2020-04-20 12:25:10,270 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.getPipeline(PipelineStateManager.java:63)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.getPipeline(SCMPipelineManager.java:267)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 2020-04-20 12:25:10,270 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
recon_1     | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:409)
datanode_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=891748352 B) is less than the container size (=1073741824 B).
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 2020-04-20 12:25:10,271 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:375)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 2020-04-20 12:25:10,271 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:249)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 2020-04-20 12:25:10,271 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2  | 2020-04-20 12:25:10,271 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 	... 13 more
datanode_2  | 2020-04-20 12:25:10,271 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
recon_1     | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:75)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1  | 2020-04-20 12:25:20,031 [ChunkWriter-1-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: 56b24e3416ae0434:ebe55fbcd1c7ca13:56b24e3416ae0434:0 , Message: ContainerID 5 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_2  | 2020-04-20 12:25:10,271 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:120)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 2020-04-20 12:25:10,272 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:31605)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 5 creation failed
datanode_2  | 2020-04-20 12:25:10,272 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
datanode_2  | 2020-04-20 12:25:10,272 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
datanode_2  | 2020-04-20 12:25:10,272 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
datanode_2  | 2020-04-20 12:25:10,273 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
datanode_2  | 2020-04-20 12:25:10,274 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | 2020-04-20 12:25:10,275 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start LeaderState
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_2  | 2020-04-20 12:25:10,276 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_2  | 2020-04-20 12:25:10,282 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/008a62b9-4e5b-43f7-be42-4584cff877b4/current/log_inprogress_0
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
datanode_2  | 2020-04-20 12:25:10,290 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-LeaderElection5] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:25:20,031 [ChunkWriter-1-0] ERROR ratis.ContainerStateMachine: group-4584CFF877B4: writeChunk writeStateMachineData failed: blockIdcontainerID: 5
datanode_2  | 2020-04-20 12:25:20,026 [ChunkWriter-36-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: 56b24e3416ae0434:ebe55fbcd1c7ca13:56b24e3416ae0434:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | localID: 104030897365057540
recon_1     | 
datanode_2  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_3  | 	... 13 more
datanode_1  | blockCommitSequenceId: 0
recon_1     | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_1  |  logIndex 1 chunkName 104030897365057540_chunk_1 Error message: ContainerID 5 creation failed Container Result: DISK_OUT_OF_SPACE
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_3  | 2020-04-20 12:25:00,101 [grpc-default-executor-1] WARN impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed groupAdd* GroupManagementRequest:client-47D2A210F73E->258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4, cid=6, seq=0, RW, null, Add:group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_1  | 2020-04-20 12:25:20,031 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4.Reason : ContainerID 5 creation failed
recon_1     | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 2020-04-20 12:25:20,040 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4.Reason : Log already failed at index 1 for task WriteLog:1: (t:2, i:1), STATEMACHINELOGENTRY, client-ED0225477BB7, cid=1
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1  | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:ebe55fbcd1c7ca13:56b24e3416ae0434:0" containerID: 5 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "008a62b9-4e5b-43f7-be42-4584cff877b4" writeChunk { blockID { containerID: 5 localID: 104030897365057540 blockCommitSequenceId: 0 } chunkData { chunkName: "104030897365057540_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1  | 2020-04-20 12:25:30,968 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #5 does not exist in datanode. Container close failed.
recon_1     | 	at com.sun.proxy.$Proxy41.submitRequest(Unknown Source)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRpcRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:123)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1  | 2020-04-20 12:25:51,040 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: addNew group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-9651DA6F239C:java.util.concurrent.CompletableFuture@6c77c9fd[Not completed]
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.submitRequest(StorageContainerLocationProtocolClientSideTranslatorPB.java:114)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1  | 2020-04-20 12:25:51,042 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: new RaftServerImpl for group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
recon_1     | 	at org.apache.hadoop.hdds.scm.protocolPB.StorageContainerLocationProtocolClientSideTranslatorPB.getPipeline(StorageContainerLocationProtocolClientSideTranslatorPB.java:347)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1  | 2020-04-20 12:25:51,044 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
recon_1     | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1  | 2020-04-20 12:25:51,044 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
recon_1     | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1  | 2020-04-20 12:25:51,044 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
recon_1     | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1  | 2020-04-20 12:25:51,044 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
recon_1     | 	at org.apache.hadoop.hdds.tracing.TraceAllMethod.invoke(TraceAllMethod.java:71)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 2020-04-20 12:25:51,044 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
recon_1     | 	at com.sun.proxy.$Proxy42.getPipeline(Unknown Source)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2020-04-20 12:25:51,044 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
recon_1     | 	at org.apache.hadoop.ozone.recon.spi.impl.StorageContainerServiceProviderImpl.getPipeline(StorageContainerServiceProviderImpl.java:55)
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:25:51,044 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconPipelineReportHandler.processPipelineReport(ReconPipelineReportHandler.java:65)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 2020-04-20 12:25:51,045 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=891752448 B) is less than the container size (=1073741824 B).
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:84)
datanode_1  | 2020-04-20 12:25:51,045 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c86a4171-f4bc-41af-b90c-9651da6f239c does not exist. Creating ...
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:47)
datanode_1  | 2020-04-20 12:25:51,047 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c86a4171-f4bc-41af-b90c-9651da6f239c/in_use.lock acquired by nodename 6@69674aa52266
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
datanode_1  | 2020-04-20 12:25:51,048 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c86a4171-f4bc-41af-b90c-9651da6f239c has been successfully formatted.
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	... 13 more
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 2020-04-20 12:25:51,049 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-9651DA6F239C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-04-20 12:25:51,055 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-04-20 12:25:20,036 [ChunkWriter-36-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: 56b24e3416ae0434:ebe55fbcd1c7ca13:56b24e3416ae0434:0 , Message: ContainerID 5 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2020-04-20 12:25:51,055 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 5 creation failed
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:25:51,056 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-20 12:28:03,810 [EventQueue-PipelineActionsForPipelineActionHandler] WARN pipeline.PipelineActionHandler: Pipeline action CLOSE received for unknown pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c, firing close pipeline event.
datanode_1  | 2020-04-20 12:25:51,056 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-4584CFF877B4:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
recon_1     | 2020-04-20 12:28:03,812 [EventQueue-DatanodeCommandForReconNodeManager] INFO scm.ReconNodeManager: Ignoring unsupported command closePipelineCommand for Datanode 258ceeb5-4c9c-49bf-b393-79534db322e4.
datanode_1  | 2020-04-20 12:25:51,056 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 2020-04-20 12:25:51,056 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 	... 13 more
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1  | 2020-04-20 12:25:51,056 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/c86a4171-f4bc-41af-b90c-9651da6f239c
datanode_3  | 2020-04-20 12:25:00,103 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1  | 2020-04-20 12:25:51,056 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | .
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1  | 2020-04-20 12:25:51,056 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-04-20 12:25:00,103 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-DFF8A315EADB:null
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1  | 2020-04-20 12:25:51,056 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-20 12:25:00,103 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1  | 2020-04-20 12:25:51,056 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 2020-04-20 12:25:51,056 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-DFF8A315EADB not found.
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2020-04-20 12:25:51,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:25:51,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 2020-04-20 12:25:20,036 [ChunkWriter-36-0] ERROR ratis.ContainerStateMachine: group-4584CFF877B4: writeChunk writeStateMachineData failed: blockIdcontainerID: 5
datanode_1  | 2020-04-20 12:25:51,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | localID: 104030897365057540
datanode_1  | 2020-04-20 12:25:51,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | blockCommitSequenceId: 0
datanode_1  | 2020-04-20 12:25:51,058 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  |  logIndex 1 chunkName 104030897365057540_chunk_1 Error message: ContainerID 5 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_1  | 2020-04-20 12:25:51,058 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-DFF8A315EADB not found.
datanode_2  | 2020-04-20 12:25:20,037 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4.Reason : ContainerID 5 creation failed
datanode_1  | 2020-04-20 12:25:51,072 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 2020-04-20 12:25:20,044 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4.Reason : Log already failed at index 1 for task WriteLog:1: (t:2, i:1), STATEMACHINELOGENTRY, client-ED0225477BB7, cid=1
datanode_1  | 2020-04-20 12:25:51,072 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:ebe55fbcd1c7ca13:56b24e3416ae0434:0" containerID: 5 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "008a62b9-4e5b-43f7-be42-4584cff877b4" writeChunk { blockID { containerID: 5 localID: 104030897365057540 blockCommitSequenceId: 0 } chunkData { chunkName: "104030897365057540_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 2020-04-20 12:25:51,072 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 2020-04-20 12:25:31,028 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #5 does not exist in datanode. Container close failed.
datanode_1  | 2020-04-20 12:25:51,072 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 2020-04-20 12:25:51,049 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: addNew group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-9651DA6F239C:java.util.concurrent.CompletableFuture@22d4e89d[Not completed]
datanode_1  | 2020-04-20 12:25:51,072 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C
datanode_3  | 	... 4 more
datanode_1  | 2020-04-20 12:25:51,073 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C
datanode_2  | 2020-04-20 12:25:51,051 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: new RaftServerImpl for group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-04-20 12:25:00,103 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-DFF8A315EADB:null
datanode_1  | 2020-04-20 12:25:51,082 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_2  | 2020-04-20 12:25:51,051 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-04-20 12:25:00,103 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
datanode_1  | 2020-04-20 12:25:51,082 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-04-20 12:25:51,051 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 
datanode_1  | 2020-04-20 12:25:51,089 [pool-69-thread-1] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start FollowerState
datanode_2  | 2020-04-20 12:25:51,051 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-DFF8A315EADB not found.
datanode_1  | 2020-04-20 12:25:51,090 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9651DA6F239C,id=bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_2  | 2020-04-20 12:25:51,051 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 2020-04-20 12:25:51,091 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C
datanode_2  | 2020-04-20 12:25:51,051 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 2020-04-20 12:25:51,110 [grpc-default-executor-4] WARN impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed groupAdd* GroupManagementRequest:client-70616D675920->bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C, cid=8, seq=0, RW, null, Add:group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_2  | 2020-04-20 12:25:51,052 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 2020-04-20 12:25:51,052 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 2020-04-20 12:25:51,052 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:25:51,052 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c86a4171-f4bc-41af-b90c-9651da6f239c does not exist. Creating ...
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-DFF8A315EADB not found.
datanode_2  | 2020-04-20 12:25:51,053 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c86a4171-f4bc-41af-b90c-9651da6f239c/in_use.lock acquired by nodename 6@f98376242d82
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 2020-04-20 12:25:51,054 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c86a4171-f4bc-41af-b90c-9651da6f239c has been successfully formatted.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 2020-04-20 12:25:51,056 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-9651DA6F239C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 2020-04-20 12:25:51,056 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 2020-04-20 12:25:51,056 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3  | 	... 4 more
datanode_2  | 2020-04-20 12:25:51,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3  | 2020-04-20 12:25:00,104 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-DFF8A315EADB:null
datanode_2  | 2020-04-20 12:25:51,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3  | 2020-04-20 12:25:00,104 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
datanode_2  | 2020-04-20 12:25:51,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 
datanode_2  | 2020-04-20 12:25:51,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-DFF8A315EADB not found.
datanode_2  | 2020-04-20 12:25:51,057 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/c86a4171-f4bc-41af-b90c-9651da6f239c
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 2020-04-20 12:25:51,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 2020-04-20 12:25:51,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 2020-04-20 12:25:51,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 2020-04-20 12:25:51,058 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:25:51,058 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-DFF8A315EADB not found.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 2020-04-20 12:25:51,058 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 2020-04-20 12:25:51,058 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 2020-04-20 12:25:51,058 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 	... 13 more
datanode_3  | 	... 4 more
datanode_2  | 2020-04-20 12:25:51,058 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-04-20 12:25:51,139 [grpc-default-executor-4] WARN impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed groupAdd* GroupManagementRequest:client-F98B9EA25F1D->bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C, cid=11, seq=0, RW, null, Add:group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_3  | 2020-04-20 12:25:00,104 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-DFF8A315EADB:null
datanode_2  | 2020-04-20 12:25:51,062 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 2020-04-20 12:25:00,104 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
datanode_2  | 2020-04-20 12:25:51,063 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 
datanode_2  | 2020-04-20 12:25:51,063 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-DFF8A315EADB not found.
datanode_2  | 2020-04-20 12:25:51,063 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 2020-04-20 12:25:51,063 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 2020-04-20 12:25:51,063 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 2020-04-20 12:25:51,063 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 2020-04-20 12:25:51,064 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-DFF8A315EADB not found.
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 2020-04-20 12:25:51,064 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 2020-04-20 12:25:51,064 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 2020-04-20 12:25:51,064 [pool-69-thread-1] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start FollowerState
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | 2020-04-20 12:25:51,070 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9651DA6F239C,id=175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2  | 2020-04-20 12:25:51,070 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C
datanode_3  | 	... 4 more
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | 2020-04-20 12:25:51,109 [grpc-default-executor-2] WARN impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed groupAdd* GroupManagementRequest:client-68493BD64124->175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C, cid=10, seq=0, RW, null, Add:group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_3  | 2020-04-20 12:25:00,118 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-DFF8A315EADB:null
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 2020-04-20 12:25:00,118 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b47aa9e4-1bde-4d0a-825f-dff8a315eadb"
datanode_3  | 
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-DFF8A315EADB not found.
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-DFF8A315EADB not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	... 13 more
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 2020-04-20 12:25:51,168 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "c86a4171-f4bc-41af-b90c-9651da6f239c"
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | .
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 2020-04-20 12:25:56,110 [Thread-303] INFO impl.FollowerState: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-FollowerState: change to CANDIDATE, lastRpcTime:5021ms, electionTimeout:5018ms
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 	... 4 more
datanode_1  | 2020-04-20 12:25:56,110 [Thread-303] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown FollowerState
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | 2020-04-20 12:25:05,170 [Thread-161] INFO impl.FollowerState: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-FollowerState: change to CANDIDATE, lastRpcTime:5155ms, electionTimeout:5127ms
datanode_1  | 2020-04-20 12:25:56,110 [Thread-303] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 2020-04-20 12:25:05,170 [Thread-161] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown FollowerState
datanode_1  | 2020-04-20 12:25:56,111 [Thread-303] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start LeaderElection
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 2020-04-20 12:25:05,171 [Thread-161] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2020-04-20 12:25:56,113 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO impl.LeaderElection: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3: begin an election at term 1 for -1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 2020-04-20 12:25:05,171 [Thread-161] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start LeaderElection
datanode_1  | 2020-04-20 12:25:56,125 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO impl.LeaderElection: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3: Election PASSED; received 1 response(s) [bb3db77a-6a57-4c4e-bdc7-ea39008446e6<-258ceeb5-4c9c-49bf-b393-79534db322e4#0:OK-t1] and 0 exception(s); bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C:t1, leader=null, voted=bb3db77a-6a57-4c4e-bdc7-ea39008446e6, raftlog=bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 2020-04-20 12:25:05,175 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-LeaderElection5] INFO impl.LeaderElection: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-LeaderElection5: begin an election at term 1 for -1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_1  | 2020-04-20 12:25:56,126 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown LeaderElection
datanode_3  | 2020-04-20 12:25:05,233 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-LeaderElection5] INFO impl.LeaderElection: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-LeaderElection5: Election REJECTED; received 2 response(s) [258ceeb5-4c9c-49bf-b393-79534db322e4<-bb3db77a-6a57-4c4e-bdc7-ea39008446e6#0:FAIL-t1, 258ceeb5-4c9c-49bf-b393-79534db322e4<-175c1ce4-a4bc-4858-9a69-a6ac92762c21#0:FAIL-t1] and 0 exception(s); 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4:t1, leader=null, voted=258ceeb5-4c9c-49bf-b393-79534db322e4, raftlog=258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2020-04-20 12:25:56,126 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-04-20 12:25:05,233 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-LeaderElection5] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:25:56,126 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-9651DA6F239C with new leaderId: bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_3  | 2020-04-20 12:25:05,234 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-LeaderElection5] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown LeaderElection
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 2020-04-20 12:25:56,131 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C: change Leader from null to bb3db77a-6a57-4c4e-bdc7-ea39008446e6 at term 1 for becomeLeader, leader elected after 5076ms
datanode_3  | 2020-04-20 12:25:05,234 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-LeaderElection5] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start FollowerState
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 2020-04-20 12:25:56,132 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-04-20 12:25:10,253 [grpc-default-executor-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 2020-04-20 12:25:56,132 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-04-20 12:25:10,253 [grpc-default-executor-1] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown FollowerState
datanode_2  | 	... 13 more
datanode_1  | 2020-04-20 12:25:56,141 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C
datanode_3  | 2020-04-20 12:25:10,253 [Thread-167] INFO impl.FollowerState: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2  | 2020-04-20 12:25:51,112 [grpc-default-executor-2] WARN impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed groupAdd* GroupManagementRequest:client-45285A2C3407->175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C, cid=10, seq=0, RW, null, Add:group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_1  | 2020-04-20 12:25:56,141 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-04-20 12:25:10,253 [grpc-default-executor-1] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start FollowerState
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 2020-04-20 12:25:56,141 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-04-20 12:25:10,293 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4584CFF877B4 with new leaderId: 175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1  | 2020-04-20 12:25:56,142 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-04-20 12:25:10,293 [grpc-default-executor-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4: change Leader from null to 175c1ce4-a4bc-4858-9a69-a6ac92762c21 at term 2 for appendEntries, leader elected after 10302ms
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1  | 2020-04-20 12:25:56,142 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-04-20 12:25:10,321 [grpc-default-executor-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1  | 2020-04-20 12:25:56,142 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-04-20 12:25:10,322 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1  | 2020-04-20 12:25:56,144 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2020-04-20 12:25:10,324 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/008a62b9-4e5b-43f7-be42-4584cff877b4/current/log_inprogress_0
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1  | 2020-04-20 12:25:56,144 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-20 12:25:20,042 [ChunkWriter-55-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: 56b24e3416ae0434:ebe55fbcd1c7ca13:56b24e3416ae0434:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1  | 2020-04-20 12:25:56,145 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1  | 2020-04-20 12:25:56,150 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1  | 2020-04-20 12:25:56,150 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1  | 2020-04-20 12:25:56,150 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1  | 2020-04-20 12:25:56,154 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | 2020-04-20 12:25:56,154 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_1  | 2020-04-20 12:25:56,154 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_1  | 2020-04-20 12:25:56,155 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1  | 2020-04-20 12:25:56,155 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1  | 2020-04-20 12:25:56,155 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1  | 2020-04-20 12:25:56,156 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start LeaderState
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 2020-04-20 12:25:56,156 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2020-04-20 12:25:56,158 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c86a4171-f4bc-41af-b90c-9651da6f239c/current/log_inprogress_0
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:25:56,161 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-LeaderElection3] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=891736064 B) is less than the container size (=1073741824 B).
datanode_1  | 2020-04-20 12:26:27,126 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove  FOLLOWER bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4:t2, leader=175c1ce4-a4bc-4858-9a69-a6ac92762c21, voted=175c1ce4-a4bc-4858-9a69-a6ac92762c21, raftlog=bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_1  | 2020-04-20 12:26:27,126 [Command processor thread] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4: shutdown
datanode_2  | 	... 13 more
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_1  | 2020-04-20 12:26:27,126 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4584CFF877B4,id=bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_2  | 2020-04-20 12:25:51,179 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "c86a4171-f4bc-41af-b90c-9651da6f239c"
datanode_3  | 	... 13 more
datanode_1  | 2020-04-20 12:26:27,126 [Command processor thread] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown FollowerState
datanode_2  | .
datanode_3  | 2020-04-20 12:25:20,043 [ChunkWriter-55-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: 56b24e3416ae0434:ebe55fbcd1c7ca13:56b24e3416ae0434:0 , Message: ContainerID 5 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1  | 2020-04-20 12:26:27,126 [Command processor thread] INFO impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-StateMachineUpdater: set stopIndex = 0
datanode_2  | 2020-04-20 12:25:56,125 [grpc-default-executor-2] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 5 creation failed
datanode_1  | 2020-04-20 12:26:27,126 [Thread-277] INFO impl.FollowerState: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2  | 2020-04-20 12:25:56,125 [grpc-default-executor-2] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown FollowerState
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_1  | 2020-04-20 12:26:27,127 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-4584CFF877B4 as the stateMachine is unhealthy. The last applied index is at (t:2, i:0)
datanode_2  | 2020-04-20 12:25:56,125 [Thread-256] INFO impl.FollowerState: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1  | 2020-04-20 12:26:27,128 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-StateMachineUpdater] ERROR impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-StateMachineUpdater: Failed to take snapshot
datanode_2  | 2020-04-20 12:25:56,125 [grpc-default-executor-2] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start FollowerState
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-4584CFF877B4 as the stateMachine is unhealthy. The last applied index is at (t:2, i:0)
datanode_2  | 2020-04-20 12:25:56,173 [grpc-default-executor-2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-9651DA6F239C with new leaderId: bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_2  | 2020-04-20 12:25:56,173 [grpc-default-executor-2] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C: change Leader from null to bb3db77a-6a57-4c4e-bdc7-ea39008446e6 at term 1 for appendEntries, leader elected after 5116ms
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_2  | 2020-04-20 12:25:56,184 [grpc-default-executor-2] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_2  | 2020-04-20 12:25:56,184 [grpc-default-executor-2] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 2020-04-20 12:25:56,186 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c86a4171-f4bc-41af-b90c-9651da6f239c/current/log_inprogress_0
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:26:20,028 [java.util.concurrent.ThreadPoolExecutor$Worker@56cbaf46[State = -1, empty queue]] WARN server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5,entriesCount=1,lastEntry=(t:2, i:1)
datanode_1  | 2020-04-20 12:26:27,128 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-4584CFF877B4 as the stateMachine is unhealthy. The last applied index is at (t:2, i:0)
datanode_3  | 2020-04-20 12:25:20,043 [ChunkWriter-55-0] ERROR ratis.ContainerStateMachine: group-4584CFF877B4: writeChunk writeStateMachineData failed: blockIdcontainerID: 5
datanode_2  | 2020-04-20 12:26:20,028 [java.util.concurrent.ThreadPoolExecutor$Worker@56cbaf46[State = -1, empty queue]] WARN server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4->258ceeb5-4c9c-49bf-b393-79534db322e4-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5,entriesCount=1,lastEntry=(t:2, i:1)
datanode_1  | 2020-04-20 12:26:27,128 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-StateMachineUpdater] ERROR impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-StateMachineUpdater: Failed to take snapshot
datanode_3  | localID: 104030897365057540
datanode_2  | 2020-04-20 12:26:20,030 [java.util.concurrent.ThreadPoolExecutor$Worker@56cbaf46[State = -1, empty queue]] WARN server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4->258ceeb5-4c9c-49bf-b393-79534db322e4-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6,entriesCount=1,lastEntry=(t:2, i:2)
datanode_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-4584CFF877B4 as the stateMachine is unhealthy. The last applied index is at (t:2, i:0)
datanode_3  | blockCommitSequenceId: 0
datanode_2  | 2020-04-20 12:26:20,036 [java.util.concurrent.ThreadPoolExecutor$Worker@56cbaf46[State = -1, empty queue]] WARN server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6,entriesCount=1,lastEntry=(t:2, i:2)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_3  |  logIndex 1 chunkName 104030897365057540_chunk_1 Error message: ContainerID 5 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_2  | 2020-04-20 12:26:52,054 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove    LEADER 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4:t2, leader=175c1ce4-a4bc-4858-9a69-a6ac92762c21, voted=175c1ce4-a4bc-4858-9a69-a6ac92762c21, raftlog=175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_3  | 2020-04-20 12:25:20,043 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4.Reason : ContainerID 5 creation failed
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_2  | 2020-04-20 12:26:52,055 [Command processor thread] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4: shutdown
datanode_3  | 2020-04-20 12:25:20,068 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=008a62b9-4e5b-43f7-be42-4584cff877b4.Reason : Log already failed at index 1 for task WriteLog:1: (t:2, i:1), STATEMACHINELOGENTRY, client-ED0225477BB7, cid=1
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_2  | 2020-04-20 12:26:52,055 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4584CFF877B4,id=175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:ebe55fbcd1c7ca13:56b24e3416ae0434:0" containerID: 5 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "008a62b9-4e5b-43f7-be42-4584cff877b4" writeChunk { blockID { containerID: 5 localID: 104030897365057540 blockCommitSequenceId: 0 } chunkData { chunkName: "104030897365057540_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_2  | 2020-04-20 12:26:52,055 [Command processor thread] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown LeaderState
datanode_1  | 2020-04-20 12:26:27,128 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4
datanode_3  | 2020-04-20 12:25:30,992 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #5 does not exist in datanode. Container close failed.
datanode_2  | 2020-04-20 12:26:52,055 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/0x0000000840609440@4a452f45] WARN server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_1  | 2020-04-20 12:26:27,129 [Command processor thread] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4: closes. applyIndex: 0
datanode_3  | 2020-04-20 12:25:51,069 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: addNew group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-9651DA6F239C:java.util.concurrent.CompletableFuture@580c1ff8[Not completed]
datanode_2  | 2020-04-20 12:26:52,055 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$532/0x0000000840609440@7bc5c737] WARN server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4->258ceeb5-4c9c-49bf-b393-79534db322e4-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_1  | 2020-04-20 12:26:27,129 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_3  | 2020-04-20 12:25:51,070 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4: new RaftServerImpl for group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-04-20 12:26:52,055 [Command processor thread] INFO impl.PendingRequests: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-PendingRequests: sendNotLeaderResponses
datanode_1  | 2020-04-20 12:26:27,130 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4-SegmentedRaftLogWorker close()
datanode_3  | 2020-04-20 12:25:51,073 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-04-20 12:26:52,062 [grpc-default-executor-2] INFO server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4->258ceeb5-4c9c-49bf-b393-79534db322e4-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_1  | 2020-04-20 12:26:27,131 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_3  | 2020-04-20 12:25:51,073 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-04-20 12:26:52,064 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4
datanode_1  | 2020-04-20 12:26:27,131 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4
datanode_3  | 2020-04-20 12:25:51,073 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-04-20 12:26:52,066 [Command processor thread] INFO impl.StateMachineUpdater: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-StateMachineUpdater: set stopIndex = 0
datanode_1  | 2020-04-20 12:26:27,131 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-4584CFF877B4
datanode_3  | 2020-04-20 12:25:51,073 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-04-20 12:26:52,068 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-4584CFF877B4 as the stateMachine is unhealthy. The last applied index is at (t:2, i:0)
datanode_1  | 2020-04-20 12:26:27,132 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_3  | 2020-04-20 12:25:51,073 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-04-20 12:26:52,069 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-StateMachineUpdater] ERROR impl.StateMachineUpdater: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-StateMachineUpdater: Failed to take snapshot
datanode_1  |  command on datanode #bb3db77a-6a57-4c4e-bdc7-ea39008446e6.
datanode_3  | 2020-04-20 12:25:51,073 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-4584CFF877B4 as the stateMachine is unhealthy. The last applied index is at (t:2, i:0)
datanode_1  | 2020-04-20 12:26:27,133 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-4584CFF877B4:null
datanode_3  | 2020-04-20 12:25:51,074 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1  | 2020-04-20 12:26:27,136 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_3  | 2020-04-20 12:25:51,074 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1  | 
datanode_3  | 2020-04-20 12:25:51,074 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c86a4171-f4bc-41af-b90c-9651da6f239c does not exist. Creating ...
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-4584CFF877B4 not found.
datanode_3  | 2020-04-20 12:25:51,077 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c86a4171-f4bc-41af-b90c-9651da6f239c/in_use.lock acquired by nodename 6@78409bf0b6e2
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 2020-04-20 12:25:51,079 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c86a4171-f4bc-41af-b90c-9651da6f239c has been successfully formatted.
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 2020-04-20 12:25:51,080 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-9651DA6F239C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-04-20 12:25:51,081 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-04-20 12:25:51,081 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-04-20 12:25:51,081 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 2020-04-20 12:25:51,083 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-20 12:26:52,069 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-4584CFF877B4 as the stateMachine is unhealthy. The last applied index is at (t:2, i:0)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 2020-04-20 12:25:51,083 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-20 12:26:52,069 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-StateMachineUpdater] ERROR impl.StateMachineUpdater: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-StateMachineUpdater: Failed to take snapshot
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:25:51,084 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-4584CFF877B4 as the stateMachine is unhealthy. The last applied index is at (t:2, i:0)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-4584CFF877B4 not found.
datanode_3  | 2020-04-20 12:25:51,084 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/c86a4171-f4bc-41af-b90c-9651da6f239c
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 2020-04-20 12:25:51,084 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 2020-04-20 12:25:51,084 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 2020-04-20 12:25:51,084 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 2020-04-20 12:25:51,084 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	... 4 more
datanode_3  | 2020-04-20 12:25:51,084 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-04-20 12:26:52,070 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4
datanode_1  | 2020-04-20 12:26:27,137 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-4584CFF877B4:null
datanode_3  | 2020-04-20 12:25:51,084 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-04-20 12:26:52,070 [Command processor thread] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4: closes. applyIndex: 0
datanode_1  | 2020-04-20 12:26:27,137 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_3  | 2020-04-20 12:25:51,084 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-04-20 12:26:52,070 [grpc-default-executor-3] INFO server.GrpcLogAppender: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4->bb3db77a-6a57-4c4e-bdc7-ea39008446e6-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_1  | 
datanode_3  | 2020-04-20 12:25:51,086 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-04-20 12:26:52,070 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-4584CFF877B4 not found.
datanode_3  | 2020-04-20 12:25:51,086 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-04-20 12:26:52,071 [grpc-default-executor-2] INFO impl.FollowerInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4->258ceeb5-4c9c-49bf-b393-79534db322e4: nextIndex: updateUnconditionally 3 -> 1
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 2020-04-20 12:25:51,086 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 2020-04-20 12:25:51,089 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-04-20 12:26:52,075 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4-SegmentedRaftLogWorker close()
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 2020-04-20 12:25:51,089 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-04-20 12:26:52,079 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 2020-04-20 12:25:51,090 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-04-20 12:26:52,079 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:25:51,090 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-04-20 12:26:52,079 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-4584CFF877B4 not found.
datanode_3  | 2020-04-20 12:25:51,090 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-04-20 12:26:52,080 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 2020-04-20 12:25:51,090 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C
datanode_2  |  command on datanode #175c1ce4-a4bc-4858-9a69-a6ac92762c21.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 2020-04-20 12:25:51,097 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C
datanode_2  | 2020-04-20 12:26:52,080 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-4584CFF877B4:null
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 2020-04-20 12:25:51,097 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_2  | 2020-04-20 12:26:52,080 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 2020-04-20 12:25:51,097 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 
datanode_1  | 	... 4 more
datanode_3  | 2020-04-20 12:25:51,097 [pool-69-thread-1] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start FollowerState
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-4584CFF877B4 not found.
datanode_1  | 2020-04-20 12:26:27,138 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-4584CFF877B4:null
datanode_3  | 2020-04-20 12:25:51,098 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9651DA6F239C,id=258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 2020-04-20 12:26:27,138 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_3  | 2020-04-20 12:25:51,098 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 
datanode_3  | 2020-04-20 12:25:51,142 [grpc-default-executor-1] WARN impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed groupAdd* GroupManagementRequest:client-B2B642FB321E->258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C, cid=11, seq=0, RW, null, Add:group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-4584CFF877B4 not found.
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-4584CFF877B4 not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-4584CFF877B4 not found.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 	... 4 more
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 2020-04-20 12:26:52,080 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-4584CFF877B4:null
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 2020-04-20 12:26:52,080 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 
datanode_1  | 	... 4 more
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-4584CFF877B4 not found.
datanode_1  | 2020-04-20 12:26:27,138 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-4584CFF877B4:null
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 2020-04-20 12:26:27,138 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-4584CFF877B4 not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-4584CFF877B4 not found.
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-4584CFF877B4 not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 	... 4 more
datanode_3  | 	... 13 more
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 2020-04-20 12:26:52,080 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-4584CFF877B4:null
datanode_3  | 2020-04-20 12:25:51,146 [grpc-default-executor-4] WARN impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed groupAdd* GroupManagementRequest:client-62C89A664BA2->258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C, cid=9, seq=0, RW, null, Add:group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_2  | 2020-04-20 12:26:52,081 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-4584CFF877B4 not found.
datanode_1  | 	... 4 more
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 2020-04-20 12:26:27,139 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-4584CFF877B4:null
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 2020-04-20 12:26:27,139 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-4584CFF877B4 not found.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-4584CFF877B4 not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | 	... 4 more
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-4584CFF877B4 not found.
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2  | 2020-04-20 12:26:52,081 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-4584CFF877B4:null
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | 2020-04-20 12:26:52,081 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-4584CFF877B4 not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	... 4 more
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 2020-04-20 12:26:52,057 [grpc-default-executor-2] INFO server.GrpcServerProtocolService: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Completed APPEND_ENTRIES, lastRequest: 175c1ce4-a4bc-4858-9a69-a6ac92762c21->bb3db77a-6a57-4c4e-bdc7-ea39008446e6#6-t2, previous=(t:2, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:2, i:2), STATEMACHINELOGENTRY, client-ED0225477BB7, cid=2
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 2020-04-20 12:26:53,173 [ChunkWriter-57-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: 56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-9651DA6F239C:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-4584CFF877B4 not found.
datanode_3  | 	... 13 more
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 2020-04-20 12:25:51,150 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "c86a4171-f4bc-41af-b90c-9651da6f239c"
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | .
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 2020-04-20 12:25:56,117 [grpc-default-executor-4] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 2020-04-20 12:25:56,117 [grpc-default-executor-4] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown FollowerState
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_2  | 	... 4 more
datanode_3  | 2020-04-20 12:25:56,117 [Thread-194] INFO impl.FollowerState: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_2  | 2020-04-20 12:26:52,083 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: remove group-4584CFF877B4:null
datanode_3  | 2020-04-20 12:25:56,117 [grpc-default-executor-4] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start FollowerState
datanode_3  | 2020-04-20 12:25:56,180 [grpc-default-executor-4] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-9651DA6F239C with new leaderId: bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_3  | 2020-04-20 12:25:56,181 [grpc-default-executor-4] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C: change Leader from null to bb3db77a-6a57-4c4e-bdc7-ea39008446e6 at term 1 for appendEntries, leader elected after 5100ms
datanode_3  | 2020-04-20 12:25:56,188 [grpc-default-executor-4] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_3  | 2020-04-20 12:25:56,189 [grpc-default-executor-4] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 2020-04-20 12:26:52,083 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_3  | 2020-04-20 12:25:56,191 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c86a4171-f4bc-41af-b90c-9651da6f239c/current/log_inprogress_0
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 
datanode_3  | 2020-04-20 12:26:52,057 [grpc-default-executor-4] INFO server.GrpcServerProtocolService: 258ceeb5-4c9c-49bf-b393-79534db322e4: Completed APPEND_ENTRIES, lastRequest: 175c1ce4-a4bc-4858-9a69-a6ac92762c21->258ceeb5-4c9c-49bf-b393-79534db322e4#6-t2, previous=(t:2, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:2, i:2), STATEMACHINELOGENTRY, client-ED0225477BB7, cid=2
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | java.io.IOException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-4584CFF877B4 not found.
datanode_3  | 2020-04-20 12:26:52,081 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove  FOLLOWER 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4:t2, leader=175c1ce4-a4bc-4858-9a69-a6ac92762c21, voted=175c1ce4-a4bc-4858-9a69-a6ac92762c21, raftlog=258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
datanode_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=891494400 B) is less than the container size (=1073741824 B).
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 2020-04-20 12:26:52,081 [Command processor thread] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4: shutdown
datanode_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 2020-04-20 12:26:52,081 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4584CFF877B4,id=258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 2020-04-20 12:26:52,081 [Command processor thread] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown FollowerState
datanode_1  | 	... 13 more
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:26:53,174 [ChunkWriter-57-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: 56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0 , Message: ContainerID 6 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_2  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Group group-4584CFF877B4 not found.
datanode_3  | 2020-04-20 12:26:52,081 [Command processor thread] INFO impl.StateMachineUpdater: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-StateMachineUpdater: set stopIndex = 0
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 6 creation failed
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 2020-04-20 12:26:52,082 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-4584CFF877B4 as the stateMachine is unhealthy. The last applied index is at (t:2, i:0)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 2020-04-20 12:26:52,082 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-StateMachineUpdater] ERROR impl.StateMachineUpdater: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-StateMachineUpdater: Failed to take snapshot
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-4584CFF877B4 as the stateMachine is unhealthy. The last applied index is at (t:2, i:0)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_2  | 	... 4 more
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_2  | 2020-04-20 12:26:52,083 [grpc-default-executor-3] INFO impl.FollowerInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-4584CFF877B4->bb3db77a-6a57-4c4e-bdc7-ea39008446e6: nextIndex: updateUnconditionally 3 -> 1
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_2  | 2020-04-20 12:26:53,214 [ChunkWriter-40-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: 56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_3  | 2020-04-20 12:26:52,082 [Thread-168] INFO impl.FollowerState: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_3  | 2020-04-20 12:26:52,082 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-4584CFF877B4 as the stateMachine is unhealthy. The last applied index is at (t:2, i:0)
datanode_1  | 2020-04-20 12:26:53,174 [grpc-default-executor-2] ERROR ratis.ContainerStateMachine: group-9651DA6F239C: writeChunk writeStateMachineData failed: blockIdcontainerID: 6
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_3  | 2020-04-20 12:26:52,082 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-StateMachineUpdater] ERROR impl.StateMachineUpdater: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-StateMachineUpdater: Failed to take snapshot
datanode_1  | localID: 104030903542153221
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_3  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-4584CFF877B4 as the stateMachine is unhealthy. The last applied index is at (t:2, i:0)
datanode_1  | blockCommitSequenceId: 0
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1  |  logIndex 1 chunkName 104030903542153221_chunk_1 Error message: ContainerID 6 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1  | 2020-04-20 12:26:53,175 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c.Reason : ContainerID 6 creation failed
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_1  | 2020-04-20 12:26:53,183 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_3  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_1  | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1  | 2020-04-20 12:26:57,127 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #6 does not exist in datanode. Container close failed.
datanode_3  | 2020-04-20 12:26:52,082 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1  | 2020-04-20 12:27:24,184 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: addNew group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-73E797E718BE:java.util.concurrent.CompletableFuture@382224ee[Not completed]
datanode_3  | 2020-04-20 12:26:52,083 [Command processor thread] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4: closes. applyIndex: 0
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 2020-04-20 12:27:24,186 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: new RaftServerImpl for group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-04-20 12:26:52,083 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2020-04-20 12:27:24,187 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-04-20 12:26:52,085 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4-SegmentedRaftLogWorker close()
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:27:24,187 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-04-20 12:26:52,085 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_2  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=891478016 B) is less than the container size (=1073741824 B).
datanode_1  | 2020-04-20 12:27:24,187 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-04-20 12:26:52,086 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4
datanode_2  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_1  | 2020-04-20 12:27:24,187 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-04-20 12:26:52,086 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.258ceeb5-4c9c-49bf-b393-79534db322e4@group-4584CFF877B4
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_1  | 2020-04-20 12:27:24,187 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-20 12:26:52,086 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_2  | 	... 13 more
datanode_1  | 2020-04-20 12:27:24,187 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_3  |  command on datanode #258ceeb5-4c9c-49bf-b393-79534db322e4.
datanode_2  | 2020-04-20 12:26:53,215 [ChunkWriter-40-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: 56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0 , Message: ContainerID 6 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1  | 2020-04-20 12:27:24,187 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-20 12:26:52,087 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-4584CFF877B4:null
datanode_2  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 6 creation failed
datanode_1  | 2020-04-20 12:27:24,187 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-04-20 12:26:52,087 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_1  | 2020-04-20 12:27:24,187 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ef41e815-9e34-4915-8c0b-73e797e718be does not exist. Creating ...
datanode_3  | 
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1  | 2020-04-20 12:27:24,188 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ef41e815-9e34-4915-8c0b-73e797e718be/in_use.lock acquired by nodename 6@69674aa52266
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-4584CFF877B4 not found.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1  | 2020-04-20 12:27:24,189 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ef41e815-9e34-4915-8c0b-73e797e718be has been successfully formatted.
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1  | 2020-04-20 12:27:24,190 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-73E797E718BE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:27:24,190 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2  | 2020-04-20 12:26:53,215 [grpc-default-executor-3] ERROR ratis.ContainerStateMachine: group-9651DA6F239C: writeChunk writeStateMachineData failed: blockIdcontainerID: 6
datanode_1  | 2020-04-20 12:27:24,190 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | localID: 104030903542153221
datanode_1  | 2020-04-20 12:27:24,190 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-4584CFF877B4 not found.
datanode_2  | blockCommitSequenceId: 0
datanode_1  | 2020-04-20 12:27:24,191 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  |  logIndex 1 chunkName 104030903542153221_chunk_1 Error message: ContainerID 6 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_1  | 2020-04-20 12:27:24,193 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 2020-04-20 12:26:53,215 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c.Reason : ContainerID 6 creation failed
datanode_1  | 2020-04-20 12:27:24,194 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 2020-04-20 12:26:53,231 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_1  | 2020-04-20 12:27:24,194 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 2020-04-20 12:27:24,194 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/ef41e815-9e34-4915-8c0b-73e797e718be
datanode_3  | 	... 4 more
datanode_2  | 2020-04-20 12:27:22,055 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #6 does not exist in datanode. Container close failed.
datanode_1  | 2020-04-20 12:27:24,194 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-04-20 12:26:52,087 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-4584CFF877B4:null
datanode_2  | 2020-04-20 12:27:24,232 [Command processor thread] INFO impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: addNew group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-73E797E718BE:java.util.concurrent.CompletableFuture@292f1fe3[Not completed]
datanode_1  | 2020-04-20 12:27:24,194 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-04-20 12:26:52,087 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_1  | 2020-04-20 12:27:24,194 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-20 12:27:24,233 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: new RaftServerImpl for group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_3  | 
datanode_1  | 2020-04-20 12:27:24,194 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-04-20 12:27:24,233 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-4584CFF877B4 not found.
datanode_1  | 2020-04-20 12:27:24,194 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-04-20 12:27:24,234 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 2020-04-20 12:27:24,195 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-04-20 12:27:24,234 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 2020-04-20 12:27:24,195 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-04-20 12:27:24,234 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 2020-04-20 12:27:24,195 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-04-20 12:27:24,234 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 2020-04-20 12:27:24,195 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-04-20 12:27:24,234 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:27:24,197 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-04-20 12:27:24,234 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-4584CFF877B4 not found.
datanode_1  | 2020-04-20 12:27:24,201 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-04-20 12:27:24,234 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 2020-04-20 12:27:24,201 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-04-20 12:27:24,234 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ef41e815-9e34-4915-8c0b-73e797e718be does not exist. Creating ...
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 2020-04-20 12:27:24,202 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-04-20 12:27:24,237 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ef41e815-9e34-4915-8c0b-73e797e718be/in_use.lock acquired by nodename 6@f98376242d82
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 2020-04-20 12:27:24,202 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-04-20 12:27:24,238 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ef41e815-9e34-4915-8c0b-73e797e718be has been successfully formatted.
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 2020-04-20 12:27:24,202 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-04-20 12:27:24,238 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-73E797E718BE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 	... 4 more
datanode_1  | 2020-04-20 12:27:24,202 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE
datanode_2  | 2020-04-20 12:27:24,238 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-04-20 12:26:52,088 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-4584CFF877B4:null
datanode_1  | 2020-04-20 12:27:24,203 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE
datanode_2  | 2020-04-20 12:27:24,238 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-04-20 12:26:52,088 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_1  | 2020-04-20 12:27:24,204 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_2  | 2020-04-20 12:27:24,238 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 
datanode_1  | 2020-04-20 12:27:24,204 [pool-69-thread-1] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-04-20 12:27:24,238 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-4584CFF877B4 not found.
datanode_1  | 2020-04-20 12:27:24,204 [pool-69-thread-1] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start FollowerState
datanode_2  | 2020-04-20 12:27:24,238 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 2020-04-20 12:27:24,205 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-73E797E718BE,id=bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_2  | 2020-04-20 12:27:24,238 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 2020-04-20 12:27:24,205 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE
datanode_2  | 2020-04-20 12:27:24,238 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2  | 2020-04-20 12:27:24,238 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/ef41e815-9e34-4915-8c0b-73e797e718be
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 2020-04-20 12:27:24,306 [grpc-default-executor-4] WARN impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed groupAdd* GroupManagementRequest:client-FD4A1E25A5BC->bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE, cid=13, seq=0, RW, null, Add:group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_2  | 2020-04-20 12:27:24,238 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 2020-04-20 12:27:24,238 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-4584CFF877B4 not found.
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 2020-04-20 12:27:24,238 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 2020-04-20 12:27:24,238 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 2020-04-20 12:27:24,239 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 2020-04-20 12:27:24,239 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 2020-04-20 12:27:24,239 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 	... 4 more
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 2020-04-20 12:27:24,239 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-04-20 12:26:52,088 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-4584CFF877B4:null
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 2020-04-20 12:27:24,239 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-04-20 12:26:52,088 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 2020-04-20 12:27:24,240 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 2020-04-20 12:27:24,241 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-4584CFF877B4 not found.
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 2020-04-20 12:27:24,243 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | 2020-04-20 12:27:24,243 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2  | 2020-04-20 12:27:24,243 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | 2020-04-20 12:27:24,243 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 2020-04-20 12:27:24,244 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 2020-04-20 12:27:24,249 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-4584CFF877B4 not found.
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 2020-04-20 12:27:24,249 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 2020-04-20 12:27:24,249 [pool-69-thread-1] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:27:24,250 [pool-69-thread-1] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start FollowerState
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 2020-04-20 12:27:24,252 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-73E797E718BE,id=175c1ce4-a4bc-4858-9a69-a6ac92762c21
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2  | 2020-04-20 12:27:24,252 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE
datanode_3  | 	... 4 more
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2  | 2020-04-20 12:27:24,273 [grpc-default-executor-3] WARN impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed groupAdd* GroupManagementRequest:client-00F49DDF33B3->175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE, cid=12, seq=0, RW, null, Add:group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_3  | 2020-04-20 12:26:52,088 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: remove group-4584CFF877B4:null
datanode_1  | 	... 13 more
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 2020-04-20 12:26:52,089 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "008a62b9-4e5b-43f7-be42-4584cff877b4"
datanode_1  | 2020-04-20 12:27:24,311 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "ef41e815-9e34-4915-8c0b-73e797e718be"
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 
datanode_1  | .
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | java.io.IOException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-4584CFF877B4 not found.
datanode_1  | 2020-04-20 12:27:24,328 [grpc-default-executor-4] WARN impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed groupAdd* GroupManagementRequest:client-73D9592BDA99->bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE, cid=11, seq=0, RW, null, Add:group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Group group-4584CFF877B4 not found.
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3  | 	... 4 more
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3  | 2020-04-20 12:26:53,190 [ChunkWriter-59-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: 56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_2  | 	... 13 more
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_2  | 2020-04-20 12:27:24,290 [grpc-default-executor-3] WARN impl.RaftServerProxy: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed groupAdd* GroupManagementRequest:client-ED687528F1D1->175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE, cid=13, seq=0, RW, null, Add:group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed to add group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1  | 	... 13 more
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1  | 2020-04-20 12:27:29,225 [Thread-336] INFO impl.FollowerState: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-FollowerState: change to CANDIDATE, lastRpcTime:5020ms, electionTimeout:5019ms
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1  | 2020-04-20 12:27:29,225 [Thread-336] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown FollowerState
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1  | 2020-04-20 12:27:29,225 [Thread-336] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1  | 2020-04-20 12:27:29,225 [Thread-336] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start LeaderElection
datanode_3  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=891486208 B) is less than the container size (=1073741824 B).
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1  | 2020-04-20 12:27:29,228 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO impl.LeaderElection: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4: begin an election at term 1 for -1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1  | 2020-04-20 12:27:29,238 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO impl.LeaderElection: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4: Election PASSED; received 1 response(s) [bb3db77a-6a57-4c4e-bdc7-ea39008446e6<-258ceeb5-4c9c-49bf-b393-79534db322e4#0:OK-t1] and 0 exception(s); bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE:t1, leader=null, voted=bb3db77a-6a57-4c4e-bdc7-ea39008446e6, raftlog=bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1  | 2020-04-20 12:27:29,238 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown LeaderElection
datanode_3  | 	... 13 more
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 2020-04-20 12:26:53,190 [ChunkWriter-59-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: 56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0 , Message: ContainerID 6 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 2020-04-20 12:27:29,238 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 6 creation failed
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 2020-04-20 12:27:29,238 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-73E797E718BE with new leaderId: bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 2020-04-20 12:27:29,238 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE: change Leader from null to bb3db77a-6a57-4c4e-bdc7-ea39008446e6 at term 1 for becomeLeader, leader elected after 5047ms
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 2020-04-20 12:27:29,238 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 2020-04-20 12:27:29,238 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2020-04-20 12:27:29,238 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:27:29,238 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Failed to add group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 2020-04-20 12:27:29,238 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 2020-04-20 12:27:29,239 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 2020-04-20 12:27:29,239 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 	... 13 more
datanode_1  | 2020-04-20 12:27:29,239 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:26:53,191 [ChunkWriter-59-0] ERROR ratis.ContainerStateMachine: group-9651DA6F239C: writeChunk writeStateMachineData failed: blockIdcontainerID: 6
datanode_1  | 2020-04-20 12:27:29,239 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | localID: 104030903542153221
datanode_2  | 2020-04-20 12:27:24,334 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "ef41e815-9e34-4915-8c0b-73e797e718be"
datanode_1  | 2020-04-20 12:27:29,239 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | blockCommitSequenceId: 0
datanode_2  | .
datanode_1  | 2020-04-20 12:27:29,240 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  |  logIndex 1 chunkName 104030903542153221_chunk_1 Error message: ContainerID 6 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_2  | 2020-04-20 12:27:29,239 [grpc-default-executor-3] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:27:29,240 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2020-04-20 12:26:53,191 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c.Reason : ContainerID 6 creation failed
datanode_2  | 2020-04-20 12:27:29,239 [grpc-default-executor-3] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown FollowerState
datanode_1  | 2020-04-20 12:27:29,240 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-04-20 12:26:53,207 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_2  | 2020-04-20 12:27:29,239 [Thread-308] INFO impl.FollowerState: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1  | 2020-04-20 12:27:29,240 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_2  | 2020-04-20 12:27:29,239 [grpc-default-executor-3] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start FollowerState
datanode_1  | 2020-04-20 12:27:29,241 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2020-04-20 12:27:22,080 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #6 does not exist in datanode. Container close failed.
datanode_2  | 2020-04-20 12:27:29,261 [grpc-default-executor-3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-73E797E718BE with new leaderId: bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_1  | 2020-04-20 12:27:29,242 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-20 12:27:24,213 [Command processor thread] INFO impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: addNew group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] returns group-73E797E718BE:java.util.concurrent.CompletableFuture@646febf[Not completed]
datanode_2  | 2020-04-20 12:27:29,261 [grpc-default-executor-3] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE: change Leader from null to bb3db77a-6a57-4c4e-bdc7-ea39008446e6 at term 1 for appendEntries, leader elected after 5023ms
datanode_1  | 2020-04-20 12:27:29,242 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 2020-04-20 12:27:24,214 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4: new RaftServerImpl for group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-04-20 12:27:29,263 [grpc-default-executor-3] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_1  | 2020-04-20 12:27:29,242 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2020-04-20 12:27:24,215 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-04-20 12:27:29,263 [grpc-default-executor-3] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-04-20 12:27:29,242 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-04-20 12:27:24,215 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-04-20 12:27:29,265 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ef41e815-9e34-4915-8c0b-73e797e718be/current/log_inprogress_0
datanode_1  | 2020-04-20 12:27:29,243 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-20 12:27:24,215 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-04-20 12:28:00,242 [grpc-default-executor-3] INFO server.GrpcServerProtocolService: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: Completed APPEND_ENTRIES, lastRequest: bb3db77a-6a57-4c4e-bdc7-ea39008446e6->175c1ce4-a4bc-4858-9a69-a6ac92762c21#25-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=5
datanode_1  | 2020-04-20 12:27:29,243 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: start LeaderState
datanode_3  | 2020-04-20 12:27:24,215 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-04-20 12:28:01,361 [ChunkWriter-7-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: 56b24e3416ae0434:c7410ab9656a4cae:56b24e3416ae0434:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1  | 2020-04-20 12:27:29,253 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-04-20 12:27:24,215 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_1  | 2020-04-20 12:27:29,257 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ef41e815-9e34-4915-8c0b-73e797e718be/current/log_inprogress_0
datanode_3  | 2020-04-20 12:27:24,216 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE: ConfigurationManager, init=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_1  | 2020-04-20 12:27:29,268 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-LeaderElection4] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_3  | 2020-04-20 12:27:24,216 [grpc-default-executor-4] WARN impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed groupAdd* GroupManagementRequest:client-4436768C8D4E->258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE, cid=12, seq=0, RW, null, Add:group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_1  | 2020-04-20 12:27:53,188 [java.util.concurrent.ThreadPoolExecutor$Worker@37305459[State = -1, empty queue]] WARN server.GrpcLogAppender: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C->258ceeb5-4c9c-49bf-b393-79534db322e4-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=24,entriesCount=1,lastEntry=(t:1, i:1)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 2020-04-20 12:27:53,189 [java.util.concurrent.ThreadPoolExecutor$Worker@37305459[State = -1, empty queue]] WARN server.GrpcLogAppender: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C->258ceeb5-4c9c-49bf-b393-79534db322e4-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=25,entriesCount=1,lastEntry=(t:1, i:2)
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1  | 2020-04-20 12:27:53,189 [java.util.concurrent.ThreadPoolExecutor$Worker@37305459[State = -1, empty queue]] WARN server.GrpcLogAppender: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C->175c1ce4-a4bc-4858-9a69-a6ac92762c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=24,entriesCount=1,lastEntry=(t:1, i:1)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1  | 2020-04-20 12:27:53,190 [java.util.concurrent.ThreadPoolExecutor$Worker@37305459[State = -1, empty queue]] WARN server.GrpcLogAppender: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C->175c1ce4-a4bc-4858-9a69-a6ac92762c21-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=25,entriesCount=1,lastEntry=(t:1, i:2)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1  | 2020-04-20 12:28:00,239 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove    LEADER bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C:t1, leader=bb3db77a-6a57-4c4e-bdc7-ea39008446e6, voted=bb3db77a-6a57-4c4e-bdc7-ea39008446e6, raftlog=bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null RUNNING
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1  | 2020-04-20 12:28:00,239 [Command processor thread] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C: shutdown
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1  | 2020-04-20 12:28:00,239 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9651DA6F239C,id=bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1  | 2020-04-20 12:28:00,239 [Command processor thread] INFO impl.RoleInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: shutdown LeaderState
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1  | 2020-04-20 12:28:00,240 [Command processor thread] INFO impl.PendingRequests: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-PendingRequests: sendNotLeaderResponses
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1  | 2020-04-20 12:28:00,240 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$533/0x0000000840609840@353d0db6] WARN server.GrpcLogAppender: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C->258ceeb5-4c9c-49bf-b393-79534db322e4-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1  | 2020-04-20 12:28:00,241 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$533/0x0000000840609840@41a05696] WARN server.GrpcLogAppender: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C->175c1ce4-a4bc-4858-9a69-a6ac92762c21-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_2  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=891203584 B) is less than the container size (=1073741824 B).
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1  | 2020-04-20 12:28:00,246 [grpc-default-executor-4] INFO server.GrpcLogAppender: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C->258ceeb5-4c9c-49bf-b393-79534db322e4-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_2  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | 2020-04-20 12:28:00,246 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C
datanode_2  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 2020-04-20 12:28:00,248 [Command processor thread] INFO impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-StateMachineUpdater: set stopIndex = 0
datanode_2  | 	... 13 more
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 2020-04-20 12:28:00,248 [grpc-default-executor-2] INFO server.GrpcLogAppender: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C->175c1ce4-a4bc-4858-9a69-a6ac92762c21-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_2  | 2020-04-20 12:28:01,362 [ChunkWriter-7-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: 56b24e3416ae0434:c7410ab9656a4cae:56b24e3416ae0434:0 , Message: ContainerID 7 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 7 creation failed
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 2020-04-20 12:28:00,248 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-9651DA6F239C as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 2020-04-20 12:28:00,250 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-StateMachineUpdater] ERROR impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-StateMachineUpdater: Failed to take snapshot
datanode_2  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-9651DA6F239C as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	... 13 more
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 2020-04-20 12:27:24,217 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-20 12:27:24,217 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:27:24,217 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ef41e815-9e34-4915-8c0b-73e797e718be does not exist. Creating ...
datanode_1  | 2020-04-20 12:28:00,250 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-9651DA6F239C as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | 2020-04-20 12:28:01,362 [ChunkWriter-7-0] ERROR ratis.ContainerStateMachine: group-73E797E718BE: writeChunk writeStateMachineData failed: blockIdcontainerID: 7
datanode_3  | 2020-04-20 12:27:24,218 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ef41e815-9e34-4915-8c0b-73e797e718be/in_use.lock acquired by nodename 6@78409bf0b6e2
datanode_1  | 2020-04-20 12:28:00,250 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-StateMachineUpdater] ERROR impl.StateMachineUpdater: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-StateMachineUpdater: Failed to take snapshot
datanode_2  | localID: 104030908011839494
datanode_3  | 2020-04-20 12:27:24,220 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ef41e815-9e34-4915-8c0b-73e797e718be has been successfully formatted.
datanode_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-9651DA6F239C as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_2  | blockCommitSequenceId: 0
datanode_3  | 2020-04-20 12:27:24,220 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-73E797E718BE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_2  |  logIndex 1 chunkName 104030908011839494_chunk_1 Error message: ContainerID 7 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_3  | 2020-04-20 12:27:24,220 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_2  | 2020-04-20 12:28:01,362 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be.Reason : ContainerID 7 creation failed
datanode_3  | 2020-04-20 12:27:24,221 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_2  | 2020-04-20 12:28:01,385 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-73E797E718BE-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-EB079894756F, cid=7
datanode_3  | 2020-04-20 12:27:24,221 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_2  | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:c7410ab9656a4cae:56b24e3416ae0434:0" containerID: 7 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "ef41e815-9e34-4915-8c0b-73e797e718be" writeChunk { blockID { containerID: 7 localID: 104030908011839494 blockCommitSequenceId: 0 } chunkData { chunkName: "104030908011839494_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_3  | 2020-04-20 12:27:24,221 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-04-20 12:28:03,732 [grpc-default-executor-3] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C: change Leader from bb3db77a-6a57-4c4e-bdc7-ea39008446e6 to null at term 2 for updateCurrentTerm
datanode_3  | 2020-04-20 12:27:24,221 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-20 12:28:00,251 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C
datanode_2  | 2020-04-20 12:28:03,732 [grpc-default-executor-3] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:27:24,222 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | 2020-04-20 12:28:00,251 [Command processor thread] INFO impl.RaftServerImpl: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C: closes. applyIndex: 0
datanode_2  | 2020-04-20 12:28:03,732 [grpc-default-executor-3] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: shutdown FollowerState
datanode_3  | 2020-04-20 12:27:24,222 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-04-20 12:28:00,252 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_2  | 2020-04-20 12:28:03,732 [grpc-default-executor-3] INFO impl.RoleInfo: 175c1ce4-a4bc-4858-9a69-a6ac92762c21: start FollowerState
datanode_3  | 2020-04-20 12:27:24,222 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/ef41e815-9e34-4915-8c0b-73e797e718be
datanode_1  | 2020-04-20 12:28:00,254 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C-SegmentedRaftLogWorker close()
datanode_2  | 2020-04-20 12:28:03,732 [Thread-260] INFO impl.FollowerState: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3  | 2020-04-20 12:27:24,222 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-04-20 12:28:00,255 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_2  | 2020-04-20 12:28:03,752 [grpc-default-executor-3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-9651DA6F239C with new leaderId: 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:27:24,222 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-04-20 12:28:00,255 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C
datanode_2  | 2020-04-20 12:28:03,752 [grpc-default-executor-3] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C: change Leader from null to 258ceeb5-4c9c-49bf-b393-79534db322e4 at term 2 for appendEntries, leader elected after 20ms
datanode_3  | 2020-04-20 12:27:24,222 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-20 12:28:00,255 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C
datanode_1  | 2020-04-20 12:28:00,256 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "c86a4171-f4bc-41af-b90c-9651da6f239c"
datanode_2  | 2020-04-20 12:28:03,758 [grpc-default-executor-3] INFO impl.RaftServerImpl: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C: set configuration 3: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 3
datanode_1  |  command on datanode #bb3db77a-6a57-4c4e-bdc7-ea39008446e6.
datanode_3  | 2020-04-20 12:27:24,222 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-04-20 12:28:03,761 [grpc-default-executor-3] INFO segmented.SegmentedRaftLogWorker: 175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C-SegmentedRaftLogWorker: Rolling segment log-0_2 to index:2
datanode_1  | 2020-04-20 12:28:00,256 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-9651DA6F239C:null
datanode_3  | 2020-04-20 12:27:24,222 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-04-20 12:28:03,762 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_1  | 2020-04-20 12:28:00,256 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "c86a4171-f4bc-41af-b90c-9651da6f239c"
datanode_3  | 2020-04-20 12:27:24,223 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 
datanode_3  | 2020-04-20 12:27:24,223 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-04-20 12:28:03,766 [175c1ce4-a4bc-4858-9a69-a6ac92762c21@group-9651DA6F239C-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-9651DA6F239C not found.
datanode_3  | 2020-04-20 12:27:24,223 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 2020-04-20 12:27:24,223 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-04-20 12:27:24,224 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 2020-04-20 12:27:24,224 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-9651DA6F239C not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_1  | 2020-04-20 12:28:00,256 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-9651DA6F239C:null
datanode_1  | 2020-04-20 12:28:00,256 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "c86a4171-f4bc-41af-b90c-9651da6f239c"
datanode_1  | 
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-9651DA6F239C not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-9651DA6F239C not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_1  | 2020-04-20 12:28:00,257 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-9651DA6F239C:null
datanode_1  | 2020-04-20 12:28:00,257 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "c86a4171-f4bc-41af-b90c-9651da6f239c"
datanode_1  | 
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-9651DA6F239C not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-9651DA6F239C not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_1  | 2020-04-20 12:28:00,257 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-9651DA6F239C:null
datanode_1  | 2020-04-20 12:28:00,257 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "c86a4171-f4bc-41af-b90c-9651da6f239c"
datanode_1  | 
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-9651DA6F239C not found.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-9651DA6F239C not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1  | 	... 4 more
datanode_1  | 2020-04-20 12:28:00,257 [Command processor thread] INFO impl.RaftServerProxy: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: remove group-9651DA6F239C:null
datanode_3  | 2020-04-20 12:27:24,241 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-04-20 12:28:00,257 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "c86a4171-f4bc-41af-b90c-9651da6f239c"
datanode_3  | 2020-04-20 12:27:24,241 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 
datanode_3  | 2020-04-20 12:27:24,242 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | java.io.IOException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-9651DA6F239C not found.
datanode_3  | 2020-04-20 12:27:24,243 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_3  | 2020-04-20 12:27:24,243 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_3  | 2020-04-20 12:27:24,244 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3  | 2020-04-20 12:27:24,250 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE: start as a follower, conf=-1: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:27:24,250 [pool-69-thread-1] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Group group-9651DA6F239C not found.
datanode_3  | 2020-04-20 12:27:24,250 [pool-69-thread-1] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start FollowerState
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_3  | 2020-04-20 12:27:24,251 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-73E797E718BE,id=258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_3  | 2020-04-20 12:27:24,251 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_3  | 2020-04-20 12:27:24,274 [grpc-default-executor-4] WARN impl.RaftServerProxy: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed groupAdd* GroupManagementRequest:client-A0B6C86B095C->258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE, cid=10, seq=0, RW, null, Add:group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858]
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_1  | 	... 4 more
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 258ceeb5-4c9c-49bf-b393-79534db322e4: Failed to add group-73E797E718BE:[bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858] since the group already exists in the map.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3  | 	... 13 more
datanode_3  | 2020-04-20 12:27:24,315 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "ef41e815-9e34-4915-8c0b-73e797e718be"
datanode_3  | .
datanode_3  | 2020-04-20 12:27:29,232 [grpc-default-executor-5] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_3  | 2020-04-20 12:27:29,232 [grpc-default-executor-5] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown FollowerState
datanode_3  | 2020-04-20 12:27:29,232 [Thread-268] INFO impl.FollowerState: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3  | 2020-04-20 12:27:29,234 [grpc-default-executor-5] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start FollowerState
datanode_3  | 2020-04-20 12:27:29,284 [grpc-default-executor-5] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-73E797E718BE with new leaderId: bb3db77a-6a57-4c4e-bdc7-ea39008446e6
datanode_3  | 2020-04-20 12:27:29,284 [grpc-default-executor-5] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE: change Leader from null to bb3db77a-6a57-4c4e-bdc7-ea39008446e6 at term 1 for appendEntries, leader elected after 5063ms
datanode_3  | 2020-04-20 12:27:29,287 [grpc-default-executor-5] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE: set configuration 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 0
datanode_3  | 2020-04-20 12:27:29,287 [grpc-default-executor-5] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-04-20 12:27:29,289 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ef41e815-9e34-4915-8c0b-73e797e718be/current/log_inprogress_0
datanode_3  | 2020-04-20 12:28:00,242 [grpc-default-executor-5] INFO server.GrpcServerProtocolService: 258ceeb5-4c9c-49bf-b393-79534db322e4: Completed APPEND_ENTRIES, lastRequest: bb3db77a-6a57-4c4e-bdc7-ea39008446e6->258ceeb5-4c9c-49bf-b393-79534db322e4#25-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=5
datanode_3  | 2020-04-20 12:28:01,364 [ChunkWriter-26-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: 56b24e3416ae0434:c7410ab9656a4cae:56b24e3416ae0434:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_1  | 2020-04-20 12:28:01,359 [ChunkWriter-30-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: 56b24e3416ae0434:c7410ab9656a4cae:56b24e3416ae0434:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=891211776 B) is less than the container size (=1073741824 B).
datanode_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_1  | 	... 13 more
datanode_1  | 2020-04-20 12:28:01,361 [ChunkWriter-30-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: 56b24e3416ae0434:c7410ab9656a4cae:56b24e3416ae0434:0 , Message: ContainerID 7 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 7 creation failed
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:28:01,365 [ChunkWriter-30-0] ERROR ratis.ContainerStateMachine: group-73E797E718BE: writeChunk writeStateMachineData failed: blockIdcontainerID: 7
datanode_1  | localID: 104030908011839494
datanode_1  | blockCommitSequenceId: 0
datanode_1  |  logIndex 1 chunkName 104030908011839494_chunk_1 Error message: ContainerID 7 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_1  | 2020-04-20 12:28:01,366 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be.Reason : ContainerID 7 creation failed
datanode_1  | 2020-04-20 12:28:01,382 [bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-73E797E718BE-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-EB079894756F, cid=7
datanode_1  | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:c7410ab9656a4cae:56b24e3416ae0434:0" containerID: 7 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "ef41e815-9e34-4915-8c0b-73e797e718be" writeChunk { blockID { containerID: 7 localID: 104030908011839494 blockCommitSequenceId: 0 } chunkData { chunkName: "104030908011839494_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_1  | 2020-04-20 12:28:03,731 [grpc-default-executor-5] WARN server.GrpcServerProtocolService: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: Failed requestVote 258ceeb5-4c9c-49bf-b393-79534db322e4->bb3db77a-6a57-4c4e-bdc7-ea39008446e6#0
datanode_1  | org.apache.ratis.protocol.GroupMismatchException: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: group-9651DA6F239C not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:122)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:269)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:278)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:273)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:445)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:166)
datanode_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:316)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-04-20 12:28:05,248 [grpc-default-executor-4] INFO impl.FollowerInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C->258ceeb5-4c9c-49bf-b393-79534db322e4: nextIndex: updateUnconditionally 3 -> 1
datanode_1  | 2020-04-20 12:28:05,252 [grpc-default-executor-2] INFO impl.FollowerInfo: bb3db77a-6a57-4c4e-bdc7-ea39008446e6@group-9651DA6F239C->175c1ce4-a4bc-4858-9a69-a6ac92762c21: nextIndex: updateUnconditionally 3 -> 1
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=891199488 B) is less than the container size (=1073741824 B).
datanode_3  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_3  | 	... 13 more
datanode_3  | 2020-04-20 12:28:01,365 [ChunkWriter-26-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: 56b24e3416ae0434:c7410ab9656a4cae:56b24e3416ae0434:0 , Message: ContainerID 7 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 7 creation failed
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-04-20 12:28:01,366 [ChunkWriter-26-0] ERROR ratis.ContainerStateMachine: group-73E797E718BE: writeChunk writeStateMachineData failed: blockIdcontainerID: 7
datanode_3  | localID: 104030908011839494
datanode_3  | blockCommitSequenceId: 0
datanode_3  |  logIndex 1 chunkName 104030908011839494_chunk_1 Error message: ContainerID 7 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_3  | 2020-04-20 12:28:01,367 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be.Reason : ContainerID 7 creation failed
datanode_3  | 2020-04-20 12:28:01,383 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-73E797E718BE-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=ef41e815-9e34-4915-8c0b-73e797e718be.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-EB079894756F, cid=7
datanode_3  | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:c7410ab9656a4cae:56b24e3416ae0434:0" containerID: 7 datanodeUuid: "258ceeb5-4c9c-49bf-b393-79534db322e4" pipelineID: "ef41e815-9e34-4915-8c0b-73e797e718be" writeChunk { blockID { containerID: 7 localID: 104030908011839494 blockCommitSequenceId: 0 } chunkData { chunkName: "104030908011839494_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_3  | 2020-04-20 12:28:03,711 [Thread-199] INFO impl.FollowerState: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-FollowerState: change to CANDIDATE, lastRpcTime:5417ms, electionTimeout:5098ms
datanode_3  | 2020-04-20 12:28:03,711 [Thread-199] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown FollowerState
datanode_3  | 2020-04-20 12:28:03,712 [Thread-199] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_3  | 2020-04-20 12:28:03,712 [Thread-199] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start LeaderElection
datanode_3  | 2020-04-20 12:28:03,717 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C: change Leader from bb3db77a-6a57-4c4e-bdc7-ea39008446e6 to null at term 1 for initElection
datanode_3  | 2020-04-20 12:28:03,722 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO impl.LeaderElection: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6: begin an election at term 2 for 0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 2020-04-20 12:28:03,737 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO impl.LeaderElection: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: group-9651DA6F239C not found.
datanode_3  | 2020-04-20 12:28:03,742 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO impl.LeaderElection: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6: Election PASSED; received 1 response(s) [258ceeb5-4c9c-49bf-b393-79534db322e4<-175c1ce4-a4bc-4858-9a69-a6ac92762c21#0:OK-t2] and 1 exception(s); 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C:t2, leader=null, voted=258ceeb5-4c9c-49bf-b393-79534db322e4, raftlog=258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null
datanode_3  | 2020-04-20 12:28:03,742 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO impl.LeaderElection:   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: bb3db77a-6a57-4c4e-bdc7-ea39008446e6: group-9651DA6F239C not found.
datanode_3  | 2020-04-20 12:28:03,742 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: shutdown LeaderElection
datanode_3  | 2020-04-20 12:28:03,742 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode_3  | 2020-04-20 12:28:03,742 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-9651DA6F239C with new leaderId: 258ceeb5-4c9c-49bf-b393-79534db322e4
datanode_3  | 2020-04-20 12:28:03,742 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C: change Leader from null to 258ceeb5-4c9c-49bf-b393-79534db322e4 at term 2 for becomeLeader, leader elected after 25ms
datanode_3  | 2020-04-20 12:28:03,743 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-04-20 12:28:03,743 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-04-20 12:28:03,743 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C
datanode_3  | 2020-04-20 12:28:03,743 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-04-20 12:28:03,743 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-04-20 12:28:03,743 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-04-20 12:28:03,743 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-04-20 12:28:03,743 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-04-20 12:28:03,743 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2020-04-20 12:28:03,743 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-20 12:28:03,743 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 2020-04-20 12:28:03,743 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2020-04-20 12:28:03,743 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-04-20 12:28:03,743 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-20 12:28:03,744 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2020-04-20 12:28:03,744 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-20 12:28:03,744 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 2020-04-20 12:28:03,744 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2020-04-20 12:28:03,744 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-04-20 12:28:03,744 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-20 12:28:03,744 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO impl.RoleInfo: 258ceeb5-4c9c-49bf-b393-79534db322e4: start LeaderState
datanode_3  | 2020-04-20 12:28:03,746 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO segmented.SegmentedRaftLogWorker: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-SegmentedRaftLogWorker: Rolling segment log-0_2 to index:2
datanode_3  | 2020-04-20 12:28:03,746 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_3  | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
datanode_3  | 2020-04-20 12:28:03,750 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-LeaderElection6] INFO impl.RaftServerImpl: 258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C: set configuration 3: [bb3db77a-6a57-4c4e-bdc7-ea39008446e6:172.21.0.8:9858, 175c1ce4-a4bc-4858-9a69-a6ac92762c21:172.21.0.3:9858, 258ceeb5-4c9c-49bf-b393-79534db322e4:172.21.0.2:9858], old=null at 3
datanode_3  | 2020-04-20 12:28:03,778 [258ceeb5-4c9c-49bf-b393-79534db322e4@group-9651DA6F239C-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=c86a4171-f4bc-41af-b90c-9651da6f239c.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DF17EC84729C, cid=4
datanode_3  | 	 State Machine: cmdType: WriteChunk traceID: "56b24e3416ae0434:b9ab7cbd99464535:56b24e3416ae0434:0" containerID: 6 datanodeUuid: "175c1ce4-a4bc-4858-9a69-a6ac92762c21" pipelineID: "c86a4171-f4bc-41af-b90c-9651da6f239c" writeChunk { blockID { containerID: 6 localID: 104030903542153221 blockCommitSequenceId: 0 } chunkData { chunkName: "104030903542153221_chunk_1" offset: 0 len: 17540 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: " wi\267" } } }, container path=nonexistent
