Attaching to ozone-topology_datanode_4_1, ozone-topology_datanode_1_1, ozone-topology_datanode_2_1, ozone-topology_datanode_3_1, ozone-topology_datanode_5_1, ozone-topology_datanode_6_1, ozone-topology_scm_1, ozone-topology_om_1
datanode_2_1  | Enabled profiling in kernel
datanode_2_1  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2_1  | 2020-04-20 12:11:11,531 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2_1  | /************************************************************
datanode_2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2_1  | STARTUP_MSG:   host = efb8b51ec4ab/10.5.0.5
datanode_2_1  | STARTUP_MSG:   args = []
datanode_2_1  | STARTUP_MSG:   version = 3.2.0
datanode_2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_2_1  | STARTUP_MSG:   java = 11.0.6
datanode_2_1  | ************************************************************/
datanode_2_1  | 2020-04-20 12:11:11,619 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2_1  | 2020-04-20 12:11:13,083 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2_1  | 2020-04-20 12:11:13,579 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2_1  | 2020-04-20 12:11:14,816 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2_1  | 2020-04-20 12:11:14,816 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2_1  | 2020-04-20 12:11:15,935 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:efb8b51ec4ab ip:10.5.0.5
datanode_2_1  | 2020-04-20 12:11:16,565 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2_1  | 2020-04-20 12:11:16,573 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2_1  | 2020-04-20 12:11:16,574 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2_1  | 2020-04-20 12:11:16,630 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2_1  | 2020-04-20 12:11:16,794 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2_1  | 2020-04-20 12:11:22,056 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2_1  | 2020-04-20 12:11:22,286 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2_1  | 2020-04-20 12:11:22,661 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2_1  | 2020-04-20 12:11:22,696 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2_1  | 2020-04-20 12:11:22,703 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-04-20 12:11:22,706 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2_1  | 2020-04-20 12:11:22,713 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-04-20 12:11:24,208 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-04-20 12:11:24,823 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2_1  | 2020-04-20 12:11:24,928 [main] INFO util.log: Logging initialized @18376ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2_1  | 2020-04-20 12:11:25,467 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2_1  | 2020-04-20 12:11:25,483 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2_1  | 2020-04-20 12:11:25,550 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2_1  | 2020-04-20 12:11:25,566 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2_1  | 2020-04-20 12:11:25,572 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2_1  | 2020-04-20 12:11:25,581 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2_1  | 2020-04-20 12:11:25,720 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2_1  | 2020-04-20 12:11:25,739 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2_1  | 2020-04-20 12:11:25,740 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2_1  | 2020-04-20 12:11:26,371 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2_1  | 2020-04-20 12:11:26,371 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2_1  | 2020-04-20 12:11:26,373 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2_1  | 2020-04-20 12:11:26,459 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f76c2cc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2_1  | 2020-04-20 12:11:26,481 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@441b8382{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2_1  | 2020-04-20 12:11:26,980 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7c011174{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-13838379146711896647.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2_1  | 2020-04-20 12:11:27,072 [main] INFO server.AbstractConnector: Started ServerConnector@1491344a{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2_1  | 2020-04-20 12:11:27,073 [main] INFO server.Server: Started @20520ms
datanode_2_1  | 2020-04-20 12:11:27,113 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2_1  | 2020-04-20 12:11:27,113 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2_1  | 2020-04-20 12:11:27,117 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2_1  | 2020-04-20 12:11:27,312 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@46adaa7c] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2_1  | 2020-04-20 12:11:27,922 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2_1  | 2020-04-20 12:11:30,361 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-04-20 12:11:31,380 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2_1  | java.net.SocketTimeoutException: Call From efb8b51ec4ab/10.5.0.5 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:44174 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_2_1  | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:44174 remote=scm/10.5.0.71:9861]
datanode_2_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_2_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_2_1  | 2020-04-20 12:11:31,653 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2_1  | 2020-04-20 12:11:31,662 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2_1  | 2020-04-20 12:11:31,663 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 8e63932d-e4c5-48a1-856f-f13c15c5f03b at port 9858
datanode_2_1  | 2020-04-20 12:11:31,763 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: start RPC server
datanode_2_1  | 2020-04-20 12:11:32,145 [Datanode State Machine Thread - 1] INFO server.GrpcService: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2_1  | 2020-04-20 12:11:36,357 [Command processor thread] INFO impl.RaftServerProxy: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: addNew group-CA703B34E48B:[8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] returns group-CA703B34E48B:java.util.concurrent.CompletableFuture@44c07e4e[Not completed]
datanode_2_1  | 2020-04-20 12:11:36,407 [pool-69-thread-1] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: new RaftServerImpl for group-CA703B34E48B:[8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-04-20 12:11:36,424 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-04-20 12:11:36,430 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-04-20 12:11:36,433 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-04-20 12:11:36,433 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-04-20 12:11:36,434 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-04-20 12:11:36,449 [pool-69-thread-1] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B: ConfigurationManager, init=-1: [8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-04-20 12:11:36,453 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-04-20 12:11:36,473 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-04-20 12:11:36,475 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fc95027a-d6cc-40a8-b22f-ca703b34e48b does not exist. Creating ...
datanode_2_1  | 2020-04-20 12:11:36,510 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fc95027a-d6cc-40a8-b22f-ca703b34e48b/in_use.lock acquired by nodename 6@efb8b51ec4ab
datanode_2_1  | 2020-04-20 12:11:36,518 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fc95027a-d6cc-40a8-b22f-ca703b34e48b has been successfully formatted.
datanode_2_1  | 2020-04-20 12:11:36,530 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-CA703B34E48B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-04-20 12:11:36,549 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-04-20 12:11:36,560 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-04-20 12:11:36,581 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-04-20 12:11:36,583 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-04-20 12:11:36,604 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-04-20 12:11:36,606 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_2_1  | 2020-04-20 12:11:36,708 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-04-20 12:11:36,716 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/fc95027a-d6cc-40a8-b22f-ca703b34e48b
datanode_2_1  | 2020-04-20 12:11:36,744 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-04-20 12:11:36,747 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-04-20 12:11:36,758 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | Enabled profiling in kernel
datanode_5_1  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_5_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_5_1  | 2020-04-20 12:11:12,783 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_5_1  | /************************************************************
datanode_5_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_5_1  | STARTUP_MSG:   host = 7a52a65e9249/10.5.0.8
datanode_5_1  | STARTUP_MSG:   args = []
datanode_5_1  | STARTUP_MSG:   version = 3.2.0
datanode_5_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_5_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_5_1  | STARTUP_MSG:   java = 11.0.6
datanode_5_1  | ************************************************************/
datanode_5_1  | 2020-04-20 12:11:12,868 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_5_1  | 2020-04-20 12:11:14,393 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_5_1  | 2020-04-20 12:11:14,866 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_5_1  | 2020-04-20 12:11:16,178 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_5_1  | 2020-04-20 12:11:16,180 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_5_1  | 2020-04-20 12:11:17,223 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:7a52a65e9249 ip:10.5.0.8
datanode_5_1  | 2020-04-20 12:11:17,794 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_5_1  | 2020-04-20 12:11:17,801 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_5_1  | 2020-04-20 12:11:17,819 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_5_1  | 2020-04-20 12:11:17,953 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_5_1  | 2020-04-20 12:11:18,103 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_5_1  | 2020-04-20 12:11:23,618 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5_1  | 2020-04-20 12:11:23,851 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_5_1  | 2020-04-20 12:11:24,209 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_5_1  | 2020-04-20 12:11:24,212 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_5_1  | 2020-04-20 12:11:24,220 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-04-20 12:11:24,229 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_5_1  | 2020-04-20 12:11:24,229 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-04-20 12:11:25,324 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-04-20 12:11:25,917 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_5_1  | 2020-04-20 12:11:26,007 [main] INFO util.log: Logging initialized @18248ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_5_1  | 2020-04-20 12:11:26,564 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_5_1  | 2020-04-20 12:11:26,579 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_5_1  | 2020-04-20 12:11:26,618 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_5_1  | 2020-04-20 12:11:26,627 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_5_1  | 2020-04-20 12:11:26,635 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_5_1  | 2020-04-20 12:11:26,639 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_5_1  | 2020-04-20 12:11:26,806 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_5_1  | 2020-04-20 12:11:26,832 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_5_1  | 2020-04-20 12:11:26,848 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_5_1  | 2020-04-20 12:11:27,027 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_5_1  | 2020-04-20 12:11:27,039 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_5_1  | 2020-04-20 12:11:27,040 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_5_1  | 2020-04-20 12:11:27,105 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f76c2cc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_5_1  | 2020-04-20 12:11:27,122 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@441b8382{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_5_1  | 2020-04-20 12:11:27,669 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7c011174{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-868583740134569014.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_5_1  | 2020-04-20 12:11:27,835 [main] INFO server.AbstractConnector: Started ServerConnector@1491344a{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_5_1  | 2020-04-20 12:11:27,837 [main] INFO server.Server: Started @20077ms
datanode_5_1  | 2020-04-20 12:11:27,863 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_5_1  | 2020-04-20 12:11:27,863 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_5_1  | 2020-04-20 12:11:27,877 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_5_1  | 2020-04-20 12:11:27,950 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@419bfc50] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_5_1  | 2020-04-20 12:11:28,519 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_5_1  | 2020-04-20 12:11:31,002 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-04-20 12:11:31,657 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_5_1  | 2020-04-20 12:11:31,662 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_5_1  | 2020-04-20 12:11:31,663 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 5add3564-1298-4085-832c-a1039ab03f55 at port 9858
datanode_5_1  | 2020-04-20 12:11:31,757 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: start RPC server
datanode_5_1  | 2020-04-20 12:11:32,089 [Datanode State Machine Thread - 0] INFO server.GrpcService: 5add3564-1298-4085-832c-a1039ab03f55: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_5_1  | 2020-04-20 12:11:37,009 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: addNew group-A9FAC20C5754:[5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858] returns group-A9FAC20C5754:java.util.concurrent.CompletableFuture@11e86e27[Not completed]
datanode_2_1  | 2020-04-20 12:11:36,758 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-04-20 12:11:36,762 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-04-20 12:11:36,763 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-04-20 12:11:36,764 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-04-20 12:11:36,766 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-04-20 12:11:36,777 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-04-20 12:11:36,866 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-04-20 12:11:36,916 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-04-20 12:11:36,934 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-04-20 12:11:36,981 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-04-20 12:11:36,985 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-04-20 12:11:36,985 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-04-20 12:11:37,049 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B
datanode_2_1  | 2020-04-20 12:11:37,062 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B
datanode_2_1  | 2020-04-20 12:11:37,073 [pool-69-thread-1] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B: start as a follower, conf=-1: [8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null
datanode_2_1  | 2020-04-20 12:11:37,074 [pool-69-thread-1] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-04-20 12:11:37,075 [pool-69-thread-1] INFO impl.RoleInfo: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: start FollowerState
datanode_2_1  | 2020-04-20 12:11:37,102 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CA703B34E48B,id=8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_2_1  | 2020-04-20 12:11:37,103 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B
datanode_2_1  | 2020-04-20 12:11:37,171 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "fc95027a-d6cc-40a8-b22f-ca703b34e48b"
datanode_2_1  | .
datanode_2_1  | 2020-04-20 12:11:37,171 [Command processor thread] INFO impl.RaftServerProxy: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: addNew group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] returns group-92ED6CA41C2F:java.util.concurrent.CompletableFuture@196930e9[Not completed]
datanode_2_1  | 2020-04-20 12:11:37,200 [pool-69-thread-1] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: new RaftServerImpl for group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-04-20 12:11:37,200 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-04-20 12:11:37,200 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-04-20 12:11:37,200 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-04-20 12:11:37,212 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-04-20 12:11:37,212 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-04-20 12:11:37,212 [pool-69-thread-1] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F: ConfigurationManager, init=-1: [bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-04-20 12:11:37,213 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-04-20 12:11:37,213 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-04-20 12:11:37,213 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/daa4732c-5873-4db2-844f-92ed6ca41c2f does not exist. Creating ...
datanode_2_1  | 2020-04-20 12:11:37,229 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/daa4732c-5873-4db2-844f-92ed6ca41c2f/in_use.lock acquired by nodename 6@efb8b51ec4ab
datanode_2_1  | 2020-04-20 12:11:37,231 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/daa4732c-5873-4db2-844f-92ed6ca41c2f has been successfully formatted.
datanode_2_1  | 2020-04-20 12:11:37,231 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-92ED6CA41C2F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-04-20 12:11:37,241 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-04-20 12:11:37,241 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-04-20 12:11:37,241 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-04-20 12:11:37,241 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-04-20 12:11:37,241 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-04-20 12:11:37,253 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-04-20 12:11:37,253 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/daa4732c-5873-4db2-844f-92ed6ca41c2f
datanode_2_1  | 2020-04-20 12:11:37,254 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-04-20 12:11:37,254 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-04-20 12:11:37,254 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-04-20 12:11:37,254 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-04-20 12:11:37,254 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-04-20 12:11:37,254 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | Enabled profiling in kernel
datanode_4_1  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_4_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_4_1  | 2020-04-20 12:11:11,218 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_4_1  | /************************************************************
datanode_4_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_4_1  | STARTUP_MSG:   host = 0e128a59471e/10.5.0.7
datanode_4_1  | STARTUP_MSG:   args = []
datanode_4_1  | STARTUP_MSG:   version = 3.2.0
datanode_4_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_4_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_4_1  | STARTUP_MSG:   java = 11.0.6
datanode_4_1  | ************************************************************/
datanode_4_1  | 2020-04-20 12:11:11,285 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_4_1  | 2020-04-20 12:11:13,066 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_4_1  | 2020-04-20 12:11:13,522 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_4_1  | 2020-04-20 12:11:14,642 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_4_1  | 2020-04-20 12:11:14,664 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_4_1  | 2020-04-20 12:11:15,782 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:0e128a59471e ip:10.5.0.7
datanode_4_1  | 2020-04-20 12:11:16,087 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_4_1  | 2020-04-20 12:11:16,120 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_4_1  | 2020-04-20 12:11:16,121 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_4_1  | 2020-04-20 12:11:16,174 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_4_1  | 2020-04-20 12:11:16,298 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_4_1  | 2020-04-20 12:11:21,166 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4_1  | 2020-04-20 12:11:21,436 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_4_1  | 2020-04-20 12:11:21,785 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_4_1  | 2020-04-20 12:11:21,800 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_4_1  | 2020-04-20 12:11:21,806 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-04-20 12:11:21,806 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_4_1  | 2020-04-20 12:11:21,809 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 2020-04-20 12:11:23,327 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-04-20 12:11:24,127 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_4_1  | 2020-04-20 12:11:24,237 [main] INFO util.log: Logging initialized @17677ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_4_1  | 2020-04-20 12:11:24,775 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_4_1  | 2020-04-20 12:11:24,794 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_4_1  | 2020-04-20 12:11:24,804 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_4_1  | 2020-04-20 12:11:24,833 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_4_1  | 2020-04-20 12:11:24,837 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_4_1  | 2020-04-20 12:11:24,837 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_4_1  | 2020-04-20 12:11:25,019 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_4_1  | 2020-04-20 12:11:25,061 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_4_1  | 2020-04-20 12:11:25,062 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_4_1  | 2020-04-20 12:11:25,379 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_4_1  | 2020-04-20 12:11:25,379 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_4_1  | 2020-04-20 12:11:25,380 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_4_1  | 2020-04-20 12:11:25,468 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f76c2cc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_4_1  | 2020-04-20 12:11:25,476 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@441b8382{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_4_1  | 2020-04-20 12:11:25,972 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7c011174{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-4778720940543677951.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_4_1  | 2020-04-20 12:11:26,035 [main] INFO server.AbstractConnector: Started ServerConnector@1491344a{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_4_1  | 2020-04-20 12:11:26,036 [main] INFO server.Server: Started @19488ms
datanode_4_1  | 2020-04-20 12:11:26,062 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_4_1  | 2020-04-20 12:11:26,062 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_4_1  | 2020-04-20 12:11:26,072 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_4_1  | 2020-04-20 12:11:26,211 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3fa475cc] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_4_1  | 2020-04-20 12:11:27,169 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_4_1  | 2020-04-20 12:11:29,281 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-04-20 12:11:30,283 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-04-20 12:11:31,309 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_4_1  | java.net.SocketTimeoutException: Call From 0e128a59471e/10.5.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:37680 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_4_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_4_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_4_1  | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:37680 remote=scm/10.5.0.71:9861]
datanode_4_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_4_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2_1  | 2020-04-20 12:11:37,254 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-04-20 12:11:37,254 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-04-20 12:11:37,254 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-04-20 12:11:37,255 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-04-20 12:11:37,258 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-04-20 12:11:37,262 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-04-20 12:11:37,262 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-04-20 12:11:37,262 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-04-20 12:11:37,262 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-04-20 12:11:37,263 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F
datanode_2_1  | 2020-04-20 12:11:37,263 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F
datanode_2_1  | 2020-04-20 12:11:37,263 [pool-69-thread-1] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F: start as a follower, conf=-1: [bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null
datanode_2_1  | 2020-04-20 12:11:37,263 [pool-69-thread-1] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-04-20 12:11:37,289 [pool-69-thread-1] INFO impl.RoleInfo: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: start FollowerState
datanode_2_1  | 2020-04-20 12:11:37,289 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-92ED6CA41C2F,id=8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_2_1  | 2020-04-20 12:11:37,289 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F
datanode_2_1  | 2020-04-20 12:11:39,713 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "daa4732c-5873-4db2-844f-92ed6ca41c2f"
datanode_2_1  | .
datanode_2_1  | 2020-04-20 12:11:39,731 [pool-69-thread-1] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: new RaftServerImpl for group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-04-20 12:11:39,731 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-04-20 12:11:39,731 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-04-20 12:11:39,731 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-04-20 12:11:39,732 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-04-20 12:11:39,732 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-04-20 12:11:39,732 [pool-69-thread-1] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD: ConfigurationManager, init=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-04-20 12:11:39,733 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-04-20 12:11:39,733 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-04-20 12:11:39,735 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/9539b8c0-47a1-400b-b528-18d4649732cd does not exist. Creating ...
datanode_2_1  | 2020-04-20 12:11:39,733 [Command processor thread] INFO impl.RaftServerProxy: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: addNew group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] returns group-18D4649732CD:java.util.concurrent.CompletableFuture@2a9f7e84[Not completed]
datanode_2_1  | 2020-04-20 12:11:39,767 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/9539b8c0-47a1-400b-b528-18d4649732cd/in_use.lock acquired by nodename 6@efb8b51ec4ab
datanode_2_1  | 2020-04-20 12:11:39,775 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/9539b8c0-47a1-400b-b528-18d4649732cd has been successfully formatted.
datanode_2_1  | 2020-04-20 12:11:39,776 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-18D4649732CD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-04-20 12:11:39,776 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-04-20 12:11:39,777 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-04-20 12:11:39,777 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-04-20 12:11:39,777 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-04-20 12:11:39,778 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-04-20 12:11:39,778 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-04-20 12:11:39,778 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/9539b8c0-47a1-400b-b528-18d4649732cd
datanode_2_1  | 2020-04-20 12:11:39,778 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-04-20 12:11:39,778 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-04-20 12:11:39,781 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-04-20 12:11:39,781 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-04-20 12:11:39,781 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-04-20 12:11:39,781 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-04-20 12:11:39,781 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om_1          | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-04-20 12:11:13,419 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = a6140dd765bb/10.5.0.70
om_1          | STARTUP_MSG:   args = [--init]
om_1          | STARTUP_MSG:   version = 3.2.0
datanode_3_1  | Enabled profiling in kernel
datanode_3_1  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3_1  | 2020-04-20 12:11:10,921 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3_1  | /************************************************************
datanode_3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3_1  | STARTUP_MSG:   host = cfcad800fa97/10.5.0.6
datanode_3_1  | STARTUP_MSG:   args = []
datanode_3_1  | STARTUP_MSG:   version = 3.2.0
datanode_3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_3_1  | STARTUP_MSG:   java = 11.0.6
datanode_3_1  | ************************************************************/
datanode_3_1  | 2020-04-20 12:11:10,965 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3_1  | 2020-04-20 12:11:12,651 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3_1  | 2020-04-20 12:11:13,200 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3_1  | 2020-04-20 12:11:14,605 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3_1  | 2020-04-20 12:11:14,605 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3_1  | 2020-04-20 12:11:15,554 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:cfcad800fa97 ip:10.5.0.6
datanode_3_1  | 2020-04-20 12:11:16,135 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3_1  | 2020-04-20 12:11:16,145 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3_1  | 2020-04-20 12:11:16,161 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3_1  | 2020-04-20 12:11:16,244 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3_1  | 2020-04-20 12:11:16,375 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3_1  | 2020-04-20 12:11:21,111 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3_1  | 2020-04-20 12:11:21,289 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3_1  | 2020-04-20 12:11:21,660 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3_1  | 2020-04-20 12:11:21,662 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3_1  | 2020-04-20 12:11:21,663 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-04-20 12:11:21,665 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3_1  | 2020-04-20 12:11:21,674 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-04-20 12:11:23,144 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-04-20 12:11:24,029 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3_1  | 2020-04-20 12:11:24,268 [main] INFO util.log: Logging initialized @17861ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3_1  | 2020-04-20 12:11:24,931 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3_1  | 2020-04-20 12:11:24,999 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3_1  | 2020-04-20 12:11:25,080 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3_1  | 2020-04-20 12:11:25,100 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3_1  | 2020-04-20 12:11:25,100 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3_1  | 2020-04-20 12:11:25,101 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3_1  | 2020-04-20 12:11:25,275 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_3_1  | 2020-04-20 12:11:25,352 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3_1  | 2020-04-20 12:11:25,357 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3_1  | 2020-04-20 12:11:26,010 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3_1  | 2020-04-20 12:11:26,020 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3_1  | 2020-04-20 12:11:26,022 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_3_1  | 2020-04-20 12:11:26,135 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6fc6deb7{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3_1  | 2020-04-20 12:11:26,139 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@32b0876c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3_1  | 2020-04-20 12:11:26,624 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@40f35e52{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-5838123352008228339.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3_1  | 2020-04-20 12:11:26,672 [main] INFO server.AbstractConnector: Started ServerConnector@5e922647{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3_1  | 2020-04-20 12:11:26,677 [main] INFO server.Server: Started @20271ms
datanode_3_1  | 2020-04-20 12:11:26,691 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3_1  | 2020-04-20 12:11:26,691 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3_1  | 2020-04-20 12:11:26,695 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3_1  | 2020-04-20 12:11:26,806 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5aeeecd4] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3_1  | 2020-04-20 12:11:27,623 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3_1  | 2020-04-20 12:11:29,866 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-04-20 12:11:30,868 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-04-20 12:11:31,657 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3_1  | 2020-04-20 12:11:31,660 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3_1  | 2020-04-20 12:11:31,660 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 68b8b2ca-801b-4940-8ace-0c902746c4e8 at port 9858
datanode_3_1  | 2020-04-20 12:11:31,792 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 68b8b2ca-801b-4940-8ace-0c902746c4e8: start RPC server
datanode_3_1  | 2020-04-20 12:11:32,037 [Datanode State Machine Thread - 0] INFO server.GrpcService: 68b8b2ca-801b-4940-8ace-0c902746c4e8: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3_1  | 2020-04-20 12:11:35,812 [Command processor thread] INFO impl.RaftServerProxy: 68b8b2ca-801b-4940-8ace-0c902746c4e8: addNew group-4DC0B3E02A28:[68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858] returns group-4DC0B3E02A28:java.util.concurrent.CompletableFuture@4236427f[Not completed]
datanode_3_1  | 2020-04-20 12:11:35,862 [pool-69-thread-1] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8: new RaftServerImpl for group-4DC0B3E02A28:[68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-04-20 12:11:35,863 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-04-20 12:11:35,865 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-04-20 12:11:35,865 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-04-20 12:11:35,866 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-04-20 12:11:35,867 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-04-20 12:11:35,875 [pool-69-thread-1] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28: ConfigurationManager, init=-1: [68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-04-20 12:11:35,876 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-04-20 12:11:35,882 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-04-20 12:11:35,885 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/66927c5b-4a56-4d19-93cb-4dc0b3e02a28 does not exist. Creating ...
datanode_3_1  | 2020-04-20 12:11:35,895 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/66927c5b-4a56-4d19-93cb-4dc0b3e02a28/in_use.lock acquired by nodename 6@cfcad800fa97
datanode_3_1  | 2020-04-20 12:11:35,898 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/66927c5b-4a56-4d19-93cb-4dc0b3e02a28 has been successfully formatted.
datanode_3_1  | 2020-04-20 12:11:35,910 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-4DC0B3E02A28: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-04-20 12:11:35,929 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-04-20 12:11:35,931 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-04-20 12:11:35,954 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-04-20 12:11:35,960 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-04-20 12:11:35,970 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-04-20 12:11:35,998 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.68b8b2ca-801b-4940-8ace-0c902746c4e8
datanode_3_1  | 2020-04-20 12:11:36,031 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-04-20 12:11:36,052 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/66927c5b-4a56-4d19-93cb-4dc0b3e02a28
datanode_5_1  | 2020-04-20 12:11:37,167 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55: new RaftServerImpl for group-A9FAC20C5754:[5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-04-20 12:11:37,171 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-04-20 12:11:37,171 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-04-20 12:11:37,171 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-04-20 12:11:37,177 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-04-20 12:11:37,179 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-04-20 12:11:37,198 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754: ConfigurationManager, init=-1: [5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-04-20 12:11:37,201 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-04-20 12:11:37,217 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-04-20 12:11:37,229 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a5263645-01c1-4afe-a7b2-a9fac20c5754 does not exist. Creating ...
datanode_5_1  | 2020-04-20 12:11:37,251 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a5263645-01c1-4afe-a7b2-a9fac20c5754/in_use.lock acquired by nodename 6@7a52a65e9249
datanode_5_1  | 2020-04-20 12:11:37,264 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a5263645-01c1-4afe-a7b2-a9fac20c5754 has been successfully formatted.
datanode_5_1  | 2020-04-20 12:11:37,283 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-A9FAC20C5754: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-04-20 12:11:37,295 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-04-20 12:11:37,313 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-04-20 12:11:37,316 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-04-20 12:11:37,334 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-04-20 12:11:37,338 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-04-20 12:11:37,373 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.5add3564-1298-4085-832c-a1039ab03f55
datanode_5_1  | 2020-04-20 12:11:37,486 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-04-20 12:11:37,565 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/a5263645-01c1-4afe-a7b2-a9fac20c5754
datanode_5_1  | 2020-04-20 12:11:37,573 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-04-20 12:11:37,574 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-04-20 12:11:37,576 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-04-20 12:11:37,582 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-04-20 12:11:37,589 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-04-20 12:11:37,599 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-04-20 12:11:37,605 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-04-20 12:11:37,618 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-04-20 12:11:37,619 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-04-20 12:11:37,726 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-04-20 12:11:37,744 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-04-20 12:11:37,788 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-04-20 12:11:37,805 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-04-20 12:11:37,806 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-04-20 12:11:37,826 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-04-20 12:11:37,936 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754
datanode_5_1  | 2020-04-20 12:11:37,986 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754
datanode_5_1  | 2020-04-20 12:11:37,997 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754: start as a follower, conf=-1: [5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858], old=null
datanode_5_1  | 2020-04-20 12:11:38,005 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-04-20 12:11:38,017 [pool-69-thread-1] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: start FollowerState
datanode_5_1  | 2020-04-20 12:11:38,042 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A9FAC20C5754,id=5add3564-1298-4085-832c-a1039ab03f55
datanode_5_1  | 2020-04-20 12:11:38,044 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754
datanode_5_1  | 2020-04-20 12:11:38,095 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "a5263645-01c1-4afe-a7b2-a9fac20c5754"
datanode_5_1  | .
datanode_5_1  | 2020-04-20 12:11:43,103 [Thread-23] INFO impl.FollowerState: 5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-FollowerState: change to CANDIDATE, lastRpcTime:5090ms, electionTimeout:5070ms
datanode_5_1  | 2020-04-20 12:11:43,105 [Thread-23] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: shutdown FollowerState
datanode_5_1  | 2020-04-20 12:11:43,105 [Thread-23] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-04-20 12:11:43,107 [Thread-23] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: start LeaderElection
datanode_5_1  | 2020-04-20 12:11:43,114 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO impl.LeaderElection: 5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1: begin an election at term 1 for -1: [5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858], old=null
datanode_5_1  | 2020-04-20 12:11:43,115 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: shutdown LeaderElection
datanode_5_1  | 2020-04-20 12:11:43,116 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-04-20 12:11:43,116 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A9FAC20C5754 with new leaderId: 5add3564-1298-4085-832c-a1039ab03f55
datanode_5_1  | 2020-04-20 12:11:43,119 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754: change Leader from null to 5add3564-1298-4085-832c-a1039ab03f55 at term 1 for becomeLeader, leader elected after 5821ms
datanode_5_1  | 2020-04-20 12:11:43,140 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | 2020-04-20 12:11:43,141 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5_1  | 2020-04-20 12:11:43,145 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754
datanode_5_1  | 2020-04-20 12:11:43,151 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5_1  | 2020-04-20 12:11:43,154 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_5_1  | 2020-04-20 12:11:43,189 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5_1  | 2020-04-20 12:11:43,189 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5_1  | 2020-04-20 12:11:43,192 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5_1  | 2020-04-20 12:11:43,215 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: start LeaderState
datanode_5_1  | 2020-04-20 12:11:43,262 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-04-20 12:11:43,354 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-LeaderElection1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754: set configuration 0: [5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858], old=null at 0
datanode_5_1  | 2020-04-20 12:11:43,475 [5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-A9FAC20C5754-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a5263645-01c1-4afe-a7b2-a9fac20c5754/current/log_inprogress_0
datanode_5_1  | 2020-04-20 12:13:14,119 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: addNew group-930049E84D30:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] returns group-930049E84D30:java.util.concurrent.CompletableFuture@eb89af7[Not completed]
datanode_5_1  | 2020-04-20 12:13:14,120 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55: new RaftServerImpl for group-930049E84D30:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-04-20 12:13:14,120 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-04-20 12:13:14,120 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-04-20 12:13:14,120 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-04-20 12:13:14,121 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-04-20 12:13:14,121 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-04-20 12:13:14,121 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30: ConfigurationManager, init=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-04-20 12:13:14,121 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-04-20 12:13:14,122 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-04-20 12:13:14,122 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2b915d42-0547-44e8-966f-930049e84d30 does not exist. Creating ...
datanode_5_1  | 2020-04-20 12:13:14,125 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2b915d42-0547-44e8-966f-930049e84d30/in_use.lock acquired by nodename 6@7a52a65e9249
datanode_5_1  | 2020-04-20 12:13:14,127 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2b915d42-0547-44e8-966f-930049e84d30 has been successfully formatted.
datanode_5_1  | 2020-04-20 12:13:14,128 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-930049E84D30: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-04-20 12:13:14,134 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-04-20 12:13:14,134 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-04-20 12:13:14,134 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-04-20 12:13:14,134 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-04-20 12:13:14,135 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-04-20 12:13:14,135 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-04-20 12:11:39,781 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-04-20 12:11:39,781 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-04-20 12:11:39,783 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-04-20 12:11:39,831 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-04-20 12:11:39,838 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-04-20 12:11:39,839 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-04-20 12:11:39,848 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-04-20 12:11:39,848 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-04-20 12:11:39,857 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD
datanode_2_1  | 2020-04-20 12:11:39,860 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD
datanode_2_1  | 2020-04-20 12:11:39,865 [pool-69-thread-1] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD: start as a follower, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null
datanode_2_1  | 2020-04-20 12:11:39,865 [pool-69-thread-1] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-04-20 12:11:39,868 [pool-69-thread-1] INFO impl.RoleInfo: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: start FollowerState
datanode_2_1  | 2020-04-20 12:11:39,881 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-18D4649732CD,id=8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_2_1  | 2020-04-20 12:11:39,928 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD
datanode_2_1  | 2020-04-20 12:11:40,028 [grpc-default-executor-1] WARN impl.RaftServerProxy: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Failed groupAdd* GroupManagementRequest:client-C7CE32C35FA1->8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F, cid=1, seq=0, RW, null, Add:group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858]
datanode_2_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Failed to add group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Failed to add group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2_1  | 	... 13 more
datanode_2_1  | 2020-04-20 12:11:40,030 [grpc-default-executor-0] WARN impl.RaftServerProxy: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Failed groupAdd* GroupManagementRequest:client-9751B7E1B0DB->8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F, cid=1, seq=0, RW, null, Add:group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858]
datanode_2_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Failed to add group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_4_1  | 2020-04-20 12:11:31,708 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_4_1  | 2020-04-20 12:11:31,709 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_4_1  | 2020-04-20 12:11:31,711 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis d427b6db-e08f-47dc-bc01-4bdf7d0252a1 at port 9858
datanode_4_1  | 2020-04-20 12:11:32,215 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: start RPC server
datanode_4_1  | 2020-04-20 12:11:32,585 [Datanode State Machine Thread - 1] INFO server.GrpcService: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_4_1  | 2020-04-20 12:11:37,277 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: addNew group-7357CCDD9E8D:[d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] returns group-7357CCDD9E8D:java.util.concurrent.CompletableFuture@46560b26[Not completed]
datanode_4_1  | 2020-04-20 12:11:37,403 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: new RaftServerImpl for group-7357CCDD9E8D:[d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-04-20 12:11:37,416 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-04-20 12:11:37,420 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-04-20 12:11:37,421 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-04-20 12:11:37,422 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-04-20 12:11:37,426 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-04-20 12:11:37,454 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D: ConfigurationManager, init=-1: [d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-04-20 12:11:37,456 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-04-20 12:11:37,471 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-04-20 12:11:37,474 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/40b4e453-ccc6-4ee4-8e46-7357ccdd9e8d does not exist. Creating ...
datanode_4_1  | 2020-04-20 12:11:37,509 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/40b4e453-ccc6-4ee4-8e46-7357ccdd9e8d/in_use.lock acquired by nodename 6@0e128a59471e
datanode_4_1  | 2020-04-20 12:11:37,517 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/40b4e453-ccc6-4ee4-8e46-7357ccdd9e8d has been successfully formatted.
datanode_4_1  | 2020-04-20 12:11:37,530 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-7357CCDD9E8D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-04-20 12:11:37,533 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-04-20 12:11:37,557 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-04-20 12:11:37,583 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-04-20 12:11:37,586 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-04-20 12:11:37,594 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-04-20 12:11:37,608 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 2020-04-20 12:11:37,741 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-04-20 12:11:37,772 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/40b4e453-ccc6-4ee4-8e46-7357ccdd9e8d
datanode_4_1  | 2020-04-20 12:11:37,792 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-04-20 12:11:37,805 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-04-20 12:11:37,825 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-04-20 12:11:37,825 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-04-20 12:11:37,826 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-04-20 12:11:37,829 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-04-20 12:11:37,832 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-04-20 12:11:37,851 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-04-20 12:11:37,852 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-04-20 12:11:37,969 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-04-20 12:11:38,003 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-04-20 12:11:38,026 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-04-20 12:11:38,036 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-04-20 12:11:38,042 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-04-20 12:11:38,043 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-04-20 12:11:38,131 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D
datanode_4_1  | 2020-04-20 12:11:38,148 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D
datanode_4_1  | 2020-04-20 12:11:38,153 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D: start as a follower, conf=-1: [d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
datanode_4_1  | 2020-04-20 12:11:38,158 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-04-20 12:11:38,162 [pool-69-thread-1] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: start FollowerState
datanode_4_1  | 2020-04-20 12:11:38,186 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7357CCDD9E8D,id=d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 2020-04-20 12:11:38,187 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D
datanode_4_1  | 2020-04-20 12:11:38,224 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "40b4e453-ccc6-4ee4-8e46-7357ccdd9e8d"
datanode_4_1  | .
datanode_4_1  | 2020-04-20 12:11:38,224 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: addNew group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] returns group-18D4649732CD:java.util.concurrent.CompletableFuture@7fe2a547[Not completed]
datanode_4_1  | 2020-04-20 12:11:38,227 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: new RaftServerImpl for group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-04-20 12:11:38,234 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-04-20 12:11:38,234 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-04-20 12:11:38,235 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-04-20 12:11:38,235 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-04-20 12:11:38,236 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-04-20 12:11:38,236 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD: ConfigurationManager, init=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-04-20 12:11:38,236 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-04-20 12:11:38,241 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-04-20 12:11:38,241 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/9539b8c0-47a1-400b-b528-18d4649732cd does not exist. Creating ...
datanode_4_1  | 2020-04-20 12:11:38,257 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/9539b8c0-47a1-400b-b528-18d4649732cd/in_use.lock acquired by nodename 6@0e128a59471e
datanode_4_1  | 2020-04-20 12:11:38,262 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/9539b8c0-47a1-400b-b528-18d4649732cd has been successfully formatted.
datanode_4_1  | 2020-04-20 12:11:38,263 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-18D4649732CD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-04-20 12:11:38,270 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-04-20 12:11:13,440 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-04-20 12:11:18,290 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-04-20 12:11:18,465 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-04-20 12:11:18,465 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-04-20 12:11:18,510 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-04-20 12:11:20,822 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-04-20 12:11:21,823 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-04-20 12:11:22,824 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-04-20 12:11:23,825 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-04-20 12:11:24,826 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-04-20 12:11:25,826 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-04-20 12:11:26,827 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-04-20 12:11:27,828 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-04-20 12:11:28,829 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-04-20 12:11:29,830 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-04-20 12:11:29,832 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1          | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-23a81e83-cb7a-4c8f-a5b3-fa9810b7b715
om_1          | 2020-04-20 12:11:34,943 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1          | /************************************************************
om_1          | SHUTDOWN_MSG: Shutting down OzoneManager at a6140dd765bb/10.5.0.70
om_1          | ************************************************************/
om_1          | Enabled profiling in kernel
om_1          | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-04-20 12:11:38,331 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = a6140dd765bb/10.5.0.70
om_1          | STARTUP_MSG:   args = []
om_1          | STARTUP_MSG:   version = 3.2.0
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-04-20 12:11:38,343 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-04-20 12:11:40,815 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-04-20 12:11:40,858 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-04-20 12:11:40,858 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-04-20 12:11:40,863 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-04-20 12:11:40,982 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-04-20 12:11:41,847 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-04-20 12:11:42,203 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1          | 2020-04-20 12:11:42,214 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1          | 2020-04-20 12:11:42,448 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1          | 2020-04-20 12:11:42,503 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1          | 2020-04-20 12:11:42,503 [main] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1          | 2020-04-20 12:11:42,551 [main] INFO om.OzoneManager: OzoneManager RPC server is listening at om/10.5.0.70:9862
om_1          | 2020-04-20 12:11:42,589 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1          | 2020-04-20 12:11:42,598 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1          | 2020-04-20 12:11:42,955 [main] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1          | 2020-04-20 12:11:42,994 [main] INFO util.log: Logging initialized @7892ms to org.eclipse.jetty.util.log.Slf4jLog
om_1          | 2020-04-20 12:11:43,243 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1          | 2020-04-20 12:11:43,258 [main] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1          | 2020-04-20 12:11:43,274 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1          | 2020-04-20 12:11:43,281 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1          | 2020-04-20 12:11:43,281 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
om_1          | 2020-04-20 12:11:43,282 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
om_1          | 2020-04-20 12:11:43,376 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1          | 2020-04-20 12:11:43,380 [main] INFO http.HttpServer2: Jetty bound to port 9874
om_1          | 2020-04-20 12:11:43,389 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1          | 2020-04-20 12:11:43,482 [main] INFO server.session: DefaultSessionIdManager workerName=node0
om_1          | 2020-04-20 12:11:43,482 [main] INFO server.session: No SessionScavenger set, using defaults
om_1          | 2020-04-20 12:11:43,491 [main] INFO server.session: node0 Scavenging every 600000ms
om_1          | 2020-04-20 12:11:43,509 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@61ecbee9{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1          | 2020-04-20 12:11:43,510 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2440022a{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1          | 2020-04-20 12:11:44,053 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@25d0cb3a{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-8640510185326281078.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1          | 2020-04-20 12:11:44,066 [main] INFO server.AbstractConnector: Started ServerConnector@69afa141{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1          | 2020-04-20 12:11:44,067 [main] INFO server.Server: Started @8965ms
om_1          | 2020-04-20 12:11:44,071 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1          | 2020-04-20 12:11:44,071 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1          | 2020-04-20 12:11:44,077 [main] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1          | 2020-04-20 12:11:50,068 [IPC Server handler 1 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-83703 for user:hadoop
om_1          | 2020-04-20 12:11:50,106 [IPC Server handler 4 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-53018 for user:hadoop
om_1          | 2020-04-20 12:11:50,114 [IPC Server handler 6 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-09218 for user:hadoop
om_1          | 2020-04-20 12:11:50,119 [IPC Server handler 7 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-75858 for user:hadoop
om_1          | 2020-04-20 12:11:50,137 [IPC Server handler 9 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-21474 for user:hadoop
datanode_3_1  | 2020-04-20 12:11:36,052 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-04-20 12:11:36,053 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-04-20 12:11:36,053 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-04-20 12:11:36,054 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-04-20 12:11:36,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-04-20 12:11:36,057 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-04-20 12:11:36,058 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-04-20 12:11:36,062 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-04-20 12:11:36,064 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-04-20 12:11:36,112 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-04-20 12:11:36,127 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-04-20 12:11:36,159 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-04-20 12:11:36,168 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-04-20 12:11:36,173 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-04-20 12:11:36,174 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-04-20 12:11:36,214 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28
datanode_3_1  | 2020-04-20 12:11:36,234 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28
datanode_3_1  | 2020-04-20 12:11:36,242 [pool-69-thread-1] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28: start as a follower, conf=-1: [68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858], old=null
datanode_3_1  | 2020-04-20 12:11:36,243 [pool-69-thread-1] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-04-20 12:11:36,246 [pool-69-thread-1] INFO impl.RoleInfo: 68b8b2ca-801b-4940-8ace-0c902746c4e8: start FollowerState
datanode_3_1  | 2020-04-20 12:11:36,282 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4DC0B3E02A28,id=68b8b2ca-801b-4940-8ace-0c902746c4e8
datanode_3_1  | 2020-04-20 12:11:36,284 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28
datanode_3_1  | 2020-04-20 12:11:36,299 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "66927c5b-4a56-4d19-93cb-4dc0b3e02a28"
datanode_3_1  | .
datanode_3_1  | 2020-04-20 12:11:36,305 [Command processor thread] INFO impl.RaftServerProxy: 68b8b2ca-801b-4940-8ace-0c902746c4e8: addNew group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] returns group-92ED6CA41C2F:java.util.concurrent.CompletableFuture@5b6902f3[Not completed]
datanode_3_1  | 2020-04-20 12:11:36,307 [pool-69-thread-1] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8: new RaftServerImpl for group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-04-20 12:11:36,307 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-04-20 12:11:36,307 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-04-20 12:11:36,307 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-04-20 12:11:36,307 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-04-20 12:11:36,308 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-04-20 12:11:36,308 [pool-69-thread-1] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F: ConfigurationManager, init=-1: [bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-04-20 12:11:36,308 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-04-20 12:11:36,308 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-04-20 12:11:36,308 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/daa4732c-5873-4db2-844f-92ed6ca41c2f does not exist. Creating ...
datanode_3_1  | 2020-04-20 12:11:36,310 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/daa4732c-5873-4db2-844f-92ed6ca41c2f/in_use.lock acquired by nodename 6@cfcad800fa97
datanode_3_1  | 2020-04-20 12:11:36,312 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/daa4732c-5873-4db2-844f-92ed6ca41c2f has been successfully formatted.
datanode_3_1  | 2020-04-20 12:11:36,312 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-92ED6CA41C2F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-04-20 12:11:36,313 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-04-20 12:11:36,313 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-04-20 12:11:36,313 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-04-20 12:11:36,331 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-04-20 12:11:36,331 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-04-20 12:11:36,331 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-04-20 12:11:36,331 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/daa4732c-5873-4db2-844f-92ed6ca41c2f
datanode_3_1  | 2020-04-20 12:11:36,331 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-04-20 12:11:36,332 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-04-20 12:11:36,332 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-04-20 12:11:36,332 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-04-20 12:11:36,332 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-04-20 12:11:36,332 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-04-20 12:11:36,332 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-04-20 12:11:36,333 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-04-20 12:11:36,333 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-04-20 12:11:36,351 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-04-20 12:11:36,352 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-04-20 12:11:36,354 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-04-20 12:11:36,354 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-04-20 12:11:36,355 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-04-20 12:11:36,355 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-04-20 12:11:36,355 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F
datanode_3_1  | 2020-04-20 12:11:36,355 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F
datanode_3_1  | 2020-04-20 12:11:36,356 [pool-69-thread-1] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F: start as a follower, conf=-1: [bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null
datanode_3_1  | 2020-04-20 12:11:36,356 [pool-69-thread-1] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-04-20 12:11:36,356 [pool-69-thread-1] INFO impl.RoleInfo: 68b8b2ca-801b-4940-8ace-0c902746c4e8: start FollowerState
datanode_3_1  | 2020-04-20 12:11:36,356 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-92ED6CA41C2F,id=68b8b2ca-801b-4940-8ace-0c902746c4e8
datanode_3_1  | 2020-04-20 12:11:36,357 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F
datanode_3_1  | 2020-04-20 12:11:39,114 [grpc-default-executor-0] WARN impl.RaftServerProxy: 68b8b2ca-801b-4940-8ace-0c902746c4e8: Failed groupAdd* GroupManagementRequest:client-1D94687C0051->68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F, cid=0, seq=0, RW, null, Add:group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858]
datanode_3_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 68b8b2ca-801b-4940-8ace-0c902746c4e8: Failed to add group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_3_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_5_1  | 2020-04-20 12:13:14,135 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2b915d42-0547-44e8-966f-930049e84d30
datanode_5_1  | 2020-04-20 12:13:14,135 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | Enabled profiling in kernel
datanode_1_1  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1_1  | 2020-04-20 12:11:13,840 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1_1  | /************************************************************
datanode_1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1_1  | STARTUP_MSG:   host = 52fe7c485517/10.5.0.4
datanode_1_1  | STARTUP_MSG:   args = []
datanode_1_1  | STARTUP_MSG:   version = 3.2.0
datanode_1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1_1  | STARTUP_MSG:   java = 11.0.6
datanode_1_1  | ************************************************************/
datanode_1_1  | 2020-04-20 12:11:13,908 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1_1  | 2020-04-20 12:11:15,700 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1_1  | 2020-04-20 12:11:16,184 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1_1  | 2020-04-20 12:11:17,272 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1_1  | 2020-04-20 12:11:17,272 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1_1  | 2020-04-20 12:11:18,483 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:52fe7c485517 ip:10.5.0.4
datanode_1_1  | 2020-04-20 12:11:18,887 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1_1  | 2020-04-20 12:11:18,898 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1_1  | 2020-04-20 12:11:18,924 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1_1  | 2020-04-20 12:11:18,956 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1_1  | 2020-04-20 12:11:19,120 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1_1  | 2020-04-20 12:11:24,267 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1_1  | 2020-04-20 12:11:24,473 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1_1  | 2020-04-20 12:11:24,776 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1_1  | 2020-04-20 12:11:24,782 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1_1  | 2020-04-20 12:11:24,785 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-04-20 12:11:24,789 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1_1  | 2020-04-20 12:11:24,790 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-04-20 12:11:25,828 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-04-20 12:11:26,492 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1_1  | 2020-04-20 12:11:26,588 [main] INFO util.log: Logging initialized @17566ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1_1  | 2020-04-20 12:11:27,054 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1_1  | 2020-04-20 12:11:27,072 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1_1  | 2020-04-20 12:11:27,116 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1_1  | 2020-04-20 12:11:27,126 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1_1  | 2020-04-20 12:11:27,131 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1_1  | 2020-04-20 12:11:27,133 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1_1  | 2020-04-20 12:11:27,308 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1_1  | 2020-04-20 12:11:27,343 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1_1  | 2020-04-20 12:11:27,350 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1_1  | 2020-04-20 12:11:27,690 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1_1  | 2020-04-20 12:11:27,693 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1_1  | 2020-04-20 12:11:27,706 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1_1  | 2020-04-20 12:11:27,776 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d7cac8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1_1  | 2020-04-20 12:11:27,782 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5349b246{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1_1  | 2020-04-20 12:11:28,234 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@480b57e2{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-13512522803680638082.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1_1  | 2020-04-20 12:11:28,259 [main] INFO server.AbstractConnector: Started ServerConnector@1386313f{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1_1  | 2020-04-20 12:11:28,261 [main] INFO server.Server: Started @19239ms
datanode_1_1  | 2020-04-20 12:11:28,283 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1_1  | 2020-04-20 12:11:28,283 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1_1  | 2020-04-20 12:11:28,293 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1_1  | 2020-04-20 12:11:28,388 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@193fd07a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1_1  | 2020-04-20 12:11:28,704 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1_1  | 2020-04-20 12:11:31,512 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_1_1  | java.net.SocketTimeoutException: Call From 52fe7c485517/10.5.0.4 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.4:37944 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_1_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_4_1  | 2020-04-20 12:11:38,276 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-04-20 12:11:38,276 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-04-20 12:11:38,276 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-04-20 12:11:38,277 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-04-20 12:11:38,277 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-04-20 12:11:38,292 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/9539b8c0-47a1-400b-b528-18d4649732cd
datanode_4_1  | 2020-04-20 12:11:38,292 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-04-20 12:11:38,292 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-04-20 12:11:38,292 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-04-20 12:11:38,293 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-04-20 12:13:14,135 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-04-20 12:13:14,135 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-04-20 12:13:14,135 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-04-20 12:13:14,135 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-04-20 12:13:14,135 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-04-20 12:13:14,136 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-04-20 12:13:14,136 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-04-20 12:13:14,136 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-04-20 12:13:14,137 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-04-20 12:13:14,137 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-04-20 12:13:14,138 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-04-20 12:13:14,138 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-04-20 12:13:14,138 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-04-20 12:13:14,138 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-04-20 12:13:14,138 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30
datanode_5_1  | 2020-04-20 12:13:14,139 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30
datanode_5_1  | 2020-04-20 12:13:14,139 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30: start as a follower, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
datanode_5_1  | 2020-04-20 12:13:14,139 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-04-20 12:13:14,139 [pool-69-thread-1] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: start FollowerState
datanode_5_1  | 2020-04-20 12:13:14,140 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-930049E84D30,id=5add3564-1298-4085-832c-a1039ab03f55
datanode_5_1  | 2020-04-20 12:13:14,140 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30
datanode_5_1  | 2020-04-20 12:13:14,508 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_5_1  | .
datanode_5_1  | 2020-04-20 12:13:19,221 [Thread-31] INFO impl.FollowerState: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-FollowerState: change to CANDIDATE, lastRpcTime:5081ms, electionTimeout:5081ms
datanode_5_1  | 2020-04-20 12:13:19,222 [Thread-31] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: shutdown FollowerState
datanode_5_1  | 2020-04-20 12:13:19,222 [Thread-31] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-04-20 12:13:19,223 [Thread-31] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: start LeaderElection
datanode_5_1  | 2020-04-20 12:13:19,226 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO impl.LeaderElection: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2: begin an election at term 1 for -1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
datanode_5_1  | 2020-04-20 12:13:19,305 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO impl.LeaderElection: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2: Election PASSED; received 1 response(s) [5add3564-1298-4085-832c-a1039ab03f55<-ea211d94-4213-43ea-b4d3-a3779a4d37c1#0:OK-t1] and 0 exception(s); 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30:t1, leader=null, voted=5add3564-1298-4085-832c-a1039ab03f55, raftlog=5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
datanode_5_1  | 2020-04-20 12:13:19,306 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: shutdown LeaderElection
datanode_5_1  | 2020-04-20 12:13:19,306 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-04-20 12:13:19,306 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-930049E84D30 with new leaderId: 5add3564-1298-4085-832c-a1039ab03f55
datanode_5_1  | 2020-04-20 12:13:19,307 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30: change Leader from null to 5add3564-1298-4085-832c-a1039ab03f55 at term 1 for becomeLeader, leader elected after 5178ms
datanode_5_1  | 2020-04-20 12:13:19,307 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | 2020-04-20 12:13:19,307 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5_1  | 2020-04-20 12:13:19,307 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30
datanode_5_1  | 2020-04-20 12:13:19,308 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5_1  | 2020-04-20 12:13:19,312 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_5_1  | 2020-04-20 12:13:19,312 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5_1  | 2020-04-20 12:13:19,312 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5_1  | 2020-04-20 12:13:19,312 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_6_1  | Enabled profiling in kernel
datanode_6_1  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_6_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_6_1  | 2020-04-20 12:11:12,208 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_6_1  | /************************************************************
datanode_6_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_6_1  | STARTUP_MSG:   host = a93fa9389f8e/10.5.0.9
datanode_6_1  | STARTUP_MSG:   args = []
datanode_6_1  | STARTUP_MSG:   version = 3.2.0
datanode_6_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_6_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_6_1  | STARTUP_MSG:   java = 11.0.6
datanode_6_1  | ************************************************************/
datanode_6_1  | 2020-04-20 12:11:12,251 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_6_1  | 2020-04-20 12:11:13,840 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_6_1  | 2020-04-20 12:11:14,357 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_6_1  | 2020-04-20 12:11:15,571 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_6_1  | 2020-04-20 12:11:15,571 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_6_1  | 2020-04-20 12:11:16,467 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:a93fa9389f8e ip:10.5.0.9
datanode_6_1  | 2020-04-20 12:11:16,952 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_6_1  | 2020-04-20 12:11:16,963 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_6_1  | 2020-04-20 12:11:16,970 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_6_1  | 2020-04-20 12:11:17,021 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_6_1  | 2020-04-20 12:11:17,150 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_6_1  | 2020-04-20 12:11:22,222 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_6_1  | 2020-04-20 12:11:22,475 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_6_1  | 2020-04-20 12:11:22,770 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_6_1  | 2020-04-20 12:11:22,775 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_6_1  | 2020-04-20 12:11:22,778 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-04-20 12:11:22,781 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_6_1  | 2020-04-20 12:11:22,785 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 2020-04-20 12:11:24,005 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-04-20 12:11:25,107 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_6_1  | 2020-04-20 12:11:25,246 [main] INFO util.log: Logging initialized @18128ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_6_1  | 2020-04-20 12:11:25,823 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_6_1  | 2020-04-20 12:11:25,831 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_6_1  | 2020-04-20 12:11:25,891 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_6_1  | 2020-04-20 12:11:25,897 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_6_1  | 2020-04-20 12:11:25,901 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_6_1  | 2020-04-20 12:11:25,901 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_6_1  | 2020-04-20 12:11:26,072 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_6_1  | 2020-04-20 12:11:26,127 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_6_1  | 2020-04-20 12:11:26,134 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_6_1  | 2020-04-20 12:11:26,475 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_6_1  | 2020-04-20 12:11:26,493 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_6_1  | 2020-04-20 12:11:26,497 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_6_1  | 2020-04-20 12:11:26,568 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f76c2cc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_6_1  | 2020-04-20 12:11:26,581 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@441b8382{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_6_1  | 2020-04-20 12:11:27,115 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7c011174{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-14083540471484161603.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_6_1  | 2020-04-20 12:11:27,183 [main] INFO server.AbstractConnector: Started ServerConnector@1491344a{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_6_1  | 2020-04-20 12:11:27,183 [main] INFO server.Server: Started @20065ms
datanode_6_1  | 2020-04-20 12:11:27,198 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_6_1  | 2020-04-20 12:11:27,198 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_6_1  | 2020-04-20 12:11:27,212 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_6_1  | 2020-04-20 12:11:27,380 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@193fd07a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_6_1  | 2020-04-20 12:11:28,171 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_6_1  | 2020-04-20 12:11:30,441 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-04-20 12:11:31,476 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_6_1  | java.net.SocketTimeoutException: Call From a93fa9389f8e/10.5.0.9 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:47348 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_6_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_6_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_5_1  | 2020-04-20 12:13:19,316 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_5_1  | 2020-04-20 12:13:19,316 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-04-20 12:13:19,317 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_5_1  | 2020-04-20 12:13:19,319 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_5_1  | 2020-04-20 12:13:19,319 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-04-20 12:13:19,320 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-04-20 12:13:19,325 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_5_1  | 2020-04-20 12:13:19,325 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-04-20 12:13:19,326 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_5_1  | 2020-04-20 12:13:19,326 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_5_1  | 2020-04-20 12:13:19,326 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-04-20 12:13:19,328 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-04-20 12:13:19,331 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: start LeaderState
datanode_5_1  | 2020-04-20 12:13:19,332 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-04-20 12:13:19,333 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-LeaderElection2] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30: set configuration 0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null at 0
datanode_5_1  | 2020-04-20 12:13:19,341 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2b915d42-0547-44e8-966f-930049e84d30/current/log_inprogress_0
datanode_5_1  | 2020-04-20 12:13:25,799 [ChunkWriter-55-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: 30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_5_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_5_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_5_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=966074368 B) is less than the container size (=1073741824 B).
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_5_1  | 	... 13 more
datanode_5_1  | 2020-04-20 12:13:25,863 [ChunkWriter-55-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: 30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0 , Message: ContainerID 3 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_5_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 3 creation failed
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_5_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-04-20 12:13:25,873 [ChunkWriter-55-0] ERROR ratis.ContainerStateMachine: group-930049E84D30: writeChunk writeStateMachineData failed: blockIdcontainerID: 3
datanode_5_1  | localID: 104030850618556420
datanode_5_1  | blockCommitSequenceId: 0
datanode_5_1  |  logIndex 1 chunkName 104030850618556420_chunk_1 Error message: ContainerID 3 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_1_1  | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.4:37944 remote=scm/10.5.0.71:9861]
datanode_1_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_1_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_1_1  | 2020-04-20 12:11:32,489 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1_1  | 2020-04-20 12:11:32,490 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1_1  | 2020-04-20 12:11:32,490 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis ea211d94-4213-43ea-b4d3-a3779a4d37c1 at port 9858
datanode_1_1  | 2020-04-20 12:11:32,621 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: start RPC server
datanode_1_1  | 2020-04-20 12:11:32,771 [Datanode State Machine Thread - 0] INFO server.GrpcService: ea211d94-4213-43ea-b4d3-a3779a4d37c1: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1_1  | 2020-04-20 12:11:37,515 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: addNew group-923DF4260D46:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858] returns group-923DF4260D46:java.util.concurrent.CompletableFuture@1f662db7[Not completed]
datanode_1_1  | 2020-04-20 12:11:37,654 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1: new RaftServerImpl for group-923DF4260D46:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-04-20 12:11:37,656 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-04-20 12:11:37,668 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-04-20 12:11:37,689 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-04-20 12:11:37,690 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-04-20 12:11:37,692 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-04-20 12:11:37,717 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46: ConfigurationManager, init=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-04-20 12:11:37,719 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-04-20 12:11:37,741 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-04-20 12:11:37,744 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/0053d728-2466-4118-a0e3-923df4260d46 does not exist. Creating ...
datanode_1_1  | 2020-04-20 12:11:37,759 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/0053d728-2466-4118-a0e3-923df4260d46/in_use.lock acquired by nodename 6@52fe7c485517
datanode_1_1  | 2020-04-20 12:11:37,766 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/0053d728-2466-4118-a0e3-923df4260d46 has been successfully formatted.
datanode_1_1  | 2020-04-20 12:11:37,785 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-923DF4260D46: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-04-20 12:11:37,789 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-04-20 12:11:37,811 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-04-20 12:11:37,816 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-04-20 12:11:37,816 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-04-20 12:11:37,850 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-04-20 12:11:37,872 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_1_1  | 2020-04-20 12:11:37,987 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-04-20 12:11:38,008 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/0053d728-2466-4118-a0e3-923df4260d46
datanode_1_1  | 2020-04-20 12:11:38,033 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-04-20 12:11:38,037 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-04-20 12:11:38,045 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-04-20 12:11:38,045 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-04-20 12:11:38,046 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-04-20 12:11:38,046 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-04-20 12:11:38,047 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-04-20 12:11:38,047 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-04-20 12:11:38,047 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-04-20 12:11:38,182 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-04-20 12:11:38,247 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-04-20 12:11:38,297 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-04-20 12:11:38,298 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-04-20 12:11:38,305 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-04-20 12:11:38,310 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-04-20 12:11:38,397 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46
datanode_1_1  | 2020-04-20 12:11:38,403 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46
datanode_1_1  | 2020-04-20 12:11:38,421 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46: start as a follower, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858], old=null
datanode_1_1  | 2020-04-20 12:11:38,423 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-04-20 12:11:38,426 [pool-69-thread-1] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: start FollowerState
datanode_1_1  | 2020-04-20 12:11:38,443 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-923DF4260D46,id=ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_1_1  | 2020-04-20 12:11:38,445 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46
datanode_1_1  | 2020-04-20 12:11:38,511 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "0053d728-2466-4118-a0e3-923df4260d46"
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_6_1  | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_6_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:47348 remote=scm/10.5.0.71:9861]
datanode_6_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_6_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_6_1  | 2020-04-20 12:11:31,654 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_6_1  | 2020-04-20 12:11:31,655 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_6_1  | 2020-04-20 12:11:31,655 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis bc8a7b14-3ca0-481c-865e-e266d4d1f071 at port 9858
datanode_6_1  | 2020-04-20 12:11:31,740 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: bc8a7b14-3ca0-481c-865e-e266d4d1f071: start RPC server
datanode_6_1  | 2020-04-20 12:11:32,153 [Datanode State Machine Thread - 1] INFO server.GrpcService: bc8a7b14-3ca0-481c-865e-e266d4d1f071: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_6_1  | 2020-04-20 12:11:36,453 [Command processor thread] INFO impl.RaftServerProxy: bc8a7b14-3ca0-481c-865e-e266d4d1f071: addNew group-A45EF9C37AB5:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858] returns group-A45EF9C37AB5:java.util.concurrent.CompletableFuture@1f662db7[Not completed]
datanode_6_1  | 2020-04-20 12:11:36,573 [pool-69-thread-1] INFO impl.RaftServerImpl: bc8a7b14-3ca0-481c-865e-e266d4d1f071: new RaftServerImpl for group-A45EF9C37AB5:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-04-20 12:11:36,579 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-04-20 12:11:36,581 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-04-20 12:11:36,581 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-04-20 12:11:36,589 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-04-20 12:11:36,590 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-04-20 12:11:36,603 [pool-69-thread-1] INFO impl.RaftServerImpl: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5: ConfigurationManager, init=-1: [bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-04-20 12:11:36,604 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-04-20 12:11:36,651 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-04-20 12:11:36,653 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7c7ec9f4-3899-4fe8-a512-a45ef9c37ab5 does not exist. Creating ...
datanode_6_1  | 2020-04-20 12:11:36,674 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7c7ec9f4-3899-4fe8-a512-a45ef9c37ab5/in_use.lock acquired by nodename 7@a93fa9389f8e
datanode_6_1  | 2020-04-20 12:11:36,682 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7c7ec9f4-3899-4fe8-a512-a45ef9c37ab5 has been successfully formatted.
datanode_6_1  | 2020-04-20 12:11:36,689 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-A45EF9C37AB5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-04-20 12:11:36,701 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_6_1  | 2020-04-20 12:11:36,717 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-04-20 12:11:36,761 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-04-20 12:11:36,762 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-04-20 12:11:36,767 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-04-20 12:11:36,781 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.bc8a7b14-3ca0-481c-865e-e266d4d1f071
datanode_6_1  | 2020-04-20 12:11:36,857 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-04-20 12:11:36,864 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/7c7ec9f4-3899-4fe8-a512-a45ef9c37ab5
datanode_6_1  | 2020-04-20 12:11:36,887 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-04-20 12:11:36,887 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-04-20 12:11:36,888 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-04-20 12:11:38,293 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-04-20 12:11:38,296 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-04-20 12:11:38,296 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-04-20 12:11:38,296 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-04-20 12:11:38,296 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-04-20 12:11:38,297 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-04-20 12:11:38,300 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-04-20 12:11:38,310 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-04-20 12:11:38,311 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-04-20 12:11:38,311 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-04-20 12:11:38,311 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-04-20 12:11:38,312 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD
datanode_4_1  | 2020-04-20 12:11:38,312 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD
datanode_4_1  | 2020-04-20 12:11:38,330 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD: start as a follower, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null
datanode_4_1  | 2020-04-20 12:11:38,333 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-04-20 12:11:38,337 [pool-69-thread-1] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: start FollowerState
datanode_4_1  | 2020-04-20 12:11:38,344 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-18D4649732CD,id=d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 2020-04-20 12:11:38,345 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD
datanode_4_1  | 2020-04-20 12:11:40,262 [grpc-default-executor-0] WARN impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Failed groupAdd* GroupManagementRequest:client-5F5C50229662->d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD, cid=0, seq=0, RW, null, Add:group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858]
datanode_4_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Failed to add group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_4_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_4_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_4_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_4_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Failed to add group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_4_1  | 	... 13 more
datanode_4_1  | 2020-04-20 12:11:40,371 [grpc-default-executor-0] WARN impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Failed groupAdd* GroupManagementRequest:client-A459B2409388->d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD, cid=3, seq=0, RW, null, Add:group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858]
datanode_4_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Failed to add group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_5_1  | 2020-04-20 12:13:25,877 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=2b915d42-0547-44e8-966f-930049e84d30.Reason : ContainerID 3 creation failed
datanode_5_1  | 2020-04-20 12:13:25,915 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=2b915d42-0547-44e8-966f-930049e84d30.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=15
datanode_5_1  | 	 State Machine: cmdType: WriteChunk traceID: "30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0" containerID: 3 datanodeUuid: "d427b6db-e08f-47dc-bc01-4bdf7d0252a1" pipelineID: "2b915d42-0547-44e8-966f-930049e84d30" writeChunk { blockID { containerID: 3 localID: 104030850618556420 blockCommitSequenceId: 0 } chunkData { chunkName: "104030850618556420_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_5_1  | 2020-04-20 12:13:45,129 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #3 does not exist in datanode. Container close failed.
datanode_5_1  | 2020-04-20 12:13:56,880 [grpc-default-executor-0] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: addNew group-12B961FFD63F:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] returns group-12B961FFD63F:java.util.concurrent.CompletableFuture@83e0ab6[Not completed]
datanode_5_1  | 2020-04-20 12:13:56,881 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55: new RaftServerImpl for group-12B961FFD63F:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-04-20 12:13:56,882 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-04-20 12:13:56,882 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-04-20 12:13:56,883 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-04-20 12:13:56,883 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-04-20 12:13:56,883 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-04-20 12:13:56,883 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F: ConfigurationManager, init=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-04-20 12:13:56,883 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-04-20 12:13:56,883 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-04-20 12:13:56,884 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b2031e52-018e-41a3-b0d9-12b961ffd63f does not exist. Creating ...
datanode_5_1  | 2020-04-20 12:13:56,885 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b2031e52-018e-41a3-b0d9-12b961ffd63f/in_use.lock acquired by nodename 6@7a52a65e9249
datanode_5_1  | 2020-04-20 12:13:56,887 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b2031e52-018e-41a3-b0d9-12b961ffd63f has been successfully formatted.
datanode_5_1  | 2020-04-20 12:13:56,891 [grpc-default-executor-0] WARN impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: Failed groupAdd* GroupManagementRequest:client-283974BDDEDB->5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F, cid=2, seq=0, RW, null, Add:group-12B961FFD63F:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858]
datanode_5_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 5add3564-1298-4085-832c-a1039ab03f55: Failed to add group-12B961FFD63F:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] since the group already exists in the map.
datanode_5_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_5_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_5_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_5_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_5_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_5_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_5_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_5_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 5add3564-1298-4085-832c-a1039ab03f55: Failed to add group-12B961FFD63F:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] since the group already exists in the map.
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_5_1  | 	... 13 more
datanode_5_1  | 2020-04-20 12:13:56,893 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-12B961FFD63F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-04-20 12:13:56,893 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-04-20 12:13:56,893 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-04-20 12:13:56,893 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Failed to add group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2_1  | 	... 13 more
datanode_2_1  | 2020-04-20 12:11:40,533 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_2_1  | .
datanode_2_1  | 2020-04-20 12:11:40,549 [grpc-default-executor-0] WARN impl.RaftServerProxy: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Failed groupAdd* GroupManagementRequest:client-34D36209A4AD->8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD, cid=1, seq=0, RW, null, Add:group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858]
datanode_2_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Failed to add group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Failed to add group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2_1  | 	... 13 more
datanode_2_1  | 2020-04-20 12:11:40,595 [grpc-default-executor-0] WARN impl.RaftServerProxy: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Failed groupAdd* GroupManagementRequest:client-0094D978A46F->8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD, cid=1, seq=0, RW, null, Add:group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858]
datanode_2_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Failed to add group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-04-20 12:11:17,063 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = d75b8d1a4d33/10.5.0.71
scm_1         | STARTUP_MSG:   args = [--init]
scm_1         | STARTUP_MSG:   version = 3.2.0
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-04-20 12:11:17,166 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-04-20 12:11:17,934 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-04-20 12:11:18,308 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-23a81e83-cb7a-4c8f-a5b3-fa9810b7b715
scm_1         | 2020-04-20 12:11:18,428 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1         | /************************************************************
scm_1         | SHUTDOWN_MSG: Shutting down StorageContainerManager at d75b8d1a4d33/10.5.0.71
scm_1         | ************************************************************/
scm_1         | Enabled profiling in kernel
scm_1         | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-04-20 12:11:28,760 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = d75b8d1a4d33/10.5.0.71
scm_1         | STARTUP_MSG:   args = []
scm_1         | STARTUP_MSG:   version = 3.2.0
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-04-20 12:11:28,782 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-04-20 12:11:28,920 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-04-20 12:11:28,936 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-04-20 12:11:29,135 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@3336e6b6
scm_1         | 2020-04-20 12:11:29,135 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1         | 2020-04-20 12:11:29,208 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1         | 2020-04-20 12:11:29,308 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
scm_1         | 2020-04-20 12:11:29,311 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-04-20 12:11:29,355 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1         | 2020-04-20 12:11:29,361 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-04-20 12:11:29,478 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1         | 2020-04-20 12:11:29,483 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1         | 2020-04-20 12:11:29,542 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1         | 2020-04-20 12:11:30,086 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-04-20 12:11:30,102 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1         | 2020-04-20 12:11:30,130 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-04-20 12:11:30,133 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1         | 2020-04-20 12:11:30,148 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-04-20 12:11:30,149 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1         | 2020-04-20 12:11:30,168 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1         | 2020-04-20 12:11:30,184 [main] INFO util.log: Logging initialized @9974ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1         | 2020-04-20 12:11:30,409 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | 2020-04-20 12:11:30,434 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1         | 2020-04-20 12:11:30,479 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1         | 2020-04-20 12:11:30,486 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1         | 2020-04-20 12:11:30,486 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
scm_1         | 2020-04-20 12:11:30,486 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1         | 2020-04-20 12:11:30,543 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
scm_1         | 2020-04-20 12:11:30,570 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1         | 2020-04-20 12:11:30,706 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1         | 2020-04-20 12:11:30,816 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1         | 2020-04-20 12:11:30,817 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1         | 2020-04-20 12:11:31,056 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1         | 2020-04-20 12:11:31,057 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-04-20 12:11:31,065 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1         | 2020-04-20 12:11:31,226 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1         | 2020-04-20 12:11:31,227 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1         | 2020-04-20 12:11:31,237 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-04-20 12:11:31,247 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1         | 2020-04-20 12:11:31,328 [main] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1         | 2020-04-20 12:11:31,328 [main] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
datanode_5_1  | 2020-04-20 12:13:56,894 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-04-20 12:13:56,894 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-04-20 12:13:56,894 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-04-20 12:13:56,894 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/b2031e52-018e-41a3-b0d9-12b961ffd63f
datanode_5_1  | 2020-04-20 12:13:56,894 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-04-20 12:13:56,894 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-04-20 12:13:56,894 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-04-20 12:13:56,894 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-04-20 12:13:56,895 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-04-20 12:13:56,895 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-04-20 12:13:56,895 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-04-20 12:13:56,895 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-04-20 12:13:56,895 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-04-20 12:13:56,896 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-04-20 12:13:56,896 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-04-20 12:13:56,897 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-04-20 12:13:56,898 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-04-20 12:13:56,898 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-04-20 12:13:56,898 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-04-20 12:13:56,898 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F
datanode_5_1  | 2020-04-20 12:13:56,899 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F
datanode_5_1  | 2020-04-20 12:13:56,900 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F: start as a follower, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
datanode_5_1  | 2020-04-20 12:13:56,900 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-04-20 12:13:56,900 [pool-69-thread-1] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: start FollowerState
datanode_5_1  | 2020-04-20 12:13:56,902 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-12B961FFD63F,id=5add3564-1298-4085-832c-a1039ab03f55
datanode_5_1  | 2020-04-20 12:13:56,902 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F
datanode_5_1  | 2020-04-20 12:14:01,976 [Thread-44] INFO impl.FollowerState: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-FollowerState: change to CANDIDATE, lastRpcTime:5076ms, electionTimeout:5073ms
datanode_5_1  | 2020-04-20 12:14:01,977 [Thread-44] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: shutdown FollowerState
datanode_5_1  | 2020-04-20 12:14:01,977 [Thread-44] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-04-20 12:14:01,977 [Thread-44] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: start LeaderElection
datanode_5_1  | 2020-04-20 12:14:01,981 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO impl.LeaderElection: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3: begin an election at term 1 for -1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
datanode_5_1  | 2020-04-20 12:14:02,000 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO impl.LeaderElection: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3: Election PASSED; received 1 response(s) [5add3564-1298-4085-832c-a1039ab03f55<-d427b6db-e08f-47dc-bc01-4bdf7d0252a1#0:OK-t1] and 0 exception(s); 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F:t1, leader=null, voted=5add3564-1298-4085-832c-a1039ab03f55, raftlog=5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
datanode_5_1  | 2020-04-20 12:14:02,000 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: shutdown LeaderElection
datanode_5_1  | 2020-04-20 12:14:02,000 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-04-20 12:14:02,000 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-12B961FFD63F with new leaderId: 5add3564-1298-4085-832c-a1039ab03f55
datanode_5_1  | 2020-04-20 12:14:02,001 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F: change Leader from null to 5add3564-1298-4085-832c-a1039ab03f55 at term 1 for becomeLeader, leader elected after 5106ms
datanode_5_1  | 2020-04-20 12:14:02,001 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | 2020-04-20 12:14:02,001 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5_1  | 2020-04-20 12:14:02,001 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F
datanode_5_1  | 2020-04-20 12:14:02,001 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5_1  | 2020-04-20 12:14:02,002 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_5_1  | 2020-04-20 12:14:02,002 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5_1  | 2020-04-20 12:14:02,002 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5_1  | 2020-04-20 12:14:02,002 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5_1  | 2020-04-20 12:14:02,002 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_5_1  | 2020-04-20 12:14:02,003 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-04-20 12:14:02,005 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_5_1  | 2020-04-20 12:14:02,006 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_5_1  | 2020-04-20 12:14:02,007 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-04-20 12:14:02,007 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-04-20 12:14:02,013 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_5_1  | 2020-04-20 12:14:02,013 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-04-20 12:14:02,013 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_5_1  | 2020-04-20 12:14:02,013 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_4_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_4_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_4_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_4_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Failed to add group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_4_1  | 	... 13 more
datanode_4_1  | 2020-04-20 12:11:40,620 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_4_1  | .
datanode_4_1  | 2020-04-20 12:11:43,201 [Thread-24] INFO impl.FollowerState: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-FollowerState: change to CANDIDATE, lastRpcTime:5041ms, electionTimeout:5029ms
datanode_4_1  | 2020-04-20 12:11:43,203 [Thread-24] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: shutdown FollowerState
datanode_4_1  | 2020-04-20 12:11:43,204 [Thread-24] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4_1  | 2020-04-20 12:11:43,206 [Thread-24] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: start LeaderElection
datanode_4_1  | 2020-04-20 12:11:43,215 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO impl.LeaderElection: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1: begin an election at term 1 for -1: [d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
datanode_4_1  | 2020-04-20 12:11:43,216 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: shutdown LeaderElection
datanode_4_1  | 2020-04-20 12:11:43,217 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_4_1  | 2020-04-20 12:11:43,217 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-7357CCDD9E8D with new leaderId: d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 2020-04-20 12:11:43,221 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D: change Leader from null to d427b6db-e08f-47dc-bc01-4bdf7d0252a1 at term 1 for becomeLeader, leader elected after 5686ms
datanode_4_1  | 2020-04-20 12:11:43,231 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4_1  | 2020-04-20 12:11:43,232 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4_1  | 2020-04-20 12:11:43,234 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D
datanode_4_1  | 2020-04-20 12:11:43,244 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4_1  | 2020-04-20 12:11:43,249 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_4_1  | 2020-04-20 12:11:43,279 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4_1  | 2020-04-20 12:11:43,288 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4_1  | 2020-04-20 12:11:43,290 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4_1  | 2020-04-20 12:11:43,312 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: start LeaderState
datanode_4_1  | 2020-04-20 12:11:43,370 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-04-20 12:11:43,437 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-LeaderElection1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D: set configuration 0: [d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null at 0
datanode_4_1  | 2020-04-20 12:11:43,487 [Thread-26] INFO impl.FollowerState: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-FollowerState: change to CANDIDATE, lastRpcTime:5150ms, electionTimeout:5139ms
datanode_4_1  | 2020-04-20 12:11:43,492 [Thread-26] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: shutdown FollowerState
datanode_4_1  | 2020-04-20 12:11:43,493 [Thread-26] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4_1  | 2020-04-20 12:11:43,500 [Thread-26] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: start LeaderElection
datanode_4_1  | 2020-04-20 12:11:43,542 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO impl.LeaderElection: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2: begin an election at term 1 for -1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null
scm_1         | 2020-04-20 12:11:31,330 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-04-20 12:11:31,330 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
datanode_5_1  | 2020-04-20 12:14:02,013 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-04-20 12:14:02,013 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-04-20 12:14:02,014 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: start LeaderState
datanode_5_1  | 2020-04-20 12:14:02,014 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-04-20 12:14:02,016 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b2031e52-018e-41a3-b0d9-12b961ffd63f/current/log_inprogress_0
datanode_5_1  | 2020-04-20 12:14:02,024 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-LeaderElection3] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F: set configuration 0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null at 0
datanode_5_1  | 2020-04-20 12:14:25,801 [java.util.concurrent.ThreadPoolExecutor$Worker@54d3c1e1[State = -1, empty queue]] WARN server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30->d427b6db-e08f-47dc-bc01-4bdf7d0252a1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4,entriesCount=1,lastEntry=(t:1, i:1)
datanode_5_1  | 2020-04-20 12:14:25,801 [java.util.concurrent.ThreadPoolExecutor$Worker@54d3c1e1[State = -1, empty queue]] WARN server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30->ea211d94-4213-43ea-b4d3-a3779a4d37c1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4,entriesCount=1,lastEntry=(t:1, i:1)
datanode_5_1  | 2020-04-20 12:14:25,831 [java.util.concurrent.ThreadPoolExecutor$Worker@54d3c1e1[State = -1, empty queue]] WARN server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30->ea211d94-4213-43ea-b4d3-a3779a4d37c1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5,entriesCount=1,lastEntry=(t:1, i:2)
datanode_5_1  | 2020-04-20 12:14:25,842 [java.util.concurrent.ThreadPoolExecutor$Worker@54d3c1e1[State = -1, empty queue]] WARN server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30->d427b6db-e08f-47dc-bc01-4bdf7d0252a1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5,entriesCount=1,lastEntry=(t:1, i:2)
datanode_5_1  | 2020-04-20 12:14:33,002 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: remove    LEADER 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30:t1, leader=5add3564-1298-4085-832c-a1039ab03f55, voted=5add3564-1298-4085-832c-a1039ab03f55, raftlog=5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null RUNNING
datanode_5_1  | 2020-04-20 12:14:33,003 [Command processor thread] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30: shutdown
datanode_5_1  | 2020-04-20 12:14:33,004 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-930049E84D30,id=5add3564-1298-4085-832c-a1039ab03f55
datanode_5_1  | 2020-04-20 12:14:33,004 [Command processor thread] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: shutdown LeaderState
datanode_5_1  | 2020-04-20 12:14:33,005 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$458/0x000000084057c040@79466b74] WARN server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30->ea211d94-4213-43ea-b4d3-a3779a4d37c1-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_5_1  | 2020-04-20 12:14:33,005 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$458/0x000000084057c040@1454205a] WARN server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30->d427b6db-e08f-47dc-bc01-4bdf7d0252a1-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_5_1  | 2020-04-20 12:14:33,006 [Command processor thread] INFO impl.PendingRequests: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-PendingRequests: sendNotLeaderResponses
datanode_5_1  | 2020-04-20 12:14:33,009 [grpc-default-executor-0] INFO server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30->ea211d94-4213-43ea-b4d3-a3779a4d37c1-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_3_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 68b8b2ca-801b-4940-8ace-0c902746c4e8: Failed to add group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3_1  | 	... 13 more
datanode_3_1  | 2020-04-20 12:11:39,142 [grpc-default-executor-0] WARN impl.RaftServerProxy: 68b8b2ca-801b-4940-8ace-0c902746c4e8: Failed groupAdd* GroupManagementRequest:client-E99EEE93C008->68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F, cid=0, seq=0, RW, null, Add:group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858]
datanode_3_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 68b8b2ca-801b-4940-8ace-0c902746c4e8: Failed to add group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_3_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 68b8b2ca-801b-4940-8ace-0c902746c4e8: Failed to add group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3_1  | 	... 13 more
datanode_3_1  | 2020-04-20 12:11:40,200 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "daa4732c-5873-4db2-844f-92ed6ca41c2f"
datanode_3_1  | .
datanode_3_1  | 2020-04-20 12:11:41,274 [Thread-23] INFO impl.FollowerState: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-FollowerState: change to CANDIDATE, lastRpcTime:5029ms, electionTimeout:5005ms
datanode_3_1  | 2020-04-20 12:11:41,276 [Thread-23] INFO impl.RoleInfo: 68b8b2ca-801b-4940-8ace-0c902746c4e8: shutdown FollowerState
datanode_3_1  | 2020-04-20 12:11:41,277 [Thread-23] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3_1  | 2020-04-20 12:11:41,279 [Thread-23] INFO impl.RoleInfo: 68b8b2ca-801b-4940-8ace-0c902746c4e8: start LeaderElection
datanode_3_1  | 2020-04-20 12:11:41,287 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO impl.LeaderElection: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1: begin an election at term 1 for -1: [68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858], old=null
datanode_3_1  | 2020-04-20 12:11:41,288 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO impl.RoleInfo: 68b8b2ca-801b-4940-8ace-0c902746c4e8: shutdown LeaderElection
datanode_3_1  | 2020-04-20 12:11:41,289 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3_1  | 2020-04-20 12:11:41,289 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4DC0B3E02A28 with new leaderId: 68b8b2ca-801b-4940-8ace-0c902746c4e8
datanode_3_1  | 2020-04-20 12:11:41,289 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28: change Leader from null to 68b8b2ca-801b-4940-8ace-0c902746c4e8 at term 1 for becomeLeader, leader elected after 5360ms
datanode_3_1  | 2020-04-20 12:11:41,294 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-04-20 12:11:41,294 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 2020-04-20 12:11:41,296 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28
datanode_3_1  | 2020-04-20 12:11:41,301 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-04-20 12:11:41,301 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-04-20 12:11:41,305 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3_1  | 2020-04-20 12:11:41,305 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-04-20 12:11:41,306 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-04-20 12:11:41,331 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO impl.RoleInfo: 68b8b2ca-801b-4940-8ace-0c902746c4e8: start LeaderState
datanode_3_1  | 2020-04-20 12:11:41,347 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-04-20 12:11:41,369 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-LeaderElection1] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28: set configuration 0: [68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858], old=null at 0
datanode_3_1  | 2020-04-20 12:11:41,401 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-4DC0B3E02A28-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/66927c5b-4a56-4d19-93cb-4dc0b3e02a28/current/log_inprogress_0
datanode_3_1  | 2020-04-20 12:11:41,548 [Thread-25] INFO impl.FollowerState: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-FollowerState: change to CANDIDATE, lastRpcTime:5192ms, electionTimeout:5191ms
datanode_3_1  | 2020-04-20 12:11:41,549 [Thread-25] INFO impl.RoleInfo: 68b8b2ca-801b-4940-8ace-0c902746c4e8: shutdown FollowerState
datanode_3_1  | 2020-04-20 12:11:41,549 [Thread-25] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3_1  | 2020-04-20 12:11:41,549 [Thread-25] INFO impl.RoleInfo: 68b8b2ca-801b-4940-8ace-0c902746c4e8: start LeaderElection
datanode_3_1  | 2020-04-20 12:11:41,553 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO impl.LeaderElection: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2: begin an election at term 1 for -1: [bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null
datanode_3_1  | 2020-04-20 12:11:41,675 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO impl.LeaderElection: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2: Election PASSED; received 1 response(s) [68b8b2ca-801b-4940-8ace-0c902746c4e8<-bc8a7b14-3ca0-481c-865e-e266d4d1f071#0:OK-t1] and 0 exception(s); 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F:t1, leader=null, voted=68b8b2ca-801b-4940-8ace-0c902746c4e8, raftlog=68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null
datanode_2_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Failed to add group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2_1  | 	... 13 more
datanode_2_1  | 2020-04-20 12:11:41,634 [grpc-default-executor-0] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:68b8b2ca-801b-4940-8ace-0c902746c4e8
datanode_2_1  | 2020-04-20 12:11:41,637 [grpc-default-executor-0] INFO impl.RoleInfo: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: shutdown FollowerState
datanode_2_1  | 2020-04-20 12:11:41,637 [grpc-default-executor-0] INFO impl.RoleInfo: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: start FollowerState
datanode_2_1  | 2020-04-20 12:11:41,637 [Thread-26] INFO impl.FollowerState: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2_1  | 2020-04-20 12:11:41,808 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-92ED6CA41C2F with new leaderId: 68b8b2ca-801b-4940-8ace-0c902746c4e8
datanode_2_1  | 2020-04-20 12:11:41,809 [grpc-default-executor-0] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F: change Leader from null to 68b8b2ca-801b-4940-8ace-0c902746c4e8 at term 1 for appendEntries, leader elected after 4577ms
datanode_2_1  | 2020-04-20 12:11:41,854 [grpc-default-executor-0] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F: set configuration 0: [bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-04-20 12:11:41,890 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-04-20 12:11:42,058 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-92ED6CA41C2F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/daa4732c-5873-4db2-844f-92ed6ca41c2f/current/log_inprogress_0
datanode_2_1  | 2020-04-20 12:11:42,240 [Thread-24] INFO impl.FollowerState: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-FollowerState: change to CANDIDATE, lastRpcTime:5165ms, electionTimeout:5136ms
datanode_2_1  | 2020-04-20 12:11:42,241 [Thread-24] INFO impl.RoleInfo: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: shutdown FollowerState
datanode_2_1  | 2020-04-20 12:11:42,241 [Thread-24] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2_1  | 2020-04-20 12:11:42,243 [Thread-24] INFO impl.RoleInfo: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: start LeaderElection
datanode_2_1  | 2020-04-20 12:11:42,254 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO impl.LeaderElection: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1: begin an election at term 1 for -1: [8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null
datanode_2_1  | 2020-04-20 12:11:42,256 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO impl.RoleInfo: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: shutdown LeaderElection
datanode_2_1  | 2020-04-20 12:11:42,256 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2_1  | 2020-04-20 12:11:42,256 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CA703B34E48B with new leaderId: 8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_2_1  | 2020-04-20 12:11:42,258 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B: change Leader from null to 8e63932d-e4c5-48a1-856f-f13c15c5f03b at term 1 for becomeLeader, leader elected after 5707ms
datanode_2_1  | 2020-04-20 12:11:42,264 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2_1  | 2020-04-20 12:11:42,265 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2_1  | 2020-04-20 12:11:42,267 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B
datanode_2_1  | 2020-04-20 12:11:42,272 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2_1  | 2020-04-20 12:11:42,272 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2_1  | 2020-04-20 12:11:42,277 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2_1  | 2020-04-20 12:11:42,278 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2_1  | 2020-04-20 12:11:42,279 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2_1  | 2020-04-20 12:11:42,286 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO impl.RoleInfo: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: start LeaderState
datanode_2_1  | 2020-04-20 12:11:42,301 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-04-20 12:11:42,304 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fc95027a-d6cc-40a8-b22f-ca703b34e48b/current/log_inprogress_0
datanode_2_1  | 2020-04-20 12:11:42,308 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B-LeaderElection1] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-CA703B34E48B: set configuration 0: [8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-04-20 12:11:43,646 [grpc-default-executor-0] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_2_1  | 2020-04-20 12:11:43,646 [grpc-default-executor-0] INFO impl.RoleInfo: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: shutdown FollowerState
datanode_2_1  | 2020-04-20 12:11:43,646 [Thread-28] INFO impl.FollowerState: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2_1  | 2020-04-20 12:11:43,647 [grpc-default-executor-0] INFO impl.RoleInfo: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: start FollowerState
datanode_1_1  | .
datanode_1_1  | 2020-04-20 12:11:38,511 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: addNew group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] returns group-18D4649732CD:java.util.concurrent.CompletableFuture@63938cc3[Not completed]
datanode_1_1  | 2020-04-20 12:11:38,546 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1: new RaftServerImpl for group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-04-20 12:11:38,547 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-04-20 12:11:38,547 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-04-20 12:11:38,547 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-04-20 12:11:38,547 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-04-20 12:11:38,556 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-04-20 12:11:38,557 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD: ConfigurationManager, init=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-04-20 12:11:38,557 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-04-20 12:11:38,557 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-04-20 12:11:38,557 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/9539b8c0-47a1-400b-b528-18d4649732cd does not exist. Creating ...
datanode_1_1  | 2020-04-20 12:11:38,573 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/9539b8c0-47a1-400b-b528-18d4649732cd/in_use.lock acquired by nodename 6@52fe7c485517
datanode_1_1  | 2020-04-20 12:11:38,581 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/9539b8c0-47a1-400b-b528-18d4649732cd has been successfully formatted.
datanode_1_1  | 2020-04-20 12:11:38,582 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-18D4649732CD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-04-20 12:11:38,585 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-04-20 12:11:38,586 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-04-20 12:11:38,586 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-04-20 12:11:38,586 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-04-20 12:11:38,586 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-04-20 12:11:38,587 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-04-20 12:11:38,587 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/9539b8c0-47a1-400b-b528-18d4649732cd
datanode_1_1  | 2020-04-20 12:11:38,587 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-04-20 12:11:38,587 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-04-20 12:11:38,588 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-04-20 12:11:38,588 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-04-20 12:11:38,588 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-04-20 12:11:38,590 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-04-20 12:11:38,595 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-04-20 12:14:33,011 [grpc-default-executor-1] INFO server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30->d427b6db-e08f-47dc-bc01-4bdf7d0252a1-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_5_1  | 2020-04-20 12:14:33,024 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30
datanode_5_1  | 2020-04-20 12:14:33,026 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-930049E84D30 as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_5_1  | 2020-04-20 12:14:33,026 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-StateMachineUpdater] ERROR impl.StateMachineUpdater: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-StateMachineUpdater: Failed to take snapshot
datanode_5_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-930049E84D30 as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_5_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_5_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_5_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-04-20 12:14:33,026 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-930049E84D30 as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_5_1  | 2020-04-20 12:14:33,026 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-StateMachineUpdater] ERROR impl.StateMachineUpdater: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-StateMachineUpdater: Failed to take snapshot
datanode_5_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-930049E84D30 as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_5_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_5_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_5_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-04-20 12:14:33,027 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30
datanode_5_1  | 2020-04-20 12:14:33,028 [Command processor thread] INFO impl.StateMachineUpdater: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-StateMachineUpdater: set stopIndex = 0
datanode_5_1  | 2020-04-20 12:14:33,029 [Command processor thread] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30: closes. applyIndex: 0
datanode_5_1  | 2020-04-20 12:14:33,036 [5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_5_1  | 2020-04-20 12:14:33,041 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30-SegmentedRaftLogWorker close()
datanode_5_1  | 2020-04-20 12:14:33,045 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.5add3564-1298-4085-832c-a1039ab03f55
datanode_5_1  | 2020-04-20 12:14:33,045 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30
datanode_5_1  | 2020-04-20 12:14:33,046 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30
datanode_5_1  | 2020-04-20 12:14:33,048 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_5_1  |  command on datanode #5add3564-1298-4085-832c-a1039ab03f55.
datanode_5_1  | 2020-04-20 12:14:33,058 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: remove group-930049E84D30:null
datanode_5_1  | 2020-04-20 12:14:33,061 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_5_1  | 
datanode_5_1  | java.io.IOException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-930049E84D30 not found.
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 2020-04-20 12:11:38,601 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-04-20 12:11:38,601 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-04-20 12:11:38,602 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-04-20 12:11:38,602 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-04-20 12:11:38,610 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-04-20 12:11:38,610 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-04-20 12:11:38,611 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-04-20 12:11:38,611 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-04-20 12:11:38,611 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD
datanode_1_1  | 2020-04-20 12:11:38,612 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD
datanode_1_1  | 2020-04-20 12:11:38,622 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD: start as a follower, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null
datanode_1_1  | 2020-04-20 12:11:38,623 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-04-20 12:11:38,623 [pool-69-thread-1] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: start FollowerState
datanode_1_1  | 2020-04-20 12:11:38,623 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-18D4649732CD,id=ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_1_1  | 2020-04-20 12:11:38,623 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD
datanode_1_1  | 2020-04-20 12:11:40,206 [grpc-default-executor-1] WARN impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Failed groupAdd* GroupManagementRequest:client-BDBF5C23C332->ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD, cid=0, seq=0, RW, null, Add:group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858]
datanode_1_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Failed to add group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Failed to add group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1_1  | 	... 13 more
datanode_1_1  | 2020-04-20 12:11:40,209 [grpc-default-executor-0] WARN impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Failed groupAdd* GroupManagementRequest:client-75355B5C4B1A->ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD, cid=2, seq=0, RW, null, Add:group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858]
datanode_1_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Failed to add group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_6_1  | 2020-04-20 12:11:36,897 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-04-20 12:11:36,897 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-04-20 12:11:36,898 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-04-20 12:11:36,899 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-04-20 12:11:36,905 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-04-20 12:11:36,906 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-04-20 12:11:36,985 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-04-20 12:11:37,021 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-04-20 12:11:37,032 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-04-20 12:11:37,043 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-04-20 12:11:37,044 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-04-20 12:11:37,056 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-04-20 12:11:37,110 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5
datanode_6_1  | 2020-04-20 12:11:37,124 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5
datanode_6_1  | 2020-04-20 12:11:37,132 [pool-69-thread-1] INFO impl.RaftServerImpl: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5: start as a follower, conf=-1: [bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858], old=null
datanode_6_1  | 2020-04-20 12:11:37,133 [pool-69-thread-1] INFO impl.RaftServerImpl: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-04-20 12:11:37,139 [pool-69-thread-1] INFO impl.RoleInfo: bc8a7b14-3ca0-481c-865e-e266d4d1f071: start FollowerState
datanode_6_1  | 2020-04-20 12:11:37,182 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A45EF9C37AB5,id=bc8a7b14-3ca0-481c-865e-e266d4d1f071
datanode_6_1  | 2020-04-20 12:11:37,183 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5
datanode_6_1  | 2020-04-20 12:11:37,278 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "7c7ec9f4-3899-4fe8-a512-a45ef9c37ab5"
datanode_6_1  | .
datanode_6_1  | 2020-04-20 12:11:37,290 [Command processor thread] INFO impl.RaftServerProxy: bc8a7b14-3ca0-481c-865e-e266d4d1f071: addNew group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] returns group-92ED6CA41C2F:java.util.concurrent.CompletableFuture@5a74a314[Not completed]
datanode_6_1  | 2020-04-20 12:11:37,345 [pool-69-thread-1] INFO impl.RaftServerImpl: bc8a7b14-3ca0-481c-865e-e266d4d1f071: new RaftServerImpl for group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-04-20 12:11:37,349 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-04-20 12:11:37,349 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-04-20 12:11:37,350 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-04-20 12:11:37,350 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-04-20 12:11:37,350 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-04-20 12:11:37,350 [pool-69-thread-1] INFO impl.RaftServerImpl: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F: ConfigurationManager, init=-1: [bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-04-20 12:11:37,365 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-04-20 12:11:37,365 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-04-20 12:11:37,365 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/daa4732c-5873-4db2-844f-92ed6ca41c2f does not exist. Creating ...
datanode_6_1  | 2020-04-20 12:11:37,380 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/daa4732c-5873-4db2-844f-92ed6ca41c2f/in_use.lock acquired by nodename 7@a93fa9389f8e
datanode_6_1  | 2020-04-20 12:11:37,386 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/daa4732c-5873-4db2-844f-92ed6ca41c2f has been successfully formatted.
datanode_6_1  | 2020-04-20 12:11:37,389 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-92ED6CA41C2F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-04-20 12:11:37,390 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_6_1  | 2020-04-20 12:11:37,392 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-04-20 12:11:37,393 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-04-20 12:11:37,397 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-04-20 12:11:37,397 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-04-20 12:11:37,397 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-04-20 12:11:37,397 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/daa4732c-5873-4db2-844f-92ed6ca41c2f
datanode_6_1  | 2020-04-20 12:11:37,398 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-04-20 12:11:37,398 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-04-20 12:11:37,398 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-04-20 12:11:37,398 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-04-20 12:11:37,400 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-04-20 12:11:37,401 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-04-20 12:11:41,675 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO impl.RoleInfo: 68b8b2ca-801b-4940-8ace-0c902746c4e8: shutdown LeaderElection
datanode_3_1  | 2020-04-20 12:11:41,676 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3_1  | 2020-04-20 12:11:41,676 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-92ED6CA41C2F with new leaderId: 68b8b2ca-801b-4940-8ace-0c902746c4e8
datanode_3_1  | 2020-04-20 12:11:41,676 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F: change Leader from null to 68b8b2ca-801b-4940-8ace-0c902746c4e8 at term 1 for becomeLeader, leader elected after 5363ms
datanode_3_1  | 2020-04-20 12:11:41,676 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-04-20 12:11:41,676 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 2020-04-20 12:11:41,685 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F
datanode_3_1  | 2020-04-20 12:11:41,689 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-04-20 12:11:41,697 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-04-20 12:11:41,697 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3_1  | 2020-04-20 12:11:41,701 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-04-20 12:11:41,701 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-04-20 12:11:41,707 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3_1  | 2020-04-20 12:11:41,709 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-04-20 12:11:41,710 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3_1  | 2020-04-20 12:11:41,712 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3_1  | 2020-04-20 12:11:41,718 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-04-20 12:11:41,719 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-04-20 12:11:41,746 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3_1  | 2020-04-20 12:11:41,746 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-04-20 12:11:41,746 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3_1  | 2020-04-20 12:11:41,746 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3_1  | 2020-04-20 12:11:41,746 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-04-20 12:11:41,746 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-04-20 12:11:41,749 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO impl.RoleInfo: 68b8b2ca-801b-4940-8ace-0c902746c4e8: start LeaderState
datanode_3_1  | 2020-04-20 12:11:41,751 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-04-20 12:11:41,752 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-LeaderElection2] INFO impl.RaftServerImpl: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F: set configuration 0: [bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null at 0
datanode_3_1  | 2020-04-20 12:11:41,761 [68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 68b8b2ca-801b-4940-8ace-0c902746c4e8@group-92ED6CA41C2F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/daa4732c-5873-4db2-844f-92ed6ca41c2f/current/log_inprogress_0
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Failed to add group-18D4649732CD:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1_1  | 	... 13 more
datanode_1_1  | 2020-04-20 12:11:40,593 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_1_1  | .
datanode_1_1  | 2020-04-20 12:11:43,517 [Thread-24] INFO impl.FollowerState: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-FollowerState: change to CANDIDATE, lastRpcTime:5091ms, electionTimeout:5089ms
datanode_1_1  | 2020-04-20 12:11:43,518 [Thread-24] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: shutdown FollowerState
datanode_1_1  | 2020-04-20 12:11:43,519 [Thread-24] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1_1  | 2020-04-20 12:11:43,521 [Thread-24] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: start LeaderElection
datanode_1_1  | 2020-04-20 12:11:43,530 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO impl.LeaderElection: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1: begin an election at term 1 for -1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858], old=null
datanode_1_1  | 2020-04-20 12:11:43,530 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: shutdown LeaderElection
datanode_1_1  | 2020-04-20 12:11:43,531 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1_1  | 2020-04-20 12:11:43,531 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-923DF4260D46 with new leaderId: ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_1_1  | 2020-04-20 12:11:43,532 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46: change Leader from null to ea211d94-4213-43ea-b4d3-a3779a4d37c1 at term 1 for becomeLeader, leader elected after 5742ms
datanode_1_1  | 2020-04-20 12:11:43,537 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1_1  | 2020-04-20 12:11:43,540 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1_1  | 2020-04-20 12:11:43,542 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46
datanode_1_1  | 2020-04-20 12:11:43,546 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1_1  | 2020-04-20 12:11:43,546 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1_1  | 2020-04-20 12:11:43,555 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1_1  | 2020-04-20 12:11:43,556 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1_1  | 2020-04-20 12:11:43,557 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1_1  | 2020-04-20 12:11:43,573 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: start LeaderState
datanode_1_1  | 2020-04-20 12:11:43,606 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-04-20 12:11:43,675 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_1_1  | 2020-04-20 12:11:43,675 [grpc-default-executor-0] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: shutdown FollowerState
datanode_1_1  | 2020-04-20 12:11:43,675 [grpc-default-executor-0] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: start FollowerState
datanode_1_1  | 2020-04-20 12:11:43,675 [Thread-26] INFO impl.FollowerState: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1_1  | 2020-04-20 12:11:43,718 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-LeaderElection1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46: set configuration 0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858], old=null at 0
datanode_1_1  | 2020-04-20 12:11:43,816 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-923DF4260D46-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0053d728-2466-4118-a0e3-923df4260d46/current/log_inprogress_0
datanode_1_1  | 2020-04-20 12:11:43,822 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-18D4649732CD with new leaderId: d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_1_1  | 2020-04-20 12:11:43,822 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD: change Leader from null to d427b6db-e08f-47dc-bc01-4bdf7d0252a1 at term 1 for appendEntries, leader elected after 5237ms
datanode_1_1  | 2020-04-20 12:11:43,926 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD: set configuration 0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null at 0
datanode_1_1  | 2020-04-20 12:11:43,926 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-04-20 12:11:43,931 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/9539b8c0-47a1-400b-b528-18d4649732cd/current/log_inprogress_0
datanode_1_1  | 2020-04-20 12:11:53,218 [ChunkWriter-24-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: ef3c38dac717a737:e6f4147bbe8a7bfc:ef3c38dac717a737:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=966356992 B) is less than the container size (=1073741824 B).
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_1_1  | 	... 13 more
datanode_1_1  | 2020-04-20 12:11:53,250 [ChunkWriter-24-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: ef3c38dac717a737:e6f4147bbe8a7bfc:ef3c38dac717a737:0 , Message: ContainerID 2 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 creation failed
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 2020-04-20 12:11:53,258 [ChunkWriter-24-0] ERROR ratis.ContainerStateMachine: group-18D4649732CD: writeChunk writeStateMachineData failed: blockIdcontainerID: 2
datanode_1_1  | localID: 104030844530458625
datanode_1_1  | blockCommitSequenceId: 0
datanode_1_1  |  logIndex 1 chunkName 104030844530458625_chunk_1 Error message: ContainerID 2 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_1_1  | 2020-04-20 12:11:53,271 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd.Reason : ContainerID 2 creation failed
datanode_1_1  | 2020-04-20 12:11:53,344 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-96D75E88687B, cid=5
datanode_1_1  | 	 State Machine: cmdType: WriteChunk traceID: "ef3c38dac717a737:e6f4147bbe8a7bfc:ef3c38dac717a737:0" containerID: 2 datanodeUuid: "ea211d94-4213-43ea-b4d3-a3779a4d37c1" pipelineID: "9539b8c0-47a1-400b-b528-18d4649732cd" writeChunk { blockID { containerID: 2 localID: 104030844530458625 blockCommitSequenceId: 0 } chunkData { chunkName: "104030844530458625_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_1_1  | 2020-04-20 12:12:09,582 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #2 does not exist in datanode. Container close failed.
datanode_1_1  | 2020-04-20 12:13:14,472 [grpc-default-executor-0] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: addNew group-930049E84D30:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] returns group-930049E84D30:java.util.concurrent.CompletableFuture@1f702eee[Not completed]
datanode_1_1  | 2020-04-20 12:13:14,474 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1: new RaftServerImpl for group-930049E84D30:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-04-20 12:13:14,475 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-04-20 12:13:14,475 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-04-20 12:13:14,476 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-04-20 12:13:14,476 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-04-20 12:13:14,476 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-04-20 12:13:14,476 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30: ConfigurationManager, init=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-04-20 12:13:14,476 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-04-20 12:13:14,476 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-04-20 12:13:14,476 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2b915d42-0547-44e8-966f-930049e84d30 does not exist. Creating ...
datanode_1_1  | 2020-04-20 12:13:14,478 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2b915d42-0547-44e8-966f-930049e84d30/in_use.lock acquired by nodename 6@52fe7c485517
datanode_1_1  | 2020-04-20 12:13:14,479 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2b915d42-0547-44e8-966f-930049e84d30 has been successfully formatted.
datanode_1_1  | 2020-04-20 12:13:14,480 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-930049E84D30: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-04-20 12:13:14,480 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-04-20 12:13:14,480 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-04-20 12:13:14,480 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-04-20 12:13:14,480 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-04-20 12:13:14,482 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-04-20 12:13:14,482 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-04-20 12:13:14,482 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2b915d42-0547-44e8-966f-930049e84d30
datanode_1_1  | 2020-04-20 12:13:14,482 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-04-20 12:13:14,482 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-04-20 12:13:14,482 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-04-20 12:13:14,482 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-04-20 12:13:14,482 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-04-20 12:13:14,483 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-04-20 12:13:14,483 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-04-20 12:13:14,483 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-04-20 12:13:14,483 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-04-20 12:13:14,486 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-04-20 12:13:14,486 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-04-20 12:13:14,487 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-04-20 12:13:14,487 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-04-20 12:13:14,487 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-04-20 12:13:14,487 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-04-20 12:13:14,487 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30
datanode_1_1  | 2020-04-20 12:13:14,488 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30
datanode_1_1  | 2020-04-20 12:13:14,494 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30: start as a follower, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
datanode_1_1  | 2020-04-20 12:13:14,494 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-04-20 12:13:14,495 [pool-69-thread-1] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: start FollowerState
datanode_1_1  | 2020-04-20 12:13:14,495 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-930049E84D30,id=ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_1_1  | 2020-04-20 12:13:14,495 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30
datanode_1_1  | 2020-04-20 12:13:19,288 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:5add3564-1298-4085-832c-a1039ab03f55
datanode_1_1  | 2020-04-20 12:13:19,288 [grpc-default-executor-0] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: shutdown FollowerState
datanode_1_1  | 2020-04-20 12:13:19,288 [Thread-76] INFO impl.FollowerState: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1_1  | 2020-04-20 12:13:19,289 [grpc-default-executor-0] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: start FollowerState
datanode_1_1  | 2020-04-20 12:13:19,352 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-930049E84D30 with new leaderId: 5add3564-1298-4085-832c-a1039ab03f55
datanode_4_1  | 2020-04-20 12:11:43,671 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO impl.LeaderElection: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2: Election PASSED; received 1 response(s) [d427b6db-e08f-47dc-bc01-4bdf7d0252a1<-8e63932d-e4c5-48a1-856f-f13c15c5f03b#0:OK-t1] and 0 exception(s); d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD:t1, leader=null, voted=d427b6db-e08f-47dc-bc01-4bdf7d0252a1, raftlog=d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null
datanode_6_1  | 2020-04-20 12:11:37,401 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1         | 2020-04-20 12:11:31,443 [IPC Server handler 6 on 9861] INFO ipc.Server: IPC Server handler 6 on 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.7:37680
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1_1  | 2020-04-20 12:13:19,353 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30: change Leader from null to 5add3564-1298-4085-832c-a1039ab03f55 at term 1 for appendEntries, leader elected after 4872ms
datanode_2_1  | 2020-04-20 12:11:43,870 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-18D4649732CD with new leaderId: d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 2020-04-20 12:11:43,672 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: shutdown LeaderElection
scm_1         | 2020-04-20 12:11:31,443 [IPC Server handler 3 on 9861] INFO ipc.Server: IPC Server handler 3 on 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.5:44174
datanode_6_1  | 2020-04-20 12:11:37,402 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 2020-04-20 12:13:19,375 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30: set configuration 0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null at 0
datanode_2_1  | 2020-04-20 12:11:43,871 [grpc-default-executor-0] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD: change Leader from null to d427b6db-e08f-47dc-bc01-4bdf7d0252a1 at term 1 for appendEntries, leader elected after 4094ms
datanode_4_1  | 2020-04-20 12:11:43,673 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm_1         | 2020-04-20 12:11:31,482 [main] INFO http.HttpServer2: Jetty bound to port 9876
datanode_6_1  | 2020-04-20 12:11:37,405 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-930049E84D30 not found.
datanode_1_1  | 2020-04-20 12:13:19,375 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-04-20 12:11:43,899 [grpc-default-executor-0] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD: set configuration 0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null at 0
datanode_4_1  | 2020-04-20 12:11:43,674 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-18D4649732CD with new leaderId: d427b6db-e08f-47dc-bc01-4bdf7d0252a1
scm_1         | 2020-04-20 12:11:31,483 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_6_1  | 2020-04-20 12:11:37,406 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_5_1  | 	... 4 more
datanode_5_1  | 2020-04-20 12:14:33,062 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: remove group-930049E84D30:null
datanode_2_1  | 2020-04-20 12:11:43,899 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-04-20 12:11:37,410 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-04-20 12:13:19,377 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2b915d42-0547-44e8-966f-930049e84d30/current/log_inprogress_0
datanode_5_1  | 2020-04-20 12:14:33,063 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
scm_1         | 2020-04-20 12:11:31,581 [IPC Server handler 2 on 9861] WARN ipc.Server: IPC Server handler 2 on 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.4:37944: output error
datanode_2_1  | 2020-04-20 12:11:43,901 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/9539b8c0-47a1-400b-b528-18d4649732cd/current/log_inprogress_0
scm_1         | 2020-04-20 12:11:31,585 [IPC Server handler 6 on 9861] WARN ipc.Server: IPC Server handler 6 on 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.9:47348: output error
datanode_4_1  | 2020-04-20 12:11:43,674 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD: change Leader from null to d427b6db-e08f-47dc-bc01-4bdf7d0252a1 at term 1 for becomeLeader, leader elected after 5404ms
datanode_5_1  | 
datanode_6_1  | 2020-04-20 12:11:37,420 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-04-20 12:11:53,069 [ChunkWriter-57-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: ef3c38dac717a737:e6f4147bbe8a7bfc:ef3c38dac717a737:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1_1  | 2020-04-20 12:13:24,316 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Completed APPEND_ENTRIES, lastRequest: d427b6db-e08f-47dc-bc01-4bdf7d0252a1->ea211d94-4213-43ea-b4d3-a3779a4d37c1#6-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-96D75E88687B, cid=6
scm_1         | 2020-04-20 12:11:31,588 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_4_1  | 2020-04-20 12:11:43,691 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | java.io.IOException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-930049E84D30 not found.
datanode_6_1  | 2020-04-20 12:11:37,420 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_1_1  | 2020-04-20 12:13:24,345 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove  FOLLOWER ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD:t1, leader=d427b6db-e08f-47dc-bc01-4bdf7d0252a1, voted=d427b6db-e08f-47dc-bc01-4bdf7d0252a1, raftlog=ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null RUNNING
scm_1         | 2020-04-20 12:11:31,595 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_4_1  | 2020-04-20 12:11:43,691 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_6_1  | 2020-04-20 12:11:37,421 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_1_1  | 2020-04-20 12:13:24,346 [Command processor thread] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD: shutdown
scm_1         | 2020-04-20 12:11:31,596 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_4_1  | 2020-04-20 12:11:43,692 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_6_1  | 2020-04-20 12:11:37,421 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_1_1  | 2020-04-20 12:13:24,346 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-18D4649732CD,id=ea211d94-4213-43ea-b4d3-a3779a4d37c1
scm_1         | 2020-04-20 12:11:31,604 [IPC Server handler 6 on 9861] INFO ipc.Server: IPC Server handler 6 on 9861 caught an exception
datanode_4_1  | 2020-04-20 12:11:43,692 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_6_1  | 2020-04-20 12:11:37,422 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F
datanode_2_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_1_1  | 2020-04-20 12:13:24,347 [Command processor thread] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: shutdown FollowerState
scm_1         | java.nio.channels.AsynchronousCloseException
datanode_4_1  | 2020-04-20 12:11:43,692 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_6_1  | 2020-04-20 12:11:37,425 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F
datanode_2_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_1_1  | 2020-04-20 12:13:24,347 [Thread-31] INFO impl.FollowerState: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_4_1  | 2020-04-20 12:11:43,693 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_6_1  | 2020-04-20 12:11:37,426 [pool-69-thread-1] INFO impl.RaftServerImpl: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F: start as a follower, conf=-1: [bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_1_1  | 2020-04-20 12:13:24,347 [Command processor thread] INFO impl.StateMachineUpdater: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-StateMachineUpdater: set stopIndex = 0
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:11:43,693 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_6_1  | 2020-04-20 12:11:37,426 [pool-69-thread-1] INFO impl.RaftServerImpl: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1_1  | 2020-04-20 12:13:24,347 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-18D4649732CD as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_5_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-930049E84D30 not found.
datanode_4_1  | 2020-04-20 12:11:43,693 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_6_1  | 2020-04-20 12:11:37,426 [pool-69-thread-1] INFO impl.RoleInfo: bc8a7b14-3ca0-481c-865e-e266d4d1f071: start FollowerState
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1_1  | 2020-04-20 12:13:24,356 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-StateMachineUpdater] ERROR impl.StateMachineUpdater: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-StateMachineUpdater: Failed to take snapshot
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 2020-04-20 12:11:43,704 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_6_1  | 2020-04-20 12:11:37,437 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-92ED6CA41C2F,id=bc8a7b14-3ca0-481c-865e-e266d4d1f071
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-18D4649732CD as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 2020-04-20 12:11:43,704 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-04-20 12:11:37,437 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 2020-04-20 12:11:43,705 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_4_1  | 2020-04-20 12:11:43,732 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_4_1  | 2020-04-20 12:11:43,737 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 2020-04-20 12:11:39,025 [grpc-default-executor-0] WARN impl.RaftServerProxy: bc8a7b14-3ca0-481c-865e-e266d4d1f071: Failed groupAdd* GroupManagementRequest:client-18877F0952F1->bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F, cid=0, seq=0, RW, null, Add:group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858]
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_4_1  | 2020-04-20 12:11:43,737 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: bc8a7b14-3ca0-481c-865e-e266d4d1f071: Failed to add group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_6_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_4_1  | 2020-04-20 12:11:43,761 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_6_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_5_1  | 	... 4 more
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:11:43,762 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_5_1  | 2020-04-20 12:14:33,068 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: remove group-930049E84D30:null
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
datanode_2_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=0 B) is less than the container size (=1073741824 B).
datanode_1_1  | 2020-04-20 12:13:24,357 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-18D4649732CD as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_4_1  | 2020-04-20 12:11:43,763 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_6_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_5_1  | 2020-04-20 12:14:33,072 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_1_1  | 2020-04-20 12:13:24,357 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-StateMachineUpdater] ERROR impl.StateMachineUpdater: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-StateMachineUpdater: Failed to take snapshot
datanode_4_1  | 2020-04-20 12:11:43,767 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_6_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_5_1  | 
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_1_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-18D4649732CD as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_4_1  | 2020-04-20 12:11:43,767 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_5_1  | java.io.IOException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-930049E84D30 not found.
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_2_1  | 	... 13 more
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_4_1  | 2020-04-20 12:11:43,767 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_2_1  | 2020-04-20 12:11:53,070 [ChunkWriter-57-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: ef3c38dac717a737:e6f4147bbe8a7bfc:ef3c38dac717a737:0 , Message: ContainerID 2 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_4_1  | 2020-04-20 12:11:43,770 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: start LeaderState
datanode_6_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_6_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
datanode_2_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 creation failed
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_4_1  | 2020-04-20 12:11:43,788 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1         | 2020-04-20 12:11:31,604 [IPC Server handler 2 on 9861] INFO ipc.Server: IPC Server handler 2 on 9861 caught an exception
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_4_1  | 2020-04-20 12:11:43,799 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-LeaderElection2] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD: set configuration 0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null at 0
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1         | java.nio.channels.AsynchronousCloseException
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 2020-04-20 12:13:24,357 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD
datanode_4_1  | 2020-04-20 12:11:43,868 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/9539b8c0-47a1-400b-b528-18d4649732cd/current/log_inprogress_0
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1_1  | 2020-04-20 12:13:24,358 [Command processor thread] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD: closes. applyIndex: 0
datanode_4_1  | 2020-04-20 12:11:43,884 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-7357CCDD9E8D-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/40b4e453-ccc6-4ee4-8e46-7357ccdd9e8d/current/log_inprogress_0
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_4_1  | 2020-04-20 12:11:53,032 [ChunkWriter-19-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: ef3c38dac717a737:e6f4147bbe8a7bfc:ef3c38dac717a737:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
datanode_5_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-930049E84D30 not found.
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_4_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_1_1  | 2020-04-20 12:13:24,359 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_1_1  | 2020-04-20 12:13:24,365 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD-SegmentedRaftLogWorker close()
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
datanode_2_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_1_1  | 2020-04-20 12:13:24,366 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 	... 4 more
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_1_1  | 2020-04-20 12:13:24,367 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD
datanode_6_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: bc8a7b14-3ca0-481c-865e-e266d4d1f071: Failed to add group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 2020-04-20 12:14:33,073 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: remove group-930049E84D30:null
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_1_1  | 2020-04-20 12:13:24,367 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-18D4649732CD
datanode_6_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-04-20 12:14:33,073 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_1_1  | 2020-04-20 12:13:24,369 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_6_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_2_1  | 2020-04-20 12:11:53,080 [ChunkWriter-57-0] ERROR ratis.ContainerStateMachine: group-18D4649732CD: writeChunk writeStateMachineData failed: blockIdcontainerID: 2
datanode_5_1  | 
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1_1  |  command on datanode #ea211d94-4213-43ea-b4d3-a3779a4d37c1.
datanode_2_1  | localID: 104030844530458625
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_5_1  | java.io.IOException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-930049E84D30 not found.
datanode_1_1  | 2020-04-20 12:13:24,370 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-18D4649732CD:null
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_2_1  | blockCommitSequenceId: 0
datanode_2_1  |  logIndex 1 chunkName 104030844530458625_chunk_1 Error message: ContainerID 2 creation failed Container Result: DISK_OUT_OF_SPACE
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1         | 2020-04-20 12:11:31,651 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68dcfd52{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_6_1  | 	... 13 more
scm_1         | 2020-04-20 12:11:31,652 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3162743f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1_1  | 2020-04-20 12:13:24,371 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2_1  | 2020-04-20 12:11:53,103 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd.Reason : ContainerID 2 creation failed
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_6_1  | 2020-04-20 12:11:39,695 [grpc-default-executor-0] WARN impl.RaftServerProxy: bc8a7b14-3ca0-481c-865e-e266d4d1f071: Failed groupAdd* GroupManagementRequest:client-8E9BAA384293->bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F, cid=1, seq=0, RW, null, Add:group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858]
scm_1         | 2020-04-20 12:11:32,577 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5a6fa56e{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-4064044019275635958.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
datanode_1_1  | 
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2_1  | 2020-04-20 12:11:53,198 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-96D75E88687B, cid=5
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: bc8a7b14-3ca0-481c-865e-e266d4d1f071: Failed to add group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
scm_1         | 2020-04-20 12:11:32,610 [main] INFO server.AbstractConnector: Started ServerConnector@26d820eb{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-18D4649732CD not found.
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2_1  | 	 State Machine: cmdType: WriteChunk traceID: "ef3c38dac717a737:e6f4147bbe8a7bfc:ef3c38dac717a737:0" containerID: 2 datanodeUuid: "ea211d94-4213-43ea-b4d3-a3779a4d37c1" pipelineID: "9539b8c0-47a1-400b-b528-18d4649732cd" writeChunk { blockID { containerID: 2 localID: 104030844530458625 blockCommitSequenceId: 0 } chunkData { chunkName: "104030844530458625_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
scm_1         | 2020-04-20 12:11:32,610 [main] INFO server.Server: Started @12401ms
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2_1  | 2020-04-20 12:12:10,778 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #2 does not exist in datanode. Container close failed.
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
scm_1         | 2020-04-20 12:11:32,619 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | 2020-04-20 12:13:24,188 [Command processor thread] INFO impl.RaftServerProxy: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: remove  FOLLOWER 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD:t1, leader=d427b6db-e08f-47dc-bc01-4bdf7d0252a1, voted=d427b6db-e08f-47dc-bc01-4bdf7d0252a1, raftlog=8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null RUNNING
datanode_4_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=966385664 B) is less than the container size (=1073741824 B).
datanode_6_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
scm_1         | 2020-04-20 12:11:32,619 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_5_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-930049E84D30 not found.
datanode_2_1  | 2020-04-20 12:13:24,190 [Command processor thread] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD: shutdown
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_6_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
scm_1         | 2020-04-20 12:11:32,625 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2_1  | 2020-04-20 12:13:24,190 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-18D4649732CD,id=8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_6_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	... 13 more
datanode_6_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
scm_1         | 2020-04-20 12:11:32,646 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7fb29ca9] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-18D4649732CD not found.
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2_1  | 2020-04-20 12:13:24,190 [Command processor thread] INFO impl.RoleInfo: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: shutdown FollowerState
datanode_4_1  | 2020-04-20 12:11:53,177 [ChunkWriter-19-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: ef3c38dac717a737:e6f4147bbe8a7bfc:ef3c38dac717a737:0 , Message: ContainerID 2 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_4_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 2 creation failed
scm_1         | 2020-04-20 12:11:32,868 [IPC Server handler 8 on 9861] INFO net.NetworkTopology: Added a new node: /rack1/68b8b2ca-801b-4940-8ace-0c902746c4e8
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_5_1  | 	... 4 more
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_6_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_6_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
scm_1         | 2020-04-20 12:11:32,877 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=66927c5b-4a56-4d19-93cb-4dc0b3e02a28 to datanode:68b8b2ca-801b-4940-8ace-0c902746c4e8
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_5_1  | 2020-04-20 12:14:33,074 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: remove group-930049E84D30:null
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_6_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2_1  | 2020-04-20 12:13:24,190 [Thread-38] INFO impl.FollowerState: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
scm_1         | 2020-04-20 12:11:32,868 [IPC Server handler 8 on 9861] INFO node.SCMNodeManager: Registered Data node : 68b8b2ca-801b-4940-8ace-0c902746c4e8{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_5_1  | 2020-04-20 12:14:33,074 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_2_1  | 2020-04-20 12:13:24,191 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-18D4649732CD as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
scm_1         | 2020-04-20 12:11:32,959 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 66927c5b-4a56-4d19-93cb-4dc0b3e02a28, Nodes: 68b8b2ca-801b-4940-8ace-0c902746c4e8{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:11:32.876503Z]
datanode_6_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_5_1  | 
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_2_1  | 2020-04-20 12:13:24,191 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-StateMachineUpdater] ERROR impl.StateMachineUpdater: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-StateMachineUpdater: Failed to take snapshot
scm_1         | 2020-04-20 12:11:32,973 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_5_1  | java.io.IOException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-930049E84D30 not found.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_2_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-18D4649732CD as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
scm_1         | 2020-04-20 12:11:32,978 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 1 nodes. Healthy nodes 1
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1_1  | 	... 4 more
scm_1         | 2020-04-20 12:11:32,983 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 4 required.
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
scm_1         | 2020-04-20 12:11:33,341 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fc95027a-d6cc-40a8-b22f-ca703b34e48b to datanode:8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_1_1  | 2020-04-20 12:13:24,371 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-18D4649732CD:null
datanode_1_1  | 2020-04-20 12:13:24,371 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_2_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1_1  | 
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1         | 2020-04-20 12:11:33,342 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: fc95027a-d6cc-40a8-b22f-ca703b34e48b, Nodes: 8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:11:33.341450Z]
datanode_2_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1         | 2020-04-20 12:11:33,342 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
datanode_2_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-18D4649732CD not found.
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1         | 2020-04-20 12:11:33,333 [IPC Server handler 11 on 9861] INFO net.NetworkTopology: Added a new node: /rack1/8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: bc8a7b14-3ca0-481c-865e-e266d4d1f071: Failed to add group-92ED6CA41C2F:[bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858] since the group already exists in the map.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-04-20 12:11:33,343 [IPC Server handler 11 on 9861] INFO node.SCMNodeManager: Registered Data node : 8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
datanode_2_1  | 2020-04-20 12:13:24,191 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-18D4649732CD as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_5_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-930049E84D30 not found.
datanode_6_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_4_1  | 2020-04-20 12:11:53,205 [ChunkWriter-19-0] ERROR ratis.ContainerStateMachine: group-18D4649732CD: writeChunk writeStateMachineData failed: blockIdcontainerID: 2
scm_1         | 2020-04-20 12:11:33,343 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2_1  | 2020-04-20 12:13:24,191 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-StateMachineUpdater] ERROR impl.StateMachineUpdater: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-StateMachineUpdater: Failed to take snapshot
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_6_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_4_1  | localID: 104030844530458625
scm_1         | 2020-04-20 12:11:33,349 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 4 required.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-18D4649732CD as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_6_1  | 	... 13 more
datanode_4_1  | blockCommitSequenceId: 0
scm_1         | 2020-04-20 12:11:33,382 [IPC Server handler 40 on 9861] INFO net.NetworkTopology: Added a new node: /rack2/bc8a7b14-3ca0-481c-865e-e266d4d1f071
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_6_1  | 2020-04-20 12:11:40,140 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "daa4732c-5873-4db2-844f-92ed6ca41c2f"
datanode_4_1  |  logIndex 1 chunkName 104030844530458625_chunk_1 Error message: ContainerID 2 creation failed Container Result: DISK_OUT_OF_SPACE
scm_1         | 2020-04-20 12:11:33,382 [IPC Server handler 40 on 9861] INFO node.SCMNodeManager: Registered Data node : bc8a7b14-3ca0-481c-865e-e266d4d1f071{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_6_1  | .
datanode_6_1  | 2020-04-20 12:11:41,613 [grpc-default-executor-0] INFO impl.RaftServerImpl: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:68b8b2ca-801b-4940-8ace-0c902746c4e8
scm_1         | 2020-04-20 12:11:33,383 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-18D4649732CD not found.
datanode_2_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_5_1  | 	... 4 more
datanode_6_1  | 2020-04-20 12:11:41,614 [grpc-default-executor-0] INFO impl.RoleInfo: bc8a7b14-3ca0-481c-865e-e266d4d1f071: shutdown FollowerState
datanode_4_1  | 2020-04-20 12:11:53,215 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd.Reason : ContainerID 2 creation failed
scm_1         | 2020-04-20 12:11:33,383 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 4 required.
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_5_1  | 2020-04-20 12:14:34,224 [ChunkWriter-39-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: f032c0d5b23e9d0d:24456efda0b889d1:f032c0d5b23e9d0d:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_4_1  | 2020-04-20 12:11:53,301 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-96D75E88687B, cid=5
scm_1         | 2020-04-20 12:11:33,383 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7c7ec9f4-3899-4fe8-a512-a45ef9c37ab5 to datanode:bc8a7b14-3ca0-481c-865e-e266d4d1f071
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-04-20 12:11:41,615 [Thread-26] INFO impl.FollowerState: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_5_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_4_1  | 	 State Machine: cmdType: WriteChunk traceID: "ef3c38dac717a737:e6f4147bbe8a7bfc:ef3c38dac717a737:0" containerID: 2 datanodeUuid: "ea211d94-4213-43ea-b4d3-a3779a4d37c1" pipelineID: "9539b8c0-47a1-400b-b528-18d4649732cd" writeChunk { blockID { containerID: 2 localID: 104030844530458625 blockCommitSequenceId: 0 } chunkData { chunkName: "104030844530458625_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
scm_1         | 2020-04-20 12:11:33,384 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 7c7ec9f4-3899-4fe8-a512-a45ef9c37ab5, Nodes: bc8a7b14-3ca0-481c-865e-e266d4d1f071{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:11:33.383606Z]
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2_1  | 2020-04-20 12:13:24,191 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD
datanode_6_1  | 2020-04-20 12:11:41,615 [grpc-default-executor-0] INFO impl.RoleInfo: bc8a7b14-3ca0-481c-865e-e266d4d1f071: start FollowerState
datanode_5_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_4_1  | 2020-04-20 12:12:09,263 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #2 does not exist in datanode. Container close failed.
scm_1         | 2020-04-20 12:11:33,385 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2_1  | 2020-04-20 12:13:24,192 [Command processor thread] INFO impl.StateMachineUpdater: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-StateMachineUpdater: set stopIndex = 0
datanode_6_1  | 2020-04-20 12:11:41,795 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-92ED6CA41C2F with new leaderId: 68b8b2ca-801b-4940-8ace-0c902746c4e8
datanode_5_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_4_1  | 2020-04-20 12:12:53,067 [java.util.concurrent.ThreadPoolExecutor$Worker@1365abe5[State = -1, empty queue]] WARN server.GrpcLogAppender: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD->8e63932d-e4c5-48a1-856f-f13c15c5f03b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5,entriesCount=1,lastEntry=(t:1, i:1)
scm_1         | 2020-04-20 12:11:33,974 [IPC Server handler 8 on 9861] INFO net.NetworkTopology: Added a new node: /rack2/5add3564-1298-4085-832c-a1039ab03f55
datanode_1_1  | 	... 4 more
datanode_2_1  | 2020-04-20 12:13:24,192 [Command processor thread] INFO impl.RaftServerImpl: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD: closes. applyIndex: 0
datanode_6_1  | 2020-04-20 12:11:41,796 [grpc-default-executor-0] INFO impl.RaftServerImpl: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F: change Leader from null to 68b8b2ca-801b-4940-8ace-0c902746c4e8 at term 1 for appendEntries, leader elected after 4405ms
datanode_5_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_4_1  | 2020-04-20 12:12:53,073 [java.util.concurrent.ThreadPoolExecutor$Worker@1365abe5[State = -1, empty queue]] WARN server.GrpcLogAppender: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD->ea211d94-4213-43ea-b4d3-a3779a4d37c1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5,entriesCount=1,lastEntry=(t:1, i:1)
scm_1         | 2020-04-20 12:11:33,974 [IPC Server handler 8 on 9861] INFO node.SCMNodeManager: Registered Data node : 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
datanode_1_1  | 2020-04-20 12:13:24,381 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-18D4649732CD:null
datanode_2_1  | 2020-04-20 12:13:24,193 [8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_6_1  | 2020-04-20 12:11:41,838 [grpc-default-executor-0] INFO impl.RaftServerImpl: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F: set configuration 0: [bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858, 68b8b2ca-801b-4940-8ace-0c902746c4e8:10.5.0.6:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null at 0
datanode_5_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_4_1  | 2020-04-20 12:12:53,093 [java.util.concurrent.ThreadPoolExecutor$Worker@1365abe5[State = -1, empty queue]] WARN server.GrpcLogAppender: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD->ea211d94-4213-43ea-b4d3-a3779a4d37c1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6,entriesCount=1,lastEntry=(t:1, i:2)
scm_1         | 2020-04-20 12:11:33,974 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
datanode_1_1  | 2020-04-20 12:13:24,381 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_1_1  | 
datanode_6_1  | 2020-04-20 12:11:41,849 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_4_1  | 2020-04-20 12:12:53,094 [java.util.concurrent.ThreadPoolExecutor$Worker@1365abe5[State = -1, empty queue]] WARN server.GrpcLogAppender: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD->8e63932d-e4c5-48a1-856f-f13c15c5f03b-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6,entriesCount=1,lastEntry=(t:1, i:2)
scm_1         | 2020-04-20 12:11:33,974 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 4 required.
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-18D4649732CD not found.
datanode_2_1  | 2020-04-20 12:13:24,194 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD-SegmentedRaftLogWorker close()
datanode_6_1  | 2020-04-20 12:11:41,979 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-92ED6CA41C2F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/daa4732c-5873-4db2-844f-92ed6ca41c2f/current/log_inprogress_0
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_4_1  | 2020-04-20 12:13:14,394 [grpc-default-executor-1] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: addNew group-930049E84D30:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] returns group-930049E84D30:java.util.concurrent.CompletableFuture@346007b3[Not completed]
scm_1         | 2020-04-20 12:11:33,974 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a5263645-01c1-4afe-a7b2-a9fac20c5754 to datanode:5add3564-1298-4085-832c-a1039ab03f55
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2_1  | 2020-04-20 12:13:24,194 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_6_1  | 2020-04-20 12:11:42,292 [Thread-24] INFO impl.FollowerState: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-FollowerState: change to CANDIDATE, lastRpcTime:5153ms, electionTimeout:5151ms
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_4_1  | 2020-04-20 12:13:14,396 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: new RaftServerImpl for group-930049E84D30:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] with ContainerStateMachine:uninitialized
scm_1         | 2020-04-20 12:11:33,975 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2_1  | 2020-04-20 12:13:24,194 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD
datanode_6_1  | 2020-04-20 12:11:42,293 [Thread-24] INFO impl.RoleInfo: bc8a7b14-3ca0-481c-865e-e266d4d1f071: shutdown FollowerState
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_4_1  | 2020-04-20 12:13:14,396 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
scm_1         | 2020-04-20 12:11:33,976 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2_1  | 2020-04-20 12:13:24,194 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.8e63932d-e4c5-48a1-856f-f13c15c5f03b@group-18D4649732CD
datanode_6_1  | 2020-04-20 12:11:42,293 [Thread-24] INFO impl.RaftServerImpl: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_4_1  | 2020-04-20 12:13:14,396 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1         | 2020-04-20 12:11:33,977 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: a5263645-01c1-4afe-a7b2-a9fac20c5754, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:11:33.974884Z]
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2_1  | 2020-04-20 12:13:24,197 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_6_1  | 2020-04-20 12:11:42,296 [Thread-24] INFO impl.RoleInfo: bc8a7b14-3ca0-481c-865e-e266d4d1f071: start LeaderElection
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_4_1  | 2020-04-20 12:13:14,397 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
scm_1         | 2020-04-20 12:11:33,977 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 4 nodes. Healthy nodes 4
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  |  command on datanode #8e63932d-e4c5-48a1-856f-f13c15c5f03b.
datanode_6_1  | 2020-04-20 12:11:42,301 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO impl.LeaderElection: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1: begin an election at term 1 for -1: [bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858], old=null
datanode_5_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_4_1  | 2020-04-20 12:13:14,397 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
scm_1         | 2020-04-20 12:11:33,978 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 4 nodes. Healthy nodes 4
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-18D4649732CD not found.
datanode_2_1  | 2020-04-20 12:13:24,197 [Command processor thread] INFO impl.RaftServerProxy: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: remove group-18D4649732CD:null
datanode_6_1  | 2020-04-20 12:11:42,302 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO impl.RoleInfo: bc8a7b14-3ca0-481c-865e-e266d4d1f071: shutdown LeaderElection
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 2020-04-20 12:13:14,397 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1         | 2020-04-20 12:11:33,984 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=daa4732c-5873-4db2-844f-92ed6ca41c2f to datanode:68b8b2ca-801b-4940-8ace-0c902746c4e8
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2_1  | 2020-04-20 12:13:24,197 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_6_1  | 2020-04-20 12:11:42,303 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO impl.RaftServerImpl: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 2020-04-20 12:13:14,397 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30: ConfigurationManager, init=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
scm_1         | 2020-04-20 12:11:33,985 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=daa4732c-5873-4db2-844f-92ed6ca41c2f to datanode:bc8a7b14-3ca0-481c-865e-e266d4d1f071
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2_1  | 
datanode_6_1  | 2020-04-20 12:11:42,303 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A45EF9C37AB5 with new leaderId: bc8a7b14-3ca0-481c-865e-e266d4d1f071
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:13:14,397 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1         | 2020-04-20 12:11:33,985 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=daa4732c-5873-4db2-844f-92ed6ca41c2f to datanode:8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2_1  | java.io.IOException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Group group-18D4649732CD not found.
datanode_6_1  | 2020-04-20 12:11:42,303 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO impl.RaftServerImpl: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5: change Leader from null to bc8a7b14-3ca0-481c-865e-e266d4d1f071 at term 1 for becomeLeader, leader elected after 5613ms
datanode_4_1  | 2020-04-20 12:13:14,398 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1         | 2020-04-20 12:11:33,986 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: daa4732c-5873-4db2-844f-92ed6ca41c2f, Nodes: 68b8b2ca-801b-4940-8ace-0c902746c4e8{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}bc8a7b14-3ca0-481c-865e-e266d4d1f071{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:11:33.984447Z]
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_5_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=965783552 B) is less than the container size (=1073741824 B).
datanode_6_1  | 2020-04-20 12:11:42,310 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1         | 2020-04-20 12:11:33,987 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 1
datanode_4_1  | 2020-04-20 12:13:14,398 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2b915d42-0547-44e8-966f-930049e84d30 does not exist. Creating ...
datanode_1_1  | 	... 4 more
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_6_1  | 2020-04-20 12:11:42,311 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1         | 2020-04-20 12:11:34,233 [IPC Server handler 11 on 9861] INFO net.NetworkTopology: Added a new node: /rack2/d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 2020-04-20 12:13:14,399 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2b915d42-0547-44e8-966f-930049e84d30/in_use.lock acquired by nodename 6@0e128a59471e
datanode_1_1  | 2020-04-20 12:13:24,382 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-18D4649732CD:null
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_6_1  | 2020-04-20 12:11:42,313 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5
scm_1         | 2020-04-20 12:11:34,234 [IPC Server handler 11 on 9861] INFO node.SCMNodeManager: Registered Data node : d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
datanode_4_1  | 2020-04-20 12:13:14,400 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2b915d42-0547-44e8-966f-930049e84d30 has been successfully formatted.
datanode_1_1  | 2020-04-20 12:13:24,382 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_6_1  | 2020-04-20 12:11:42,321 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4_1  | 2020-04-20 12:13:14,401 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-930049E84D30: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-04-20 12:11:34,235 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
datanode_5_1  | 	... 13 more
datanode_6_1  | 2020-04-20 12:11:42,321 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_4_1  | 2020-04-20 12:13:14,402 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-18D4649732CD not found.
datanode_2_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Group group-18D4649732CD not found.
scm_1         | 2020-04-20 12:11:34,235 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
datanode_6_1  | 2020-04-20 12:11:42,330 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4_1  | 2020-04-20 12:13:14,402 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-04-20 12:14:34,238 [ChunkWriter-39-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: f032c0d5b23e9d0d:24456efda0b889d1:f032c0d5b23e9d0d:0 , Message: ContainerID 4 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1         | 2020-04-20 12:11:34,236 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=40b4e453-ccc6-4ee4-8e46-7357ccdd9e8d to datanode:d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_6_1  | 2020-04-20 12:11:42,330 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_6_1  | 2020-04-20 12:11:42,331 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4_1  | 2020-04-20 12:13:14,402 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 4 creation failed
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_6_1  | 2020-04-20 12:11:42,340 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO impl.RoleInfo: bc8a7b14-3ca0-481c-865e-e266d4d1f071: start LeaderState
scm_1         | 2020-04-20 12:11:34,237 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 40b4e453-ccc6-4ee4-8e46-7357ccdd9e8d, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:11:34.236579Z]
datanode_4_1  | 2020-04-20 12:13:14,402 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_6_1  | 2020-04-20 12:11:42,343 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-SegmentedRaftLogWorker: Starting segment from index:0
scm_1         | 2020-04-20 12:11:34,239 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 5 nodes. Healthy nodes 5
datanode_4_1  | 2020-04-20 12:13:14,403 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1         | 2020-04-20 12:11:34,246 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 2
datanode_6_1  | 2020-04-20 12:11:42,345 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7c7ec9f4-3899-4fe8-a512-a45ef9c37ab5/current/log_inprogress_0
datanode_4_1  | 2020-04-20 12:13:14,403 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | 	... 4 more
scm_1         | 2020-04-20 12:11:34,379 [IPC Server handler 40 on 9861] INFO net.NetworkTopology: Added a new node: /rack1/ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_6_1  | 2020-04-20 12:11:42,356 [bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5-LeaderElection1] INFO impl.RaftServerImpl: bc8a7b14-3ca0-481c-865e-e266d4d1f071@group-A45EF9C37AB5: set configuration 0: [bc8a7b14-3ca0-481c-865e-e266d4d1f071:10.5.0.9:9858], old=null at 0
datanode_4_1  | 2020-04-20 12:13:14,403 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2b915d42-0547-44e8-966f-930049e84d30
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-18D4649732CD not found.
datanode_2_1  | 2020-04-20 12:13:24,206 [Command processor thread] INFO impl.RaftServerProxy: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: remove group-18D4649732CD:null
scm_1         | 2020-04-20 12:11:34,379 [IPC Server handler 40 on 9861] INFO node.SCMNodeManager: Registered Data node : ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
datanode_4_1  | 2020-04-20 12:13:14,403 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-04-20 12:13:14,403 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2_1  | 2020-04-20 12:13:24,206 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
scm_1         | 2020-04-20 12:11:34,379 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=0053d728-2466-4118-a0e3-923df4260d46 to datanode:ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_4_1  | 2020-04-20 12:13:14,403 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2_1  | 
scm_1         | 2020-04-20 12:11:34,380 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 0053d728-2466-4118-a0e3-923df4260d46, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:11:34.379734Z]
datanode_4_1  | 2020-04-20 12:13:14,404 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2_1  | java.io.IOException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Group group-18D4649732CD not found.
scm_1         | 2020-04-20 12:11:34,381 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
datanode_4_1  | 2020-04-20 12:13:14,404 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1         | 2020-04-20 12:11:34,380 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
datanode_4_1  | 2020-04-20 12:13:14,404 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 	... 4 more
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1         | 2020-04-20 12:11:34,381 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
datanode_4_1  | 2020-04-20 12:13:14,404 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-04-20 12:14:34,239 [ChunkWriter-39-0] ERROR ratis.ContainerStateMachine: group-12B961FFD63F: writeChunk writeStateMachineData failed: blockIdcontainerID: 4
datanode_1_1  | 2020-04-20 12:13:24,382 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-18D4649732CD:null
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1         | 2020-04-20 12:11:34,382 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd to datanode:ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_4_1  | 2020-04-20 12:13:14,404 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | localID: 104030855114194950
datanode_1_1  | 2020-04-20 12:13:24,382 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1         | 2020-04-20 12:11:34,382 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd to datanode:d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 2020-04-20 12:13:14,404 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | blockCommitSequenceId: 0
datanode_1_1  | 
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-04-20 12:11:34,382 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd to datanode:8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_4_1  | 2020-04-20 12:13:14,405 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  |  logIndex 1 chunkName 104030855114194950_chunk_1 Error message: ContainerID 4 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-18D4649732CD not found.
datanode_2_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Group group-18D4649732CD not found.
scm_1         | 2020-04-20 12:11:34,383 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 9539b8c0-47a1-400b-b528-18d4649732cd, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:11:34.382338Z]
datanode_4_1  | 2020-04-20 12:13:14,405 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-04-20 12:14:34,239 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f.Reason : ContainerID 4 creation failed
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1         | 2020-04-20 12:11:34,383 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 1
datanode_4_1  | 2020-04-20 12:13:14,417 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-04-20 12:14:34,240 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-184A811F9848, cid=22
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1         | 2020-04-20 12:11:36,172 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 66927c5b-4a56-4d19-93cb-4dc0b3e02a28, Nodes: 68b8b2ca-801b-4940-8ace-0c902746c4e8{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:68b8b2ca-801b-4940-8ace-0c902746c4e8, CreationTimestamp2020-04-20T12:11:32.876503Z] moved to OPEN state
datanode_4_1  | 2020-04-20 12:13:14,417 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 	 State Machine: cmdType: WriteChunk traceID: "f032c0d5b23e9d0d:24456efda0b889d1:f032c0d5b23e9d0d:0" containerID: 4 datanodeUuid: "5add3564-1298-4085-832c-a1039ab03f55" pipelineID: "b2031e52-018e-41a3-b0d9-12b961ffd63f" writeChunk { blockID { containerID: 4 localID: 104030855114194950 blockCommitSequenceId: 0 } chunkData { chunkName: "104030855114194950_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1         | 2020-04-20 12:11:36,182 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_4_1  | 2020-04-20 12:13:14,417 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-04-20 12:14:38,011 [grpc-default-executor-0] INFO impl.FollowerInfo: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30->ea211d94-4213-43ea-b4d3-a3779a4d37c1: nextIndex: updateUnconditionally 3 -> 1
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1         | 2020-04-20 12:11:36,201 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
datanode_4_1  | 2020-04-20 12:13:14,417 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-04-20 12:14:38,013 [grpc-default-executor-1] INFO impl.FollowerInfo: 5add3564-1298-4085-832c-a1039ab03f55@group-930049E84D30->d427b6db-e08f-47dc-bc01-4bdf7d0252a1: nextIndex: updateUnconditionally 3 -> 1
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | 	... 4 more
scm_1         | 2020-04-20 12:11:36,982 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: fc95027a-d6cc-40a8-b22f-ca703b34e48b, Nodes: 8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:8e63932d-e4c5-48a1-856f-f13c15c5f03b, CreationTimestamp2020-04-20T12:11:33.341450Z] moved to OPEN state
datanode_4_1  | 2020-04-20 12:13:14,417 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30
datanode_5_1  | 2020-04-20 12:14:40,582 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: 5add3564-1298-4085-832c-a1039ab03f55: Failed requestVote d427b6db-e08f-47dc-bc01-4bdf7d0252a1->5add3564-1298-4085-832c-a1039ab03f55#0
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-18D4649732CD not found.
scm_1         | 2020-04-20 12:11:36,982 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_2_1  | 2020-04-20 12:13:24,209 [Command processor thread] INFO impl.RaftServerProxy: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: remove group-18D4649732CD:null
datanode_4_1  | 2020-04-20 12:13:14,417 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30
datanode_5_1  | org.apache.ratis.protocol.GroupMismatchException: 5add3564-1298-4085-832c-a1039ab03f55: group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1         | 2020-04-20 12:11:36,982 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-04-20 12:11:37,089 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 7c7ec9f4-3899-4fe8-a512-a45ef9c37ab5, Nodes: bc8a7b14-3ca0-481c-865e-e266d4d1f071{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:bc8a7b14-3ca0-481c-865e-e266d4d1f071, CreationTimestamp2020-04-20T12:11:33.383606Z] moved to OPEN state
datanode_4_1  | 2020-04-20 12:13:14,418 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30: start as a follower, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:122)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1         | 2020-04-20 12:11:37,090 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_2_1  | 2020-04-20 12:13:24,209 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_4_1  | 2020-04-20 12:13:14,418 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:269)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1         | 2020-04-20 12:11:37,090 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
datanode_2_1  | 
datanode_4_1  | 2020-04-20 12:13:14,418 [pool-69-thread-1] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: start FollowerState
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:278)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1         | 2020-04-20 12:11:37,992 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: a5263645-01c1-4afe-a7b2-a9fac20c5754, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:11:33.974884Z] moved to OPEN state
datanode_2_1  | java.io.IOException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Group group-18D4649732CD not found.
datanode_4_1  | 2020-04-20 12:13:14,418 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-930049E84D30,id=d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:273)
datanode_1_1  | 	... 4 more
scm_1         | 2020-04-20 12:11:37,992 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 2020-04-20 12:13:14,418 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:445)
datanode_1_1  | 2020-04-20 12:13:25,805 [ChunkWriter-47-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: 30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
scm_1         | 2020-04-20 12:11:37,993 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 2020-04-20 12:13:19,282 [grpc-default-executor-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:5add3564-1298-4085-832c-a1039ab03f55
datanode_5_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:166)
datanode_1_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1         | 2020-04-20 12:11:38,147 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 40b4e453-ccc6-4ee4-8e46-7357ccdd9e8d, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:d427b6db-e08f-47dc-bc01-4bdf7d0252a1, CreationTimestamp2020-04-20T12:11:34.236579Z] moved to OPEN state
datanode_4_1  | 2020-04-20 12:13:19,282 [grpc-default-executor-1] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: shutdown FollowerState
datanode_5_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:316)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1         | 2020-04-20 12:11:38,154 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_4_1  | 2020-04-20 12:13:19,282 [grpc-default-executor-1] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: start FollowerState
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-04-20 12:11:38,154 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
datanode_4_1  | 2020-04-20 12:13:19,282 [Thread-44] INFO impl.FollowerState: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_2_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Group group-18D4649732CD not found.
scm_1         | 2020-04-20 12:11:38,401 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 0053d728-2466-4118-a0e3-923df4260d46, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:ea211d94-4213-43ea-b4d3-a3779a4d37c1, CreationTimestamp2020-04-20T12:11:34.379734Z] moved to OPEN state
datanode_4_1  | 2020-04-20 12:13:19,362 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-930049E84D30 with new leaderId: 5add3564-1298-4085-832c-a1039ab03f55
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1         | 2020-04-20 12:11:38,403 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_4_1  | 2020-04-20 12:13:19,362 [grpc-default-executor-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30: change Leader from null to 5add3564-1298-4085-832c-a1039ab03f55 at term 1 for appendEntries, leader elected after 4961ms
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1         | 2020-04-20 12:11:38,403 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
datanode_4_1  | 2020-04-20 12:13:19,385 [grpc-default-executor-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30: set configuration 0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null at 0
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1         | 2020-04-20 12:11:41,679 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: daa4732c-5873-4db2-844f-92ed6ca41c2f, Nodes: 68b8b2ca-801b-4940-8ace-0c902746c4e8{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}bc8a7b14-3ca0-481c-865e-e266d4d1f071{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:68b8b2ca-801b-4940-8ace-0c902746c4e8, CreationTimestamp2020-04-20T12:11:33.984447Z] moved to OPEN state
datanode_4_1  | 2020-04-20 12:13:19,385 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1         | 2020-04-20 12:11:41,680 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_4_1  | 2020-04-20 12:13:19,387 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2b915d42-0547-44e8-966f-930049e84d30/current/log_inprogress_0
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_2_1  | 	... 4 more
scm_1         | 2020-04-20 12:11:41,680 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
datanode_4_1  | 2020-04-20 12:13:24,302 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove    LEADER d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD:t1, leader=d427b6db-e08f-47dc-bc01-4bdf7d0252a1, voted=d427b6db-e08f-47dc-bc01-4bdf7d0252a1, raftlog=d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858, 8e63932d-e4c5-48a1-856f-f13c15c5f03b:10.5.0.5:9858], old=null RUNNING
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
scm_1         | 2020-04-20 12:11:41,681 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
datanode_5_1  | 2020-04-20 12:14:57,860 [grpc-default-executor-1] INFO server.GrpcServerProtocolService: 5add3564-1298-4085-832c-a1039ab03f55: Completed APPEND_ENTRIES, lastRequest: d427b6db-e08f-47dc-bc01-4bdf7d0252a1->5add3564-1298-4085-832c-a1039ab03f55#1-t2, previous=(t:1, i:2), leaderCommit=0, initializing? false, entries: size=1, first=(t:2, i:3), CONFIGURATIONENTRY
datanode_4_1  | 2020-04-20 12:13:24,309 [Command processor thread] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD: shutdown
datanode_2_1  | 2020-04-20 12:13:24,210 [Command processor thread] INFO impl.RaftServerProxy: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: remove group-18D4649732CD:null
scm_1         | 2020-04-20 12:11:41,681 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_5_1  | 2020-04-20 12:15:03,001 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: remove group-930049E84D30:null
datanode_4_1  | 2020-04-20 12:13:24,310 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-18D4649732CD,id=d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_2_1  | 2020-04-20 12:13:24,210 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
scm_1         | 2020-04-20 12:11:41,682 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 2020-04-20 12:15:03,001 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_4_1  | 2020-04-20 12:13:24,311 [Command processor thread] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: shutdown LeaderState
datanode_2_1  | 
scm_1         | 2020-04-20 12:11:43,683 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 9539b8c0-47a1-400b-b528-18d4649732cd, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:d427b6db-e08f-47dc-bc01-4bdf7d0252a1, CreationTimestamp2020-04-20T12:11:34.382338Z] moved to OPEN state
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 
datanode_4_1  | 2020-04-20 12:13:24,312 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$443/0x0000000840592040@6575dd10] WARN server.GrpcLogAppender: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD->ea211d94-4213-43ea-b4d3-a3779a4d37c1-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_2_1  | java.io.IOException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Group group-18D4649732CD not found.
scm_1         | 2020-04-20 12:11:53,133 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd from datanode 8e63932d-e4c5-48a1-856f-f13c15c5f03b. Reason : ContainerID 2 creation failed
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | java.io.IOException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-930049E84D30 not found.
datanode_4_1  | 2020-04-20 12:13:24,313 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$443/0x0000000840592040@4248e5f] WARN server.GrpcLogAppender: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD->8e63932d-e4c5-48a1-856f-f13c15c5f03b-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1         | 2020-04-20 12:11:53,134 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 9539b8c0-47a1-400b-b528-18d4649732cd, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:d427b6db-e08f-47dc-bc01-4bdf7d0252a1, CreationTimestamp2020-04-20T12:11:34.382338Z]
datanode_1_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=966070272 B) is less than the container size (=1073741824 B).
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 2020-04-20 12:13:24,313 [Command processor thread] INFO impl.PendingRequests: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-PendingRequests: sendNotLeaderResponses
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1         | 2020-04-20 12:11:53,134 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 9539b8c0-47a1-400b-b528-18d4649732cd, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:d427b6db-e08f-47dc-bc01-4bdf7d0252a1, CreationTimestamp2020-04-20T12:11:34.382338Z] moved to CLOSED state
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 2020-04-20 12:13:24,319 [grpc-default-executor-2] INFO server.GrpcLogAppender: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD->8e63932d-e4c5-48a1-856f-f13c15c5f03b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1         | 2020-04-20 12:11:53,135 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 2020-04-20 12:13:24,319 [grpc-default-executor-1] INFO server.GrpcLogAppender: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD->ea211d94-4213-43ea-b4d3-a3779a4d37c1-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1         | 2020-04-20 12:11:53,191 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd from datanode 8e63932d-e4c5-48a1-856f-f13c15c5f03b. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-96D75E88687B, cid=5
datanode_1_1  | 	... 13 more
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 2020-04-20 12:13:24,324 [grpc-default-executor-1] INFO impl.FollowerInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD->ea211d94-4213-43ea-b4d3-a3779a4d37c1: nextIndex: updateUnconditionally 3 -> 1
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "ef3c38dac717a737:e6f4147bbe8a7bfc:ef3c38dac717a737:0" containerID: 2 datanodeUuid: "ea211d94-4213-43ea-b4d3-a3779a4d37c1" pipelineID: "9539b8c0-47a1-400b-b528-18d4649732cd" writeChunk { blockID { containerID: 2 localID: 104030844530458625 blockCommitSequenceId: 0 } chunkData { chunkName: "104030844530458625_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_1_1  | 2020-04-20 12:13:25,806 [ChunkWriter-47-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: 30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0 , Message: ContainerID 3 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:13:24,324 [grpc-default-executor-2] INFO impl.FollowerInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD->8e63932d-e4c5-48a1-856f-f13c15c5f03b: nextIndex: updateUnconditionally 3 -> 1
scm_1         | 2020-04-20 12:11:53,193 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 9539b8c0-47a1-400b-b528-18d4649732cd, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:d427b6db-e08f-47dc-bc01-4bdf7d0252a1, CreationTimestamp2020-04-20T12:11:34.382338Z]
datanode_1_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 3 creation failed
datanode_5_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-930049E84D30 not found.
datanode_2_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Group group-18D4649732CD not found.
datanode_4_1  | 2020-04-20 12:13:24,334 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
scm_1         | 2020-04-20 12:11:53,219 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd from datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1. Reason : ContainerID 2 creation failed
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 2020-04-20 12:13:24,334 [Command processor thread] INFO impl.StateMachineUpdater: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-StateMachineUpdater: set stopIndex = 0
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
scm_1         | 2020-04-20 12:11:53,220 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 9539b8c0-47a1-400b-b528-18d4649732cd, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:d427b6db-e08f-47dc-bc01-4bdf7d0252a1, CreationTimestamp2020-04-20T12:11:34.382338Z]
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 2020-04-20 12:13:24,337 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-18D4649732CD as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
scm_1         | 2020-04-20 12:11:53,271 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd from datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1. Reason : ContainerID 2 creation failed
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 2020-04-20 12:13:24,337 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-StateMachineUpdater] ERROR impl.StateMachineUpdater: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-StateMachineUpdater: Failed to take snapshot
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
scm_1         | 2020-04-20 12:11:53,271 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 9539b8c0-47a1-400b-b528-18d4649732cd, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:d427b6db-e08f-47dc-bc01-4bdf7d0252a1, CreationTimestamp2020-04-20T12:11:34.382338Z]
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-18D4649732CD as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
scm_1         | 2020-04-20 12:11:53,303 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd from datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-96D75E88687B, cid=5
datanode_5_1  | 	... 4 more
datanode_2_1  | 	... 4 more
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "ef3c38dac717a737:e6f4147bbe8a7bfc:ef3c38dac717a737:0" containerID: 2 datanodeUuid: "ea211d94-4213-43ea-b4d3-a3779a4d37c1" pipelineID: "9539b8c0-47a1-400b-b528-18d4649732cd" writeChunk { blockID { containerID: 2 localID: 104030844530458625 blockCommitSequenceId: 0 } chunkData { chunkName: "104030844530458625_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_5_1  | 2020-04-20 12:15:03,002 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #4 does not exist in datanode. Container close failed.
datanode_2_1  | 2020-04-20 12:13:24,210 [Command processor thread] INFO impl.RaftServerProxy: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: remove group-18D4649732CD:null
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1         | 2020-04-20 12:11:53,304 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 9539b8c0-47a1-400b-b528-18d4649732cd, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:d427b6db-e08f-47dc-bc01-4bdf7d0252a1, CreationTimestamp2020-04-20T12:11:34.382338Z]
datanode_5_1  | 2020-04-20 12:15:34,225 [java.util.concurrent.ThreadPoolExecutor$Worker@54d3c1e1[State = -1, empty queue]] WARN server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F->ea211d94-4213-43ea-b4d3-a3779a4d37c1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=14,entriesCount=1,lastEntry=(t:1, i:1)
datanode_2_1  | 2020-04-20 12:13:24,211 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:13:24,340 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-18D4649732CD as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 2020-04-20 12:13:24,341 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-StateMachineUpdater] ERROR impl.StateMachineUpdater: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-StateMachineUpdater: Failed to take snapshot
datanode_2_1  | 
scm_1         | 2020-04-20 12:11:53,347 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd from datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-96D75E88687B, cid=5
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-18D4649732CD as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_5_1  | 2020-04-20 12:15:34,225 [java.util.concurrent.ThreadPoolExecutor$Worker@54d3c1e1[State = -1, empty queue]] WARN server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F->d427b6db-e08f-47dc-bc01-4bdf7d0252a1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=14,entriesCount=1,lastEntry=(t:1, i:1)
datanode_2_1  | java.io.IOException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Group group-18D4649732CD not found.
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "ef3c38dac717a737:e6f4147bbe8a7bfc:ef3c38dac717a737:0" containerID: 2 datanodeUuid: "ea211d94-4213-43ea-b4d3-a3779a4d37c1" pipelineID: "9539b8c0-47a1-400b-b528-18d4649732cd" writeChunk { blockID { containerID: 2 localID: 104030844530458625 blockCommitSequenceId: 0 } chunkData { chunkName: "104030844530458625_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_1_1  | 2020-04-20 12:13:25,807 [ChunkWriter-47-0] ERROR ratis.ContainerStateMachine: group-930049E84D30: writeChunk writeStateMachineData failed: blockIdcontainerID: 3
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_5_1  | 2020-04-20 12:15:34,234 [java.util.concurrent.ThreadPoolExecutor$Worker@54d3c1e1[State = -1, empty queue]] WARN server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F->d427b6db-e08f-47dc-bc01-4bdf7d0252a1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=15,entriesCount=1,lastEntry=(t:1, i:2)
scm_1         | 2020-04-20 12:11:53,347 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 9539b8c0-47a1-400b-b528-18d4649732cd, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:d427b6db-e08f-47dc-bc01-4bdf7d0252a1, CreationTimestamp2020-04-20T12:11:34.382338Z]
datanode_1_1  | localID: 104030850618556420
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_5_1  | 2020-04-20 12:15:34,234 [java.util.concurrent.ThreadPoolExecutor$Worker@54d3c1e1[State = -1, empty queue]] WARN server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F->ea211d94-4213-43ea-b4d3-a3779a4d37c1-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=15,entriesCount=1,lastEntry=(t:1, i:2)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | blockCommitSequenceId: 0
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1         | 2020-04-20 12:12:59,139 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_5_1  | 2020-04-20 12:15:35,241 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: addNew group-522AC6C9A985:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] returns group-522AC6C9A985:java.util.concurrent.CompletableFuture@4e4bd6a[Not completed]
datanode_1_1  |  logIndex 1 chunkName 104030850618556420_chunk_1 Error message: ContainerID 3 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1         | 2020-04-20 12:12:59,140 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_5_1  | 2020-04-20 12:15:35,243 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55: new RaftServerImpl for group-522AC6C9A985:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-04-20 12:13:25,807 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=2b915d42-0547-44e8-966f-930049e84d30.Reason : ContainerID 3 creation failed
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1         | 2020-04-20 12:12:59,140 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode 8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-04-20 12:15:35,243 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-04-20 12:13:25,832 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=2b915d42-0547-44e8-966f-930049e84d30.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=15
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-04-20 12:12:59,140 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 9539b8c0-47a1-400b-b528-18d4649732cd, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:d427b6db-e08f-47dc-bc01-4bdf7d0252a1, CreationTimestamp2020-04-20T12:11:34.382338Z] removed from db
datanode_4_1  | 2020-04-20 12:13:24,342 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD
datanode_5_1  | 2020-04-20 12:15:35,243 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 	 State Machine: cmdType: WriteChunk traceID: "30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0" containerID: 3 datanodeUuid: "d427b6db-e08f-47dc-bc01-4bdf7d0252a1" pipelineID: "2b915d42-0547-44e8-966f-930049e84d30" writeChunk { blockID { containerID: 3 localID: 104030850618556420 blockCommitSequenceId: 0 } chunkData { chunkName: "104030850618556420_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_2_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Group group-18D4649732CD not found.
scm_1         | 2020-04-20 12:12:59,141 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
datanode_4_1  | 2020-04-20 12:13:24,342 [Command processor thread] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD: closes. applyIndex: 0
datanode_5_1  | 2020-04-20 12:15:35,243 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-04-20 12:13:45,481 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-18D4649732CD:null
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1         | 2020-04-20 12:12:59,141 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 to datanode:d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 2020-04-20 12:13:24,347 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_5_1  | 2020-04-20 12:15:35,243 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-04-20 12:13:45,481 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1         | 2020-04-20 12:12:59,141 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 to datanode:ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_4_1  | 2020-04-20 12:13:24,349 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD-SegmentedRaftLogWorker close()
datanode_5_1  | 2020-04-20 12:15:35,243 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 
datanode_2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1         | 2020-04-20 12:12:59,142 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 to datanode:5add3564-1298-4085-832c-a1039ab03f55
datanode_4_1  | 2020-04-20 12:13:24,349 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_5_1  | 2020-04-20 12:15:35,243 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985: ConfigurationManager, init=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-18D4649732CD not found.
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 2020-04-20 12:13:24,349 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD
scm_1         | 2020-04-20 12:12:59,142 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 2b915d42-0547-44e8-966f-930049e84d30, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:12:59.141880Z]
datanode_5_1  | 2020-04-20 12:15:35,243 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_2_1  | 	... 4 more
datanode_4_1  | 2020-04-20 12:13:24,350 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-18D4649732CD
scm_1         | 2020-04-20 12:12:59,142 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
datanode_5_1  | 2020-04-20 12:15:35,244 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_2_1  | 2020-04-20 12:13:24,316 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 8e63932d-e4c5-48a1-856f-f13c15c5f03b: Completed APPEND_ENTRIES, lastRequest: d427b6db-e08f-47dc-bc01-4bdf7d0252a1->8e63932d-e4c5-48a1-856f-f13c15c5f03b#6-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-96D75E88687B, cid=6
datanode_4_1  | 2020-04-20 12:13:24,352 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
scm_1         | 2020-04-20 12:12:59,194 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_5_1  | 2020-04-20 12:15:35,244 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/17ae8adc-4d8e-4ba0-b62e-522ac6c9a985 does not exist. Creating ...
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  |  command on datanode #d427b6db-e08f-47dc-bc01-4bdf7d0252a1.
scm_1         | 2020-04-20 12:12:59,194 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_5_1  | 2020-04-20 12:15:35,245 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/17ae8adc-4d8e-4ba0-b62e-522ac6c9a985/in_use.lock acquired by nodename 6@7a52a65e9249
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 2020-04-20 12:13:24,353 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-18D4649732CD:null
scm_1         | 2020-04-20 12:12:59,194 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode 8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_5_1  | 2020-04-20 12:15:35,247 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/17ae8adc-4d8e-4ba0-b62e-522ac6c9a985 has been successfully formatted.
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:13:24,353 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
scm_1         | 2020-04-20 12:12:59,194 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 9539b8c0-47a1-400b-b528-18d4649732cd, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:d427b6db-e08f-47dc-bc01-4bdf7d0252a1, CreationTimestamp2020-04-20T12:11:34.382338Z]
datanode_5_1  | 2020-04-20 12:15:35,247 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-522AC6C9A985: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-18D4649732CD not found.
datanode_4_1  | 
scm_1         | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd not found
datanode_5_1  | 2020-04-20 12:15:35,247 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-18D4649732CD not found.
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_5_1  | 2020-04-20 12:15:35,247 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_5_1  | 2020-04-20 12:15:35,247 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_5_1  | 2020-04-20 12:15:35,248 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_5_1  | 2020-04-20 12:15:35,248 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 	... 4 more
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_5_1  | 2020-04-20 12:15:35,248 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.5add3564-1298-4085-832c-a1039ab03f55
datanode_1_1  | 2020-04-20 12:13:45,481 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #3 does not exist in datanode. Container close failed.
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1         | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_1_1  | 2020-04-20 12:13:56,833 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: addNew group-12B961FFD63F:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] returns group-12B961FFD63F:java.util.concurrent.CompletableFuture@76cae788[Not completed]
scm_1         | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5_1  | 2020-04-20 12:15:35,248 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-18D4649732CD not found.
datanode_1_1  | 2020-04-20 12:13:56,835 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1: new RaftServerImpl for group-12B961FFD63F:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] with ContainerStateMachine:uninitialized
scm_1         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 2020-04-20 12:15:35,248 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/17ae8adc-4d8e-4ba0-b62e-522ac6c9a985
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 2020-04-20 12:13:56,835 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
scm_1         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_5_1  | 2020-04-20 12:15:35,248 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1_1  | 2020-04-20 12:13:56,835 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 2020-04-20 12:15:35,248 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1_1  | 2020-04-20 12:13:56,835 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 2020-04-20 12:15:35,248 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | 2020-04-20 12:13:56,835 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
scm_1         | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 	... 4 more
scm_1         | 2020-04-20 12:12:59,221 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_5_1  | 2020-04-20 12:15:35,248 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-04-20 12:13:56,835 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-04-20 12:13:24,354 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-18D4649732CD:null
scm_1         | 2020-04-20 12:12:59,222 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_5_1  | 2020-04-20 12:15:35,248 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-04-20 12:13:56,836 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F: ConfigurationManager, init=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
scm_1         | 2020-04-20 12:12:59,222 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode 8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_5_1  | 2020-04-20 12:15:35,248 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-04-20 12:13:24,354 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_1_1  | 2020-04-20 12:13:56,836 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-04-20 12:15:35,248 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-04-20 12:13:56,836 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1         | 2020-04-20 12:12:59,222 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 9539b8c0-47a1-400b-b528-18d4649732cd, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:d427b6db-e08f-47dc-bc01-4bdf7d0252a1, CreationTimestamp2020-04-20T12:11:34.382338Z]
datanode_4_1  | 
datanode_5_1  | 2020-04-20 12:15:35,248 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-04-20 12:13:56,836 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b2031e52-018e-41a3-b0d9-12b961ffd63f does not exist. Creating ...
scm_1         | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd not found
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-18D4649732CD not found.
datanode_5_1  | 2020-04-20 12:15:35,248 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_1_1  | 2020-04-20 12:13:56,838 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b2031e52-018e-41a3-b0d9-12b961ffd63f/in_use.lock acquired by nodename 6@52fe7c485517
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_5_1  | 2020-04-20 12:15:35,250 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_1_1  | 2020-04-20 12:13:56,839 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b2031e52-018e-41a3-b0d9-12b961ffd63f has been successfully formatted.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_5_1  | 2020-04-20 12:15:35,250 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_1_1  | 2020-04-20 12:13:56,840 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-12B961FFD63F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_5_1  | 2020-04-20 12:15:35,251 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_1_1  | 2020-04-20 12:13:56,840 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_5_1  | 2020-04-20 12:15:35,251 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_1_1  | 2020-04-20 12:13:56,840 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-04-20 12:15:35,251 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1         | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_1_1  | 2020-04-20 12:13:56,840 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-18D4649732CD not found.
datanode_5_1  | 2020-04-20 12:15:35,251 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
scm_1         | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1_1  | 2020-04-20 12:13:56,840 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-04-20 12:13:56,840 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-04-20 12:15:35,251 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985
scm_1         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1_1  | 2020-04-20 12:13:56,840 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_5_1  | 2020-04-20 12:15:35,252 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985
scm_1         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_1_1  | 2020-04-20 12:13:56,840 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_5_1  | 2020-04-20 12:15:35,252 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985: start as a follower, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | 2020-04-20 12:13:56,840 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/b2031e52-018e-41a3-b0d9-12b961ffd63f
datanode_5_1  | 2020-04-20 12:15:35,252 [pool-69-thread-1] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1         | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-04-20 12:12:59,272 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_1_1  | 2020-04-20 12:13:56,840 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-04-20 12:15:35,252 [pool-69-thread-1] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: start FollowerState
scm_1         | 2020-04-20 12:12:59,272 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 	... 4 more
datanode_1_1  | 2020-04-20 12:13:56,840 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-04-20 12:15:35,255 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-522AC6C9A985,id=5add3564-1298-4085-832c-a1039ab03f55
scm_1         | 2020-04-20 12:12:59,272 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode 8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_4_1  | 2020-04-20 12:13:24,355 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-18D4649732CD:null
datanode_1_1  | 2020-04-20 12:13:56,840 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-04-20 12:15:35,255 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985
datanode_4_1  | 2020-04-20 12:13:24,355 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_1_1  | 2020-04-20 12:13:56,840 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm_1         | 2020-04-20 12:12:59,272 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 9539b8c0-47a1-400b-b528-18d4649732cd, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:d427b6db-e08f-47dc-bc01-4bdf7d0252a1, CreationTimestamp2020-04-20T12:11:34.382338Z]
datanode_5_1  | 2020-04-20 12:15:35,324 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "17ae8adc-4d8e-4ba0-b62e-522ac6c9a985"
datanode_4_1  | 
datanode_1_1  | 2020-04-20 12:13:56,840 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
scm_1         | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd not found
datanode_5_1  | .
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-18D4649732CD not found.
datanode_1_1  | 2020-04-20 12:13:56,841 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_5_1  | 2020-04-20 12:15:40,298 [Thread-61] INFO impl.FollowerState: 5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-FollowerState: change to CANDIDATE, lastRpcTime:5045ms, electionTimeout:5042ms
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | 2020-04-20 12:13:56,841 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_5_1  | 2020-04-20 12:15:40,298 [Thread-61] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: shutdown FollowerState
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1_1  | 2020-04-20 12:13:56,841 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_5_1  | 2020-04-20 12:15:40,299 [Thread-61] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 2020-04-20 12:13:56,841 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_5_1  | 2020-04-20 12:15:40,299 [Thread-61] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: start LeaderElection
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1_1  | 2020-04-20 12:13:56,851 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_5_1  | 2020-04-20 12:15:40,303 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO impl.LeaderElection: 5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4: begin an election at term 1 for -1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-18D4649732CD not found.
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_5_1  | 2020-04-20 12:15:40,328 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO impl.LeaderElection: 5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4: Election PASSED; received 1 response(s) [5add3564-1298-4085-832c-a1039ab03f55<-ea211d94-4213-43ea-b4d3-a3779a4d37c1#0:OK-t1] and 0 exception(s); 5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985:t1, leader=null, voted=5add3564-1298-4085-832c-a1039ab03f55, raftlog=5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 2020-04-20 12:13:56,852 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1         | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_5_1  | 2020-04-20 12:15:40,329 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: shutdown LeaderElection
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1_1  | 2020-04-20 12:13:56,852 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1         | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5_1  | 2020-04-20 12:15:40,329 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | 2020-04-20 12:13:56,852 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
scm_1         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 2020-04-20 12:15:40,329 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-522AC6C9A985 with new leaderId: 5add3564-1298-4085-832c-a1039ab03f55
datanode_4_1  | 	... 4 more
datanode_1_1  | 2020-04-20 12:13:56,852 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_5_1  | 2020-04-20 12:15:40,333 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985: change Leader from null to 5add3564-1298-4085-832c-a1039ab03f55 at term 1 for becomeLeader, leader elected after 5082ms
datanode_4_1  | 2020-04-20 12:13:24,355 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-18D4649732CD:null
datanode_1_1  | 2020-04-20 12:13:56,852 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 2020-04-20 12:15:40,333 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4_1  | 2020-04-20 12:13:24,355 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_1_1  | 2020-04-20 12:13:56,852 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 2020-04-20 12:15:40,333 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4_1  | 
datanode_1_1  | 2020-04-20 12:13:56,853 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F
scm_1         | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-04-20 12:15:40,336 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-18D4649732CD not found.
datanode_1_1  | 2020-04-20 12:13:56,853 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F: start as a follower, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
scm_1         | 2020-04-20 12:12:59,304 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
scm_1         | 2020-04-20 12:12:59,305 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | 2020-04-20 12:13:56,853 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1         | 2020-04-20 12:12:59,305 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode 8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_5_1  | 2020-04-20 12:15:40,336 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1_1  | 2020-04-20 12:13:56,853 [pool-69-thread-1] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: start FollowerState
scm_1         | 2020-04-20 12:12:59,305 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 9539b8c0-47a1-400b-b528-18d4649732cd, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:d427b6db-e08f-47dc-bc01-4bdf7d0252a1, CreationTimestamp2020-04-20T12:11:34.382338Z]
datanode_5_1  | 2020-04-20 12:15:40,336 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 2020-04-20 12:13:56,855 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-12B961FFD63F,id=ea211d94-4213-43ea-b4d3-a3779a4d37c1
scm_1         | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd not found
datanode_5_1  | 2020-04-20 12:15:40,336 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_5_1  | 2020-04-20 12:15:40,337 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-18D4649732CD not found.
datanode_1_1  | 2020-04-20 12:13:56,855 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_5_1  | 2020-04-20 12:15:40,337 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 2020-04-20 12:13:56,934 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_5_1  | 2020-04-20 12:15:40,337 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1_1  | .
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_5_1  | 2020-04-20 12:15:40,337 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1_1  | 2020-04-20 12:13:56,959 [grpc-default-executor-0] WARN impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Failed groupAdd* GroupManagementRequest:client-9D2C5D4F6366->ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F, cid=3, seq=0, RW, null, Add:group-12B961FFD63F:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858]
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_5_1  | 2020-04-20 12:15:40,337 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Failed to add group-12B961FFD63F:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] since the group already exists in the map.
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_5_1  | 2020-04-20 12:15:40,337 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_4_1  | 	... 4 more
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
scm_1         | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_5_1  | 2020-04-20 12:15:40,337 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 2020-04-20 12:13:24,356 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-18D4649732CD:null
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
scm_1         | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5_1  | 2020-04-20 12:15:40,338 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-04-20 12:13:24,358 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
scm_1         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 2020-04-20 12:15:40,341 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_4_1  | 
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
scm_1         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_5_1  | 2020-04-20 12:15:40,341 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-18D4649732CD not found.
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 2020-04-20 12:15:40,341 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 2020-04-20 12:15:40,342 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
scm_1         | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-04-20 12:15:40,342 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
scm_1         | 2020-04-20 12:12:59,348 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_5_1  | 2020-04-20 12:15:40,342 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
scm_1         | 2020-04-20 12:12:59,348 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_5_1  | 2020-04-20 12:15:40,343 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: start LeaderState
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
scm_1         | 2020-04-20 12:12:59,348 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd close command to datanode 8e63932d-e4c5-48a1-856f-f13c15c5f03b
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-18D4649732CD not found.
datanode_5_1  | 2020-04-20 12:15:40,344 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
scm_1         | 2020-04-20 12:12:59,348 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 9539b8c0-47a1-400b-b528-18d4649732cd, Nodes: ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}8e63932d-e4c5-48a1-856f-f13c15c5f03b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:d427b6db-e08f-47dc-bc01-4bdf7d0252a1, CreationTimestamp2020-04-20T12:11:34.382338Z]
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_5_1  | 2020-04-20 12:15:40,345 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/17ae8adc-4d8e-4ba0-b62e-522ac6c9a985/current/log_inprogress_0
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
scm_1         | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=9539b8c0-47a1-400b-b528-18d4649732cd not found
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_5_1  | 2020-04-20 12:15:40,347 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-LeaderElection4] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985: set configuration 0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null at 0
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_5_1  | 2020-04-20 12:16:06,247 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: remove    LEADER 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F:t1, leader=5add3564-1298-4085-832c-a1039ab03f55, voted=5add3564-1298-4085-832c-a1039ab03f55, raftlog=5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null RUNNING
datanode_5_1  | 2020-04-20 12:16:06,248 [Command processor thread] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F: shutdown
datanode_4_1  | 	... 4 more
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_5_1  | 2020-04-20 12:16:06,248 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-12B961FFD63F,id=5add3564-1298-4085-832c-a1039ab03f55
datanode_5_1  | 2020-04-20 12:16:06,248 [Command processor thread] INFO impl.RoleInfo: 5add3564-1298-4085-832c-a1039ab03f55: shutdown LeaderState
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_4_1  | 2020-04-20 12:13:25,803 [ChunkWriter-46-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: 30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_5_1  | 2020-04-20 12:16:06,248 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$458/0x000000084057c040@e6473da] WARN server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F->ea211d94-4213-43ea-b4d3-a3779a4d37c1-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_4_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_5_1  | 2020-04-20 12:16:06,248 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$458/0x000000084057c040@3fa0fedd] WARN server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F->d427b6db-e08f-47dc-bc01-4bdf7d0252a1-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_5_1  | 2020-04-20 12:16:06,252 [grpc-default-executor-0] INFO server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F->ea211d94-4213-43ea-b4d3-a3779a4d37c1-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_5_1  | 2020-04-20 12:16:06,252 [grpc-default-executor-1] INFO server.GrpcLogAppender: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F->d427b6db-e08f-47dc-bc01-4bdf7d0252a1-AppendLogResponseHandler: follower responses appendEntries COMPLETED
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_5_1  | 2020-04-20 12:16:06,253 [Command processor thread] INFO impl.PendingRequests: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-PendingRequests: sendNotLeaderResponses
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
scm_1         | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_5_1  | 2020-04-20 12:16:06,257 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
scm_1         | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5_1  | 2020-04-20 12:16:06,257 [Command processor thread] INFO impl.StateMachineUpdater: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-StateMachineUpdater: set stopIndex = 0
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
scm_1         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 2020-04-20 12:16:06,262 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-12B961FFD63F as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Failed to add group-12B961FFD63F:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] since the group already exists in the map.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
scm_1         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_5_1  | 2020-04-20 12:16:06,262 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-StateMachineUpdater] ERROR impl.StateMachineUpdater: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-StateMachineUpdater: Failed to take snapshot
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-12B961FFD63F as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1_1  | 	... 13 more
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
scm_1         | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1_1  | 2020-04-20 12:14:01,985 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:5add3564-1298-4085-832c-a1039ab03f55
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_5_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
scm_1         | 2020-04-20 12:13:19,315 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 2b915d42-0547-44e8-966f-930049e84d30, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:12:59.141880Z] moved to OPEN state
datanode_1_1  | 2020-04-20 12:14:01,985 [grpc-default-executor-0] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: shutdown FollowerState
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_5_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
scm_1         | 2020-04-20 12:13:25,818 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=2b915d42-0547-44e8-966f-930049e84d30 from datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1. Reason : ContainerID 3 creation failed
datanode_1_1  | 2020-04-20 12:14:01,985 [grpc-default-executor-0] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: start FollowerState
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-04-20 12:13:25,819 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 2b915d42-0547-44e8-966f-930049e84d30, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:12:59.141880Z]
datanode_1_1  | 2020-04-20 12:14:01,985 [Thread-105] INFO impl.FollowerState: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 2020-04-20 12:16:06,263 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-12B961FFD63F as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
scm_1         | 2020-04-20 12:13:25,820 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 2b915d42-0547-44e8-966f-930049e84d30, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:12:59.141880Z] moved to CLOSED state
datanode_1_1  | 2020-04-20 12:14:02,018 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-12B961FFD63F with new leaderId: 5add3564-1298-4085-832c-a1039ab03f55
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 2020-04-20 12:16:06,263 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-StateMachineUpdater] ERROR impl.StateMachineUpdater: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-StateMachineUpdater: Failed to take snapshot
scm_1         | 2020-04-20 12:13:25,820 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #3
datanode_1_1  | 2020-04-20 12:14:02,018 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F: change Leader from null to 5add3564-1298-4085-832c-a1039ab03f55 at term 1 for appendEntries, leader elected after 5178ms
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-12B961FFD63F as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
scm_1         | 2020-04-20 12:13:25,824 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=2b915d42-0547-44e8-966f-930049e84d30 from datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1. Reason : ContainerID 3 creation failed
datanode_1_1  | 2020-04-20 12:14:02,021 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F: set configuration 0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null at 0
datanode_4_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=966074368 B) is less than the container size (=1073741824 B).
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
scm_1         | 2020-04-20 12:13:25,825 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 2b915d42-0547-44e8-966f-930049e84d30, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:12:59.141880Z]
datanode_1_1  | 2020-04-20 12:14:02,021 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_5_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
scm_1         | 2020-04-20 12:13:25,835 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=2b915d42-0547-44e8-966f-930049e84d30 from datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=15
datanode_1_1  | 2020-04-20 12:14:02,023 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b2031e52-018e-41a3-b0d9-12b961ffd63f/current/log_inprogress_0
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_5_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0" containerID: 3 datanodeUuid: "d427b6db-e08f-47dc-bc01-4bdf7d0252a1" pipelineID: "2b915d42-0547-44e8-966f-930049e84d30" writeChunk { blockID { containerID: 3 localID: 104030850618556420 blockCommitSequenceId: 0 } chunkData { chunkName: "104030850618556420_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_1_1  | 2020-04-20 12:14:33,006 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Completed APPEND_ENTRIES, lastRequest: 5add3564-1298-4085-832c-a1039ab03f55->ea211d94-4213-43ea-b4d3-a3779a4d37c1#5-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=16
datanode_4_1  | 	... 13 more
datanode_5_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
scm_1         | 2020-04-20 12:13:25,835 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 2b915d42-0547-44e8-966f-930049e84d30, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:12:59.141880Z]
datanode_1_1  | 2020-04-20 12:14:34,267 [ChunkWriter-31-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: f032c0d5b23e9d0d:24456efda0b889d1:f032c0d5b23e9d0d:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_4_1  | 2020-04-20 12:13:25,805 [ChunkWriter-46-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: 30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0 , Message: ContainerID 3 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-04-20 12:13:25,852 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=2b915d42-0547-44e8-966f-930049e84d30 from datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=15
datanode_1_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_4_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 3 creation failed
datanode_5_1  | 2020-04-20 12:16:06,263 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0" containerID: 3 datanodeUuid: "d427b6db-e08f-47dc-bc01-4bdf7d0252a1" pipelineID: "2b915d42-0547-44e8-966f-930049e84d30" writeChunk { blockID { containerID: 3 localID: 104030850618556420 blockCommitSequenceId: 0 } chunkData { chunkName: "104030850618556420_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_5_1  | 2020-04-20 12:16:06,263 [Command processor thread] INFO impl.RaftServerImpl: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F: closes. applyIndex: 0
scm_1         | 2020-04-20 12:13:25,852 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 2b915d42-0547-44e8-966f-930049e84d30, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:12:59.141880Z]
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_5_1  | 2020-04-20 12:16:06,263 [5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
scm_1         | 2020-04-20 12:13:25,879 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=2b915d42-0547-44e8-966f-930049e84d30 from datanode 5add3564-1298-4085-832c-a1039ab03f55. Reason : ContainerID 3 creation failed
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_5_1  | 2020-04-20 12:16:06,264 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F-SegmentedRaftLogWorker close()
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
scm_1         | 2020-04-20 12:13:25,880 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 2b915d42-0547-44e8-966f-930049e84d30, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:12:59.141880Z]
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_5_1  | 2020-04-20 12:16:06,264 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.5add3564-1298-4085-832c-a1039ab03f55
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
scm_1         | 2020-04-20 12:13:25,916 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=2b915d42-0547-44e8-966f-930049e84d30 from datanode 5add3564-1298-4085-832c-a1039ab03f55. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=15
datanode_5_1  | 2020-04-20 12:16:06,264 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0" containerID: 3 datanodeUuid: "d427b6db-e08f-47dc-bc01-4bdf7d0252a1" pipelineID: "2b915d42-0547-44e8-966f-930049e84d30" writeChunk { blockID { containerID: 3 localID: 104030850618556420 blockCommitSequenceId: 0 } chunkData { chunkName: "104030850618556420_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_5_1  | 2020-04-20 12:16:06,264 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1         | 2020-04-20 12:13:25,916 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 2b915d42-0547-44e8-966f-930049e84d30, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:12:59.141880Z]
datanode_5_1  | 2020-04-20 12:16:06,265 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1         | 2020-04-20 12:13:29,543 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
datanode_5_1  |  command on datanode #5add3564-1298-4085-832c-a1039ab03f55.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-04-20 12:13:29,545 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f to datanode:5add3564-1298-4085-832c-a1039ab03f55
datanode_5_1  | 2020-04-20 12:16:06,265 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: remove group-12B961FFD63F:null
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
scm_1         | 2020-04-20 12:13:29,545 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f to datanode:ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_4_1  | 2020-04-20 12:13:25,808 [ChunkWriter-46-0] ERROR ratis.ContainerStateMachine: group-930049E84D30: writeChunk writeStateMachineData failed: blockIdcontainerID: 3
datanode_5_1  | 2020-04-20 12:16:06,265 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
scm_1         | 2020-04-20 12:13:29,545 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f to datanode:d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | localID: 104030850618556420
datanode_5_1  | 
scm_1         | 2020-04-20 12:13:29,546 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: b2031e52-018e-41a3-b0d9-12b961ffd63f, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:13:29.545124Z]
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | blockCommitSequenceId: 0
datanode_5_1  | java.io.IOException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-12B961FFD63F not found.
scm_1         | 2020-04-20 12:13:29,546 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=965783552 B) is less than the container size (=1073741824 B).
datanode_4_1  |  logIndex 1 chunkName 104030850618556420_chunk_1 Error message: ContainerID 3 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1         | 2020-04-20 12:14:02,004 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: b2031e52-018e-41a3-b0d9-12b961ffd63f, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:13:29.545124Z] moved to OPEN state
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_4_1  | 2020-04-20 12:13:25,809 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=2b915d42-0547-44e8-966f-930049e84d30.Reason : ContainerID 3 creation failed
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1         | 2020-04-20 12:14:31,823 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_4_1  | 2020-04-20 12:13:25,843 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=2b915d42-0547-44e8-966f-930049e84d30.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=15
datanode_4_1  | 	 State Machine: cmdType: WriteChunk traceID: "30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0" containerID: 3 datanodeUuid: "d427b6db-e08f-47dc-bc01-4bdf7d0252a1" pipelineID: "2b915d42-0547-44e8-966f-930049e84d30" writeChunk { blockID { containerID: 3 localID: 104030850618556420 blockCommitSequenceId: 0 } chunkData { chunkName: "104030850618556420_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1         | 2020-04-20 12:14:31,823 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_1_1  | 	... 13 more
datanode_4_1  | 2020-04-20 12:13:45,402 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-18D4649732CD:null
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1         | 2020-04-20 12:14:31,823 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode 5add3564-1298-4085-832c-a1039ab03f55
datanode_1_1  | 2020-04-20 12:14:34,271 [ChunkWriter-31-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: f032c0d5b23e9d0d:24456efda0b889d1:f032c0d5b23e9d0d:0 , Message: ContainerID 4 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_4_1  | 2020-04-20 12:13:45,402 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "9539b8c0-47a1-400b-b528-18d4649732cd"
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-04-20 12:14:31,823 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 2b915d42-0547-44e8-966f-930049e84d30, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:12:59.141880Z] removed from db
datanode_1_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 4 creation failed
datanode_4_1  | 
datanode_5_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-12B961FFD63F not found.
scm_1         | 2020-04-20 12:14:31,824 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-18D4649732CD not found.
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
scm_1         | 2020-04-20 12:14:31,824 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1         | 2020-04-20 12:14:31,826 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1         | 2020-04-20 12:14:31,826 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
scm_1         | 2020-04-20 12:14:31,826 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode 5add3564-1298-4085-832c-a1039ab03f55
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_5_1  | 	... 4 more
scm_1         | 2020-04-20 12:14:31,826 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 2b915d42-0547-44e8-966f-930049e84d30, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:12:59.141880Z]
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_5_1  | 2020-04-20 12:16:06,265 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: remove group-12B961FFD63F:null
scm_1         | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=2b915d42-0547-44e8-966f-930049e84d30 not found
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 2020-04-20 12:16:06,265 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-18D4649732CD not found.
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 
datanode_5_1  | java.io.IOException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1_1  | 2020-04-20 12:14:34,271 [ChunkWriter-31-0] ERROR ratis.ContainerStateMachine: group-12B961FFD63F: writeChunk writeStateMachineData failed: blockIdcontainerID: 4
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | localID: 104030855114194950
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 	... 4 more
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_1_1  | blockCommitSequenceId: 0
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 2020-04-20 12:13:45,402 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #3 does not exist in datanode. Container close failed.
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_1_1  |  logIndex 1 chunkName 104030855114194950_chunk_1 Error message: ContainerID 4 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:13:56,844 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: addNew group-12B961FFD63F:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] returns group-12B961FFD63F:java.util.concurrent.CompletableFuture@3767683e[Not completed]
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_5_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-12B961FFD63F not found.
datanode_1_1  | 2020-04-20 12:14:34,271 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f.Reason : ContainerID 4 creation failed
datanode_4_1  | 2020-04-20 12:13:56,846 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: new RaftServerImpl for group-12B961FFD63F:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] with ContainerStateMachine:uninitialized
scm_1         | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 2020-04-20 12:14:34,272 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-184A811F9848, cid=22
datanode_4_1  | 2020-04-20 12:13:56,848 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
scm_1         | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1_1  | 	 State Machine: cmdType: WriteChunk traceID: "f032c0d5b23e9d0d:24456efda0b889d1:f032c0d5b23e9d0d:0" containerID: 4 datanodeUuid: "5add3564-1298-4085-832c-a1039ab03f55" pipelineID: "b2031e52-018e-41a3-b0d9-12b961ffd63f" writeChunk { blockID { containerID: 4 localID: 104030855114194950 blockCommitSequenceId: 0 } chunkData { chunkName: "104030855114194950_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_4_1  | 2020-04-20 12:13:56,848 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1_1  | 2020-04-20 12:14:40,577 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30: change Leader from 5add3564-1298-4085-832c-a1039ab03f55 to null at term 2 for updateCurrentTerm
datanode_4_1  | 2020-04-20 12:13:56,848 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
scm_1         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | 2020-04-20 12:14:40,577 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:d427b6db-e08f-47dc-bc01-4bdf7d0252a1
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 2020-04-20 12:13:56,848 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 	... 4 more
datanode_1_1  | 2020-04-20 12:14:40,578 [grpc-default-executor-0] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: shutdown FollowerState
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 2020-04-20 12:13:56,848 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-04-20 12:16:06,266 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: remove group-12B961FFD63F:null
datanode_1_1  | 2020-04-20 12:14:40,578 [grpc-default-executor-0] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: start FollowerState
scm_1         | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:13:56,849 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F: ConfigurationManager, init=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-04-20 12:16:06,266 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_1_1  | 2020-04-20 12:14:40,578 [Thread-80] INFO impl.FollowerState: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
scm_1         | 2020-04-20 12:14:31,835 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 2020-04-20 12:13:56,849 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 
scm_1         | 2020-04-20 12:14:31,835 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_4_1  | 2020-04-20 12:13:56,849 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | java.io.IOException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-12B961FFD63F not found.
datanode_1_1  | 2020-04-20 12:14:40,616 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-930049E84D30 with new leaderId: d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_1_1  | 2020-04-20 12:14:40,616 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30: change Leader from null to d427b6db-e08f-47dc-bc01-4bdf7d0252a1 at term 2 for appendEntries, leader elected after 38ms
datanode_1_1  | 2020-04-20 12:14:40,620 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30: set configuration 3: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null at 3
datanode_1_1  | 2020-04-20 12:14:40,620 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-SegmentedRaftLogWorker: Rolling segment log-0_2 to index:2
datanode_1_1  | 2020-04-20 12:14:40,621 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=2b915d42-0547-44e8-966f-930049e84d30.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=15
datanode_1_1  | 	 State Machine: cmdType: WriteChunk traceID: "30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0" containerID: 3 datanodeUuid: "d427b6db-e08f-47dc-bc01-4bdf7d0252a1" pipelineID: "2b915d42-0547-44e8-966f-930049e84d30" writeChunk { blockID { containerID: 3 localID: 104030850618556420 blockCommitSequenceId: 0 } chunkData { chunkName: "104030850618556420_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_1_1  | 2020-04-20 12:14:40,623 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=2b915d42-0547-44e8-966f-930049e84d30.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=15
datanode_1_1  | 	 State Machine: cmdType: WriteChunk traceID: "30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0" containerID: 3 datanodeUuid: "d427b6db-e08f-47dc-bc01-4bdf7d0252a1" pipelineID: "2b915d42-0547-44e8-966f-930049e84d30" writeChunk { blockID { containerID: 3 localID: 104030850618556420 blockCommitSequenceId: 0 } chunkData { chunkName: "104030850618556420_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_1_1  | 2020-04-20 12:14:57,840 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove  FOLLOWER ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30:t2, leader=d427b6db-e08f-47dc-bc01-4bdf7d0252a1, voted=d427b6db-e08f-47dc-bc01-4bdf7d0252a1, raftlog=ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-SegmentedRaftLog:OPENED:c0,f0,i3, conf=3: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null RUNNING
datanode_1_1  | 2020-04-20 12:14:57,841 [Command processor thread] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30: shutdown
datanode_1_1  | 2020-04-20 12:14:57,841 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-930049E84D30,id=ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_1_1  | 2020-04-20 12:14:57,841 [Command processor thread] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: shutdown FollowerState
datanode_1_1  | 2020-04-20 12:14:57,841 [Command processor thread] INFO impl.StateMachineUpdater: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-StateMachineUpdater: set stopIndex = 0
scm_1         | 2020-04-20 12:14:31,835 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode 5add3564-1298-4085-832c-a1039ab03f55
scm_1         | 2020-04-20 12:14:31,835 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 2b915d42-0547-44e8-966f-930049e84d30, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:12:59.141880Z]
datanode_4_1  | 2020-04-20 12:13:56,849 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b2031e52-018e-41a3-b0d9-12b961ffd63f does not exist. Creating ...
datanode_4_1  | 2020-04-20 12:13:56,852 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b2031e52-018e-41a3-b0d9-12b961ffd63f/in_use.lock acquired by nodename 6@0e128a59471e
scm_1         | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=2b915d42-0547-44e8-966f-930049e84d30 not found
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | 2020-04-20 12:14:57,841 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-930049E84D30 as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_4_1  | 2020-04-20 12:13:56,855 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b2031e52-018e-41a3-b0d9-12b961ffd63f has been successfully formatted.
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1_1  | 2020-04-20 12:14:57,842 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-StateMachineUpdater] ERROR impl.StateMachineUpdater: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-StateMachineUpdater: Failed to take snapshot
datanode_4_1  | 2020-04-20 12:13:56,856 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-12B961FFD63F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-930049E84D30 as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_4_1  | 2020-04-20 12:13:56,856 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_4_1  | 2020-04-20 12:13:56,856 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_4_1  | 2020-04-20 12:13:56,856 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_5_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-12B961FFD63F not found.
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_4_1  | 2020-04-20 12:13:56,861 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_4_1  | 2020-04-20 12:13:56,861 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1         | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:13:56,861 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d427b6db-e08f-47dc-bc01-4bdf7d0252a1
scm_1         | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1_1  | 2020-04-20 12:14:57,841 [Thread-144] INFO impl.FollowerState: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1_1  | 2020-04-20 12:14:57,842 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-930049E84D30 as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_4_1  | 2020-04-20 12:13:56,861 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | 2020-04-20 12:14:57,842 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-StateMachineUpdater] ERROR impl.StateMachineUpdater: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-StateMachineUpdater: Failed to take snapshot
scm_1         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_5_1  | 	... 4 more
datanode_4_1  | 2020-04-20 12:13:56,861 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/b2031e52-018e-41a3-b0d9-12b961ffd63f
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-930049E84D30 as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_5_1  | 2020-04-20 12:16:06,266 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: remove group-12B961FFD63F:null
datanode_4_1  | 2020-04-20 12:13:56,861 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1         | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-04-20 12:16:06,267 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_4_1  | 2020-04-20 12:13:56,861 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
scm_1         | 2020-04-20 12:14:31,852 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_5_1  | 
datanode_4_1  | 2020-04-20 12:13:56,861 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1         | 2020-04-20 12:14:31,852 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_5_1  | java.io.IOException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-12B961FFD63F not found.
datanode_4_1  | 2020-04-20 12:13:56,862 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm_1         | 2020-04-20 12:14:31,853 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode 5add3564-1298-4085-832c-a1039ab03f55
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 2020-04-20 12:13:56,862 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
scm_1         | 2020-04-20 12:14:31,853 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 2b915d42-0547-44e8-966f-930049e84d30, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:12:59.141880Z]
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 2020-04-20 12:13:56,862 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1         | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=2b915d42-0547-44e8-966f-930049e84d30 not found
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 2020-04-20 12:13:56,862 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_1_1  | 2020-04-20 12:14:57,843 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 2020-04-20 12:13:56,862 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_1_1  | 2020-04-20 12:14:57,843 [Command processor thread] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30: closes. applyIndex: 0
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:13:56,862 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_1_1  | 2020-04-20 12:14:57,843 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_5_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-12B961FFD63F not found.
datanode_4_1  | 2020-04-20 12:13:56,863 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_1_1  | 2020-04-20 12:14:57,844 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30-SegmentedRaftLogWorker close()
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 2020-04-20 12:13:56,863 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_1_1  | 2020-04-20 12:14:57,845 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 2020-04-20 12:13:56,865 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_1_1  | 2020-04-20 12:14:57,845 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 2020-04-20 12:13:56,865 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
scm_1         | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_1_1  | 2020-04-20 12:14:57,845 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-930049E84D30
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 2020-04-20 12:13:56,865 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1         | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1_1  | 2020-04-20 12:14:57,846 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_5_1  | 	... 4 more
datanode_4_1  | 2020-04-20 12:13:56,865 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
scm_1         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1_1  |  command on datanode #ea211d94-4213-43ea-b4d3-a3779a4d37c1.
datanode_5_1  | 2020-04-20 12:16:06,267 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: remove group-12B961FFD63F:null
datanode_4_1  | 2020-04-20 12:13:56,866 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F
scm_1         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_1_1  | 2020-04-20 12:14:57,846 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-930049E84D30:null
datanode_5_1  | 2020-04-20 12:16:06,268 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_4_1  | 2020-04-20 12:13:56,866 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 2020-04-20 12:14:57,846 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_5_1  | 
datanode_4_1  | 2020-04-20 12:13:56,866 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F: start as a follower, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 
datanode_4_1  | 2020-04-20 12:13:56,866 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1         | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | java.io.IOException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-12B961FFD63F not found.
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | 	... 4 more
datanode_1_1  | 2020-04-20 12:14:57,846 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-930049E84D30:null
datanode_4_1  | 2020-04-20 12:13:56,867 [pool-69-thread-1] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: start FollowerState
datanode_4_1  | 2020-04-20 12:13:56,867 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-12B961FFD63F,id=d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 2020-04-20 12:13:56,868 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F
datanode_4_1  | 2020-04-20 12:13:56,918 [grpc-default-executor-2] WARN impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Failed groupAdd* GroupManagementRequest:client-3C34C8B63617->d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F, cid=3, seq=0, RW, null, Add:group-12B961FFD63F:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858]
datanode_4_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Failed to add group-12B961FFD63F:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] since the group already exists in the map.
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
scm_1         | 2020-04-20 12:14:31,880 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_1_1  | 2020-04-20 12:14:57,846 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
scm_1         | 2020-04-20 12:14:31,880 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_1_1  | 
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
scm_1         | 2020-04-20 12:14:31,880 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode 5add3564-1298-4085-832c-a1039ab03f55
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-930049E84D30 not found.
datanode_5_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-12B961FFD63F not found.
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1         | 2020-04-20 12:14:31,880 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 2b915d42-0547-44e8-966f-930049e84d30, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:12:59.141880Z]
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1         | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=2b915d42-0547-44e8-966f-930049e84d30 not found
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_4_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_4_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_4_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_5_1  | 	... 4 more
datanode_5_1  | 2020-04-20 12:16:07,328 [ChunkWriter-3-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: f032c0d5b23e9d0d:f914658b37083b69:f032c0d5b23e9d0d:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_5_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_5_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1         | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1         | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1         | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-04-20 12:14:31,916 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
scm_1         | 2020-04-20 12:14:31,916 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
scm_1         | 2020-04-20 12:14:31,916 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=2b915d42-0547-44e8-966f-930049e84d30 close command to datanode 5add3564-1298-4085-832c-a1039ab03f55
scm_1         | 2020-04-20 12:14:31,917 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: 2b915d42-0547-44e8-966f-930049e84d30, Nodes: d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:12:59.141880Z]
scm_1         | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=2b915d42-0547-44e8-966f-930049e84d30 not found
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1         | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_4_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
scm_1         | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-930049E84D30 not found.
datanode_5_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
scm_1         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
scm_1         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
scm_1         | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_5_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=965574656 B) is less than the container size (=1073741824 B).
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_5_1  | 	... 13 more
datanode_5_1  | 2020-04-20 12:16:07,329 [ChunkWriter-3-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: f032c0d5b23e9d0d:f914658b37083b69:f032c0d5b23e9d0d:0 , Message: ContainerID 5 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_5_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 5 creation failed
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_1_1  | 	... 4 more
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
scm_1         | 2020-04-20 12:14:34,244 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f from datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1. Reason : ContainerID 4 creation failed
datanode_1_1  | 2020-04-20 12:14:57,847 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-930049E84D30:null
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 2020-04-20 12:14:57,847 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
scm_1         | 2020-04-20 12:14:34,247 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b2031e52-018e-41a3-b0d9-12b961ffd63f, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:13:29.545124Z]
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 
scm_1         | 2020-04-20 12:14:34,247 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: b2031e52-018e-41a3-b0d9-12b961ffd63f, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:13:29.545124Z] moved to CLOSED state
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_4_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Failed to add group-12B961FFD63F:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] since the group already exists in the map.
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-930049E84D30 not found.
scm_1         | 2020-04-20 12:14:34,249 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #4
datanode_5_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1         | 2020-04-20 12:14:34,250 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f from datanode 5add3564-1298-4085-832c-a1039ab03f55. Reason : ContainerID 4 creation failed
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1         | 2020-04-20 12:14:34,257 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b2031e52-018e-41a3-b0d9-12b961ffd63f, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:13:29.545124Z]
datanode_4_1  | 	... 13 more
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1         | 2020-04-20 12:14:34,263 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f from datanode 5add3564-1298-4085-832c-a1039ab03f55. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-184A811F9848, cid=22
datanode_4_1  | 2020-04-20 12:13:56,974 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "f032c0d5b23e9d0d:24456efda0b889d1:f032c0d5b23e9d0d:0" containerID: 4 datanodeUuid: "5add3564-1298-4085-832c-a1039ab03f55" pipelineID: "b2031e52-018e-41a3-b0d9-12b961ffd63f" writeChunk { blockID { containerID: 4 localID: 104030855114194950 blockCommitSequenceId: 0 } chunkData { chunkName: "104030855114194950_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_4_1  | .
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-04-20 12:16:07,329 [ChunkWriter-3-0] ERROR ratis.ContainerStateMachine: group-522AC6C9A985: writeChunk writeStateMachineData failed: blockIdcontainerID: 5
scm_1         | 2020-04-20 12:14:34,263 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b2031e52-018e-41a3-b0d9-12b961ffd63f, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:13:29.545124Z]
datanode_4_1  | 2020-04-20 12:14:01,989 [grpc-default-executor-2] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:5add3564-1298-4085-832c-a1039ab03f55
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-930049E84D30 not found.
datanode_5_1  | localID: 104030861216907271
scm_1         | 2020-04-20 12:14:34,266 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f from datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-184A811F9848, cid=22
datanode_4_1  | 2020-04-20 12:14:01,989 [grpc-default-executor-2] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: shutdown FollowerState
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_5_1  | blockCommitSequenceId: 0
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "f032c0d5b23e9d0d:24456efda0b889d1:f032c0d5b23e9d0d:0" containerID: 4 datanodeUuid: "5add3564-1298-4085-832c-a1039ab03f55" pipelineID: "b2031e52-018e-41a3-b0d9-12b961ffd63f" writeChunk { blockID { containerID: 4 localID: 104030855114194950 blockCommitSequenceId: 0 } chunkData { chunkName: "104030855114194950_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_4_1  | 2020-04-20 12:14:01,989 [grpc-default-executor-2] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: start FollowerState
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_5_1  |  logIndex 1 chunkName 104030861216907271_chunk_1 Error message: ContainerID 5 creation failed Container Result: DISK_OUT_OF_SPACE
scm_1         | 2020-04-20 12:14:34,266 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b2031e52-018e-41a3-b0d9-12b961ffd63f, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:13:29.545124Z]
datanode_4_1  | 2020-04-20 12:14:01,989 [Thread-71] INFO impl.FollowerState: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_5_1  | 2020-04-20 12:16:07,333 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=17ae8adc-4d8e-4ba0-b62e-522ac6c9a985.Reason : ContainerID 5 creation failed
scm_1         | 2020-04-20 12:14:34,279 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f from datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1. Reason : ContainerID 4 creation failed
datanode_4_1  | 2020-04-20 12:14:02,035 [grpc-default-executor-2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-12B961FFD63F with new leaderId: 5add3564-1298-4085-832c-a1039ab03f55
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_5_1  | 2020-04-20 12:16:07,351 [5add3564-1298-4085-832c-a1039ab03f55@group-522AC6C9A985-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=17ae8adc-4d8e-4ba0-b62e-522ac6c9a985.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DB9CD499EE10, cid=25
scm_1         | 2020-04-20 12:14:34,283 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b2031e52-018e-41a3-b0d9-12b961ffd63f, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:13:29.545124Z]
datanode_4_1  | 2020-04-20 12:14:02,035 [grpc-default-executor-2] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F: change Leader from null to 5add3564-1298-4085-832c-a1039ab03f55 at term 1 for appendEntries, leader elected after 5179ms
datanode_1_1  | 	... 4 more
datanode_1_1  | 2020-04-20 12:14:57,847 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-930049E84D30:null
datanode_1_1  | 2020-04-20 12:14:57,847 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_1_1  | 
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_5_1  | 	 State Machine: cmdType: WriteChunk traceID: "f032c0d5b23e9d0d:f914658b37083b69:f032c0d5b23e9d0d:0" containerID: 5 datanodeUuid: "5add3564-1298-4085-832c-a1039ab03f55" pipelineID: "17ae8adc-4d8e-4ba0-b62e-522ac6c9a985" writeChunk { blockID { containerID: 5 localID: 104030861216907271 blockCommitSequenceId: 0 } chunkData { chunkName: "104030861216907271_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_4_1  | 2020-04-20 12:14:02,036 [grpc-default-executor-2] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F: set configuration 0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null at 0
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
scm_1         | 2020-04-20 12:14:34,286 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f from datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-184A811F9848, cid=22
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "f032c0d5b23e9d0d:24456efda0b889d1:f032c0d5b23e9d0d:0" containerID: 4 datanodeUuid: "5add3564-1298-4085-832c-a1039ab03f55" pipelineID: "b2031e52-018e-41a3-b0d9-12b961ffd63f" writeChunk { blockID { containerID: 4 localID: 104030855114194950 blockCommitSequenceId: 0 } chunkData { chunkName: "104030855114194950_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_5_1  | 2020-04-20 12:16:11,253 [grpc-default-executor-0] INFO impl.FollowerInfo: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F->ea211d94-4213-43ea-b4d3-a3779a4d37c1: nextIndex: updateUnconditionally 3 -> 1
datanode_4_1  | 2020-04-20 12:14:02,036 [grpc-default-executor-2] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-SegmentedRaftLogWorker: Starting segment from index:0
scm_1         | 2020-04-20 12:14:34,286 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: b2031e52-018e-41a3-b0d9-12b961ffd63f, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:13:29.545124Z]
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | 	... 4 more
datanode_1_1  | 2020-04-20 12:14:57,847 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-930049E84D30:null
datanode_1_1  | 2020-04-20 12:14:57,848 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_1_1  | 
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1         | 2020-04-20 12:14:40,601 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=2b915d42-0547-44e8-966f-930049e84d30 from datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=15
datanode_5_1  | 2020-04-20 12:16:11,254 [grpc-default-executor-1] INFO impl.FollowerInfo: 5add3564-1298-4085-832c-a1039ab03f55@group-12B961FFD63F->d427b6db-e08f-47dc-bc01-4bdf7d0252a1: nextIndex: updateUnconditionally 3 -> 1
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 2020-04-20 12:14:02,038 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b2031e52-018e-41a3-b0d9-12b961ffd63f/current/log_inprogress_0
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0" containerID: 3 datanodeUuid: "d427b6db-e08f-47dc-bc01-4bdf7d0252a1" pipelineID: "2b915d42-0547-44e8-966f-930049e84d30" writeChunk { blockID { containerID: 3 localID: 104030850618556420 blockCommitSequenceId: 0 } chunkData { chunkName: "104030850618556420_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_5_1  | 2020-04-20 12:16:11,330 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: remove group-12B961FFD63F:null
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:14:33,009 [grpc-default-executor-2] INFO server.GrpcServerProtocolService: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Completed APPEND_ENTRIES, lastRequest: 5add3564-1298-4085-832c-a1039ab03f55->d427b6db-e08f-47dc-bc01-4bdf7d0252a1#5-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=16
scm_1         | 2020-04-20 12:14:40,602 [EventQueue-PipelineActionsForPipelineActionHandler] WARN pipeline.PipelineActionHandler: Pipeline action CLOSE received for unknown pipeline PipelineID=2b915d42-0547-44e8-966f-930049e84d30, firing close pipeline event.
datanode_5_1  | 2020-04-20 12:16:11,330 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-930049E84D30 not found.
datanode_4_1  | 2020-04-20 12:14:34,230 [ChunkWriter-2-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: f032c0d5b23e9d0d:24456efda0b889d1:f032c0d5b23e9d0d:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
scm_1         | 2020-04-20 12:14:40,605 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=2b915d42-0547-44e8-966f-930049e84d30 from datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=15
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0" containerID: 3 datanodeUuid: "d427b6db-e08f-47dc-bc01-4bdf7d0252a1" pipelineID: "2b915d42-0547-44e8-966f-930049e84d30" writeChunk { blockID { containerID: 3 localID: 104030850618556420 blockCommitSequenceId: 0 } chunkData { chunkName: "104030850618556420_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
scm_1         | 2020-04-20 12:14:40,605 [EventQueue-PipelineActionsForPipelineActionHandler] WARN pipeline.PipelineActionHandler: Pipeline action CLOSE received for unknown pipeline PipelineID=2b915d42-0547-44e8-966f-930049e84d30, firing close pipeline event.
datanode_5_1  | 
datanode_4_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
scm_1         | 2020-04-20 12:14:40,623 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=2b915d42-0547-44e8-966f-930049e84d30 from datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=15
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_5_1  | java.io.IOException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-12B961FFD63F not found.
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0" containerID: 3 datanodeUuid: "d427b6db-e08f-47dc-bc01-4bdf7d0252a1" pipelineID: "2b915d42-0547-44e8-966f-930049e84d30" writeChunk { blockID { containerID: 3 localID: 104030850618556420 blockCommitSequenceId: 0 } chunkData { chunkName: "104030850618556420_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
scm_1         | 2020-04-20 12:14:40,624 [EventQueue-PipelineActionsForPipelineActionHandler] WARN pipeline.PipelineActionHandler: Pipeline action CLOSE received for unknown pipeline PipelineID=2b915d42-0547-44e8-966f-930049e84d30, firing close pipeline event.
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
scm_1         | 2020-04-20 12:14:40,627 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=2b915d42-0547-44e8-966f-930049e84d30 from datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=15
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0" containerID: 3 datanodeUuid: "d427b6db-e08f-47dc-bc01-4bdf7d0252a1" pipelineID: "2b915d42-0547-44e8-966f-930049e84d30" writeChunk { blockID { containerID: 3 localID: 104030850618556420 blockCommitSequenceId: 0 } chunkData { chunkName: "104030850618556420_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_1_1  | 	... 4 more
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
scm_1         | 2020-04-20 12:14:40,628 [EventQueue-PipelineActionsForPipelineActionHandler] WARN pipeline.PipelineActionHandler: Pipeline action CLOSE received for unknown pipeline PipelineID=2b915d42-0547-44e8-966f-930049e84d30, firing close pipeline event.
datanode_1_1  | 2020-04-20 12:14:57,848 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #4 does not exist in datanode. Container close failed.
datanode_5_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
scm_1         | 2020-04-20 12:15:29,547 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
datanode_1_1  | 2020-04-20 12:14:57,849 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-930049E84D30:null
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
scm_1         | 2020-04-20 12:15:29,549 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=17ae8adc-4d8e-4ba0-b62e-522ac6c9a985 to datanode:5add3564-1298-4085-832c-a1039ab03f55
datanode_1_1  | 2020-04-20 12:14:57,849 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_1_1  | 
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
scm_1         | 2020-04-20 12:15:29,549 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=17ae8adc-4d8e-4ba0-b62e-522ac6c9a985 to datanode:ea211d94-4213-43ea-b4d3-a3779a4d37c1
scm_1         | 2020-04-20 12:15:29,549 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=17ae8adc-4d8e-4ba0-b62e-522ac6c9a985 to datanode:d427b6db-e08f-47dc-bc01-4bdf7d0252a1
scm_1         | 2020-04-20 12:15:29,549 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 17ae8adc-4d8e-4ba0-b62e-522ac6c9a985, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-20T12:15:29.549085Z]
scm_1         | 2020-04-20 12:15:29,549 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-04-20 12:15:40,248 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode 5add3564-1298-4085-832c-a1039ab03f55
scm_1         | 2020-04-20 12:15:40,255 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
scm_1         | 2020-04-20 12:15:40,255 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
scm_1         | 2020-04-20 12:15:40,255 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: b2031e52-018e-41a3-b0d9-12b961ffd63f, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:13:29.545124Z] removed from db
scm_1         | 2020-04-20 12:15:40,256 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-04-20 12:15:40,257 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-04-20 12:15:40,263 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode 5add3564-1298-4085-832c-a1039ab03f55
scm_1         | 2020-04-20 12:15:40,263 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
scm_1         | 2020-04-20 12:15:40,264 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
scm_1         | 2020-04-20 12:15:40,264 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: b2031e52-018e-41a3-b0d9-12b961ffd63f, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:13:29.545124Z]
scm_1         | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f not found
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | 	... 4 more
datanode_1_1  | 2020-04-20 12:14:57,864 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Completed APPEND_ENTRIES, lastRequest: d427b6db-e08f-47dc-bc01-4bdf7d0252a1->ea211d94-4213-43ea-b4d3-a3779a4d37c1#1-t2, previous=(t:1, i:2), leaderCommit=0, initializing? false, entries: size=1, first=(t:2, i:3), CONFIGURATIONENTRY
datanode_1_1  | 2020-04-20 12:15:11,625 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-930049E84D30:null
datanode_1_1  | 2020-04-20 12:15:11,626 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_1_1  | 
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | 	... 4 more
datanode_1_1  | 2020-04-20 12:15:35,265 [grpc-default-executor-0] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: addNew group-522AC6C9A985:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] returns group-522AC6C9A985:java.util.concurrent.CompletableFuture@95633fa[Not completed]
datanode_1_1  | 2020-04-20 12:15:35,267 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1: new RaftServerImpl for group-522AC6C9A985:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-04-20 12:15:35,267 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
scm_1         | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
scm_1         | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1         | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-04-20 12:15:40,264 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode 5add3564-1298-4085-832c-a1039ab03f55
scm_1         | 2020-04-20 12:15:40,264 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
scm_1         | 2020-04-20 12:15:40,264 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
scm_1         | 2020-04-20 12:15:40,264 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: b2031e52-018e-41a3-b0d9-12b961ffd63f, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:13:29.545124Z]
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
scm_1         | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f not found
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1_1  | 2020-04-20 12:15:35,267 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 2020-04-20 12:15:35,267 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_5_1  | 	... 4 more
datanode_1_1  | 2020-04-20 12:15:35,267 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_5_1  | 2020-04-20 12:16:11,330 [Command processor thread] INFO impl.RaftServerProxy: 5add3564-1298-4085-832c-a1039ab03f55: remove group-12B961FFD63F:null
datanode_1_1  | 2020-04-20 12:15:35,267 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=965783552 B) is less than the container size (=1073741824 B).
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_5_1  | 2020-04-20 12:16:11,331 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_1_1  | 2020-04-20 12:15:35,268 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985: ConfigurationManager, init=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
scm_1         | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_5_1  | 
datanode_1_1  | 2020-04-20 12:15:35,268 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
scm_1         | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5_1  | java.io.IOException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-12B961FFD63F not found.
datanode_1_1  | 2020-04-20 12:15:35,268 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 	... 13 more
scm_1         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | 2020-04-20 12:15:35,268 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/17ae8adc-4d8e-4ba0-b62e-522ac6c9a985 does not exist. Creating ...
datanode_4_1  | 2020-04-20 12:14:34,235 [ChunkWriter-2-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: f032c0d5b23e9d0d:24456efda0b889d1:f032c0d5b23e9d0d:0 , Message: ContainerID 4 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
scm_1         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1_1  | 2020-04-20 12:15:35,270 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/17ae8adc-4d8e-4ba0-b62e-522ac6c9a985/in_use.lock acquired by nodename 6@52fe7c485517
datanode_4_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 4 creation failed
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 2020-04-20 12:15:35,271 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/17ae8adc-4d8e-4ba0-b62e-522ac6c9a985 has been successfully formatted.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1_1  | 2020-04-20 12:15:35,271 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-522AC6C9A985: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
scm_1         | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm_1         | 2020-04-20 12:15:40,269 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode 5add3564-1298-4085-832c-a1039ab03f55
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_5_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: 5add3564-1298-4085-832c-a1039ab03f55: Group group-12B961FFD63F not found.
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1         | 2020-04-20 12:15:40,270 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1         | 2020-04-20 12:15:40,270 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
scm_1         | 2020-04-20 12:15:40,270 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: b2031e52-018e-41a3-b0d9-12b961ffd63f, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:13:29.545124Z]
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1         | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f not found
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/17ae8adc-4d8e-4ba0-b62e-522ac6c9a985
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 	... 4 more
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_4_1  | 2020-04-20 12:14:34,235 [ChunkWriter-2-0] ERROR ratis.ContainerStateMachine: group-12B961FFD63F: writeChunk writeStateMachineData failed: blockIdcontainerID: 4
datanode_5_1  | 2020-04-20 12:16:38,352 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #5 does not exist in datanode. Container close failed.
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_4_1  | localID: 104030855114194950
datanode_1_1  | 2020-04-20 12:15:35,272 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_4_1  | blockCommitSequenceId: 0
datanode_1_1  | 2020-04-20 12:15:35,274 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_4_1  |  logIndex 1 chunkName 104030855114194950_chunk_1 Error message: ContainerID 4 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_1_1  | 2020-04-20 12:15:35,274 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1         | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_4_1  | 2020-04-20 12:14:34,236 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f.Reason : ContainerID 4 creation failed
datanode_1_1  | 2020-04-20 12:15:35,281 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1         | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4_1  | 2020-04-20 12:14:34,243 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-184A811F9848, cid=22
datanode_1_1  | 2020-04-20 12:15:35,282 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
scm_1         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	 State Machine: cmdType: WriteChunk traceID: "f032c0d5b23e9d0d:24456efda0b889d1:f032c0d5b23e9d0d:0" containerID: 4 datanodeUuid: "5add3564-1298-4085-832c-a1039ab03f55" pipelineID: "b2031e52-018e-41a3-b0d9-12b961ffd63f" writeChunk { blockID { containerID: 4 localID: 104030855114194950 blockCommitSequenceId: 0 } chunkData { chunkName: "104030855114194950_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_1_1  | 2020-04-20 12:15:35,282 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_4_1  | 2020-04-20 12:14:40,561 [Thread-46] INFO impl.FollowerState: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-FollowerState: change to CANDIDATE, lastRpcTime:9607ms, electionTimeout:5019ms
datanode_1_1  | 2020-04-20 12:15:35,284 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-04-20 12:15:35,284 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 2020-04-20 12:15:35,284 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985
datanode_4_1  | 2020-04-20 12:14:40,561 [Thread-46] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: shutdown FollowerState
datanode_4_1  | 2020-04-20 12:14:40,561 [Thread-46] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_4_1  | 2020-04-20 12:14:40,562 [Thread-46] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: start LeaderElection
datanode_4_1  | 2020-04-20 12:14:40,562 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30: change Leader from 5add3564-1298-4085-832c-a1039ab03f55 to null at term 1 for initElection
datanode_4_1  | 2020-04-20 12:14:40,564 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO impl.LeaderElection: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3: begin an election at term 2 for 0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
datanode_4_1  | 2020-04-20 12:14:40,592 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO impl.LeaderElection: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 5add3564-1298-4085-832c-a1039ab03f55: group-930049E84D30 not found.
datanode_4_1  | 2020-04-20 12:14:40,593 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO impl.LeaderElection: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3: Election PASSED; received 1 response(s) [d427b6db-e08f-47dc-bc01-4bdf7d0252a1<-ea211d94-4213-43ea-b4d3-a3779a4d37c1#0:OK-t2] and 1 exception(s); d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30:t2, leader=null, voted=d427b6db-e08f-47dc-bc01-4bdf7d0252a1, raftlog=d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
datanode_4_1  | 2020-04-20 12:14:40,594 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO impl.LeaderElection:   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: 5add3564-1298-4085-832c-a1039ab03f55: group-930049E84D30 not found.
datanode_4_1  | 2020-04-20 12:14:40,594 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: shutdown LeaderElection
datanode_4_1  | 2020-04-20 12:14:40,594 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode_4_1  | 2020-04-20 12:14:40,594 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-930049E84D30 with new leaderId: d427b6db-e08f-47dc-bc01-4bdf7d0252a1
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 2020-04-20 12:14:40,594 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30: change Leader from null to d427b6db-e08f-47dc-bc01-4bdf7d0252a1 at term 2 for becomeLeader, leader elected after 32ms
datanode_1_1  | 2020-04-20 12:15:35,285 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985: start as a follower, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
scm_1         | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:14:40,594 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1_1  | 2020-04-20 12:15:35,285 [pool-69-thread-1] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-04-20 12:14:40,594 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1         | 2020-04-20 12:15:40,283 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode 5add3564-1298-4085-832c-a1039ab03f55
datanode_1_1  | 2020-04-20 12:15:35,285 [pool-69-thread-1] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: start FollowerState
datanode_4_1  | 2020-04-20 12:14:40,594 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30
scm_1         | 2020-04-20 12:15:40,283 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_1_1  | 2020-04-20 12:15:35,285 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-522AC6C9A985,id=ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_4_1  | 2020-04-20 12:14:40,595 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
scm_1         | 2020-04-20 12:15:40,283 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_1_1  | 2020-04-20 12:15:35,285 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985
datanode_4_1  | 2020-04-20 12:14:40,595 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_4_1  | 2020-04-20 12:14:40,595 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
scm_1         | 2020-04-20 12:15:40,284 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: b2031e52-018e-41a3-b0d9-12b961ffd63f, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:13:29.545124Z]
datanode_4_1  | 2020-04-20 12:14:40,595 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1_1  | 2020-04-20 12:15:40,316 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:5add3564-1298-4085-832c-a1039ab03f55
scm_1         | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f not found
datanode_4_1  | 2020-04-20 12:14:40,595 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1_1  | 2020-04-20 12:15:40,316 [grpc-default-executor-0] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: shutdown FollowerState
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_4_1  | 2020-04-20 12:14:40,595 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1_1  | 2020-04-20 12:15:40,316 [Thread-179] INFO impl.FollowerState: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_4_1  | 2020-04-20 12:14:40,597 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-04-20 12:15:40,316 [grpc-default-executor-0] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: start FollowerState
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_4_1  | 2020-04-20 12:14:40,597 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1_1  | 2020-04-20 12:15:40,356 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-522AC6C9A985 with new leaderId: 5add3564-1298-4085-832c-a1039ab03f55
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_4_1  | 2020-04-20 12:14:40,597 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1_1  | 2020-04-20 12:15:40,357 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985: change Leader from null to 5add3564-1298-4085-832c-a1039ab03f55 at term 1 for appendEntries, leader elected after 5084ms
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_4_1  | 2020-04-20 12:14:40,597 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_1_1  | 2020-04-20 12:15:40,362 [grpc-default-executor-0] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985: set configuration 0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null at 0
datanode_4_1  | 2020-04-20 12:14:40,597 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1         | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_1_1  | 2020-04-20 12:15:40,362 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-04-20 12:14:40,598 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm_1         | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4_1  | 2020-04-20 12:14:40,598 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-04-20 12:15:40,363 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/17ae8adc-4d8e-4ba0-b62e-522ac6c9a985/current/log_inprogress_0
scm_1         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 2020-04-20 12:14:40,598 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1_1  | 2020-04-20 12:16:06,250 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Completed APPEND_ENTRIES, lastRequest: 5add3564-1298-4085-832c-a1039ab03f55->ea211d94-4213-43ea-b4d3-a3779a4d37c1#15-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-184A811F9848, cid=23
scm_1         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_4_1  | 2020-04-20 12:14:40,598 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1_1  | 2020-04-20 12:16:06,271 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove  FOLLOWER ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F:t1, leader=5add3564-1298-4085-832c-a1039ab03f55, voted=5add3564-1298-4085-832c-a1039ab03f55, raftlog=ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null RUNNING
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 2020-04-20 12:14:40,599 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-04-20 12:16:06,272 [Command processor thread] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F: shutdown
datanode_4_1  | 2020-04-20 12:14:40,599 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-04-20 12:16:06,272 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-12B961FFD63F,id=ea211d94-4213-43ea-b4d3-a3779a4d37c1
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 2020-04-20 12:14:40,599 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: start LeaderState
datanode_1_1  | 2020-04-20 12:16:06,272 [Command processor thread] INFO impl.RoleInfo: ea211d94-4213-43ea-b4d3-a3779a4d37c1: shutdown FollowerState
scm_1         | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:14:40,600 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-SegmentedRaftLogWorker: Rolling segment log-0_2 to index:2
datanode_1_1  | 2020-04-20 12:16:06,272 [Command processor thread] INFO impl.StateMachineUpdater: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-StateMachineUpdater: set stopIndex = 0
scm_1         | 2020-04-20 12:15:40,286 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode 5add3564-1298-4085-832c-a1039ab03f55
datanode_4_1  | 2020-04-20 12:14:40,600 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=2b915d42-0547-44e8-966f-930049e84d30.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=15
datanode_1_1  | 2020-04-20 12:16:06,272 [Thread-109] INFO impl.FollowerState: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
scm_1         | 2020-04-20 12:15:40,286 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_4_1  | 	 State Machine: cmdType: WriteChunk traceID: "30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0" containerID: 3 datanodeUuid: "d427b6db-e08f-47dc-bc01-4bdf7d0252a1" pipelineID: "2b915d42-0547-44e8-966f-930049e84d30" writeChunk { blockID { containerID: 3 localID: 104030850618556420 blockCommitSequenceId: 0 } chunkData { chunkName: "104030850618556420_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_1_1  | 2020-04-20 12:16:06,272 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-12B961FFD63F as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
scm_1         | 2020-04-20 12:15:40,286 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Send pipeline:PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f close command to datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 2020-04-20 12:14:40,602 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=2b915d42-0547-44e8-966f-930049e84d30.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-A5E67C0D7C94, cid=15
datanode_1_1  | 2020-04-20 12:16:06,273 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-StateMachineUpdater] ERROR impl.StateMachineUpdater: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-StateMachineUpdater: Failed to take snapshot
scm_1         | 2020-04-20 12:15:40,287 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Destroy pipeline failed for pipeline:Pipeline[ Id: b2031e52-018e-41a3-b0d9-12b961ffd63f, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:13:29.545124Z]
datanode_4_1  | 	 State Machine: cmdType: WriteChunk traceID: "30703be124c1fa5c:efcd2c15a37c8500:30703be124c1fa5c:0" containerID: 3 datanodeUuid: "d427b6db-e08f-47dc-bc01-4bdf7d0252a1" pipelineID: "2b915d42-0547-44e8-966f-930049e84d30" writeChunk { blockID { containerID: 3 localID: 104030850618556420 blockCommitSequenceId: 0 } chunkData { chunkName: "104030850618556420_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_1_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-12B961FFD63F as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
scm_1         | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b2031e52-018e-41a3-b0d9-12b961ffd63f not found
datanode_4_1  | 2020-04-20 12:14:40,608 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-LeaderElection3] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30: set configuration 3: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null at 3
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:133)
datanode_4_1  | 2020-04-20 12:14:57,856 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove    LEADER d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30:t2, leader=d427b6db-e08f-47dc-bc01-4bdf7d0252a1, voted=d427b6db-e08f-47dc-bc01-4bdf7d0252a1, raftlog=d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-SegmentedRaftLog:OPENED:c0,f0,i3, conf=3: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null RUNNING
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removePipeline(PipelineStateMap.java:323)
datanode_4_1  | 2020-04-20 12:14:57,857 [Command processor thread] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30: shutdown
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removePipeline(PipelineStateManager.java:104)
datanode_4_1  | 2020-04-20 12:14:57,857 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-930049E84D30,id=d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removePipeline(SCMPipelineManager.java:595)
datanode_4_1  | 2020-04-20 12:14:57,857 [Command processor thread] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: shutdown LeaderState
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.destroyPipeline(SCMPipelineManager.java:579)
datanode_4_1  | 2020-04-20 12:14:57,857 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$443/0x0000000840592040@71fe8020] WARN server.GrpcLogAppender: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30->ea211d94-4213-43ea-b4d3-a3779a4d37c1-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_1_1  | 2020-04-20 12:16:06,273 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-12B961FFD63F as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
scm_1         | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.lambda$finalizeAndDestroyPipeline$0(SCMPipelineManager.java:422)
datanode_4_1  | 2020-04-20 12:14:57,858 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$443/0x0000000840592040@205bbc51] WARN server.GrpcLogAppender: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30->5add3564-1298-4085-832c-a1039ab03f55-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
datanode_1_1  | 2020-04-20 12:16:06,273 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-StateMachineUpdater] ERROR impl.StateMachineUpdater: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-StateMachineUpdater: Failed to take snapshot
scm_1         | 	at org.apache.hadoop.hdds.utils.Scheduler.lambda$schedule$1(Scheduler.java:70)
datanode_4_1  | 2020-04-20 12:14:57,858 [Command processor thread] INFO impl.PendingRequests: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-PendingRequests: sendNotLeaderResponses
datanode_1_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-12B961FFD63F as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
scm_1         | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4_1  | 2020-04-20 12:14:57,862 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_appender.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
scm_1         | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 2020-04-20 12:14:57,862 [Command processor thread] INFO impl.StateMachineUpdater: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-StateMachineUpdater: set stopIndex = 0
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
scm_1         | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
datanode_4_1  | 2020-04-20 12:14:57,862 [grpc-default-executor-2] INFO server.GrpcLogAppender: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30->5add3564-1298-4085-832c-a1039ab03f55-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1         | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1         | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-04-20 12:15:40,336 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 17ae8adc-4d8e-4ba0-b62e-522ac6c9a985, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:15:29.549085Z] moved to OPEN state
scm_1         | 2020-04-20 12:16:07,347 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=17ae8adc-4d8e-4ba0-b62e-522ac6c9a985 from datanode 5add3564-1298-4085-832c-a1039ab03f55. Reason : ContainerID 5 creation failed
scm_1         | 2020-04-20 12:16:07,348 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 17ae8adc-4d8e-4ba0-b62e-522ac6c9a985, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:15:29.549085Z]
scm_1         | 2020-04-20 12:16:07,348 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 17ae8adc-4d8e-4ba0-b62e-522ac6c9a985, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:15:29.549085Z] moved to CLOSED state
scm_1         | 2020-04-20 12:16:07,349 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #5
scm_1         | 2020-04-20 12:16:07,350 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=17ae8adc-4d8e-4ba0-b62e-522ac6c9a985 from datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1. Reason : ContainerID 5 creation failed
scm_1         | 2020-04-20 12:16:07,367 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 17ae8adc-4d8e-4ba0-b62e-522ac6c9a985, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:15:29.549085Z]
scm_1         | 2020-04-20 12:16:07,368 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=17ae8adc-4d8e-4ba0-b62e-522ac6c9a985 from datanode 5add3564-1298-4085-832c-a1039ab03f55. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DB9CD499EE10, cid=25
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "f032c0d5b23e9d0d:f914658b37083b69:f032c0d5b23e9d0d:0" containerID: 5 datanodeUuid: "5add3564-1298-4085-832c-a1039ab03f55" pipelineID: "17ae8adc-4d8e-4ba0-b62e-522ac6c9a985" writeChunk { blockID { containerID: 5 localID: 104030861216907271 blockCommitSequenceId: 0 } chunkData { chunkName: "104030861216907271_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
scm_1         | 2020-04-20 12:16:07,368 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 17ae8adc-4d8e-4ba0-b62e-522ac6c9a985, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:15:29.549085Z]
scm_1         | 2020-04-20 12:16:07,368 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=17ae8adc-4d8e-4ba0-b62e-522ac6c9a985 from datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1. Reason : ContainerID 5 creation failed
datanode_4_1  | 2020-04-20 12:14:57,867 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-930049E84D30 as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
scm_1         | 2020-04-20 12:16:07,368 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 17ae8adc-4d8e-4ba0-b62e-522ac6c9a985, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:15:29.549085Z]
datanode_4_1  | 2020-04-20 12:14:57,867 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-StateMachineUpdater] ERROR impl.StateMachineUpdater: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-StateMachineUpdater: Failed to take snapshot
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-04-20 12:16:07,369 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=17ae8adc-4d8e-4ba0-b62e-522ac6c9a985 from datanode ea211d94-4213-43ea-b4d3-a3779a4d37c1. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DB9CD499EE10, cid=25
datanode_4_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-930049E84D30 as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1_1  | 2020-04-20 12:16:06,273 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "f032c0d5b23e9d0d:f914658b37083b69:f032c0d5b23e9d0d:0" containerID: 5 datanodeUuid: "5add3564-1298-4085-832c-a1039ab03f55" pipelineID: "17ae8adc-4d8e-4ba0-b62e-522ac6c9a985" writeChunk { blockID { containerID: 5 localID: 104030861216907271 blockCommitSequenceId: 0 } chunkData { chunkName: "104030861216907271_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1_1  | 2020-04-20 12:16:06,273 [Command processor thread] INFO impl.RaftServerImpl: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F: closes. applyIndex: 0
datanode_1_1  | 2020-04-20 12:16:06,274 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_1_1  | 2020-04-20 12:16:06,274 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F-SegmentedRaftLogWorker close()
datanode_1_1  | 2020-04-20 12:16:06,275 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.ea211d94-4213-43ea-b4d3-a3779a4d37c1
datanode_1_1  | 2020-04-20 12:16:06,275 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F
datanode_1_1  | 2020-04-20 12:16:06,275 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-12B961FFD63F
datanode_1_1  | 2020-04-20 12:16:06,276 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_1_1  |  command on datanode #ea211d94-4213-43ea-b4d3-a3779a4d37c1.
datanode_1_1  | 2020-04-20 12:16:06,276 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-12B961FFD63F:null
datanode_1_1  | 2020-04-20 12:16:06,276 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_1_1  | 
scm_1         | 2020-04-20 12:16:07,369 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 17ae8adc-4d8e-4ba0-b62e-522ac6c9a985, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:15:29.549085Z]
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-12B961FFD63F not found.
scm_1         | 2020-04-20 12:16:07,375 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.PipelineActionHandler: Received pipeline action CLOSE for PipelineID=17ae8adc-4d8e-4ba0-b62e-522ac6c9a985 from datanode d427b6db-e08f-47dc-bc01-4bdf7d0252a1. Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DB9CD499EE10, cid=25
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
scm_1         | 	 State Machine: cmdType: WriteChunk traceID: "f032c0d5b23e9d0d:f914658b37083b69:f032c0d5b23e9d0d:0" containerID: 5 datanodeUuid: "5add3564-1298-4085-832c-a1039ab03f55" pipelineID: "17ae8adc-4d8e-4ba0-b62e-522ac6c9a985" writeChunk { blockID { containerID: 5 localID: 104030861216907271 blockCommitSequenceId: 0 } chunkData { chunkName: "104030861216907271_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
scm_1         | 2020-04-20 12:16:07,376 [EventQueue-PipelineActionsForPipelineActionHandler] INFO pipeline.SCMPipelineManager: Destroying pipeline:Pipeline[ Id: 17ae8adc-4d8e-4ba0-b62e-522ac6c9a985, Nodes: 5add3564-1298-4085-832c-a1039ab03f55{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}ea211d94-4213-43ea-b4d3-a3779a4d37c1{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}d427b6db-e08f-47dc-bc01-4bdf7d0252a1{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:CLOSED, leaderId:5add3564-1298-4085-832c-a1039ab03f55, CreationTimestamp2020-04-20T12:15:29.549085Z]
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
scm_1         | 2020-04-20 12:16:41,702 [Thread-338] INFO container.ReplicationManager: Starting Replication Monitor Thread.
datanode_4_1  | 2020-04-20 12:14:57,867 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-930049E84D30 as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
scm_1         | 2020-04-20 12:16:41,710 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 4 milliseconds for processing 5 containers.
datanode_4_1  | 2020-04-20 12:14:57,868 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-StateMachineUpdater] ERROR impl.StateMachineUpdater: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-StateMachineUpdater: Failed to take snapshot
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-930049E84D30 as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 	... 4 more
datanode_4_1  | 2020-04-20 12:14:57,868 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30
datanode_1_1  | 2020-04-20 12:16:06,276 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-12B961FFD63F:null
datanode_4_1  | 2020-04-20 12:14:57,869 [Command processor thread] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30: closes. applyIndex: 0
datanode_1_1  | 2020-04-20 12:16:06,276 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_4_1  | 2020-04-20 12:14:57,869 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_1_1  | 
datanode_4_1  | 2020-04-20 12:14:57,870 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30-SegmentedRaftLogWorker close()
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-12B961FFD63F not found.
datanode_4_1  | 2020-04-20 12:14:57,870 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 2020-04-20 12:14:57,871 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 2020-04-20 12:14:57,871 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 2020-04-20 12:14:57,871 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  |  command on datanode #d427b6db-e08f-47dc-bc01-4bdf7d0252a1.
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:14:57,872 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-930049E84D30:null
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-12B961FFD63F not found.
datanode_4_1  | 2020-04-20 12:14:57,872 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 
datanode_1_1  | 	... 4 more
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_1_1  | 2020-04-20 12:16:06,276 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-12B961FFD63F:null
datanode_1_1  | 2020-04-20 12:16:06,276 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_1_1  | 
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	... 4 more
datanode_4_1  | 2020-04-20 12:14:57,873 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-930049E84D30:null
datanode_4_1  | 2020-04-20 12:14:57,873 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_4_1  | 
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	... 4 more
datanode_4_1  | 2020-04-20 12:14:57,874 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-930049E84D30:null
datanode_4_1  | 2020-04-20 12:14:57,874 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_4_1  | 
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 	... 4 more
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-12B961FFD63F not found.
datanode_4_1  | 2020-04-20 12:14:57,875 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-930049E84D30:null
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 2020-04-20 12:14:57,875 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | 	... 4 more
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1_1  | 2020-04-20 12:16:06,277 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-12B961FFD63F:null
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 2020-04-20 12:16:06,277 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1_1  | 
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-12B961FFD63F not found.
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 	... 4 more
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-12B961FFD63F not found.
datanode_4_1  | 2020-04-20 12:14:57,875 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-930049E84D30:null
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 2020-04-20 12:14:57,876 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_4_1  | 
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1_1  | 	... 4 more
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 2020-04-20 12:16:06,277 [Command processor thread] INFO impl.RaftServerProxy: ea211d94-4213-43ea-b4d3-a3779a4d37c1: remove group-12B961FFD63F:null
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1_1  | 2020-04-20 12:16:06,277 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_1_1  | java.io.IOException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-12B961FFD63F not found.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: ea211d94-4213-43ea-b4d3-a3779a4d37c1: Group group-12B961FFD63F not found.
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | 	... 4 more
datanode_1_1  | 2020-04-20 12:16:07,342 [ChunkWriter-5-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: f032c0d5b23e9d0d:f914658b37083b69:f032c0d5b23e9d0d:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_1_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	... 4 more
datanode_4_1  | 2020-04-20 12:14:57,877 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #4 does not exist in datanode. Container close failed.
datanode_4_1  | 2020-04-20 12:14:57,877 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-930049E84D30:null
datanode_4_1  | 2020-04-20 12:14:57,877 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_4_1  | 
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_4_1  | 	... 4 more
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_4_1  | 2020-04-20 12:14:57,877 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-930049E84D30:null
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_4_1  | 2020-04-20 12:14:57,878 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_4_1  | 
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_1_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=965562368 B) is less than the container size (=1073741824 B).
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_1_1  | 	... 13 more
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_1_1  | 2020-04-20 12:16:07,343 [ChunkWriter-5-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: f032c0d5b23e9d0d:f914658b37083b69:f032c0d5b23e9d0d:0 , Message: ContainerID 5 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_4_1  | 	... 4 more
datanode_1_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 5 creation failed
datanode_4_1  | 2020-04-20 12:14:57,881 [grpc-default-executor-2] INFO impl.FollowerInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30->5add3564-1298-4085-832c-a1039ab03f55: nextIndex: updateUnconditionally 4 -> 1
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_4_1  | 2020-04-20 12:14:57,881 [grpc-default-executor-3] INFO server.GrpcLogAppender: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30->ea211d94-4213-43ea-b4d3-a3779a4d37c1-AppendLogResponseHandler: follower responses appendEntries COMPLETED
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_4_1  | 2020-04-20 12:14:57,883 [grpc-default-executor-3] INFO impl.FollowerInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-930049E84D30->ea211d94-4213-43ea-b4d3-a3779a4d37c1: nextIndex: updateUnconditionally 4 -> 1
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_4_1  | 2020-04-20 12:15:11,602 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-930049E84D30:null
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_4_1  | 2020-04-20 12:15:11,602 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "2b915d42-0547-44e8-966f-930049e84d30"
datanode_1_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_4_1  | 
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 2020-04-20 12:16:07,343 [ChunkWriter-5-0] ERROR ratis.ContainerStateMachine: group-522AC6C9A985: writeChunk writeStateMachineData failed: blockIdcontainerID: 5
datanode_1_1  | localID: 104030861216907271
datanode_1_1  | blockCommitSequenceId: 0
datanode_1_1  |  logIndex 1 chunkName 104030861216907271_chunk_1 Error message: ContainerID 5 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_1_1  | 2020-04-20 12:16:07,344 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=17ae8adc-4d8e-4ba0-b62e-522ac6c9a985.Reason : ContainerID 5 creation failed
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_1_1  | 2020-04-20 12:16:07,356 [ea211d94-4213-43ea-b4d3-a3779a4d37c1@group-522AC6C9A985-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=17ae8adc-4d8e-4ba0-b62e-522ac6c9a985.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DB9CD499EE10, cid=25
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_1_1  | 	 State Machine: cmdType: WriteChunk traceID: "f032c0d5b23e9d0d:f914658b37083b69:f032c0d5b23e9d0d:0" containerID: 5 datanodeUuid: "5add3564-1298-4085-832c-a1039ab03f55" pipelineID: "17ae8adc-4d8e-4ba0-b62e-522ac6c9a985" writeChunk { blockID { containerID: 5 localID: 104030861216907271 blockCommitSequenceId: 0 } chunkData { chunkName: "104030861216907271_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 2020-04-20 12:16:36,271 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #5 does not exist in datanode. Container close failed.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-930049E84D30 not found.
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	... 4 more
datanode_4_1  | 2020-04-20 12:15:35,295 [grpc-default-executor-3] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: addNew group-522AC6C9A985:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] returns group-522AC6C9A985:java.util.concurrent.CompletableFuture@2e26e99f[Not completed]
datanode_4_1  | 2020-04-20 12:15:35,297 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: new RaftServerImpl for group-522AC6C9A985:[ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-04-20 12:15:35,297 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-04-20 12:15:35,297 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-04-20 12:15:35,297 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-04-20 12:15:35,297 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-04-20 12:15:35,297 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-04-20 12:15:35,297 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985: ConfigurationManager, init=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-04-20 12:15:35,297 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-04-20 12:15:35,298 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-04-20 12:15:35,298 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/17ae8adc-4d8e-4ba0-b62e-522ac6c9a985 does not exist. Creating ...
datanode_4_1  | 2020-04-20 12:15:35,300 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/17ae8adc-4d8e-4ba0-b62e-522ac6c9a985/in_use.lock acquired by nodename 6@0e128a59471e
datanode_4_1  | 2020-04-20 12:15:35,302 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/17ae8adc-4d8e-4ba0-b62e-522ac6c9a985 has been successfully formatted.
datanode_4_1  | 2020-04-20 12:15:35,302 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-522AC6C9A985: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-04-20 12:15:35,302 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-04-20 12:15:35,302 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-04-20 12:15:35,302 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-04-20 12:15:35,302 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-04-20 12:15:35,302 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-04-20 12:15:35,302 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 2020-04-20 12:15:35,303 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-04-20 12:15:35,303 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/17ae8adc-4d8e-4ba0-b62e-522ac6c9a985
datanode_4_1  | 2020-04-20 12:15:35,303 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-04-20 12:15:35,303 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-04-20 12:15:35,303 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-04-20 12:15:35,303 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-04-20 12:15:35,303 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-04-20 12:15:35,303 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-04-20 12:15:35,303 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-04-20 12:15:35,303 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-04-20 12:15:35,303 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-04-20 12:15:35,312 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-04-20 12:15:35,312 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-04-20 12:15:35,313 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-04-20 12:15:35,314 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-04-20 12:15:35,317 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-04-20 12:15:35,318 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-04-20 12:15:35,318 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985
datanode_4_1  | 2020-04-20 12:15:35,318 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985
datanode_4_1  | 2020-04-20 12:15:35,318 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985: start as a follower, conf=-1: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null
datanode_4_1  | 2020-04-20 12:15:35,318 [pool-69-thread-1] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-04-20 12:15:35,319 [pool-69-thread-1] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: start FollowerState
datanode_4_1  | 2020-04-20 12:15:35,319 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-522AC6C9A985,id=d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 2020-04-20 12:15:35,319 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985
datanode_4_1  | 2020-04-20 12:15:40,327 [grpc-default-executor-3] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:5add3564-1298-4085-832c-a1039ab03f55
datanode_4_1  | 2020-04-20 12:15:40,327 [grpc-default-executor-3] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: shutdown FollowerState
datanode_4_1  | 2020-04-20 12:15:40,327 [Thread-141] INFO impl.FollowerState: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_4_1  | 2020-04-20 12:15:40,327 [grpc-default-executor-3] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: start FollowerState
datanode_4_1  | 2020-04-20 12:15:40,350 [grpc-default-executor-3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-522AC6C9A985 with new leaderId: 5add3564-1298-4085-832c-a1039ab03f55
datanode_4_1  | 2020-04-20 12:15:40,350 [grpc-default-executor-3] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985: change Leader from null to 5add3564-1298-4085-832c-a1039ab03f55 at term 1 for appendEntries, leader elected after 5047ms
datanode_4_1  | 2020-04-20 12:15:40,353 [grpc-default-executor-3] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985: set configuration 0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null at 0
datanode_4_1  | 2020-04-20 12:15:40,354 [grpc-default-executor-3] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-04-20 12:15:40,357 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/17ae8adc-4d8e-4ba0-b62e-522ac6c9a985/current/log_inprogress_0
datanode_4_1  | 2020-04-20 12:16:06,250 [grpc-default-executor-3] INFO server.GrpcServerProtocolService: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Completed APPEND_ENTRIES, lastRequest: 5add3564-1298-4085-832c-a1039ab03f55->d427b6db-e08f-47dc-bc01-4bdf7d0252a1#15-t1, previous=(t:1, i:1), leaderCommit=0, initializing? false, entries: size=1, first=(t:1, i:2), STATEMACHINELOGENTRY, client-184A811F9848, cid=23
datanode_4_1  | 2020-04-20 12:16:06,302 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove  FOLLOWER d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F:t1, leader=5add3564-1298-4085-832c-a1039ab03f55, voted=5add3564-1298-4085-832c-a1039ab03f55, raftlog=d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-SegmentedRaftLog:OPENED:c0,f0,i2, conf=0: [ea211d94-4213-43ea-b4d3-a3779a4d37c1:10.5.0.4:9858, 5add3564-1298-4085-832c-a1039ab03f55:10.5.0.8:9858, d427b6db-e08f-47dc-bc01-4bdf7d0252a1:10.5.0.7:9858], old=null RUNNING
datanode_4_1  | 2020-04-20 12:16:06,303 [Command processor thread] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F: shutdown
datanode_4_1  | 2020-04-20 12:16:06,303 [Command processor thread] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-12B961FFD63F,id=d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 2020-04-20 12:16:06,303 [Command processor thread] INFO impl.RoleInfo: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: shutdown FollowerState
datanode_4_1  | 2020-04-20 12:16:06,303 [Command processor thread] INFO impl.StateMachineUpdater: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-StateMachineUpdater: set stopIndex = 0
datanode_4_1  | 2020-04-20 12:16:06,303 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-12B961FFD63F as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_4_1  | 2020-04-20 12:16:06,304 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-StateMachineUpdater] ERROR impl.StateMachineUpdater: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-StateMachineUpdater: Failed to take snapshot
datanode_4_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-12B961FFD63F as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:169)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:16:06,303 [Thread-75] INFO impl.FollowerState: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_4_1  | 2020-04-20 12:16:06,304 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-StateMachineUpdater] ERROR ratis.ContainerStateMachine: Failed to take snapshot  for group-12B961FFD63F as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_4_1  | 2020-04-20 12:16:06,304 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-StateMachineUpdater] ERROR impl.StateMachineUpdater: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-StateMachineUpdater: Failed to take snapshot
datanode_4_1  | org.apache.ratis.protocol.StateMachineException: Failed to take snapshot  for group-12B961FFD63F as the stateMachine is unhealthy. The last applied index is at (t:1, i:0)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.takeSnapshot(ContainerStateMachine.java:288)
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.takeSnapshot(StateMachineUpdater.java:258)
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.checkAndTakeSnapshot(StateMachineUpdater.java:250)
datanode_4_1  | 	at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:172)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:16:06,305 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-StateMachineUpdater] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.state_machine.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F
datanode_4_1  | 2020-04-20 12:16:06,305 [Command processor thread] INFO impl.RaftServerImpl: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F: closes. applyIndex: 0
datanode_4_1  | 2020-04-20 12:16:06,305 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
datanode_4_1  | 2020-04-20 12:16:06,306 [Command processor thread] INFO segmented.SegmentedRaftLogWorker: d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F-SegmentedRaftLogWorker close()
datanode_4_1  | 2020-04-20 12:16:06,307 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.log_worker.d427b6db-e08f-47dc-bc01-4bdf7d0252a1
datanode_4_1  | 2020-04-20 12:16:06,307 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.leader_election.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F
datanode_4_1  | 2020-04-20 12:16:06,307 [Command processor thread] INFO metrics.RatisMetrics: Unregistering Metrics Registry : ratis.server.d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-12B961FFD63F
datanode_4_1  | 2020-04-20 12:16:06,308 [Command processor thread] INFO commandhandler.ClosePipelineCommandHandler: Close Pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_4_1  |  command on datanode #d427b6db-e08f-47dc-bc01-4bdf7d0252a1.
datanode_4_1  | 2020-04-20 12:16:06,308 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-12B961FFD63F:null
datanode_4_1  | 2020-04-20 12:16:06,308 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_4_1  | 
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	... 4 more
datanode_4_1  | 2020-04-20 12:16:06,308 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-12B961FFD63F:null
datanode_4_1  | 2020-04-20 12:16:06,309 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_4_1  | 
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	... 4 more
datanode_4_1  | 2020-04-20 12:16:06,309 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-12B961FFD63F:null
datanode_4_1  | 2020-04-20 12:16:06,309 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_4_1  | 
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	... 4 more
datanode_4_1  | 2020-04-20 12:16:06,310 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-12B961FFD63F:null
datanode_4_1  | 2020-04-20 12:16:06,310 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_4_1  | 
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	... 4 more
datanode_4_1  | 2020-04-20 12:16:06,310 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-12B961FFD63F:null
datanode_4_1  | 2020-04-20 12:16:06,311 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_4_1  | 
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	... 4 more
datanode_4_1  | 2020-04-20 12:16:07,340 [ChunkWriter-38-0] INFO keyvalue.KeyValueHandler: Operation: CreateContainer , Trace ID: f032c0d5b23e9d0d:f914658b37083b69:f032c0d5b23e9d0d:0 , Message: Container creation failed, due to disk out of space , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_4_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Container creation failed, due to disk out of space
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:165)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleCreateContainer(KeyValueHandler.java:247)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:164)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:152)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.createContainer(HddsDispatcher.java:414)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:250)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=965566464 B) is less than the container size (=1073741824 B).
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.volume.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:77)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.create(KeyValueContainer.java:124)
datanode_4_1  | 	... 13 more
datanode_4_1  | 2020-04-20 12:16:07,341 [ChunkWriter-38-0] INFO impl.HddsDispatcher: Operation: WriteChunk , Trace ID: f032c0d5b23e9d0d:f914658b37083b69:f032c0d5b23e9d0d:0 , Message: ContainerID 5 creation failed , Result: DISK_OUT_OF_SPACE , StorageContainerException Occurred.
datanode_4_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 5 creation failed
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:254)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:162)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.dispatchCommand(ContainerStateMachine.java:402)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.runCommand(ContainerStateMachine.java:412)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.lambda$handleWriteChunk$2(ContainerStateMachine.java:447)
datanode_4_1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-04-20 12:16:07,343 [ChunkWriter-38-0] ERROR ratis.ContainerStateMachine: group-522AC6C9A985: writeChunk writeStateMachineData failed: blockIdcontainerID: 5
datanode_4_1  | localID: 104030861216907271
datanode_4_1  | blockCommitSequenceId: 0
datanode_4_1  |  logIndex 1 chunkName 104030861216907271_chunk_1 Error message: ContainerID 5 creation failed Container Result: DISK_OUT_OF_SPACE
datanode_4_1  | 2020-04-20 12:16:07,343 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=17ae8adc-4d8e-4ba0-b62e-522ac6c9a985.Reason : ContainerID 5 creation failed
datanode_4_1  | 2020-04-20 12:16:07,359 [d427b6db-e08f-47dc-bc01-4bdf7d0252a1@group-522AC6C9A985-SegmentedRaftLogWorker] ERROR ratis.XceiverServerRatis: pipeline Action CLOSE on pipeline PipelineID=17ae8adc-4d8e-4ba0-b62e-522ac6c9a985.Reason : Log already failed at index 1 for task WriteLog:1: (t:1, i:1), STATEMACHINELOGENTRY, client-DB9CD499EE10, cid=25
datanode_4_1  | 	 State Machine: cmdType: WriteChunk traceID: "f032c0d5b23e9d0d:f914658b37083b69:f032c0d5b23e9d0d:0" containerID: 5 datanodeUuid: "5add3564-1298-4085-832c-a1039ab03f55" pipelineID: "17ae8adc-4d8e-4ba0-b62e-522ac6c9a985" writeChunk { blockID { containerID: 5 localID: 104030861216907271 blockCommitSequenceId: 0 } chunkData { chunkName: "104030861216907271_chunk_1" offset: 0 len: 10240 checksumData { type: CRC32 bytesPerChecksum: 1048576 checksums: "h\232\347\247" } } }, container path=nonexistent
datanode_4_1  | 2020-04-20 12:16:36,303 [Command processor thread] INFO impl.RaftServerProxy: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: remove group-12B961FFD63F:null
datanode_4_1  | 2020-04-20 12:16:36,303 [Command processor thread] ERROR commandhandler.ClosePipelineCommandHandler: Can't close pipeline #id: "b2031e52-018e-41a3-b0d9-12b961ffd63f"
datanode_4_1  | 
datanode_4_1  | java.io.IOException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:659)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.handle(ClosePipelineCommandHandler.java:77)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: org.apache.ratis.protocol.GroupMismatchException: d427b6db-e08f-47dc-bc01-4bdf7d0252a1: Group group-12B961FFD63F not found.
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupRemoveAsync(RaftServerProxy.java:404)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:367)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagement(RaftServerProxy.java:350)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.removeGroup(XceiverServerRatis.java:657)
datanode_4_1  | 	... 4 more
datanode_4_1  | 2020-04-20 12:16:36,305 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler: Container #5 does not exist in datanode. Container close failed.
