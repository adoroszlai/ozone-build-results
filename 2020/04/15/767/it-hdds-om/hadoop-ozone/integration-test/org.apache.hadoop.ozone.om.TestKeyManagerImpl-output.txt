2020-04-15 04:19:15,021 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:19:28,814 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(126)) - Loading file from sun.misc.CompoundEnumeration@1405aa6a
2020-04-15 04:19:29,159 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(172)) - Loading network topology layer schema file
2020-04-15 04:19:30,538 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/6fe95a2f-d250-4f14-a1db-614f9de93e47
2020-04-15 04:19:30,539 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/b62d7ec7-4155-4112-9d2f-92f368ccfbe5
2020-04-15 04:19:30,562 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/6619ce5a-7401-4afb-ab66-de9ef56aa415
2020-04-15 04:19:30,563 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/4913a4a2-4a2d-417b-a43d-fe94789f76fe
2020-04-15 04:19:30,563 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/f79b807b-9bf4-45a7-96d4-0a3f3215eb48
2020-04-15 04:19:30,564 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/984fd1e3-3f30-4d90-b077-ccd90ea3038c
2020-04-15 04:19:30,565 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/250ee7a3-69f9-478f-96e6-fe41fc539658
2020-04-15 04:19:30,565 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/cfe06f51-2df6-4b8f-8434-7472103af3e6
2020-04-15 04:19:30,566 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/2e644625-a6ff-45bd-afe6-2f45533ac52b
2020-04-15 04:19:30,567 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/c21b55c2-f859-4a55-803a-3cf204e7d500
2020-04-15 04:19:30,797 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/2e644625-a6ff-45bd-afe6-2f45533ac52b
2020-04-15 04:19:30,819 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/cfe06f51-2df6-4b8f-8434-7472103af3e6
2020-04-15 04:19:30,819 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/f79b807b-9bf4-45a7-96d4-0a3f3215eb48
2020-04-15 04:19:30,855 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/250ee7a3-69f9-478f-96e6-fe41fc539658
2020-04-15 04:19:30,855 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/6fe95a2f-d250-4f14-a1db-614f9de93e47
2020-04-15 04:19:30,855 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/b62d7ec7-4155-4112-9d2f-92f368ccfbe5
2020-04-15 04:19:30,855 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/c21b55c2-f859-4a55-803a-3cf204e7d500
2020-04-15 04:19:30,856 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/984fd1e3-3f30-4d90-b077-ccd90ea3038c
2020-04-15 04:19:30,856 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/6619ce5a-7401-4afb-ab66-de9ef56aa415
2020-04-15 04:19:30,856 [main] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/4913a4a2-4a2d-417b-a43d-fe94789f76fe
2020-04-15 04:19:31,607 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:19:36,558 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:19:38,549 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:19:42,178 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(59)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2020-04-15 04:19:42,240 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:19:42,572 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(167)) - No pipeline exists in current db
2020-04-15 04:19:42,587 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:19:51,520 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:<init>(88)) - Total pipeline count is 0, healthy pipeline threshold count is 0
2020-04-15 04:19:51,524 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:<init>(79)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2020-04-15 04:20:02,021 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=6e3d87ea-1e96-4896-a878-ddd810b9fd89 to datanode:6fe95a2f-d250-4f14-a1db-614f9de93e47
2020-04-15 04:20:02,460 [RatisPipelineUtilsThread] WARN  events.EventQueue (EventQueue.java:fireEvent(186)) - No event handler registered for event TypedEvent{payloadType=CommandForDatanode, name='Datanode_Command'}
2020-04-15 04:20:06,222 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 6e3d87ea-1e96-4896-a878-ddd810b9fd89, Nodes: 6fe95a2f-d250-4f14-a1db-614f9de93e47{ip: 73.193.61.145, host: localhost-73.193.61.145, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:20:00.754Z]
2020-04-15 04:20:08,556 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=8b91a7af-f073-401e-849f-e4b4244b1b96 to datanode:b62d7ec7-4155-4112-9d2f-92f368ccfbe5
2020-04-15 04:20:08,588 [RatisPipelineUtilsThread] WARN  events.EventQueue (EventQueue.java:fireEvent(186)) - No event handler registered for event TypedEvent{payloadType=CommandForDatanode, name='Datanode_Command'}
2020-04-15 04:20:08,792 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 8b91a7af-f073-401e-849f-e4b4244b1b96, Nodes: b62d7ec7-4155-4112-9d2f-92f368ccfbe5{ip: 61.236.254.26, host: localhost-61.236.254.26, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:20:08.513Z]
2020-04-15 04:20:08,848 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=552277c5-7d67-4a0c-8c17-de1a3a660196 to datanode:6619ce5a-7401-4afb-ab66-de9ef56aa415
2020-04-15 04:20:08,848 [RatisPipelineUtilsThread] WARN  events.EventQueue (EventQueue.java:fireEvent(186)) - No event handler registered for event TypedEvent{payloadType=CommandForDatanode, name='Datanode_Command'}
2020-04-15 04:20:08,893 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 552277c5-7d67-4a0c-8c17-de1a3a660196, Nodes: 6619ce5a-7401-4afb-ab66-de9ef56aa415{ip: 2.3.255.95, host: localhost-2.3.255.95, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:20:08.848Z]
2020-04-15 04:20:08,894 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=6f81d3ce-68d8-4c3f-9ba6-055c5841ffbe to datanode:4913a4a2-4a2d-417b-a43d-fe94789f76fe
2020-04-15 04:20:08,894 [RatisPipelineUtilsThread] WARN  events.EventQueue (EventQueue.java:fireEvent(186)) - No event handler registered for event TypedEvent{payloadType=CommandForDatanode, name='Datanode_Command'}
2020-04-15 04:20:08,906 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 6f81d3ce-68d8-4c3f-9ba6-055c5841ffbe, Nodes: 4913a4a2-4a2d-417b-a43d-fe94789f76fe{ip: 176.65.20.24, host: localhost-176.65.20.24, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:20:08.894Z]
2020-04-15 04:20:08,906 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=8a2b80b0-a07b-4300-8705-e1f20b40bfdb to datanode:f79b807b-9bf4-45a7-96d4-0a3f3215eb48
2020-04-15 04:20:08,906 [RatisPipelineUtilsThread] WARN  events.EventQueue (EventQueue.java:fireEvent(186)) - No event handler registered for event TypedEvent{payloadType=CommandForDatanode, name='Datanode_Command'}
2020-04-15 04:20:08,907 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 8a2b80b0-a07b-4300-8705-e1f20b40bfdb, Nodes: f79b807b-9bf4-45a7-96d4-0a3f3215eb48{ip: 164.197.233.180, host: localhost-164.197.233.180, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:20:08.906Z]
2020-04-15 04:20:08,908 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=46e40097-91fe-4e6c-812f-6cc912b29d3d to datanode:984fd1e3-3f30-4d90-b077-ccd90ea3038c
2020-04-15 04:20:08,908 [RatisPipelineUtilsThread] WARN  events.EventQueue (EventQueue.java:fireEvent(186)) - No event handler registered for event TypedEvent{payloadType=CommandForDatanode, name='Datanode_Command'}
2020-04-15 04:20:08,908 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 46e40097-91fe-4e6c-812f-6cc912b29d3d, Nodes: 984fd1e3-3f30-4d90-b077-ccd90ea3038c{ip: 90.150.195.153, host: localhost-90.150.195.153, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:20:08.908Z]
2020-04-15 04:20:08,909 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=f00c114e-31a6-43e0-953b-0738142fc015 to datanode:250ee7a3-69f9-478f-96e6-fe41fc539658
2020-04-15 04:20:08,909 [RatisPipelineUtilsThread] WARN  events.EventQueue (EventQueue.java:fireEvent(186)) - No event handler registered for event TypedEvent{payloadType=CommandForDatanode, name='Datanode_Command'}
2020-04-15 04:20:08,910 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: f00c114e-31a6-43e0-953b-0738142fc015, Nodes: 250ee7a3-69f9-478f-96e6-fe41fc539658{ip: 32.34.186.10, host: localhost-32.34.186.10, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:20:08.909Z]
2020-04-15 04:20:08,921 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=efdc2e0c-ce88-483a-9820-59477947eb28 to datanode:cfe06f51-2df6-4b8f-8434-7472103af3e6
2020-04-15 04:20:08,921 [RatisPipelineUtilsThread] WARN  events.EventQueue (EventQueue.java:fireEvent(186)) - No event handler registered for event TypedEvent{payloadType=CommandForDatanode, name='Datanode_Command'}
2020-04-15 04:20:08,922 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: efdc2e0c-ce88-483a-9820-59477947eb28, Nodes: cfe06f51-2df6-4b8f-8434-7472103af3e6{ip: 48.55.105.213, host: localhost-48.55.105.213, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:20:08.921Z]
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2020-04-15 04:20:23,072 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-15 04:20:23,853 [Socket Reader #1 for port 42839] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42839
2020-04-15 04:20:27,434 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-15 04:20:27,479 [Socket Reader #1 for port 35655] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35655
2020-04-15 04:20:27,742 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-15 04:20:27,743 [Socket Reader #1 for port 40467] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 40467
2020-04-15 04:20:27,926 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(171)) - Starting Web-server for scm at: http://0.0.0.0:0
2020-04-15 04:20:28,125 [main] INFO  util.log (Log.java:initialized(169)) - Logging initialized @139935ms to org.eclipse.jetty.util.log.Slf4jLog
2020-04-15 04:20:33,897 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-15 04:20:34,651 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-04-15 04:20:34,781 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-04-15 04:20:34,967 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(946)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context scm
2020-04-15 04:20:34,978 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-15 04:20:34,978 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-15 04:20:36,553 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(773)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:40467
2020-04-15 04:20:37,029 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2020-04-15 04:20:41,163 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-04-15 04:20:41,163 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2020-04-15 04:20:51,184 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(155)) - RPC server for Client  is listening at /0.0.0.0:40467
2020-04-15 04:20:51,196 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2020-04-15 04:20:51,229 [IPC Server listener on 40467] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 40467: starting
2020-04-15 04:20:51,588 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(785)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:35655
2020-04-15 04:20:51,862 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(149)) - RPC server for Block Protocol is listening at /0.0.0.0:35655
2020-04-15 04:20:52,260 [IPC Server listener on 35655] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 35655: starting
2020-04-15 04:20:52,260 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2020-04-15 04:20:52,567 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(791)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:42839
2020-04-15 04:20:52,600 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(172)) - RPC server for DataNodes is listening at /0.0.0.0:42839
2020-04-15 04:20:52,944 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2020-04-15 04:20:52,944 [IPC Server listener on 42839] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42839: starting
2020-04-15 04:20:53,472 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1188)) - Jetty bound to port 45787
2020-04-15 04:20:53,838 [main] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-04-15 04:20:55,837 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-04-15 04:20:55,838 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-04-15 04:20:56,374 [main] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-04-15 04:20:58,617 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@3bc22ada{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-04-15 04:20:58,629 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@568514f{static,/static,file:///github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2020-04-15 04:20:59,814 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@78464205{scm,/,file:///github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2020-04-15 04:21:01,321 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@155770e0{HTTP/1.1,[http/1.1]}{0.0.0.0:45787}
2020-04-15 04:21:01,322 [main] INFO  server.Server (Server.java:doStart(399)) - Started @173133ms
2020-04-15 04:21:02,412 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2020-04-15 04:21:02,445 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2020-04-15 04:21:03,159 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(285)) - HTTP server of scm listening at http://0.0.0.0:45787
2020-04-15 04:21:03,893 [main] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(225)) - SCM exiting safe mode.
2020-04-15 04:21:04,287 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@21ea8719] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-15 04:21:07,942 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@21ea8719] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 1999ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=1506ms
GC pool 'PS Scavenge' had collection(s): count=1 time=17ms
2020-04-15 04:21:22,346 [main] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 28617a32-47c0-4fc3-ada0-51eb2f5fa5a9, Nodes: 984fd1e3-3f30-4d90-b077-ccd90ea3038c{ip: 90.150.195.153, host: localhost-90.150.195.153, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN, leaderId:null, CreationTimestamp2020-04-15T04:21:22.249Z]
2020-04-15 04:21:29,749 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:21:29,829 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:21:29,829 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:21:29,941 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(126)) - Loading file from sun.misc.CompoundEnumeration@73340f6c
2020-04-15 04:21:29,941 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(172)) - Loading network topology layer schema file
2020-04-15 04:21:30,902 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(73)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2020-04-15 04:21:30,904 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(73)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2020-04-15 04:21:32,780 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 1 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:21:34,055 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2020-04-15 04:21:34,500 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(59)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2020-04-15 04:21:34,512 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:21:34,631 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(167)) - No pipeline exists in current db
2020-04-15 04:21:34,708 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:21:34,858 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:<init>(88)) - Total pipeline count is 0, healthy pipeline threshold count is 0
2020-04-15 04:21:34,907 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:<init>(79)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2020-04-15 04:21:34,933 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-15 04:21:34,956 [Socket Reader #1 for port 36627] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36627
2020-04-15 04:21:35,109 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-15 04:21:35,121 [Socket Reader #1 for port 39547] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 39547
2020-04-15 04:21:35,134 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-15 04:21:35,222 [Socket Reader #1 for port 36825] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 36825
2020-04-15 04:21:35,312 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(171)) - Starting Web-server for scm at: http://0.0.0.0:0
2020-04-15 04:21:35,383 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-15 04:21:35,504 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-04-15 04:21:35,518 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-04-15 04:21:35,563 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(946)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context scm
2020-04-15 04:21:35,574 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-15 04:21:35,574 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-15 04:21:35,767 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(773)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:36825
2020-04-15 04:21:35,801 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2020-04-15 04:21:35,819 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(155)) - RPC server for Client  is listening at /0.0.0.0:36825
2020-04-15 04:21:35,820 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2020-04-15 04:21:35,820 [IPC Server listener on 36825] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36825: starting
2020-04-15 04:21:35,914 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(785)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:39547
2020-04-15 04:21:35,926 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(149)) - RPC server for Block Protocol is listening at /0.0.0.0:39547
2020-04-15 04:21:35,928 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2020-04-15 04:21:35,937 [IPC Server listener on 39547] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 39547: starting
2020-04-15 04:21:35,944 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(791)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:36627
2020-04-15 04:21:35,944 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(172)) - RPC server for DataNodes is listening at /0.0.0.0:36627
2020-04-15 04:21:35,957 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2020-04-15 04:21:35,957 [IPC Server listener on 36627] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 36627: starting
2020-04-15 04:21:35,997 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1188)) - Jetty bound to port 34473
2020-04-15 04:21:35,997 [main] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-04-15 04:21:36,000 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-04-15 04:21:36,000 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-04-15 04:21:36,000 [main] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-04-15 04:21:36,013 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@3e217bf7{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-04-15 04:21:36,014 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@306b2912{static,/static,file:///github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2020-04-15 04:21:36,174 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@8b81bd3{scm,/,file:///github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2020-04-15 04:21:36,533 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@26ab1ea4{HTTP/1.1,[http/1.1]}{0.0.0.0:34473}
2020-04-15 04:21:36,555 [main] INFO  server.Server (Server.java:doStart(399)) - Started @208366ms
2020-04-15 04:21:36,556 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-04-15 04:21:36,687 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(285)) - HTTP server of scm listening at http://0.0.0.0:34473
2020-04-15 04:21:37,049 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:21:37,050 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36ef1d8d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-15 04:21:41,628 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:21:44,573 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:21:47,379 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(104)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2020-04-15 04:21:47,380 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(207)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2020-04-15 04:21:47,401 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(237)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2020-04-15 04:21:47,403 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:21:47,415 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:21:51,559 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:21:56,225 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:22:08,324 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:22:11,270 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:22:13,907 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:22:18,512 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-15 04:22:18,534 [Socket Reader #1 for port 41617] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 41617
2020-04-15 04:22:24,226 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2020-04-15 04:22:24,277 [main] INFO  om.OzoneManager (OzoneManager.java:start(1111)) - OzoneManager RPC server is listening at localhost/127.0.0.1:41617
2020-04-15 04:22:25,105 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2020-04-15 04:22:25,106 [IPC Server listener on 41617] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 41617: starting
2020-04-15 04:22:26,180 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(171)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2020-04-15 04:22:26,557 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-15 04:22:26,611 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-04-15 04:22:26,767 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-04-15 04:22:26,825 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(946)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2020-04-15 04:22:26,825 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-15 04:22:26,825 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-15 04:22:27,239 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1188)) - Jetty bound to port 38679
2020-04-15 04:22:27,240 [main] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-04-15 04:22:27,365 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-04-15 04:22:27,366 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-04-15 04:22:27,366 [main] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-04-15 04:22:27,378 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@1310db90{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-04-15 04:22:27,378 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@1c8044a1{static,/static,file:///github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2020-04-15 04:22:27,506 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@7c1b8b82{ozoneManager,/,file:///github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2020-04-15 04:22:27,592 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@69e12888{HTTP/1.1,[http/1.1]}{0.0.0.0:38679}
2020-04-15 04:22:27,625 [main] INFO  server.Server (Server.java:doStart(399)) - Started @259435ms
2020-04-15 04:22:27,625 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-04-15 04:22:27,629 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(285)) - HTTP server of ozoneManager listening at http://0.0.0.0:38679
2020-04-15 04:22:28,356 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:22:31,437 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:22:32,957 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:22:33,038 [main] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2020-04-15 04:22:33,342 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-04-15 04:22:37,103 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(204)) - HddsDatanodeService host:edabee8e3155 ip:172.17.0.2
2020-04-15 04:22:39,214 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:22:41,384 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:22:45,269 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:22:46,373 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(177)) - Creating Volume: /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-0/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-04-15 04:22:46,744 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(188)) - Added Volume : /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-0/data-0/containers/hdds to VolumeSet
2020-04-15 04:22:46,791 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-0/data-0/containers/hdds
2020-04-15 04:22:48,344 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-0/data-0/containers/hdds
2020-04-15 04:22:52,937 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:22:55,287 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-04-15 04:22:57,016 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:22:58,754 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-04-15 04:22:58,858 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-04-15 04:22:58,859 [main] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-04-15 04:22:58,859 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-04-15 04:22:58,860 [main] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-04-15 04:22:58,905 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-04-15 04:22:59,886 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:00,166 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:07,135 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:10,348 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:12,228 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:13,466 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:16,024 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-0/data/ratis] (custom)
2020-04-15 04:23:16,095 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:18,157 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:19,530 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(171)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-04-15 04:23:19,668 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-15 04:23:19,733 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-04-15 04:23:19,813 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-04-15 04:23:19,826 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(946)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2020-04-15 04:23:19,826 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-15 04:23:19,826 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-15 04:23:19,828 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1188)) - Jetty bound to port 37289
2020-04-15 04:23:19,828 [main] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-04-15 04:23:19,852 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-04-15 04:23:19,852 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-04-15 04:23:19,852 [main] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-04-15 04:23:19,906 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@5242f806{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-04-15 04:23:19,907 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@4d2c2c2b{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-04-15 04:23:20,655 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@55698d56{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-37289-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-8781581053180687594.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-04-15 04:23:20,798 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@7a376350{HTTP/1.1,[http/1.1]}{0.0.0.0:37289}
2020-04-15 04:23:20,831 [main] INFO  server.Server (Server.java:doStart(399)) - Started @312642ms
2020-04-15 04:23:20,831 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-04-15 04:23:20,834 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(285)) - HTTP server of hddsDatanode listening at http://0.0.0.0:37289
2020-04-15 04:23:20,878 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-04-15 04:23:20,992 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(204)) - HddsDatanodeService host:edabee8e3155 ip:172.17.0.2
2020-04-15 04:23:21,605 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(177)) - Creating Volume: /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-1/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-04-15 04:23:21,793 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(188)) - Added Volume : /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-1/data-0/containers/hdds to VolumeSet
2020-04-15 04:23:21,815 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-1/data-0/containers/hdds
2020-04-15 04:23:21,859 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-1/data-0/containers/hdds
2020-04-15 04:23:22,784 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:23,160 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-04-15 04:23:23,204 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@598cb221] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-15 04:23:23,226 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-04-15 04:23:23,227 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-04-15 04:23:23,227 [main] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-04-15 04:23:23,227 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-04-15 04:23:23,227 [main] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-04-15 04:23:23,228 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-04-15 04:23:23,261 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-1/data/ratis] (custom)
2020-04-15 04:23:23,323 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(171)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-04-15 04:23:23,598 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-15 04:23:23,928 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-04-15 04:23:24,564 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-04-15 04:23:24,586 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(946)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2020-04-15 04:23:24,629 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-15 04:23:24,629 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-15 04:23:24,630 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1188)) - Jetty bound to port 35557
2020-04-15 04:23:24,630 [main] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-04-15 04:23:24,654 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-04-15 04:23:24,654 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-04-15 04:23:24,654 [main] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-04-15 04:23:24,688 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@6973cb98{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-04-15 04:23:24,689 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@5f013be0{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-04-15 04:23:25,809 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@41a33cc9{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-35557-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-6201010932267802663.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-04-15 04:23:25,915 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@48186c05{HTTP/1.1,[http/1.1]}{0.0.0.0:35557}
2020-04-15 04:23:25,937 [main] INFO  server.Server (Server.java:doStart(399)) - Started @317748ms
2020-04-15 04:23:25,937 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-04-15 04:23:25,973 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(285)) - HTTP server of hddsDatanode listening at http://0.0.0.0:35557
2020-04-15 04:23:25,997 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-04-15 04:23:26,103 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(204)) - HddsDatanodeService host:edabee8e3155 ip:172.17.0.2
2020-04-15 04:23:26,133 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(177)) - Creating Volume: /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-2/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-04-15 04:23:26,133 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(188)) - Added Volume : /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-2/data-0/containers/hdds to VolumeSet
2020-04-15 04:23:26,145 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-2/data-0/containers/hdds
2020-04-15 04:23:26,145 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@20b9aff0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-15 04:23:26,283 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-2/data-0/containers/hdds
2020-04-15 04:23:26,803 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:start(232)) - Unable to finish the execution.
java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.get(FutureTask.java:205)
	at org.apache.hadoop.ozone.container.common.states.datanode.InitDatanodeState.await(InitDatanodeState.java:187)
	at org.apache.hadoop.ozone.container.common.states.datanode.InitDatanodeState.await(InitDatanodeState.java:51)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:420)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:386)
	at java.lang.Thread.run(Thread.java:748)
2020-04-15 04:23:27,091 [Datanode State Machine Thread - 1] WARN  statemachine.SCMConnectionManager (SCMConnectionManager.java:addSCMServer(137)) - Trying to add an existing SCM Machine to Machines group. Ignoring the request.
2020-04-15 04:23:27,280 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-04-15 04:23:27,323 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-04-15 04:23:27,323 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-04-15 04:23:27,323 [main] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-04-15 04:23:27,324 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-04-15 04:23:27,324 [main] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-04-15 04:23:27,324 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-04-15 04:23:27,326 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-2/data/ratis] (custom)
2020-04-15 04:23:27,439 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(171)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-04-15 04:23:27,462 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(147)) - DatanodeDetails is persisted to /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-0/meta/datanode.id
2020-04-15 04:23:27,879 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-15 04:23:27,932 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-04-15 04:23:27,955 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-04-15 04:23:27,956 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(946)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2020-04-15 04:23:27,956 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-15 04:23:27,956 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-15 04:23:27,957 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1188)) - Jetty bound to port 37761
2020-04-15 04:23:27,957 [main] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-04-15 04:23:27,991 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-04-15 04:23:27,991 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-04-15 04:23:27,991 [main] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-04-15 04:23:28,003 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@18f5c2f9{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-04-15 04:23:28,003 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@d628eff{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-04-15 04:23:28,159 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(147)) - DatanodeDetails is persisted to /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-1/meta/datanode.id
2020-04-15 04:23:28,147 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:start(232)) - Unable to finish the execution.
java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.get(FutureTask.java:205)
	at org.apache.hadoop.ozone.container.common.states.datanode.InitDatanodeState.await(InitDatanodeState.java:187)
	at org.apache.hadoop.ozone.container.common.states.datanode.InitDatanodeState.await(InitDatanodeState.java:51)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:420)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:386)
	at java.lang.Thread.run(Thread.java:748)
2020-04-15 04:23:28,342 [Datanode State Machine Thread - 0] WARN  statemachine.SCMConnectionManager (SCMConnectionManager.java:addSCMServer(137)) - Trying to add an existing SCM Machine to Machines group. Ignoring the request.
2020-04-15 04:23:29,419 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:29,546 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@3a90928{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-37761-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-7324652326921143531.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-04-15 04:23:30,205 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@3ad36b98{HTTP/1.1,[http/1.1]}{0.0.0.0:37761}
2020-04-15 04:23:30,205 [main] INFO  server.Server (Server.java:doStart(399)) - Started @322016ms
2020-04-15 04:23:30,525 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-04-15 04:23:30,606 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(285)) - HTTP server of hddsDatanode listening at http://0.0.0.0:37761
2020-04-15 04:23:30,674 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:30,674 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:30,677 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1012115d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-15 04:23:30,772 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(147)) - DatanodeDetails is persisted to /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-19ef148c-ce34-4404-b98c-24c6d5de95fa/datanode-2/meta/datanode.id
2020-04-15 04:23:31,698 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:31,981 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:33,331 [Datanode State Machine Thread - 0] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(217)) - Unable to communicate to SCM server at 0.0.0.0:36627 for past 0 seconds.
java.net.SocketTimeoutException: Call From edabee8e3155/172.17.0.2 to 0.0.0.0:36627 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35570 remote=/0.0.0.0:36627]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35570 remote=/0.0.0.0:36627]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2020-04-15 04:23:33,647 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:33,494 [Datanode State Machine Thread - 0] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(217)) - Unable to communicate to SCM server at 0.0.0.0:36627 for past 0 seconds.
java.net.SocketTimeoutException: Call From edabee8e3155/172.17.0.2 to 0.0.0.0:36627 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35570 remote=/0.0.0.0:36627]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35570 remote=/0.0.0.0:36627]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2020-04-15 04:23:33,873 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:34,629 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:34,901 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:35,009 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:36,067 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:36,067 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:36,547 [IPC Server handler 19 on 36627] WARN  ipc.Server (Server.java:processResponse(1523)) - IPC Server handler 19 on 36627, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.17.0.2:35570: output error
2020-04-15 04:23:36,779 [IPC Server handler 19 on 36627] INFO  ipc.Server (Server.java:run(2695)) - IPC Server handler 19 on 36627 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2020-04-15 04:23:36,856 [IPC Server handler 13 on 36627] WARN  ipc.Server (Server.java:processResponse(1523)) - IPC Server handler 13 on 36627, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.17.0.2:35570: output error
2020-04-15 04:23:36,856 [IPC Server handler 13 on 36627] INFO  ipc.Server (Server.java:run(2695)) - IPC Server handler 13 on 36627 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2020-04-15 04:23:37,354 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:37,527 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:38,766 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:38,821 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:38,864 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:39,320 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:39,411 [Datanode State Machine Thread - 1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-04-15 04:23:39,433 [Datanode State Machine Thread - 1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-04-15 04:23:39,747 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-04-15 04:23:39,886 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:39,909 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:40,157 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:40,163 [Datanode State Machine Thread - 1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-04-15 04:23:40,252 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-04-15 04:23:40,342 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(406)) - Starting XceiverServerRatis c60a4125-c5e9-407e-b7ee-21a3ad869205 at port 0
2020-04-15 04:23:40,186 [Datanode State Machine Thread - 1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-04-15 04:23:40,355 [Datanode State Machine Thread - 1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(406)) - Starting XceiverServerRatis ba9295ef-0504-497a-a6c7-3b6ac81dc313 at port 0
2020-04-15 04:23:40,378 [Datanode State Machine Thread - 1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(406)) - Starting XceiverServerRatis 79cb4a0c-bd79-4cf6-b94c-4687eac8248c at port 0
2020-04-15 04:23:41,110 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:41,165 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:42,116 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - c60a4125-c5e9-407e-b7ee-21a3ad869205: start RPC server
2020-04-15 04:23:42,116 [Datanode State Machine Thread - 1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - ba9295ef-0504-497a-a6c7-3b6ac81dc313: start RPC server
2020-04-15 04:23:42,172 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:42,116 [Datanode State Machine Thread - 1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 79cb4a0c-bd79-4cf6-b94c-4687eac8248c: start RPC server
2020-04-15 04:23:42,183 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:43,257 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:43,294 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:44,324 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:44,324 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:45,375 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:45,430 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:46,434 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:46,434 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:47,875 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:48,008 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:48,096 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:49,125 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:49,565 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:50,608 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:50,630 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:51,642 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:51,642 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:51,972 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - c60a4125-c5e9-407e-b7ee-21a3ad869205: GrpcService started, listening on 0.0.0.0/0.0.0.0:46837
2020-04-15 04:23:52,005 [Datanode State Machine Thread - 1] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 79cb4a0c-bd79-4cf6-b94c-4687eac8248c: GrpcService started, listening on 0.0.0.0/0.0.0.0:37905
2020-04-15 04:23:52,008 [Datanode State Machine Thread - 1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - XceiverServerRatis 79cb4a0c-bd79-4cf6-b94c-4687eac8248c is started using port 37905
2020-04-15 04:23:52,005 [Datanode State Machine Thread - 1] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - ba9295ef-0504-497a-a6c7-3b6ac81dc313: GrpcService started, listening on 0.0.0.0/0.0.0.0:38185
2020-04-15 04:23:52,010 [Datanode State Machine Thread - 1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - XceiverServerRatis ba9295ef-0504-497a-a6c7-3b6ac81dc313 is started using port 38185
2020-04-15 04:23:52,010 [Datanode State Machine Thread - 1] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 79cb4a0c-bd79-4cf6-b94c-4687eac8248c is started using port 38395
2020-04-15 04:23:52,009 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - XceiverServerRatis c60a4125-c5e9-407e-b7ee-21a3ad869205 is started using port 46837
2020-04-15 04:23:52,733 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:52,733 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:52,734 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:52,878 [Datanode State Machine Thread - 1] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc ba9295ef-0504-497a-a6c7-3b6ac81dc313 is started using port 46691
2020-04-15 04:23:52,889 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc c60a4125-c5e9-407e-b7ee-21a3ad869205 is started using port 45575
2020-04-15 04:23:53,815 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:23:53,816 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:54,694 [IPC Server handler 1 on 36627] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/79cb4a0c-bd79-4cf6-b94c-4687eac8248c
2020-04-15 04:23:54,728 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=2bc48bc4-213d-4b00-bf79-706510a7856b to datanode:79cb4a0c-bd79-4cf6-b94c-4687eac8248c
2020-04-15 04:23:54,739 [IPC Server handler 1 on 36627] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 79cb4a0c-bd79-4cf6-b94c-4687eac8248c{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}
2020-04-15 04:23:54,932 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 1 of 3 DN Heartbeats.
2020-04-15 04:23:55,235 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:55,257 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 2bc48bc4-213d-4b00-bf79-706510a7856b, Nodes: 79cb4a0c-bd79-4cf6-b94c-4687eac8248c{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:23:54.728Z]
2020-04-15 04:23:55,260 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:55,260 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=e7f72b82-5352-4cd6-9dba-f2f7693622f8 to datanode:ba9295ef-0504-497a-a6c7-3b6ac81dc313
2020-04-15 04:23:55,327 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: e7f72b82-5352-4cd6-9dba-f2f7693622f8, Nodes: ba9295ef-0504-497a-a6c7-3b6ac81dc313{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:23:55.260Z]
2020-04-15 04:23:55,372 [IPC Server handler 6 on 36627] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/ba9295ef-0504-497a-a6c7-3b6ac81dc313
2020-04-15 04:23:55,372 [IPC Server handler 6 on 36627] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : ba9295ef-0504-497a-a6c7-3b6ac81dc313{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}
2020-04-15 04:23:55,375 [IPC Server handler 19 on 36627] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/c60a4125-c5e9-407e-b7ee-21a3ad869205
2020-04-15 04:23:55,375 [IPC Server handler 19 on 36627] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : c60a4125-c5e9-407e-b7ee-21a3ad869205{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}
2020-04-15 04:23:55,640 [Datanode State Machine Thread - 9] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(217)) - Unable to communicate to SCM server at 0.0.0.0:36627 for past 0 seconds.
java.net.SocketTimeoutException: Call From edabee8e3155/172.17.0.2 to 0.0.0.0:36627 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35656 remote=0.0.0.0/0.0.0.0:36627]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.register(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:173)
	at org.apache.hadoop.ozone.container.common.states.endpoint.RegisterEndpointTask.call(RegisterEndpointTask.java:122)
	at org.apache.hadoop.ozone.container.common.states.endpoint.RegisterEndpointTask.call(RegisterEndpointTask.java:47)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35656 remote=0.0.0.0/0.0.0.0:36627]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2020-04-15 04:23:57,145 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:23:57,146 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:57,168 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36ef1d8d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 1431ms
No GCs detected
2020-04-15 04:23:57,259 [Datanode State Machine Thread - 8] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(217)) - Unable to communicate to SCM server at 0.0.0.0:36627 for past 0 seconds.
java.net.SocketTimeoutException: Call From edabee8e3155/172.17.0.2 to 0.0.0.0:36627 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35656 remote=0.0.0.0/0.0.0.0:36627]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.register(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:173)
	at org.apache.hadoop.ozone.container.common.states.endpoint.RegisterEndpointTask.call(RegisterEndpointTask.java:122)
	at org.apache.hadoop.ozone.container.common.states.endpoint.RegisterEndpointTask.call(RegisterEndpointTask.java:47)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35656 remote=0.0.0.0/0.0.0.0:36627]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2020-04-15 04:23:57,262 [Datanode State Machine Thread - 9] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(217)) - Unable to communicate to SCM server at 0.0.0.0:36627 for past 0 seconds.
java.net.SocketTimeoutException: Call From edabee8e3155/172.17.0.2 to 0.0.0.0:36627 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35656 remote=0.0.0.0/0.0.0.0:36627]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.register(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:173)
	at org.apache.hadoop.ozone.container.common.states.endpoint.RegisterEndpointTask.call(RegisterEndpointTask.java:122)
	at org.apache.hadoop.ozone.container.common.states.endpoint.RegisterEndpointTask.call(RegisterEndpointTask.java:47)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35656 remote=0.0.0.0/0.0.0.0:36627]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2020-04-15 04:23:57,262 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2020-04-15 04:23:56,954 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - ContainerSafeModeRule rule is successfully validated
2020-04-15 04:23:58,022 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - DataNodeSafeModeRule rule is successfully validated
2020-04-15 04:23:58,022 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(210)) - All SCM safe mode pre check rules have passed
2020-04-15 04:23:58,022 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - DataNodeSafeModeRule rule is successfully validated
2020-04-15 04:23:58,023 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - DataNodeSafeModeRule rule is successfully validated
2020-04-15 04:23:58,049 [IPC Server handler 6 on 36627] WARN  ipc.Server (Server.java:processResponse(1523)) - IPC Server handler 6 on 36627, call Call#7 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.17.0.2:35656: output error
2020-04-15 04:23:58,049 [IPC Server handler 6 on 36627] INFO  ipc.Server (Server.java:run(2695)) - IPC Server handler 6 on 36627 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2020-04-15 04:23:58,049 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:23:58,118 [IPC Server handler 19 on 36627] WARN  ipc.Server (Server.java:processResponse(1523)) - IPC Server handler 19 on 36627, call Call#8 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.17.0.2:35656: output error
2020-04-15 04:23:58,387 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:23:58,399 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:58,399 [IPC Server handler 19 on 36627] INFO  ipc.Server (Server.java:run(2695)) - IPC Server handler 19 on 36627 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2020-04-15 04:23:58,421 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - ContainerSafeModeRule rule is successfully validated
2020-04-15 04:23:58,524 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - DataNodeSafeModeRule rule is successfully validated
2020-04-15 04:23:58,547 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - DataNodeSafeModeRule rule is successfully validated
2020-04-15 04:23:58,547 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - ContainerSafeModeRule rule is successfully validated
2020-04-15 04:23:58,547 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - ContainerSafeModeRule rule is successfully validated
2020-04-15 04:23:58,547 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - ContainerSafeModeRule rule is successfully validated
2020-04-15 04:23:58,591 [IPC Server handler 1 on 36627] WARN  ipc.Server (Server.java:processResponse(1523)) - IPC Server handler 1 on 36627, call Call#6 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.17.0.2:35656: output error
2020-04-15 04:23:58,591 [IPC Server handler 1 on 36627] INFO  ipc.Server (Server.java:run(2695)) - IPC Server handler 1 on 36627 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2020-04-15 04:23:58,603 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=3e800165-c30f-4336-b889-bc82f1b9c91e to datanode:c60a4125-c5e9-407e-b7ee-21a3ad869205
2020-04-15 04:23:58,602 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - ContainerSafeModeRule rule is successfully validated
2020-04-15 04:23:58,801 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - DataNodeSafeModeRule rule is successfully validated
2020-04-15 04:23:58,802 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 3e800165-c30f-4336-b889-bc82f1b9c91e, Nodes: c60a4125-c5e9-407e-b7ee-21a3ad869205{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:23:58.603Z]
2020-04-15 04:23:59,438 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:23:59,439 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:23:59,953 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=163105af-521c-4f62-b861-e0bf13f4c66f to datanode:c60a4125-c5e9-407e-b7ee-21a3ad869205
2020-04-15 04:23:59,954 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=163105af-521c-4f62-b861-e0bf13f4c66f to datanode:ba9295ef-0504-497a-a6c7-3b6ac81dc313
2020-04-15 04:23:59,954 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=163105af-521c-4f62-b861-e0bf13f4c66f to datanode:79cb4a0c-bd79-4cf6-b94c-4687eac8248c
2020-04-15 04:24:00,020 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 163105af-521c-4f62-b861-e0bf13f4c66f, Nodes: c60a4125-c5e9-407e-b7ee-21a3ad869205{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}ba9295ef-0504-497a-a6c7-3b6ac81dc313{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}79cb4a0c-bd79-4cf6-b94c-4687eac8248c{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:23:59.942Z]
2020-04-15 04:24:00,569 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:00,570 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:00,725 [Datanode State Machine Thread - 8] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(217)) - Unable to communicate to SCM server at 0.0.0.0:36627 for past 0 seconds.
java.net.SocketTimeoutException: Call From edabee8e3155/172.17.0.2 to 0.0.0.0:36627 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35662 remote=/0.0.0.0:36627]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:148)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:145)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:76)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35662 remote=/0.0.0.0:36627]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2020-04-15 04:24:00,725 [Datanode State Machine Thread - 8] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(217)) - Unable to communicate to SCM server at 0.0.0.0:36627 for past 0 seconds.
java.net.SocketTimeoutException: Call From edabee8e3155/172.17.0.2 to 0.0.0.0:36627 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35662 remote=/0.0.0.0:36627]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:148)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:145)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:76)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35662 remote=/0.0.0.0:36627]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2020-04-15 04:24:00,827 [Datanode State Machine Thread - 6] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(217)) - Unable to communicate to SCM server at 0.0.0.0:36627 for past 0 seconds.
java.net.SocketTimeoutException: Call From edabee8e3155/172.17.0.2 to 0.0.0.0:36627 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35662 remote=/0.0.0.0:36627]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:148)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:145)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:76)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35662 remote=/0.0.0.0:36627]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2020-04-15 04:24:01,248 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:24:01,921 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:02,088 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:24:02,441 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:03,442 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:03,443 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:04,041 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:24:04,778 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:05,073 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:06,011 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:24:06,097 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:06,097 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:06,669 [IPC Server handler 16 on 36627] WARN  ipc.Server (Server.java:processResponse(1523)) - IPC Server handler 16 on 36627, call Call#20 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.17.0.2:35686: output error
2020-04-15 04:24:07,490 [IPC Server handler 4 on 36627] WARN  ipc.Server (Server.java:processResponse(1523)) - IPC Server handler 4 on 36627, call Call#18 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.17.0.2:35686: output error
2020-04-15 04:24:07,490 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:07,490 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:07,490 [IPC Server handler 16 on 36627] INFO  ipc.Server (Server.java:run(2695)) - IPC Server handler 16 on 36627 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:272)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2020-04-15 04:24:07,490 [IPC Server handler 13 on 36627] WARN  ipc.Server (Server.java:processResponse(1523)) - IPC Server handler 13 on 36627, call Call#19 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.17.0.2:35686: output error
2020-04-15 04:24:08,047 [IPC Server handler 13 on 36627] INFO  ipc.Server (Server.java:run(2695)) - IPC Server handler 13 on 36627 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2020-04-15 04:24:07,490 [IPC Server handler 4 on 36627] INFO  ipc.Server (Server.java:run(2695)) - IPC Server handler 4 on 36627 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2020-04-15 04:24:08,680 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:08,769 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:09,775 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:09,833 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:11,011 [IPC Server handler 9 on 36627] WARN  ipc.Server (Server.java:processResponse(1523)) - IPC Server handler 9 on 36627, call Call#14 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.17.0.2:35662: output error
2020-04-15 04:24:11,012 [IPC Server handler 9 on 36627] INFO  ipc.Server (Server.java:run(2695)) - IPC Server handler 9 on 36627 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2020-04-15 04:24:11,014 [IPC Server handler 6 on 36627] WARN  ipc.Server (Server.java:processResponse(1523)) - IPC Server handler 6 on 36627, call Call#16 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.17.0.2:35684: output error
2020-04-15 04:24:11,015 [IPC Server handler 6 on 36627] INFO  ipc.Server (Server.java:run(2695)) - IPC Server handler 6 on 36627 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2020-04-15 04:24:11,015 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:11,015 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:11,043 [IPC Server handler 5 on 36627] WARN  ipc.Server (Server.java:processResponse(1523)) - IPC Server handler 5 on 36627, call Call#15 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.17.0.2:35684: output error
2020-04-15 04:24:11,044 [IPC Server handler 7 on 36627] WARN  ipc.Server (Server.java:processResponse(1523)) - IPC Server handler 7 on 36627, call Call#13 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.17.0.2:35662: output error
2020-04-15 04:24:11,044 [IPC Server handler 7 on 36627] INFO  ipc.Server (Server.java:run(2695)) - IPC Server handler 7 on 36627 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2020-04-15 04:24:11,044 [IPC Server handler 1 on 36627] WARN  ipc.Server (Server.java:processResponse(1523)) - IPC Server handler 1 on 36627, call Call#12 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.17.0.2:35662: output error
2020-04-15 04:24:11,044 [IPC Server handler 1 on 36627] INFO  ipc.Server (Server.java:run(2695)) - IPC Server handler 1 on 36627 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2020-04-15 04:24:11,044 [IPC Server handler 5 on 36627] INFO  ipc.Server (Server.java:run(2695)) - IPC Server handler 5 on 36627 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2020-04-15 04:24:11,045 [IPC Server handler 3 on 36627] WARN  ipc.Server (Server.java:processResponse(1523)) - IPC Server handler 3 on 36627, call Call#17 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.17.0.2:35684: output error
2020-04-15 04:24:11,109 [IPC Server handler 3 on 36627] INFO  ipc.Server (Server.java:run(2695)) - IPC Server handler 3 on 36627 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2020-04-15 04:24:12,034 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:12,538 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:13,434 [Datanode State Machine Thread - 5] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(217)) - Unable to communicate to SCM server at 0.0.0.0:36627 for past 0 seconds.
java.net.SocketTimeoutException: Call From edabee8e3155/172.17.0.2 to 0.0.0.0:36627 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35700 remote=/0.0.0.0:36627]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:148)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:145)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:76)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35700 remote=/0.0.0.0:36627]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2020-04-15 04:24:13,545 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:13,747 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:13,659 [Datanode State Machine Thread - 8] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(217)) - Unable to communicate to SCM server at 0.0.0.0:36627 for past 0 seconds.
java.net.SocketTimeoutException: Call From edabee8e3155/172.17.0.2 to 0.0.0.0:36627 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35700 remote=/0.0.0.0:36627]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:148)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:145)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:76)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35700 remote=/0.0.0.0:36627]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2020-04-15 04:24:13,838 [Datanode State Machine Thread - 6] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(217)) - Unable to communicate to SCM server at 0.0.0.0:36627 for past 0 seconds.
java.net.SocketTimeoutException: Call From edabee8e3155/172.17.0.2 to 0.0.0.0:36627 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35700 remote=/0.0.0.0:36627]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:148)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:145)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:76)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:35700 remote=/0.0.0.0:36627]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2020-04-15 04:24:13,769 [IPC Server handler 16 on 36627] WARN  ipc.Server (Server.java:processResponse(1523)) - IPC Server handler 16 on 36627, call Call#39 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.17.0.2:35700: output error
2020-04-15 04:24:13,877 [IPC Server handler 16 on 36627] INFO  ipc.Server (Server.java:run(2695)) - IPC Server handler 16 on 36627 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
2020-04-15 04:24:14,860 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:14,861 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:15,869 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:15,870 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:16,900 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:16,965 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:17,976 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:18,019 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:18,790 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:24:19,111 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:19,220 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:20,238 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:20,302 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:21,353 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:21,569 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:22,291 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:24:22,779 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:22,779 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:23,780 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:23,780 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:24,476 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:24:24,828 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:24,890 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:24:24,972 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:25,976 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:26,009 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:27,010 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:27,021 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:28,021 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:28,022 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:29,039 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:29,040 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:30,065 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:30,065 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:31,068 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:31,069 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:32,144 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:32,219 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:33,230 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:33,241 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:34,464 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:34,465 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:35,517 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:35,572 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:36,582 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:36,646 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:37,707 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:37,751 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:38,764 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:38,807 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:39,812 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:39,908 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:40,921 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:40,953 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:42,009 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:42,020 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:43,031 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:43,079 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:44,079 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:44,080 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:44,900 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:24:45,121 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:45,216 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:46,217 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:46,217 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:47,218 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:47,218 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:48,240 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:48,240 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:49,250 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:49,328 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:50,340 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:50,340 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:51,405 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:51,417 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:52,428 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:52,428 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:53,468 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:53,480 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:54,505 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:54,527 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:55,539 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:55,539 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:56,541 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:56,542 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:57,603 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:57,604 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:58,625 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:58,669 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:24:59,673 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:24:59,705 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:00,477 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:25:00,734 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:00,767 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:01,799 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:01,893 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:02,911 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:03,008 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:04,078 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:04,121 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:05,154 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:05,231 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:06,235 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:06,334 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:07,362 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:07,363 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:08,365 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:08,523 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:09,958 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:25:10,177 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:10,177 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:11,188 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:11,232 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:12,244 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:12,298 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:13,761 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:13,784 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:14,794 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:14,875 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:15,886 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:15,927 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:16,927 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:17,004 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:18,026 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:18,091 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:19,126 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:19,191 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:20,202 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:20,202 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:21,202 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:21,231 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:22,250 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:22,435 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:23,437 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:23,437 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:24,452 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:24,507 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:25,508 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:25,508 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:26,508 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:26,541 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:27,555 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:27,697 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:28,708 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:28,719 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:29,217 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:25:29,720 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:29,731 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:30,735 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:25:30,735 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:25:31,962 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(387)) - Shutting down the Mini Ozone Cluster
2020-04-15 04:25:32,049 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(402)) - Stopping the Mini Ozone Cluster
2020-04-15 04:25:32,050 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(484)) - Stopping the OzoneManager
2020-04-15 04:25:32,050 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 41617
2020-04-15 04:25:32,063 [IPC Server listener on 41617] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 41617
2020-04-15 04:25:32,131 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(272)) - Stopping OMDoubleBuffer flush thread
2020-04-15 04:25:32,131 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2020-04-15 04:25:32,131 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(206)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2020-04-15 04:25:32,220 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service KeyDeletingService
2020-04-15 04:25:33,501 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@7c1b8b82{ozoneManager,/,null,UNAVAILABLE}{file:/github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2020-04-15 04:25:33,782 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@69e12888{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-15 04:25:33,847 [main] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-04-15 04:25:33,869 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@1c8044a1{static,/static,file:///github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2020-04-15 04:25:33,880 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@1310db90{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-04-15 04:25:33,906 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(461)) - Stopping the HddsDatanodes
2020-04-15 04:25:34,782 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(387)) - Ozone container server started.
2020-04-15 04:25:34,922 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:25:34,878 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(387)) - Ozone container server started.
2020-04-15 04:25:39,119 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(246)) - Attempting to stop container services.
2020-04-15 04:25:39,401 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(246)) - Attempting to stop container services.
2020-04-15 04:25:39,702 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - ba9295ef-0504-497a-a6c7-3b6ac81dc313: close
2020-04-15 04:25:39,713 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 79cb4a0c-bd79-4cf6-b94c-4687eac8248c: close
2020-04-15 04:25:39,726 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - ba9295ef-0504-497a-a6c7-3b6ac81dc313: shutdown server with port 38185 now
2020-04-15 04:25:39,737 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 79cb4a0c-bd79-4cf6-b94c-4687eac8248c: shutdown server with port 37905 now
2020-04-15 04:25:40,181 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 79cb4a0c-bd79-4cf6-b94c-4687eac8248c: shutdown server with port 37905 successfully
2020-04-15 04:25:40,711 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - ba9295ef-0504-497a-a6c7-3b6ac81dc313: shutdown server with port 38185 successfully
2020-04-15 04:25:42,908 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service BlockDeletingService
2020-04-15 04:25:43,205 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service BlockDeletingService
2020-04-15 04:25:43,343 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(435)) - Ozone container server stopped.
2020-04-15 04:25:43,378 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(435)) - Ozone container server stopped.
2020-04-15 04:25:43,617 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@41a33cc9{hddsDatanode,/,null,UNAVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-04-15 04:25:43,617 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@48186c05{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-15 04:25:43,625 [main] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-04-15 04:25:43,611 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@55698d56{hddsDatanode,/,null,UNAVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-04-15 04:25:43,810 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@5f013be0{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2020-04-15 04:25:43,921 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@6973cb98{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-04-15 04:25:43,973 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@7a376350{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-15 04:25:44,072 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-04-15 04:25:44,105 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@4d2c2c2b{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2020-04-15 04:25:44,106 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@5242f806{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-04-15 04:25:44,507 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(387)) - Ozone container server started.
2020-04-15 04:25:45,613 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:25:48,981 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(246)) - Attempting to stop container services.
2020-04-15 04:25:49,034 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - c60a4125-c5e9-407e-b7ee-21a3ad869205: close
2020-04-15 04:25:49,034 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - c60a4125-c5e9-407e-b7ee-21a3ad869205: shutdown server with port 46837 now
2020-04-15 04:25:49,134 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - c60a4125-c5e9-407e-b7ee-21a3ad869205: shutdown server with port 46837 successfully
2020-04-15 04:25:49,631 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service BlockDeletingService
2020-04-15 04:25:49,786 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(435)) - Ozone container server stopped.
2020-04-15 04:25:49,854 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@3a90928{hddsDatanode,/,null,UNAVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-04-15 04:25:49,867 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@3ad36b98{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-15 04:25:49,867 [main] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-04-15 04:25:49,867 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@d628eff{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2020-04-15 04:25:49,868 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@18f5c2f9{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-04-15 04:25:49,869 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(476)) - Stopping the StorageContainerManager
2020-04-15 04:25:49,870 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(816)) - Stopping Replication Manager Service.
2020-04-15 04:25:49,870 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(212)) - Replication Monitor Thread is not running.
2020-04-15 04:25:49,870 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(823)) - Stopping Lease Manager of the command watchers
2020-04-15 04:25:49,870 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping datanode service RPC server
2020-04-15 04:25:49,870 [CommandWatcher-LeaseManager#LeaseMonitor] ERROR lease.LeaseManager (LeaseManager.java:run(238)) - Execution was interrupted 
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:234)
	at java.lang.Thread.run(Thread.java:748)
2020-04-15 04:25:49,870 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(361)) - Stopping the RPC server for DataNodes
2020-04-15 04:25:49,871 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 36627
2020-04-15 04:25:49,884 [IPC Server listener on 36627] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 36627
2020-04-15 04:25:49,906 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2020-04-15 04:25:49,973 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(656)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2020-04-15 04:25:49,974 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(838)) - Stopping block service RPC server
2020-04-15 04:25:49,974 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(158)) - Stopping the RPC server for Block Protocol
2020-04-15 04:25:49,974 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 39547
2020-04-15 04:25:49,988 [IPC Server listener on 39547] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 39547
2020-04-15 04:25:49,988 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2020-04-15 04:25:49,989 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(845)) - Stopping the StorageContainerLocationProtocol RPC server
2020-04-15 04:25:49,989 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(164)) - Stopping the RPC server for Client Protocol
2020-04-15 04:25:49,989 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 36825
2020-04-15 04:25:50,003 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(852)) - Stopping Storage Container Manager HTTP server.
2020-04-15 04:25:50,014 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2020-04-15 04:25:50,025 [IPC Server listener on 36825] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 36825
2020-04-15 04:25:50,059 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@8b81bd3{scm,/,null,UNAVAILABLE}{file:/github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2020-04-15 04:25:50,070 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@26ab1ea4{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-15 04:25:50,071 [main] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-04-15 04:25:50,071 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@306b2912{static,/static,file:///github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2020-04-15 04:25:50,071 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@3e217bf7{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-04-15 04:25:50,104 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(863)) - Stopping Block Manager Service.
2020-04-15 04:25:50,104 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service SCMBlockDeletingService
2020-04-15 04:25:50,118 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service SCMBlockDeletingService
2020-04-15 04:25:50,118 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(888)) - Stopping SCM Event Queue.
2020-04-15 04:25:50,255 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2020-04-15 04:25:50,313 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2020-04-15 04:25:50,313 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2020-04-15 04:25:55,912 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@21ea8719] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2018ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=2087ms
GC pool 'PS Scavenge' had collection(s): count=1 time=50ms
2020-04-15 04:25:56,463 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:25:57,598 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:25:57,664 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:25:58,351 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(126)) - Loading file from sun.misc.CompoundEnumeration@7bf8940b
2020-04-15 04:25:58,417 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(172)) - Loading network topology layer schema file
2020-04-15 04:25:58,454 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(73)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2020-04-15 04:25:58,454 [main] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(73)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2020-04-15 04:25:58,488 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2020-04-15 04:25:58,531 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(59)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2020-04-15 04:25:58,532 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:25:58,890 [main] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(167)) - No pipeline exists in current db
2020-04-15 04:25:58,911 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:25:58,985 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:<init>(88)) - Total pipeline count is 0, healthy pipeline threshold count is 0
2020-04-15 04:25:59,007 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:<init>(79)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2020-04-15 04:25:59,062 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-15 04:25:59,074 [Socket Reader #1 for port 37603] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 37603
2020-04-15 04:25:59,132 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-15 04:25:59,133 [Socket Reader #1 for port 35971] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35971
2020-04-15 04:25:59,133 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-15 04:25:59,134 [Socket Reader #1 for port 43135] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43135
2020-04-15 04:25:59,251 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(171)) - Starting Web-server for scm at: http://0.0.0.0:0
2020-04-15 04:25:59,295 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-15 04:25:59,306 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-04-15 04:25:59,336 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-04-15 04:25:59,337 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(946)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context scm
2020-04-15 04:25:59,337 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-15 04:25:59,337 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-15 04:25:59,384 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(773)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:43135
2020-04-15 04:25:59,387 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2020-04-15 04:25:59,471 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-04-15 04:25:59,482 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2020-04-15 04:26:02,438 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-04-15 04:26:02,543 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(155)) - RPC server for Client  is listening at /0.0.0.0:43135
2020-04-15 04:26:02,546 [IPC Server listener on 43135] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 43135: starting
2020-04-15 04:26:02,546 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2020-04-15 04:26:02,646 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(785)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:35971
2020-04-15 04:26:02,647 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(149)) - RPC server for Block Protocol is listening at /0.0.0.0:35971
2020-04-15 04:26:02,647 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2020-04-15 04:26:02,647 [IPC Server listener on 35971] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 35971: starting
2020-04-15 04:26:02,650 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(791)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:37603
2020-04-15 04:26:02,650 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(172)) - RPC server for DataNodes is listening at /0.0.0.0:37603
2020-04-15 04:26:02,651 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2020-04-15 04:26:02,651 [IPC Server listener on 37603] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 37603: starting
2020-04-15 04:26:02,702 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1188)) - Jetty bound to port 35011
2020-04-15 04:26:02,702 [main] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-04-15 04:26:02,715 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-04-15 04:26:02,715 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-04-15 04:26:02,715 [main] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-04-15 04:26:02,716 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@79b6663b{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-04-15 04:26:02,717 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@5c191b44{static,/static,file:///github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2020-04-15 04:26:02,873 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@1245a728{scm,/,file:///github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2020-04-15 04:26:03,047 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@7ecc74a0{HTTP/1.1,[http/1.1]}{0.0.0.0:35011}
2020-04-15 04:26:03,080 [main] INFO  server.Server (Server.java:doStart(399)) - Started @474891ms
2020-04-15 04:26:03,091 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-04-15 04:26:03,115 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(285)) - HTTP server of scm listening at http://0.0.0.0:35011
2020-04-15 04:26:03,148 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:26:03,356 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@427363f6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-15 04:26:03,368 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(104)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2020-04-15 04:26:03,369 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(207)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2020-04-15 04:26:03,369 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(237)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2020-04-15 04:26:03,369 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:26:03,392 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:26:04,098 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-04-15 04:26:05,780 [Thread-328] INFO  container.ReplicationManager (ReplicationManager.java:start(165)) - Starting Replication Monitor Thread.
2020-04-15 04:26:06,095 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(228)) - Replication Monitor Thread took 46 milliseconds for processing 3 containers.
2020-04-15 04:26:06,502 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=c0cd4f73-d46b-49c1-99e0-452ad8150884 to datanode:cfe06f51-2df6-4b8f-8434-7472103af3e6
2020-04-15 04:26:06,618 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=c0cd4f73-d46b-49c1-99e0-452ad8150884 to datanode:6619ce5a-7401-4afb-ab66-de9ef56aa415
2020-04-15 04:26:06,642 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=c0cd4f73-d46b-49c1-99e0-452ad8150884 to datanode:250ee7a3-69f9-478f-96e6-fe41fc539658
2020-04-15 04:26:06,678 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: c0cd4f73-d46b-49c1-99e0-452ad8150884, Nodes: cfe06f51-2df6-4b8f-8434-7472103af3e6{ip: 48.55.105.213, host: localhost-48.55.105.213, networkLocation: /default-rack, certSerialId: null}6619ce5a-7401-4afb-ab66-de9ef56aa415{ip: 2.3.255.95, host: localhost-2.3.255.95, networkLocation: /default-rack, certSerialId: null}250ee7a3-69f9-478f-96e6-fe41fc539658{ip: 32.34.186.10, host: localhost-32.34.186.10, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:26:06.502Z]
2020-04-15 04:26:06,680 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=19ad2026-8337-4ffc-a7eb-e5b3392cc0b3 to datanode:f79b807b-9bf4-45a7-96d4-0a3f3215eb48
2020-04-15 04:26:06,680 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=19ad2026-8337-4ffc-a7eb-e5b3392cc0b3 to datanode:4913a4a2-4a2d-417b-a43d-fe94789f76fe
2020-04-15 04:26:06,680 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=19ad2026-8337-4ffc-a7eb-e5b3392cc0b3 to datanode:b62d7ec7-4155-4112-9d2f-92f368ccfbe5
2020-04-15 04:26:06,694 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 19ad2026-8337-4ffc-a7eb-e5b3392cc0b3, Nodes: f79b807b-9bf4-45a7-96d4-0a3f3215eb48{ip: 164.197.233.180, host: localhost-164.197.233.180, networkLocation: /default-rack, certSerialId: null}4913a4a2-4a2d-417b-a43d-fe94789f76fe{ip: 176.65.20.24, host: localhost-176.65.20.24, networkLocation: /default-rack, certSerialId: null}b62d7ec7-4155-4112-9d2f-92f368ccfbe5{ip: 61.236.254.26, host: localhost-61.236.254.26, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:26:06.680Z]
2020-04-15 04:26:06,937 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-15 04:26:07,046 [Socket Reader #1 for port 42605] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42605
2020-04-15 04:26:07,443 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2020-04-15 04:26:07,536 [main] INFO  om.OzoneManager (OzoneManager.java:start(1111)) - OzoneManager RPC server is listening at localhost/127.0.0.1:42605
2020-04-15 04:26:07,722 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2020-04-15 04:26:07,722 [IPC Server listener on 42605] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42605: starting
2020-04-15 04:26:07,819 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(171)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2020-04-15 04:26:07,863 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-15 04:26:07,864 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-04-15 04:26:07,888 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-04-15 04:26:07,888 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(946)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2020-04-15 04:26:07,889 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-15 04:26:07,889 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-15 04:26:07,889 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1188)) - Jetty bound to port 40531
2020-04-15 04:26:07,890 [main] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-04-15 04:26:07,891 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-04-15 04:26:07,892 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-04-15 04:26:07,892 [main] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-04-15 04:26:07,904 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@296e7880{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-04-15 04:26:07,904 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@3cede6af{static,/static,file:///github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2020-04-15 04:26:07,973 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@5b92ec75{ozoneManager,/,file:///github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2020-04-15 04:26:08,054 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@7a75660d{HTTP/1.1,[http/1.1]}{0.0.0.0:40531}
2020-04-15 04:26:08,055 [main] INFO  server.Server (Server.java:doStart(399)) - Started @479865ms
2020-04-15 04:26:08,055 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-04-15 04:26:08,189 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(285)) - HTTP server of ozoneManager listening at http://0.0.0.0:40531
2020-04-15 04:26:08,274 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-04-15 04:26:08,344 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(204)) - HddsDatanodeService host:edabee8e3155 ip:172.17.0.2
2020-04-15 04:26:08,461 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(177)) - Creating Volume: /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-04-15 04:26:08,462 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(188)) - Added Volume : /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data-0/containers/hdds to VolumeSet
2020-04-15 04:26:08,462 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data-0/containers/hdds
2020-04-15 04:26:08,462 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data-0/containers/hdds
2020-04-15 04:26:08,732 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-04-15 04:26:08,808 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-04-15 04:26:08,809 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-04-15 04:26:08,809 [main] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-04-15 04:26:08,809 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-04-15 04:26:08,809 [main] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-04-15 04:26:08,809 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-04-15 04:26:08,810 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data/ratis] (custom)
2020-04-15 04:26:08,826 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(171)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-04-15 04:26:08,905 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-15 04:26:08,938 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-04-15 04:26:08,952 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-04-15 04:26:08,953 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(946)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2020-04-15 04:26:08,953 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-15 04:26:08,953 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-15 04:26:08,955 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1188)) - Jetty bound to port 34167
2020-04-15 04:26:08,955 [main] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-04-15 04:26:08,958 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-04-15 04:26:08,958 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-04-15 04:26:08,958 [main] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-04-15 04:26:08,959 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@3763ef0d{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-04-15 04:26:08,960 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@5834b11{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-04-15 04:26:09,152 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@8432199{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-34167-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-7260179770436071463.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-04-15 04:26:09,186 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@1065ea4c{HTTP/1.1,[http/1.1]}{0.0.0.0:34167}
2020-04-15 04:26:09,186 [main] INFO  server.Server (Server.java:doStart(399)) - Started @480997ms
2020-04-15 04:26:09,187 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-04-15 04:26:09,191 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(285)) - HTTP server of hddsDatanode listening at http://0.0.0.0:34167
2020-04-15 04:26:09,191 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-04-15 04:26:09,338 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(204)) - HddsDatanodeService host:edabee8e3155 ip:172.17.0.2
2020-04-15 04:26:09,352 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(177)) - Creating Volume: /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-04-15 04:26:09,352 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(188)) - Added Volume : /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data-0/containers/hdds to VolumeSet
2020-04-15 04:26:09,352 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data-0/containers/hdds
2020-04-15 04:26:09,352 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@471baec3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-15 04:26:09,355 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(147)) - DatanodeDetails is persisted to /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/meta/datanode.id
2020-04-15 04:26:09,355 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data-0/containers/hdds
2020-04-15 04:26:09,657 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-04-15 04:26:09,738 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-04-15 04:26:09,740 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-04-15 04:26:09,741 [main] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-04-15 04:26:09,741 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-04-15 04:26:09,741 [main] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-04-15 04:26:09,741 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-04-15 04:26:09,753 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data/ratis] (custom)
2020-04-15 04:26:09,813 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(171)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-04-15 04:26:10,113 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-15 04:26:10,189 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-04-15 04:26:10,257 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-04-15 04:26:10,291 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(946)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2020-04-15 04:26:10,291 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-15 04:26:10,291 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-15 04:26:10,292 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1188)) - Jetty bound to port 34165
2020-04-15 04:26:10,292 [main] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-04-15 04:26:10,317 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-04-15 04:26:10,317 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-04-15 04:26:10,328 [main] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-04-15 04:26:10,361 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@e097855{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-04-15 04:26:10,372 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@323c470{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-04-15 04:26:10,895 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@4cb2b67c{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-34165-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-4804441949042662310.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-04-15 04:26:11,059 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@483937e{HTTP/1.1,[http/1.1]}{0.0.0.0:34165}
2020-04-15 04:26:11,124 [main] INFO  server.Server (Server.java:doStart(399)) - Started @482935ms
2020-04-15 04:26:11,125 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-04-15 04:26:11,128 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(285)) - HTTP server of hddsDatanode listening at http://0.0.0.0:34165
2020-04-15 04:26:11,171 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-04-15 04:26:11,539 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(204)) - HddsDatanodeService host:edabee8e3155 ip:172.17.0.2
2020-04-15 04:26:11,561 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3807d1f8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-15 04:26:12,100 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(177)) - Creating Volume: /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-04-15 04:26:12,101 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(188)) - Added Volume : /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data-0/containers/hdds to VolumeSet
2020-04-15 04:26:12,101 [main] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data-0/containers/hdds
2020-04-15 04:26:12,101 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(147)) - DatanodeDetails is persisted to /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/meta/datanode.id
2020-04-15 04:26:12,201 [main] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data-0/containers/hdds
2020-04-15 04:26:12,397 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-04-15 04:26:12,583 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-04-15 04:26:12,616 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(406)) - Starting XceiverServerRatis 21110601-e41d-4616-83a0-0c4b7d33d307 at port 0
2020-04-15 04:26:12,650 [main] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-04-15 04:26:12,694 [main] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-04-15 04:26:12,694 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-04-15 04:26:12,694 [main] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-04-15 04:26:12,694 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-04-15 04:26:12,694 [main] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-04-15 04:26:12,695 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-04-15 04:26:12,695 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis] (custom)
2020-04-15 04:26:12,713 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 21110601-e41d-4616-83a0-0c4b7d33d307: start RPC server
2020-04-15 04:26:12,807 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(171)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-04-15 04:26:12,957 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 21110601-e41d-4616-83a0-0c4b7d33d307: GrpcService started, listening on 0.0.0.0/0.0.0.0:39893
2020-04-15 04:26:13,002 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - XceiverServerRatis 21110601-e41d-4616-83a0-0c4b7d33d307 is started using port 39893
2020-04-15 04:26:13,130 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-15 04:26:13,289 [main] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-04-15 04:26:13,313 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 21110601-e41d-4616-83a0-0c4b7d33d307 is started using port 38603
2020-04-15 04:26:13,485 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-04-15 04:26:13,517 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(946)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2020-04-15 04:26:13,518 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-15 04:26:13,518 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(954)) - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-15 04:26:13,530 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1188)) - Jetty bound to port 33329
2020-04-15 04:26:13,530 [main] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-04-15 04:26:13,535 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-04-15 04:26:13,535 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-04-15 04:26:13,535 [main] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-04-15 04:26:13,610 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@7c5dbf7f{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-04-15 04:26:13,741 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@6a0ad14f{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-04-15 04:26:13,869 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-04-15 04:26:14,204 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-04-15 04:26:14,259 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(406)) - Starting XceiverServerRatis feab17e5-d3c3-4212-b199-a0ad2a9d8bbd at port 0
2020-04-15 04:26:14,314 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@63c1dcd{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-33329-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-4263706361200623875.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-04-15 04:26:14,535 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: start RPC server
2020-04-15 04:26:14,572 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@212d0cb0{HTTP/1.1,[http/1.1]}{0.0.0.0:33329}
2020-04-15 04:26:14,572 [main] INFO  server.Server (Server.java:doStart(399)) - Started @486383ms
2020-04-15 04:26:14,572 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-04-15 04:26:14,683 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(285)) - HTTP server of hddsDatanode listening at http://0.0.0.0:33329
2020-04-15 04:26:14,877 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-04-15 04:26:15,121 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4afd8e3e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-15 04:26:15,233 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:15,287 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: GrpcService started, listening on 0.0.0.0/0.0.0.0:33235
2020-04-15 04:26:15,287 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - XceiverServerRatis feab17e5-d3c3-4212-b199-a0ad2a9d8bbd is started using port 33235
2020-04-15 04:26:15,402 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc feab17e5-d3c3-4212-b199-a0ad2a9d8bbd is started using port 44423
2020-04-15 04:26:15,414 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(147)) - DatanodeDetails is persisted to /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/meta/datanode.id
2020-04-15 04:26:15,561 [IPC Server handler 19 on 37603] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/21110601-e41d-4616-83a0-0c4b7d33d307
2020-04-15 04:26:15,561 [IPC Server handler 19 on 37603] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 21110601-e41d-4616-83a0-0c4b7d33d307{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}
2020-04-15 04:26:15,643 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2020-04-15 04:26:15,643 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - DataNodeSafeModeRule rule is successfully validated
2020-04-15 04:26:15,643 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(210)) - All SCM safe mode pre check rules have passed
2020-04-15 04:26:15,654 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=4259674b-f726-4afa-88eb-67089499e161 to datanode:21110601-e41d-4616-83a0-0c4b7d33d307
2020-04-15 04:26:15,708 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - ContainerSafeModeRule rule is successfully validated
2020-04-15 04:26:15,722 [IPC Server handler 7 on 37603] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/feab17e5-d3c3-4212-b199-a0ad2a9d8bbd
2020-04-15 04:26:15,722 [IPC Server handler 7 on 37603] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : feab17e5-d3c3-4212-b199-a0ad2a9d8bbd{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}
2020-04-15 04:26:15,733 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - DataNodeSafeModeRule rule is successfully validated
2020-04-15 04:26:15,734 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - ContainerSafeModeRule rule is successfully validated
2020-04-15 04:26:15,734 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 4259674b-f726-4afa-88eb-67089499e161, Nodes: 21110601-e41d-4616-83a0-0c4b7d33d307{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:26:15.620Z]
2020-04-15 04:26:15,789 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=41cf3cc1-29b0-4cd0-ab24-7e1409131c68 to datanode:feab17e5-d3c3-4212-b199-a0ad2a9d8bbd
2020-04-15 04:26:15,789 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 41cf3cc1-29b0-4cd0-ab24-7e1409131c68, Nodes: feab17e5-d3c3-4212-b199-a0ad2a9d8bbd{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:26:15.757Z]
2020-04-15 04:26:15,790 [RatisPipelineUtilsThread] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(150)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2020-04-15 04:26:16,287 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 2 of 3 DN Heartbeats.
2020-04-15 04:26:16,374 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:17,391 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 2 of 3 DN Heartbeats.
2020-04-15 04:26:17,531 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:17,587 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-04-15 04:26:17,697 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-04-15 04:26:17,743 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(406)) - Starting XceiverServerRatis 0254fda8-66ba-4c89-ba34-a1168c48e4b4 at port 0
2020-04-15 04:26:17,767 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: start RPC server
2020-04-15 04:26:18,556 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 2 of 3 DN Heartbeats.
2020-04-15 04:26:18,577 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:19,065 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(158)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: GrpcService started, listening on 0.0.0.0/0.0.0.0:36297
2020-04-15 04:26:19,065 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - XceiverServerRatis 0254fda8-66ba-4c89-ba34-a1168c48e4b4 is started using port 36297
2020-04-15 04:26:19,113 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 0254fda8-66ba-4c89-ba34-a1168c48e4b4 is started using port 42745
2020-04-15 04:26:19,157 [IPC Server handler 19 on 37603] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/0254fda8-66ba-4c89-ba34-a1168c48e4b4
2020-04-15 04:26:19,233 [IPC Server handler 19 on 37603] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 0254fda8-66ba-4c89-ba34-a1168c48e4b4{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}
2020-04-15 04:26:19,234 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - DataNodeSafeModeRule rule is successfully validated
2020-04-15 04:26:19,342 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - ContainerSafeModeRule rule is successfully validated
2020-04-15 04:26:19,407 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=3ac49010-9342-4bb5-b8e8-b2ef0e579312 to datanode:0254fda8-66ba-4c89-ba34-a1168c48e4b4
2020-04-15 04:26:19,451 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 3ac49010-9342-4bb5-b8e8-b2ef0e579312, Nodes: 0254fda8-66ba-4c89-ba34-a1168c48e4b4{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:26:19.407Z]
2020-04-15 04:26:19,462 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=b26b5514-bea2-4a16-9cee-a48347e84b3b to datanode:0254fda8-66ba-4c89-ba34-a1168c48e4b4
2020-04-15 04:26:19,484 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=b26b5514-bea2-4a16-9cee-a48347e84b3b to datanode:21110601-e41d-4616-83a0-0c4b7d33d307
2020-04-15 04:26:19,506 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$3(170)) - Sending CreatePipelineCommand for pipeline:PipelineID=b26b5514-bea2-4a16-9cee-a48347e84b3b to datanode:feab17e5-d3c3-4212-b199-a0ad2a9d8bbd
2020-04-15 04:26:19,520 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: b26b5514-bea2-4a16-9cee-a48347e84b3b, Nodes: 0254fda8-66ba-4c89-ba34-a1168c48e4b4{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}21110601-e41d-4616-83a0-0c4b7d33d307{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}feab17e5-d3c3-4212-b199-a0ad2a9d8bbd{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-15T04:26:19.462Z]
2020-04-15 04:26:19,704 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:19,727 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:19,727 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: addNew group-7E1409131C68:[feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235] returns group-7E1409131C68:java.util.concurrent.CompletableFuture@6c8136f3[Not completed]
2020-04-15 04:26:20,703 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 21110601-e41d-4616-83a0-0c4b7d33d307: addNew group-67089499E161:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893] returns group-67089499E161:java.util.concurrent.CompletableFuture@3e2d251b[Not completed]
2020-04-15 04:26:20,758 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:20,758 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:21,760 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:22,059 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:22,333 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: addNew group-B2EF0E579312:[0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] returns group-B2EF0E579312:java.util.concurrent.CompletableFuture@19e02119[Not completed]
2020-04-15 04:26:23,092 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:23,135 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:23,417 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:26:23,995 [pool-127-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(97)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: new RaftServerImpl for group-7E1409131C68:[feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235] with ContainerStateMachine:uninitialized
2020-04-15 04:26:23,995 [pool-112-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(97)) - 21110601-e41d-4616-83a0-0c4b7d33d307: new RaftServerImpl for group-67089499E161:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893] with ContainerStateMachine:uninitialized
2020-04-15 04:26:23,995 [pool-142-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(97)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: new RaftServerImpl for group-B2EF0E579312:[0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] with ContainerStateMachine:uninitialized
2020-04-15 04:26:24,309 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-04-15 04:26:24,343 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-04-15 04:26:24,354 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-04-15 04:26:24,309 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-04-15 04:26:24,365 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-04-15 04:26:24,365 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-04-15 04:26:24,365 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-04-15 04:26:24,365 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-04-15 04:26:24,376 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-04-15 04:26:24,399 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-04-15 04:26:24,399 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-04-15 04:26:24,399 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-04-15 04:26:24,421 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-04-15 04:26:24,422 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-04-15 04:26:24,422 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-04-15 04:26:24,776 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:24,832 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:24,859 [pool-142-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312: ConfigurationManager, init=-1: [0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null, confs=<EMPTY_MAP>
2020-04-15 04:26:24,859 [pool-127-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68: ConfigurationManager, init=-1: [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235], old=null, confs=<EMPTY_MAP>
2020-04-15 04:26:24,870 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data/ratis] (custom)
2020-04-15 04:26:24,859 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis] (custom)
2020-04-15 04:26:24,859 [pool-112-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161: ConfigurationManager, init=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893], old=null, confs=<EMPTY_MAP>
2020-04-15 04:26:24,904 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data/ratis] (custom)
2020-04-15 04:26:25,170 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:26:25,172 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-04-15 04:26:25,173 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-04-15 04:26:25,173 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-04-15 04:26:25,196 [pool-142-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(253)) - The storage directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis/3ac49010-9342-4bb5-b8e8-b2ef0e579312 does not exist. Creating ...
2020-04-15 04:26:25,242 [pool-127-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(253)) - The storage directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data/ratis/41cf3cc1-29b0-4cd0-ab24-7e1409131c68 does not exist. Creating ...
2020-04-15 04:26:25,196 [pool-112-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(253)) - The storage directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data/ratis/4259674b-f726-4afa-88eb-67089499e161 does not exist. Creating ...
2020-04-15 04:26:25,392 [pool-127-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(335)) - Lock on /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data/ratis/41cf3cc1-29b0-4cd0-ab24-7e1409131c68/in_use.lock acquired by nodename 11899@edabee8e3155
2020-04-15 04:26:25,392 [pool-112-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(335)) - Lock on /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data/ratis/4259674b-f726-4afa-88eb-67089499e161/in_use.lock acquired by nodename 11899@edabee8e3155
2020-04-15 04:26:25,458 [pool-142-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(335)) - Lock on /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis/3ac49010-9342-4bb5-b8e8-b2ef0e579312/in_use.lock acquired by nodename 11899@edabee8e3155
2020-04-15 04:26:25,683 [pool-142-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis/3ac49010-9342-4bb5-b8e8-b2ef0e579312 has been successfully formatted.
2020-04-15 04:26:25,817 [pool-112-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data/ratis/4259674b-f726-4afa-88eb-67089499e161 has been successfully formatted.
2020-04-15 04:26:25,683 [pool-127-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data/ratis/41cf3cc1-29b0-4cd0-ab24-7e1409131c68 has been successfully formatted.
2020-04-15 04:26:25,979 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:25,979 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:26,166 [pool-112-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(233)) - group-67089499E161: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-04-15 04:26:26,166 [pool-127-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(233)) - group-7E1409131C68: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-04-15 04:26:26,274 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:openPipeline(131)) - Pipeline Pipeline[ Id: 4259674b-f726-4afa-88eb-67089499e161, Nodes: 21110601-e41d-4616-83a0-0c4b7d33d307{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:21110601-e41d-4616-83a0-0c4b7d33d307, CreationTimestamp2020-04-15T04:26:15.620Z] moved to OPEN state
2020-04-15 04:26:26,166 [pool-142-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(233)) - group-B2EF0E579312: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-04-15 04:26:26,379 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-04-15 04:26:26,390 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-04-15 04:26:26,390 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-04-15 04:26:26,792 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(131)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2020-04-15 04:26:26,835 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:openPipeline(131)) - Pipeline Pipeline[ Id: 3ac49010-9342-4bb5-b8e8-b2ef0e579312, Nodes: 0254fda8-66ba-4c89-ba34-a1168c48e4b4{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:0254fda8-66ba-4c89-ba34-a1168c48e4b4, CreationTimestamp2020-04-15T04:26:19.407Z] moved to OPEN state
2020-04-15 04:26:26,967 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:openPipeline(131)) - Pipeline Pipeline[ Id: 41cf3cc1-29b0-4cd0-ab24-7e1409131c68, Nodes: feab17e5-d3c3-4212-b199-a0ad2a9d8bbd{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:feab17e5-d3c3-4212-b199-a0ad2a9d8bbd, CreationTimestamp2020-04-15T04:26:15.757Z] moved to OPEN state
2020-04-15 04:26:26,803 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - AtleastOneDatanodeReportedRule rule is successfully validated
2020-04-15 04:26:26,967 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - AtleastOneDatanodeReportedRule rule is successfully validated
2020-04-15 04:26:26,967 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - AtleastOneDatanodeReportedRule rule is successfully validated
2020-04-15 04:26:26,968 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(131)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2020-04-15 04:26:26,968 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(131)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2020-04-15 04:26:26,979 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:26,980 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:27,111 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-04-15 04:26:27,111 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-04-15 04:26:27,188 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-04-15 04:26:27,400 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-04-15 04:26:27,472 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-04-15 04:26:27,494 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-04-15 04:26:27,402 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-04-15 04:26:27,495 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-04-15 04:26:27,495 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-04-15 04:26:27,574 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-04-15 04:26:27,585 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-04-15 04:26:27,585 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-04-15 04:26:27,938 [pool-142-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.0254fda8-66ba-4c89-ba34-a1168c48e4b4
2020-04-15 04:26:28,030 [pool-112-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.21110601-e41d-4616-83a0-0c4b7d33d307
2020-04-15 04:26:27,938 [pool-127-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd
2020-04-15 04:26:27,997 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:28,153 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:29,186 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:29,230 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:29,477 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:26:29,904 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-04-15 04:26:29,949 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-04-15 04:26:29,926 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-04-15 04:26:30,110 [pool-142-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis/3ac49010-9342-4bb5-b8e8-b2ef0e579312
2020-04-15 04:26:30,133 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-04-15 04:26:30,174 [pool-112-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data/ratis/4259674b-f726-4afa-88eb-67089499e161
2020-04-15 04:26:30,121 [pool-127-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data/ratis/41cf3cc1-29b0-4cd0-ab24-7e1409131c68
2020-04-15 04:26:30,273 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-04-15 04:26:30,273 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-04-15 04:26:30,273 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-04-15 04:26:30,274 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-04-15 04:26:30,274 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-04-15 04:26:30,307 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-04-15 04:26:30,307 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-04-15 04:26:30,308 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-04-15 04:26:30,308 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-04-15 04:26:30,308 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-04-15 04:26:30,308 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-04-15 04:26:30,308 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-04-15 04:26:30,308 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-04-15 04:26:30,374 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-04-15 04:26:30,363 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:30,374 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:30,374 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-04-15 04:26:30,375 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-04-15 04:26:30,375 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-04-15 04:26:30,733 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-04-15 04:26:30,746 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-04-15 04:26:30,746 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-04-15 04:26:30,746 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-04-15 04:26:30,749 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-04-15 04:26:30,761 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-04-15 04:26:30,827 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-04-15 04:26:30,827 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-04-15 04:26:30,827 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-04-15 04:26:31,403 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:31,520 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:31,797 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-04-15 04:26:31,811 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-04-15 04:26:31,809 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-04-15 04:26:32,407 [pool-127-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-04-15 04:26:32,661 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:32,420 [pool-142-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-04-15 04:26:32,683 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:32,683 [pool-112-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-04-15 04:26:33,060 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-04-15 04:26:33,093 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-04-15 04:26:33,093 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-04-15 04:26:33,115 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-04-15 04:26:33,198 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-04-15 04:26:33,198 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-04-15 04:26:33,198 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-04-15 04:26:33,198 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-04-15 04:26:33,198 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-04-15 04:26:33,198 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-04-15 04:26:33,198 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-04-15 04:26:33,198 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-04-15 04:26:33,694 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:33,737 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:33,859 [pool-112-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161
2020-04-15 04:26:33,918 [pool-112-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161
2020-04-15 04:26:33,920 [pool-112-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(183)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161: start as a follower, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893], old=null
2020-04-15 04:26:33,935 [pool-127-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68
2020-04-15 04:26:33,949 [pool-142-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312
2020-04-15 04:26:33,950 [pool-142-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312
2020-04-15 04:26:33,961 [pool-142-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(183)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312: start as a follower, conf=-1: [0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:33,998 [pool-127-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68
2020-04-15 04:26:34,111 [pool-127-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(183)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68: start as a follower, conf=-1: [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235], old=null
2020-04-15 04:26:34,123 [pool-112-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-04-15 04:26:34,134 [pool-142-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-04-15 04:26:34,134 [pool-127-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-04-15 04:26:34,435 [pool-142-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: start FollowerState
2020-04-15 04:26:34,479 [pool-112-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21110601-e41d-4616-83a0-0c4b7d33d307: start FollowerState
2020-04-15 04:26:34,479 [pool-127-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: start FollowerState
2020-04-15 04:26:34,592 [pool-142-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B2EF0E579312,id=0254fda8-66ba-4c89-ba34-a1168c48e4b4
2020-04-15 04:26:34,592 [pool-112-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-67089499E161,id=21110601-e41d-4616-83a0-0c4b7d33d307
2020-04-15 04:26:34,592 [pool-127-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7E1409131C68,id=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd
2020-04-15 04:26:34,742 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:34,743 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:34,890 [pool-112-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161
2020-04-15 04:26:34,912 [pool-127-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68
2020-04-15 04:26:35,013 [pool-142-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312
2020-04-15 04:26:36,047 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:36,080 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:37,034 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(112)) - Created Pipeline RATIS ONE #id: "41cf3cc1-29b0-4cd0-ab24-7e1409131c68"
.
2020-04-15 04:26:37,088 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:37,089 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:37,135 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: addNew group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] returns group-A48347E84B3B:java.util.concurrent.CompletableFuture@2e9e3a9e[Not completed]
2020-04-15 04:26:37,157 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(112)) - Created Pipeline RATIS ONE #id: "4259674b-f726-4afa-88eb-67089499e161"
.
2020-04-15 04:26:37,323 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 21110601-e41d-4616-83a0-0c4b7d33d307: addNew group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] returns group-A48347E84B3B:java.util.concurrent.CompletableFuture@3a12a606[Not completed]
2020-04-15 04:26:37,190 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(112)) - Created Pipeline RATIS ONE #id: "3ac49010-9342-4bb5-b8e8-b2ef0e579312"
.
2020-04-15 04:26:37,323 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: addNew group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] returns group-A48347E84B3B:java.util.concurrent.CompletableFuture@1ddfb6fd[Not completed]
2020-04-15 04:26:37,325 [pool-127-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(97)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: new RaftServerImpl for group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] with ContainerStateMachine:uninitialized
2020-04-15 04:26:37,325 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-04-15 04:26:37,325 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-04-15 04:26:37,325 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-04-15 04:26:37,325 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-04-15 04:26:37,325 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-04-15 04:26:37,325 [pool-127-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B: ConfigurationManager, init=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null, confs=<EMPTY_MAP>
2020-04-15 04:26:37,325 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data/ratis] (custom)
2020-04-15 04:26:37,326 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-04-15 04:26:37,342 [pool-112-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(97)) - 21110601-e41d-4616-83a0-0c4b7d33d307: new RaftServerImpl for group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] with ContainerStateMachine:uninitialized
2020-04-15 04:26:37,374 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-04-15 04:26:37,375 [pool-142-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(97)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: new RaftServerImpl for group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] with ContainerStateMachine:uninitialized
2020-04-15 04:26:37,375 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-04-15 04:26:37,375 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-04-15 04:26:37,376 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-04-15 04:26:37,376 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-04-15 04:26:37,376 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-04-15 04:26:37,376 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-04-15 04:26:37,376 [pool-142-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: ConfigurationManager, init=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null, confs=<EMPTY_MAP>
2020-04-15 04:26:37,376 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis] (custom)
2020-04-15 04:26:37,377 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-04-15 04:26:37,388 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-04-15 04:26:37,388 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-04-15 04:26:37,389 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-04-15 04:26:37,389 [pool-112-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B: ConfigurationManager, init=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null, confs=<EMPTY_MAP>
2020-04-15 04:26:37,389 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data/ratis] (custom)
2020-04-15 04:26:37,389 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-04-15 04:26:37,389 [pool-112-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(253)) - The storage directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data/ratis/b26b5514-bea2-4a16-9cee-a48347e84b3b does not exist. Creating ...
2020-04-15 04:26:37,390 [pool-142-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(253)) - The storage directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis/b26b5514-bea2-4a16-9cee-a48347e84b3b does not exist. Creating ...
2020-04-15 04:26:37,391 [pool-112-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(335)) - Lock on /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data/ratis/b26b5514-bea2-4a16-9cee-a48347e84b3b/in_use.lock acquired by nodename 11899@edabee8e3155
2020-04-15 04:26:37,405 [pool-112-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data/ratis/b26b5514-bea2-4a16-9cee-a48347e84b3b has been successfully formatted.
2020-04-15 04:26:37,416 [pool-142-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(335)) - Lock on /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis/b26b5514-bea2-4a16-9cee-a48347e84b3b/in_use.lock acquired by nodename 11899@edabee8e3155
2020-04-15 04:26:37,417 [pool-112-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(233)) - group-A48347E84B3B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-04-15 04:26:37,418 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-04-15 04:26:37,418 [pool-142-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis/b26b5514-bea2-4a16-9cee-a48347e84b3b has been successfully formatted.
2020-04-15 04:26:37,418 [pool-142-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(233)) - group-A48347E84B3B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-04-15 04:26:37,419 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-04-15 04:26:37,419 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-04-15 04:26:37,419 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-04-15 04:26:37,419 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-04-15 04:26:37,419 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-04-15 04:26:37,419 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-04-15 04:26:37,419 [pool-142-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis/b26b5514-bea2-4a16-9cee-a48347e84b3b
2020-04-15 04:26:37,419 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-04-15 04:26:37,419 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-04-15 04:26:37,419 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-04-15 04:26:37,420 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-04-15 04:26:37,420 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-04-15 04:26:37,420 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-04-15 04:26:37,420 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-04-15 04:26:37,420 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-04-15 04:26:37,420 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-04-15 04:26:37,420 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-04-15 04:26:37,432 [pool-127-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(253)) - The storage directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data/ratis/b26b5514-bea2-4a16-9cee-a48347e84b3b does not exist. Creating ...
2020-04-15 04:26:37,433 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-04-15 04:26:37,433 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-04-15 04:26:37,433 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-04-15 04:26:37,433 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-04-15 04:26:37,439 [pool-127-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(335)) - Lock on /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data/ratis/b26b5514-bea2-4a16-9cee-a48347e84b3b/in_use.lock acquired by nodename 11899@edabee8e3155
2020-04-15 04:26:37,439 [pool-142-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-04-15 04:26:37,439 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-04-15 04:26:37,440 [pool-112-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data/ratis/b26b5514-bea2-4a16-9cee-a48347e84b3b
2020-04-15 04:26:37,440 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-04-15 04:26:37,440 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-04-15 04:26:37,440 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-04-15 04:26:37,466 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-04-15 04:26:37,466 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-04-15 04:26:37,466 [pool-127-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data/ratis/b26b5514-bea2-4a16-9cee-a48347e84b3b has been successfully formatted.
2020-04-15 04:26:37,466 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-04-15 04:26:37,466 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-04-15 04:26:37,466 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-04-15 04:26:37,467 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-04-15 04:26:37,469 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-04-15 04:26:37,469 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-04-15 04:26:37,469 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-04-15 04:26:37,469 [pool-142-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-04-15 04:26:37,469 [pool-142-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B
2020-04-15 04:26:37,502 [pool-127-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(233)) - group-A48347E84B3B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-04-15 04:26:37,502 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-04-15 04:26:37,502 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-04-15 04:26:37,502 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-04-15 04:26:37,502 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-04-15 04:26:37,502 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-04-15 04:26:37,502 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-04-15 04:26:37,502 [pool-127-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data/ratis/b26b5514-bea2-4a16-9cee-a48347e84b3b
2020-04-15 04:26:37,503 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-04-15 04:26:37,503 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-04-15 04:26:37,503 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-04-15 04:26:37,503 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-04-15 04:26:37,503 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-04-15 04:26:37,503 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-04-15 04:26:37,503 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-04-15 04:26:37,503 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-04-15 04:26:37,503 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-04-15 04:26:37,504 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-04-15 04:26:37,528 [pool-142-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B
2020-04-15 04:26:37,515 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-04-15 04:26:37,540 [pool-112-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-04-15 04:26:37,540 [pool-127-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-04-15 04:26:37,541 [pool-142-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(183)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: start as a follower, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:37,541 [pool-142-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-04-15 04:26:37,542 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-04-15 04:26:37,542 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-04-15 04:26:37,542 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-04-15 04:26:37,542 [pool-112-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-04-15 04:26:37,542 [pool-112-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B
2020-04-15 04:26:37,543 [pool-112-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B
2020-04-15 04:26:37,544 [pool-112-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(183)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B: start as a follower, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:37,544 [pool-112-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-04-15 04:26:37,544 [pool-112-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21110601-e41d-4616-83a0-0c4b7d33d307: start FollowerState
2020-04-15 04:26:37,585 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-04-15 04:26:37,586 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-04-15 04:26:37,586 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-04-15 04:26:37,597 [pool-142-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: start FollowerState
2020-04-15 04:26:37,598 [pool-112-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A48347E84B3B,id=21110601-e41d-4616-83a0-0c4b7d33d307
2020-04-15 04:26:37,598 [pool-112-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B
2020-04-15 04:26:37,630 [pool-127-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-04-15 04:26:37,631 [pool-127-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B
2020-04-15 04:26:37,631 [pool-127-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B
2020-04-15 04:26:37,652 [pool-142-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A48347E84B3B,id=0254fda8-66ba-4c89-ba34-a1168c48e4b4
2020-04-15 04:26:37,731 [pool-127-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(183)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B: start as a follower, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:37,796 [pool-127-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-04-15 04:26:37,807 [pool-142-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B
2020-04-15 04:26:37,885 [pool-127-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: start FollowerState
2020-04-15 04:26:37,886 [pool-127-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A48347E84B3B,id=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd
2020-04-15 04:26:37,886 [pool-127-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B
2020-04-15 04:26:38,102 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:38,207 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:39,359 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:39,670 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:39,594 [Thread-686] INFO  impl.FollowerState (FollowerState.java:run(108)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-FollowerState: change to CANDIDATE, lastRpcTime:5183ms, electionTimeout:5025ms
2020-04-15 04:26:39,704 [Thread-687] INFO  impl.FollowerState (FollowerState.java:run(108)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-FollowerState: change to CANDIDATE, lastRpcTime:5282ms, electionTimeout:5124ms
2020-04-15 04:26:40,077 [Thread-685] INFO  impl.FollowerState (FollowerState.java:run(108)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-FollowerState: change to CANDIDATE, lastRpcTime:5677ms, electionTimeout:5178ms
2020-04-15 04:26:40,677 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:40,677 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:40,911 [Thread-686] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: shutdown FollowerState
2020-04-15 04:26:41,124 [Thread-686] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-04-15 04:26:40,950 [Thread-685] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: shutdown FollowerState
2020-04-15 04:26:40,934 [Thread-687] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 21110601-e41d-4616-83a0-0c4b7d33d307: shutdown FollowerState
2020-04-15 04:26:41,125 [Thread-685] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-04-15 04:26:41,125 [Thread-687] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-04-15 04:26:41,326 [Thread-686] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: start LeaderElection
2020-04-15 04:26:41,337 [Thread-687] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21110601-e41d-4616-83a0-0c4b7d33d307: start LeaderElection
2020-04-15 04:26:41,570 [Thread-685] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: start LeaderElection
2020-04-15 04:26:41,769 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3: begin an election at term 1 for -1: [0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:41,680 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:41,917 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:42,373 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1: begin an election at term 1 for -1: [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235], old=null
2020-04-15 04:26:42,592 [Thread-691] INFO  impl.FollowerState (FollowerState.java:run(108)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-FollowerState: change to CANDIDATE, lastRpcTime:5048ms, electionTimeout:5007ms
2020-04-15 04:26:42,647 [Thread-691] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 21110601-e41d-4616-83a0-0c4b7d33d307: shutdown FollowerState
2020-04-15 04:26:42,647 [Thread-691] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-04-15 04:26:42,647 [Thread-691] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21110601-e41d-4616-83a0-0c4b7d33d307: start LeaderElection
2020-04-15 04:26:42,816 [Thread-689] INFO  impl.FollowerState (FollowerState.java:run(108)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-FollowerState: change to CANDIDATE, lastRpcTime:5263ms, electionTimeout:5068ms
2020-04-15 04:26:42,816 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2: begin an election at term 1 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893], old=null
2020-04-15 04:26:42,816 [Thread-689] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: shutdown FollowerState
2020-04-15 04:26:42,917 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:42,930 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:42,930 [Thread-689] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-04-15 04:26:42,963 [Thread-689] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: start LeaderElection
2020-04-15 04:26:42,986 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4: begin an election at term 1 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:43,070 [Thread-693] INFO  impl.FollowerState (FollowerState.java:run(108)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-FollowerState: change to CANDIDATE, lastRpcTime:5229ms, electionTimeout:5166ms
2020-04-15 04:26:43,372 [Thread-693] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: shutdown FollowerState
2020-04-15 04:26:43,394 [Thread-693] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-04-15 04:26:43,427 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5: begin an election at term 1 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:43,427 [Thread-693] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: start LeaderElection
2020-04-15 04:26:44,022 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:44,065 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:44,132 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6: begin an election at term 1 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:44,303 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: shutdown LeaderElection
2020-04-15 04:26:44,368 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 21110601-e41d-4616-83a0-0c4b7d33d307: shutdown LeaderElection
2020-04-15 04:26:44,314 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: shutdown LeaderElection
2020-04-15 04:26:44,807 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-04-15 04:26:44,807 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(739)) - Leader change notification received for group: group-B2EF0E579312 with new leaderId: 0254fda8-66ba-4c89-ba34-a1168c48e4b4
2020-04-15 04:26:44,839 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-04-15 04:26:44,840 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(739)) - Leader change notification received for group: group-67089499E161 with new leaderId: 21110601-e41d-4616-83a0-0c4b7d33d307
2020-04-15 04:26:44,861 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-04-15 04:26:44,862 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(739)) - Leader change notification received for group: group-7E1409131C68 with new leaderId: feab17e5-d3c3-4212-b199-a0ad2a9d8bbd
2020-04-15 04:26:44,873 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68: change Leader from null to feab17e5-d3c3-4212-b199-a0ad2a9d8bbd at term 1 for becomeLeader, leader elected after 18576ms
2020-04-15 04:26:44,896 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312: change Leader from null to 0254fda8-66ba-4c89-ba34-a1168c48e4b4 at term 1 for becomeLeader, leader elected after 18510ms
2020-04-15 04:26:44,896 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161: change Leader from null to 21110601-e41d-4616-83a0-0c4b7d33d307 at term 1 for becomeLeader, leader elected after 18673ms
2020-04-15 04:26:45,082 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:45,138 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:45,039 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:26:45,578 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-04-15 04:26:45,611 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-04-15 04:26:45,622 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-04-15 04:26:45,622 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-04-15 04:26:45,633 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-04-15 04:26:45,644 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-04-15 04:26:45,932 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312
2020-04-15 04:26:45,957 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161
2020-04-15 04:26:46,121 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-04-15 04:26:46,122 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-04-15 04:26:45,957 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68
2020-04-15 04:26:46,150 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:46,237 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-04-15 04:26:46,303 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-04-15 04:26:46,303 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:46,304 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-04-15 04:26:46,304 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-04-15 04:26:46,393 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-04-15 04:26:46,393 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-04-15 04:26:46,393 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-04-15 04:26:46,546 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-04-15 04:26:46,546 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-04-15 04:26:46,546 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-04-15 04:26:46,595 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21110601-e41d-4616-83a0-0c4b7d33d307: start LeaderState
2020-04-15 04:26:46,722 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: start LeaderState
2020-04-15 04:26:46,766 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-04-15 04:26:46,788 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-04-15 04:26:46,789 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-04-15 04:26:46,789 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: start LeaderState
2020-04-15 04:26:46,803 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-SegmentedRaftLogWorker: Starting segment from index:0
2020-04-15 04:26:46,803 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-SegmentedRaftLogWorker: Starting segment from index:0
2020-04-15 04:26:46,803 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-SegmentedRaftLogWorker: Starting segment from index:0
2020-04-15 04:26:47,312 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:47,450 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:48,464 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:48,464 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:49,270 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312: set configuration 0: [0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null at 0
2020-04-15 04:26:49,397 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68: set configuration 0: [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235], old=null at 0
2020-04-15 04:26:49,505 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:49,505 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161: set configuration 0: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893], old=null at 0
2020-04-15 04:26:49,518 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:50,118 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-SegmentedRaftLogWorker: created new log segment /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data/ratis/41cf3cc1-29b0-4cd0-ab24-7e1409131c68/current/log_inprogress_0
2020-04-15 04:26:50,140 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-SegmentedRaftLogWorker: created new log segment /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data/ratis/4259674b-f726-4afa-88eb-67089499e161/current/log_inprogress_0
2020-04-15 04:26:50,118 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-SegmentedRaftLogWorker: created new log segment /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis/3ac49010-9342-4bb5-b8e8-b2ef0e579312/current/log_inprogress_0
2020-04-15 04:26:50,633 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:50,633 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:51,668 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:51,781 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B:t1, leader=null, voted=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd, raftlog=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:51,756 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B:t1, leader=null, voted=0254fda8-66ba-4c89-ba34-a1168c48e4b4, raftlog=0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:52,048 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:52,155 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B:t1, leader=null, voted=21110601-e41d-4616-83a0-0c4b7d33d307, raftlog=21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:52,231 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6: begin an election at term 2 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:52,230 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5: begin an election at term 2 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:52,371 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4: begin an election at term 2 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:53,134 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:53,242 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:54,262 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:54,295 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:55,389 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:55,660 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:56,810 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:56,854 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:57,438 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B:t2, leader=null, voted=0254fda8-66ba-4c89-ba34-a1168c48e4b4, raftlog=0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:57,599 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B:t2, leader=null, voted=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd, raftlog=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:57,479 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B:t2, leader=null, voted=21110601-e41d-4616-83a0-0c4b7d33d307, raftlog=21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:57,713 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4: begin an election at term 3 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:57,713 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6: begin an election at term 3 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:57,735 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5: begin an election at term 3 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:26:57,860 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:57,860 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:58,929 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:58,940 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:26:59,948 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:26:59,948 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:27:00,963 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:27:01,009 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:27:02,014 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:27:02,083 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:27:02,832 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B:t3, leader=null, voted=21110601-e41d-4616-83a0-0c4b7d33d307, raftlog=21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:02,844 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B:t3, leader=null, voted=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd, raftlog=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:02,868 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6: begin an election at term 4 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:02,879 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4: begin an election at term 4 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:03,195 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:27:03,228 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:27:03,228 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B:t3, leader=null, voted=0254fda8-66ba-4c89-ba34-a1168c48e4b4, raftlog=0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:03,652 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5: begin an election at term 4 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:04,128 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:27:04,234 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:27:04,729 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:27:04,829 [grpc-default-executor-5] WARN  impl.RaftServerProxy (RaftServerProxy.java:lambda$groupAddAsync$11(390)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: Failed groupAdd* GroupManagementRequest:client-6916F96EC85A->0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B, cid=2, seq=0, RW, null, Add:group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297]
java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 0254fda8-66ba-4c89-ba34-a1168c48e4b4: Failed to add group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] since the group already exists in the map.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:607)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)
	at java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:631)
	at java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2006)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.protocol.AlreadyExistsException: 0254fda8-66ba-4c89-ba34-a1168c48e4b4: Failed to add group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] since the group already exists in the map.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
	... 13 more
2020-04-15 04:27:04,841 [grpc-default-executor-10] WARN  impl.RaftServerProxy (RaftServerProxy.java:lambda$groupAddAsync$11(390)) - 21110601-e41d-4616-83a0-0c4b7d33d307: Failed groupAdd* GroupManagementRequest:client-1A55C42AF364->21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B, cid=1, seq=0, RW, null, Add:group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297]
java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 21110601-e41d-4616-83a0-0c4b7d33d307: Failed to add group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] since the group already exists in the map.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:607)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)
	at java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:631)
	at java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2006)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.protocol.AlreadyExistsException: 21110601-e41d-4616-83a0-0c4b7d33d307: Failed to add group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] since the group already exists in the map.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
	... 13 more
2020-04-15 04:27:04,842 [grpc-default-executor-0] WARN  impl.RaftServerProxy (RaftServerProxy.java:lambda$groupAddAsync$11(390)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: Failed groupAdd* GroupManagementRequest:client-95739C14B433->0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B, cid=0, seq=0, RW, null, Add:group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297]
java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 0254fda8-66ba-4c89-ba34-a1168c48e4b4: Failed to add group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] since the group already exists in the map.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:607)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)
	at java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:631)
	at java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2006)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.protocol.AlreadyExistsException: 0254fda8-66ba-4c89-ba34-a1168c48e4b4: Failed to add group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] since the group already exists in the map.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
	... 13 more
2020-04-15 04:27:05,735 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:27:05,927 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:27:06,936 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:27:06,970 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:27:07,274 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5: Election REJECTED; received 2 response(s) [0254fda8-66ba-4c89-ba34-a1168c48e4b4<-feab17e5-d3c3-4212-b199-a0ad2a9d8bbd#0:FAIL-t4, 0254fda8-66ba-4c89-ba34-a1168c48e4b4<-21110601-e41d-4616-83a0-0c4b7d33d307#0:FAIL-t4] and 0 exception(s); 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B:t4, leader=null, voted=0254fda8-66ba-4c89-ba34-a1168c48e4b4, raftlog=0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:07,364 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6: Election REJECTED; received 2 response(s) [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd<-21110601-e41d-4616-83a0-0c4b7d33d307#0:FAIL-t4, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd<-0254fda8-66ba-4c89-ba34-a1168c48e4b4#0:FAIL-t4] and 0 exception(s); feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B:t4, leader=null, voted=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd, raftlog=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:07,364 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4: Election REJECTED; received 2 response(s) [21110601-e41d-4616-83a0-0c4b7d33d307<-feab17e5-d3c3-4212-b199-a0ad2a9d8bbd#0:FAIL-t4, 21110601-e41d-4616-83a0-0c4b7d33d307<-0254fda8-66ba-4c89-ba34-a1168c48e4b4#0:FAIL-t4] and 0 exception(s); 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B:t4, leader=null, voted=21110601-e41d-4616-83a0-0c4b7d33d307, raftlog=21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:07,866 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B: changes role from CANDIDATE to FOLLOWER at term 4 for DISCOVERED_A_NEW_TERM
2020-04-15 04:27:07,773 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: changes role from CANDIDATE to FOLLOWER at term 4 for DISCOVERED_A_NEW_TERM
2020-04-15 04:27:07,911 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: shutdown LeaderElection
2020-04-15 04:27:07,663 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B: changes role from CANDIDATE to FOLLOWER at term 4 for DISCOVERED_A_NEW_TERM
2020-04-15 04:27:07,944 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: shutdown LeaderElection
2020-04-15 04:27:07,945 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: start FollowerState
2020-04-15 04:27:07,979 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 21110601-e41d-4616-83a0-0c4b7d33d307: shutdown LeaderElection
2020-04-15 04:27:07,980 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21110601-e41d-4616-83a0-0c4b7d33d307: start FollowerState
2020-04-15 04:27:07,980 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:27:07,980 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:27:08,192 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: start FollowerState
2020-04-15 04:27:09,073 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:27:09,433 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:27:10,461 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:27:10,461 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:27:10,906 [grpc-default-executor-23] WARN  impl.RaftServerProxy (RaftServerProxy.java:lambda$groupAddAsync$11(390)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: Failed groupAdd* GroupManagementRequest:client-414691BA9A33->feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B, cid=5, seq=0, RW, null, Add:group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297]
java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: Failed to add group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] since the group already exists in the map.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:607)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)
	at java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:631)
	at java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2006)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.protocol.AlreadyExistsException: feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: Failed to add group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] since the group already exists in the map.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
	... 13 more
2020-04-15 04:27:10,983 [grpc-default-executor-12] WARN  impl.RaftServerProxy (RaftServerProxy.java:lambda$groupAddAsync$11(390)) - 21110601-e41d-4616-83a0-0c4b7d33d307: Failed groupAdd* GroupManagementRequest:client-3B51B2AC422B->21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B, cid=4, seq=0, RW, null, Add:group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297]
java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 21110601-e41d-4616-83a0-0c4b7d33d307: Failed to add group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] since the group already exists in the map.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:607)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)
	at java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:631)
	at java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2006)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.protocol.AlreadyExistsException: 21110601-e41d-4616-83a0-0c4b7d33d307: Failed to add group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] since the group already exists in the map.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
	... 13 more
2020-04-15 04:27:10,984 [grpc-default-executor-2] WARN  impl.RaftServerProxy (RaftServerProxy.java:lambda$groupAddAsync$11(390)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: Failed groupAdd* GroupManagementRequest:client-8BEEF7A2DF81->feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B, cid=3, seq=0, RW, null, Add:group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297]
java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: Failed to add group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] since the group already exists in the map.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:607)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)
	at java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:631)
	at java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2006)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.ratis.protocol.AlreadyExistsException: feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: Failed to add group-A48347E84B3B:[21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297] since the group already exists in the map.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
	... 13 more
2020-04-15 04:27:11,470 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:27:11,798 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(112)) - Created Pipeline RATIS THREE #id: "b26b5514-bea2-4a16-9cee-a48347e84b3b"
.
2020-04-15 04:27:12,250 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:27:12,251 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(112)) - Created Pipeline RATIS THREE #id: "b26b5514-bea2-4a16-9cee-a48347e84b3b"
.
2020-04-15 04:27:12,333 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(112)) - Created Pipeline RATIS THREE #id: "b26b5514-bea2-4a16-9cee-a48347e84b3b"
.
2020-04-15 04:27:13,130 [Thread-732] INFO  impl.FollowerState (FollowerState.java:run(108)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-FollowerState: change to CANDIDATE, lastRpcTime:5150ms, electionTimeout:5059ms
2020-04-15 04:27:13,151 [Thread-731] INFO  impl.FollowerState (FollowerState.java:run(108)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-FollowerState: change to CANDIDATE, lastRpcTime:5206ms, electionTimeout:5193ms
2020-04-15 04:27:13,217 [Thread-731] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: shutdown FollowerState
2020-04-15 04:27:13,261 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:27:13,261 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:27:13,261 [Thread-732] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 21110601-e41d-4616-83a0-0c4b7d33d307: shutdown FollowerState
2020-04-15 04:27:13,273 [Thread-731] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
2020-04-15 04:27:13,273 [Thread-731] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: start LeaderElection
2020-04-15 04:27:13,360 [Thread-730] INFO  impl.FollowerState (FollowerState.java:run(108)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-FollowerState: change to CANDIDATE, lastRpcTime:5179ms, electionTimeout:5026ms
2020-04-15 04:27:13,360 [Thread-730] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: shutdown FollowerState
2020-04-15 04:27:13,361 [Thread-730] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
2020-04-15 04:27:13,361 [Thread-730] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: start LeaderElection
2020-04-15 04:27:13,361 [Thread-732] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
2020-04-15 04:27:13,385 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8: begin an election at term 5 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:13,385 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection7: begin an election at term 5 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:13,468 [Thread-732] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21110601-e41d-4616-83a0-0c4b7d33d307: start LeaderElection
2020-04-15 04:27:13,469 [grpc-default-executor-23] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B: changes role from CANDIDATE to FOLLOWER at term 5 for recognizeCandidate:feab17e5-d3c3-4212-b199-a0ad2a9d8bbd
2020-04-15 04:27:13,469 [grpc-default-executor-23] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 21110601-e41d-4616-83a0-0c4b7d33d307: shutdown LeaderElection
2020-04-15 04:27:13,469 [grpc-default-executor-23] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21110601-e41d-4616-83a0-0c4b7d33d307: start FollowerState
2020-04-15 04:27:13,469 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:run(155)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection9: skip running since this is already CLOSING
2020-04-15 04:27:13,499 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B: changes role from  FOLLOWER to FOLLOWER at term 5 for recognizeCandidate:0254fda8-66ba-4c89-ba34-a1168c48e4b4
2020-04-15 04:27:13,499 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 21110601-e41d-4616-83a0-0c4b7d33d307: shutdown FollowerState
2020-04-15 04:27:13,500 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21110601-e41d-4616-83a0-0c4b7d33d307: start FollowerState
2020-04-15 04:27:13,500 [Thread-744] INFO  impl.FollowerState (FollowerState.java:run(117)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-04-15 04:27:13,656 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection7: Election REJECTED; received 2 response(s) [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd<-21110601-e41d-4616-83a0-0c4b7d33d307#0:FAIL-t5, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd<-0254fda8-66ba-4c89-ba34-a1168c48e4b4#0:FAIL-t5] and 0 exception(s); feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B:t5, leader=null, voted=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd, raftlog=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:13,754 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B: changes role from CANDIDATE to FOLLOWER at term 5 for DISCOVERED_A_NEW_TERM
2020-04-15 04:27:13,776 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: shutdown LeaderElection
2020-04-15 04:27:13,809 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: start FollowerState
2020-04-15 04:27:14,271 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:27:14,451 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-04-15 04:27:14,473 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8: Election PASSED; received 2 response(s) [0254fda8-66ba-4c89-ba34-a1168c48e4b4<-feab17e5-d3c3-4212-b199-a0ad2a9d8bbd#0:FAIL-t5, 0254fda8-66ba-4c89-ba34-a1168c48e4b4<-21110601-e41d-4616-83a0-0c4b7d33d307#0:OK-t5] and 0 exception(s); 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B:t5, leader=null, voted=0254fda8-66ba-4c89-ba34-a1168c48e4b4, raftlog=0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:14,557 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: shutdown LeaderElection
2020-04-15 04:27:14,557 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: changes role from CANDIDATE to LEADER at term 5 for changeToLeader
2020-04-15 04:27:14,557 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(739)) - Leader change notification received for group: group-A48347E84B3B with new leaderId: 0254fda8-66ba-4c89-ba34-a1168c48e4b4
2020-04-15 04:27:14,558 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: change Leader from null to 0254fda8-66ba-4c89-ba34-a1168c48e4b4 at term 5 for becomeLeader, leader elected after 37138ms
2020-04-15 04:27:14,558 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-04-15 04:27:14,558 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-04-15 04:27:14,558 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:openPipeline(131)) - Pipeline Pipeline[ Id: b26b5514-bea2-4a16-9cee-a48347e84b3b, Nodes: 0254fda8-66ba-4c89-ba34-a1168c48e4b4{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}21110601-e41d-4616-83a0-0c4b7d33d307{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}feab17e5-d3c3-4212-b199-a0ad2a9d8bbd{ip: 172.17.0.2, host: edabee8e3155, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:0254fda8-66ba-4c89-ba34-a1168c48e4b4, CreationTimestamp2020-04-15T04:26:19.462Z] moved to OPEN state
2020-04-15 04:27:14,562 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(131)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2020-04-15 04:27:14,562 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(182)) - HealthyPipelineSafeModeRule rule is successfully validated
2020-04-15 04:27:14,562 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(196)) - ScmSafeModeManager, all rules are successfully validated
2020-04-15 04:27:14,562 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(225)) - SCM exiting safe mode.
2020-04-15 04:27:14,565 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B
2020-04-15 04:27:14,566 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-04-15 04:27:14,566 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-04-15 04:27:14,599 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-04-15 04:27:14,599 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-04-15 04:27:14,600 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-04-15 04:27:14,604 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-04-15 04:27:14,605 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-04-15 04:27:14,605 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2020-04-15 04:27:15,495 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-04-15 04:27:15,664 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Cluster exits safe mode
2020-04-15 04:27:17,193 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2020-04-15 04:27:17,226 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-04-15 04:27:17,226 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-04-15 04:27:17,451 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-04-15 04:27:17,451 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-04-15 04:27:17,452 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2020-04-15 04:27:17,464 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2020-04-15 04:27:17,464 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-04-15 04:27:17,464 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-04-15 04:27:17,527 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: start LeaderState
2020-04-15 04:27:17,579 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-SegmentedRaftLogWorker: Starting segment from index:0
2020-04-15 04:27:17,590 [Thread-748] INFO  container.ReplicationManager (ReplicationManager.java:start(165)) - Starting Replication Monitor Thread.
2020-04-15 04:27:17,688 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(387)) - Shutting down the Mini Ozone Cluster
2020-04-15 04:27:17,912 [ReplicationMonitor] INFO  container.ReplicationManager (ReplicationManager.java:run(228)) - Replication Monitor Thread took 47 milliseconds for processing 0 containers.
2020-04-15 04:27:17,800 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-SegmentedRaftLogWorker: created new log segment /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis/b26b5514-bea2-4a16-9cee-a48347e84b3b/current/log_inprogress_0
2020-04-15 04:27:17,923 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(402)) - Stopping the Mini Ozone Cluster
2020-04-15 04:27:17,966 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(484)) - Stopping the OzoneManager
2020-04-15 04:27:17,966 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42605
2020-04-15 04:27:18,055 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: set configuration 0: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null at 0
2020-04-15 04:27:18,233 [IPC Server listener on 42605] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42605
2020-04-15 04:27:18,244 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2020-04-15 04:27:18,244 [main] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(272)) - Stopping OMDoubleBuffer flush thread
2020-04-15 04:27:18,321 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(206)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2020-04-15 04:27:18,321 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service KeyDeletingService
2020-04-15 04:27:18,663 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@5b92ec75{ozoneManager,/,null,UNAVAILABLE}{file:/github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2020-04-15 04:27:18,674 [Thread-745] INFO  impl.FollowerState (FollowerState.java:run(108)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-FollowerState: change to CANDIDATE, lastRpcTime:5174ms, electionTimeout:5145ms
2020-04-15 04:27:18,674 [Thread-745] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 21110601-e41d-4616-83a0-0c4b7d33d307: shutdown FollowerState
2020-04-15 04:27:18,674 [Thread-745] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
2020-04-15 04:27:18,674 [Thread-745] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21110601-e41d-4616-83a0-0c4b7d33d307: start LeaderElection
2020-04-15 04:27:18,675 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@7a75660d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-15 04:27:18,675 [main] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-04-15 04:27:18,784 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@3cede6af{static,/static,file:///github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2020-04-15 04:27:18,860 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@296e7880{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-04-15 04:27:18,895 [Thread-746] INFO  impl.FollowerState (FollowerState.java:run(108)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-FollowerState: change to CANDIDATE, lastRpcTime:5085ms, electionTimeout:5034ms
2020-04-15 04:27:18,895 [Thread-746] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: shutdown FollowerState
2020-04-15 04:27:18,895 [Thread-746] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
2020-04-15 04:27:18,895 [Thread-746] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: start LeaderElection
2020-04-15 04:27:18,919 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(461)) - Stopping the HddsDatanodes
2020-04-15 04:27:18,920 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection10: begin an election at term 6 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:18,975 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection11: begin an election at term 6 for -1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:19,388 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(387)) - Ozone container server started.
2020-04-15 04:27:19,586 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(387)) - Ozone container server started.
2020-04-15 04:27:20,595 [grpc-default-executor-12] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: change Leader from 0254fda8-66ba-4c89-ba34-a1168c48e4b4 to null at term 6 for updateCurrentTerm
2020-04-15 04:27:20,628 [grpc-default-executor-12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: changes role from    LEADER to FOLLOWER at term 6 for recognizeCandidate:feab17e5-d3c3-4212-b199-a0ad2a9d8bbd
2020-04-15 04:27:20,628 [grpc-default-executor-12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: shutdown LeaderState
2020-04-15 04:27:21,488 [grpc-default-executor-12] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(240)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-PendingRequests: sendNotLeaderResponses
2020-04-15 04:27:21,544 [SCM Heartbeat Processing Thread - 0] ERROR node.NodeStateManager (NodeStateManager.java:checkNodesHealth(636)) - Total time spend processing datanode HB's is greater than configured values for datanode heartbeats. Please adjust the heartbeat configs. Time Spend on HB processing: 0 seconds Datanode heartbeat Interval: 100 seconds.
2020-04-15 04:27:22,151 [grpc-default-executor-12] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_appender.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B
2020-04-15 04:27:22,832 [grpc-default-executor-23] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(137)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: Completed APPEND_ENTRIES, lastRequest: null
2020-04-15 04:27:22,764 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$620/1743261201@71eeac68] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(153)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B->21110601-e41d-4616-83a0-0c4b7d33d307-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2020-04-15 04:27:23,214 [grpc-default-executor-12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: start FollowerState
2020-04-15 04:27:23,236 [grpc-default-executor-23] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(137)) - 21110601-e41d-4616-83a0-0c4b7d33d307: Completed APPEND_ENTRIES, lastRequest: null
2020-04-15 04:27:23,282 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: changes role from  FOLLOWER to FOLLOWER at term 6 for recognizeCandidate:21110601-e41d-4616-83a0-0c4b7d33d307
2020-04-15 04:27:23,282 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: shutdown FollowerState
2020-04-15 04:27:23,293 [Thread-762] INFO  impl.FollowerState (FollowerState.java:run(117)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-04-15 04:27:23,350 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: start FollowerState
2020-04-15 04:27:23,350 [grpc-default-executor-21] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(308)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B->feab17e5-d3c3-4212-b199-a0ad2a9d8bbd-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2020-04-15 04:27:23,350 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(308)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B->21110601-e41d-4616-83a0-0c4b7d33d307-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2020-04-15 04:27:23,447 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection11: Election REJECTED; received 2 response(s) [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd<-21110601-e41d-4616-83a0-0c4b7d33d307#0:FAIL-t6, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd<-0254fda8-66ba-4c89-ba34-a1168c48e4b4#0:FAIL-t6] and 0 exception(s); feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B:t6, leader=null, voted=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd, raftlog=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:23,461 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B: changes role from CANDIDATE to FOLLOWER at term 6 for DISCOVERED_A_NEW_TERM
2020-04-15 04:27:23,472 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: shutdown LeaderElection
2020-04-15 04:27:23,581 [grpc-default-executor-21] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B->feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: nextIndex: updateUnconditionally 0 -> 0
2020-04-15 04:27:23,708 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: start FollowerState
2020-04-15 04:27:23,722 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B->21110601-e41d-4616-83a0-0c4b7d33d307: nextIndex: updateUnconditionally 1 -> 0
2020-04-15 04:27:23,801 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection10: Election REJECTED; received 2 response(s) [21110601-e41d-4616-83a0-0c4b7d33d307<-feab17e5-d3c3-4212-b199-a0ad2a9d8bbd#0:FAIL-t6, 21110601-e41d-4616-83a0-0c4b7d33d307<-0254fda8-66ba-4c89-ba34-a1168c48e4b4#0:FAIL-t6] and 0 exception(s); 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B:t6, leader=null, voted=21110601-e41d-4616-83a0-0c4b7d33d307, raftlog=21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:23,824 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B: changes role from CANDIDATE to FOLLOWER at term 6 for DISCOVERED_A_NEW_TERM
2020-04-15 04:27:23,824 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 21110601-e41d-4616-83a0-0c4b7d33d307: shutdown LeaderElection
2020-04-15 04:27:23,824 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 21110601-e41d-4616-83a0-0c4b7d33d307: start FollowerState
2020-04-15 04:27:24,243 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(246)) - Attempting to stop container services.
2020-04-15 04:27:24,364 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: close
2020-04-15 04:27:24,376 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(246)) - Attempting to stop container services.
2020-04-15 04:27:24,398 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 21110601-e41d-4616-83a0-0c4b7d33d307: close
2020-04-15 04:27:24,399 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(249)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68: shutdown
2020-04-15 04:27:24,400 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-7E1409131C68,id=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd
2020-04-15 04:27:24,400 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: shutdown LeaderState
2020-04-15 04:27:24,412 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(249)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161: shutdown
2020-04-15 04:27:24,412 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-67089499E161,id=21110601-e41d-4616-83a0-0c4b7d33d307
2020-04-15 04:27:24,412 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 21110601-e41d-4616-83a0-0c4b7d33d307: shutdown LeaderState
2020-04-15 04:27:24,532 [ForkJoinPool.commonPool-worker-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(240)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-PendingRequests: sendNotLeaderResponses
2020-04-15 04:27:24,532 [ForkJoinPool.commonPool-worker-0] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_appender.21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161
2020-04-15 04:27:24,533 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(139)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-StateMachineUpdater: set stopIndex = 0
2020-04-15 04:27:24,411 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(240)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-PendingRequests: sendNotLeaderResponses
2020-04-15 04:27:24,598 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(295)) - group-67089499E161: Taking a snapshot at:(t:1, i:0) file /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data/ratis/4259674b-f726-4afa-88eb-67089499e161/sm/snapshot.1_0
2020-04-15 04:27:24,655 [main] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_appender.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68
2020-04-15 04:27:24,666 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(139)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-StateMachineUpdater: set stopIndex = 0
2020-04-15 04:27:24,978 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(295)) - group-7E1409131C68: Taking a snapshot at:(t:1, i:0) file /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data/ratis/41cf3cc1-29b0-4cd0-ab24-7e1409131c68/sm/snapshot.1_0
2020-04-15 04:27:25,791 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(306)) - group-7E1409131C68: Finished taking a snapshot at:(t:1, i:0) file:/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-1/data/ratis/41cf3cc1-29b0-4cd0-ab24-7e1409131c68/sm/snapshot.1_0 time:813
2020-04-15 04:27:25,802 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(306)) - group-67089499E161: Finished taking a snapshot at:(t:1, i:0) file:/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-0/data/ratis/4259674b-f726-4afa-88eb-67089499e161/sm/snapshot.1_0 time:1204
2020-04-15 04:27:25,958 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(274)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-StateMachineUpdater: Took a snapshot at index 0
2020-04-15 04:27:25,958 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(274)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-StateMachineUpdater: Took a snapshot at index 0
2020-04-15 04:27:25,958 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(86)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-04-15 04:27:25,958 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(86)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-04-15 04:27:26,050 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68
2020-04-15 04:27:26,050 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161
2020-04-15 04:27:26,116 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68: closes. applyIndex: 0
2020-04-15 04:27:26,150 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161: closes. applyIndex: 0
2020-04-15 04:27:26,185 [21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-04-15 04:27:26,196 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-04-15 04:27:26,229 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68-SegmentedRaftLogWorker close()
2020-04-15 04:27:26,229 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161-SegmentedRaftLogWorker close()
2020-04-15 04:27:26,230 [main] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd
2020-04-15 04:27:26,231 [main] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68
2020-04-15 04:27:26,231 [main] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-7E1409131C68
2020-04-15 04:27:26,231 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(249)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B: shutdown
2020-04-15 04:27:26,232 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A48347E84B3B,id=feab17e5-d3c3-4212-b199-a0ad2a9d8bbd
2020-04-15 04:27:26,276 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: shutdown FollowerState
2020-04-15 04:27:26,277 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(139)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-StateMachineUpdater: set stopIndex = -1
2020-04-15 04:27:26,277 [Thread-764] INFO  impl.FollowerState (FollowerState.java:run(117)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-04-15 04:27:26,278 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B
2020-04-15 04:27:26,278 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B: closes. applyIndex: -1
2020-04-15 04:27:26,279 [feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-04-15 04:27:26,279 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B-SegmentedRaftLogWorker close()
2020-04-15 04:27:26,280 [ForkJoinPool.commonPool-worker-0] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.21110601-e41d-4616-83a0-0c4b7d33d307
2020-04-15 04:27:26,280 [ForkJoinPool.commonPool-worker-0] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161
2020-04-15 04:27:26,280 [ForkJoinPool.commonPool-worker-0] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.21110601-e41d-4616-83a0-0c4b7d33d307@group-67089499E161
2020-04-15 04:27:26,281 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(249)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B: shutdown
2020-04-15 04:27:26,281 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A48347E84B3B,id=21110601-e41d-4616-83a0-0c4b7d33d307
2020-04-15 04:27:26,281 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 21110601-e41d-4616-83a0-0c4b7d33d307: shutdown FollowerState
2020-04-15 04:27:26,281 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(139)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-StateMachineUpdater: set stopIndex = -1
2020-04-15 04:27:26,281 [Thread-765] INFO  impl.FollowerState (FollowerState.java:run(117)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-04-15 04:27:26,281 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B
2020-04-15 04:27:26,282 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B: closes. applyIndex: -1
2020-04-15 04:27:26,282 [21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-04-15 04:27:26,283 [main] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd
2020-04-15 04:27:26,284 [main] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B
2020-04-15 04:27:26,284 [main] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.feab17e5-d3c3-4212-b199-a0ad2a9d8bbd@group-A48347E84B3B
2020-04-15 04:27:26,295 [ForkJoinPool.commonPool-worker-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - 21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B-SegmentedRaftLogWorker close()
2020-04-15 04:27:26,321 [ForkJoinPool.commonPool-worker-0] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.21110601-e41d-4616-83a0-0c4b7d33d307
2020-04-15 04:27:26,321 [ForkJoinPool.commonPool-worker-0] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B
2020-04-15 04:27:26,321 [ForkJoinPool.commonPool-worker-0] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.21110601-e41d-4616-83a0-0c4b7d33d307@group-A48347E84B3B
2020-04-15 04:27:26,322 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 21110601-e41d-4616-83a0-0c4b7d33d307: shutdown server with port 39893 now
2020-04-15 04:27:26,333 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: shutdown server with port 33235 now
2020-04-15 04:27:26,869 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 21110601-e41d-4616-83a0-0c4b7d33d307: shutdown server with port 39893 successfully
2020-04-15 04:27:26,891 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - feab17e5-d3c3-4212-b199-a0ad2a9d8bbd: shutdown server with port 33235 successfully
2020-04-15 04:27:27,874 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service BlockDeletingService
2020-04-15 04:27:27,928 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service BlockDeletingService
2020-04-15 04:27:28,165 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(435)) - Ozone container server stopped.
2020-04-15 04:27:28,177 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@4cb2b67c{hddsDatanode,/,null,UNAVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-04-15 04:27:28,211 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(435)) - Ozone container server stopped.
2020-04-15 04:27:28,211 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@483937e{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-15 04:27:28,212 [main] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-04-15 04:27:28,212 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@323c470{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2020-04-15 04:27:28,212 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@e097855{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-04-15 04:27:28,311 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@8432199{hddsDatanode,/,null,UNAVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-04-15 04:27:28,409 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@1065ea4c{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-15 04:27:28,409 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-04-15 04:27:28,411 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@5834b11{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2020-04-15 04:27:28,415 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@3763ef0d{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-04-15 04:27:28,547 [Thread-763] INFO  impl.FollowerState (FollowerState.java:run(108)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-FollowerState: change to CANDIDATE, lastRpcTime:5196ms, electionTimeout:5170ms
2020-04-15 04:27:28,590 [Thread-763] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: shutdown FollowerState
2020-04-15 04:27:28,590 [Thread-763] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
2020-04-15 04:27:28,602 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(387)) - Ozone container server started.
2020-04-15 04:27:28,613 [Thread-763] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: start LeaderElection
2020-04-15 04:27:28,681 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection12: begin an election at term 7 for 0: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:29,219 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection12] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection12 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2020-04-15 04:27:29,251 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection12] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection12 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2020-04-15 04:27:29,251 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection12: Election REJECTED; received 0 response(s) [] and 2 exception(s); 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B:t7, leader=null, voted=0254fda8-66ba-4c89-ba34-a1168c48e4b4, raftlog=0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-SegmentedRaftLog:OPENED:c0,f0,i0, conf=0: [21110601-e41d-4616-83a0-0c4b7d33d307:172.17.0.2:39893, feab17e5-d3c3-4212-b199-a0ad2a9d8bbd:172.17.0.2:33235, 0254fda8-66ba-4c89-ba34-a1168c48e4b4:172.17.0.2:36297], old=null
2020-04-15 04:27:29,251 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection12] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2020-04-15 04:27:29,252 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection12] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2020-04-15 04:27:29,266 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(172)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: changes role from CANDIDATE to FOLLOWER at term 7 for DISCOVERED_A_NEW_TERM
2020-04-15 04:27:29,277 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: shutdown LeaderElection
2020-04-15 04:27:29,298 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: start FollowerState
2020-04-15 04:27:33,282 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(246)) - Attempting to stop container services.
2020-04-15 04:27:33,393 [main] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: close
2020-04-15 04:27:33,415 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(249)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312: shutdown
2020-04-15 04:27:33,415 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B2EF0E579312,id=0254fda8-66ba-4c89-ba34-a1168c48e4b4
2020-04-15 04:27:33,459 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: shutdown LeaderState
2020-04-15 04:27:33,459 [main] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(240)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-PendingRequests: sendNotLeaderResponses
2020-04-15 04:27:33,460 [main] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_appender.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312
2020-04-15 04:27:33,514 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(295)) - group-B2EF0E579312: Taking a snapshot at:(t:1, i:0) file /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis/3ac49010-9342-4bb5-b8e8-b2ef0e579312/sm/snapshot.1_0
2020-04-15 04:27:33,569 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(139)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-StateMachineUpdater: set stopIndex = 0
2020-04-15 04:27:33,570 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(306)) - group-B2EF0E579312: Finished taking a snapshot at:(t:1, i:0) file:/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis/3ac49010-9342-4bb5-b8e8-b2ef0e579312/sm/snapshot.1_0 time:57
2020-04-15 04:27:33,571 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(274)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-StateMachineUpdater: Took a snapshot at index 0
2020-04-15 04:27:33,571 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(86)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-04-15 04:27:33,571 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312
2020-04-15 04:27:33,571 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312: closes. applyIndex: 0
2020-04-15 04:27:33,571 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-04-15 04:27:33,584 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312-SegmentedRaftLogWorker close()
2020-04-15 04:27:33,585 [main] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.0254fda8-66ba-4c89-ba34-a1168c48e4b4
2020-04-15 04:27:33,585 [main] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312
2020-04-15 04:27:33,586 [main] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-B2EF0E579312
2020-04-15 04:27:33,586 [main] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(249)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: shutdown
2020-04-15 04:27:33,586 [main] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A48347E84B3B,id=0254fda8-66ba-4c89-ba34-a1168c48e4b4
2020-04-15 04:27:33,586 [main] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: shutdown FollowerState
2020-04-15 04:27:33,586 [main] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(139)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-StateMachineUpdater: set stopIndex = 0
2020-04-15 04:27:33,586 [Thread-769] INFO  impl.FollowerState (FollowerState.java:run(117)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-04-15 04:27:33,653 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(295)) - group-A48347E84B3B: Taking a snapshot at:(t:5, i:0) file /github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis/b26b5514-bea2-4a16-9cee-a48347e84b3b/sm/snapshot.5_0
2020-04-15 04:27:33,721 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(306)) - group-A48347E84B3B: Finished taking a snapshot at:(t:5, i:0) file:/github/workspace/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-663b4687-650b-40ef-8582-3f3e0ab463db/datanode-2/data/ratis/b26b5514-bea2-4a16-9cee-a48347e84b3b/sm/snapshot.5_0 time:68
2020-04-15 04:27:33,744 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(274)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-StateMachineUpdater: Took a snapshot at index 0
2020-04-15 04:27:33,744 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(86)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-04-15 04:27:33,744 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B
2020-04-15 04:27:33,744 [main] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B: closes. applyIndex: 0
2020-04-15 04:27:33,756 [0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-04-15 04:27:33,881 [main] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B-SegmentedRaftLogWorker close()
2020-04-15 04:27:34,008 [main] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.0254fda8-66ba-4c89-ba34-a1168c48e4b4
2020-04-15 04:27:34,009 [main] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B
2020-04-15 04:27:34,009 [main] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.0254fda8-66ba-4c89-ba34-a1168c48e4b4@group-A48347E84B3B
2020-04-15 04:27:34,021 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(164)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: shutdown server with port 36297 now
2020-04-15 04:27:34,217 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(172)) - 0254fda8-66ba-4c89-ba34-a1168c48e4b4: shutdown server with port 36297 successfully
2020-04-15 04:27:34,436 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service BlockDeletingService
2020-04-15 04:27:34,561 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(435)) - Ozone container server stopped.
2020-04-15 04:27:34,641 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@63c1dcd{hddsDatanode,/,null,UNAVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-04-15 04:27:34,685 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@212d0cb0{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-15 04:27:34,686 [main] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-04-15 04:27:34,686 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@6a0ad14f{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2020-04-15 04:27:34,686 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@7c5dbf7f{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-04-15 04:27:34,709 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(476)) - Stopping the StorageContainerManager
2020-04-15 04:27:34,720 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(816)) - Stopping Replication Manager Service.
2020-04-15 04:27:34,720 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(206)) - Stopping Replication Monitor Thread.
2020-04-15 04:27:34,720 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(823)) - Stopping Lease Manager of the command watchers
2020-04-15 04:27:34,720 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping datanode service RPC server
2020-04-15 04:27:34,720 [CommandWatcher-LeaseManager#LeaseMonitor] ERROR lease.LeaseManager (LeaseManager.java:run(238)) - Execution was interrupted 
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:234)
	at java.lang.Thread.run(Thread.java:748)
2020-04-15 04:27:34,721 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(361)) - Stopping the RPC server for DataNodes
2020-04-15 04:27:34,721 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 37603
2020-04-15 04:27:34,723 [IPC Server listener on 37603] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 37603
2020-04-15 04:27:34,803 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2020-04-15 04:27:34,946 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(656)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2020-04-15 04:27:35,011 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(838)) - Stopping block service RPC server
2020-04-15 04:27:35,011 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(158)) - Stopping the RPC server for Block Protocol
2020-04-15 04:27:35,011 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 35971
2020-04-15 04:27:35,024 [IPC Server listener on 35971] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 35971
2020-04-15 04:27:35,114 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(845)) - Stopping the StorageContainerLocationProtocol RPC server
2020-04-15 04:27:35,125 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2020-04-15 04:27:35,126 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(164)) - Stopping the RPC server for Client Protocol
2020-04-15 04:27:35,126 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 43135
2020-04-15 04:27:35,151 [IPC Server listener on 43135] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 43135
2020-04-15 04:27:35,151 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(852)) - Stopping Storage Container Manager HTTP server.
2020-04-15 04:27:35,162 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2020-04-15 04:27:35,196 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@1245a728{scm,/,null,UNAVAILABLE}{file:/github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2020-04-15 04:27:35,218 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@7ecc74a0{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-15 04:27:35,218 [main] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-04-15 04:27:35,218 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@5c191b44{static,/static,file:///github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2020-04-15 04:27:35,218 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@79b6663b{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-04-15 04:27:35,220 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(863)) - Stopping Block Manager Service.
2020-04-15 04:27:35,220 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service SCMBlockDeletingService
2020-04-15 04:27:35,221 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service SCMBlockDeletingService
2020-04-15 04:27:35,221 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(888)) - Stopping SCM Event Queue.
2020-04-15 04:27:35,246 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2020-04-15 04:27:35,288 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2020-04-15 04:27:36,513 [main] ERROR om.KeyManagerImpl (KeyManagerImpl.java:verifyNoFilesInPath(2110)) - Unable to create directory (File already exists): volume: vol1 bucket: bucket1 key: OlYme
2020-04-15 04:27:36,900 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(816)) - Stopping Replication Manager Service.
2020-04-15 04:27:36,900 [main] INFO  container.ReplicationManager (ReplicationManager.java:stop(206)) - Stopping Replication Monitor Thread.
2020-04-15 04:27:36,900 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(823)) - Stopping Lease Manager of the command watchers
2020-04-15 04:27:36,900 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(830)) - Stopping datanode service RPC server
2020-04-15 04:27:36,945 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(361)) - Stopping the RPC server for DataNodes
2020-04-15 04:27:36,945 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42839
2020-04-15 04:27:36,900 [CommandWatcher-LeaseManager#LeaseMonitor] ERROR lease.LeaseManager (LeaseManager.java:run(238)) - Execution was interrupted 
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:234)
	at java.lang.Thread.run(Thread.java:748)
2020-04-15 04:27:36,983 [IPC Server listener on 42839] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42839
2020-04-15 04:27:36,983 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2020-04-15 04:27:36,983 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(838)) - Stopping block service RPC server
2020-04-15 04:27:36,994 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(158)) - Stopping the RPC server for Block Protocol
2020-04-15 04:27:36,994 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 35655
2020-04-15 04:27:37,038 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(845)) - Stopping the StorageContainerLocationProtocol RPC server
2020-04-15 04:27:37,038 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2020-04-15 04:27:37,038 [IPC Server listener on 35655] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 35655
2020-04-15 04:27:37,052 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(164)) - Stopping the RPC server for Client Protocol
2020-04-15 04:27:37,052 [main] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 40467
2020-04-15 04:27:37,160 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(852)) - Stopping Storage Container Manager HTTP server.
2020-04-15 04:27:37,160 [IPC Server listener on 40467] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 40467
2020-04-15 04:27:37,171 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2020-04-15 04:27:37,307 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@78464205{scm,/,null,UNAVAILABLE}{file:/github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2020-04-15 04:27:37,332 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@155770e0{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-15 04:27:37,333 [main] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-04-15 04:27:37,333 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@568514f{static,/static,file:///github/workspace/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2020-04-15 04:27:37,333 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@3bc22ada{logs,/logs,file:///github/workspace/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-04-15 04:27:37,349 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(863)) - Stopping Block Manager Service.
2020-04-15 04:27:37,349 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service SCMBlockDeletingService
2020-04-15 04:27:37,349 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service SCMBlockDeletingService
2020-04-15 04:27:37,349 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(888)) - Stopping SCM Event Queue.
2020-04-15 04:27:37,408 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(205)) - HddsDatanode metrics system stopped (again)
