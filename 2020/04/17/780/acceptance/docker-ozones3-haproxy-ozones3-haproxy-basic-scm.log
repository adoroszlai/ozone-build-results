Attaching to ozones3-haproxy_datanode_3, ozones3-haproxy_datanode_2, ozones3-haproxy_s3g_1, ozones3-haproxy_s3g1_1, ozones3-haproxy_datanode_1, ozones3-haproxy_s3g3_1, ozones3-haproxy_om_1, ozones3-haproxy_scm_1, ozones3-haproxy_s3g2_1
om_1        | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-04-17 04:56:29,295 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = 0f1b5f718ebe/172.22.0.8
om_1        | STARTUP_MSG:   args = [--init]
om_1        | STARTUP_MSG:   version = 3.2.0
datanode_1  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2020-04-17 04:56:29,664 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = ca5fa3da651c/172.22.0.7
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 3.2.0
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1  | STARTUP_MSG:   java = 11.0.6
datanode_1  | ************************************************************/
datanode_1  | 2020-04-17 04:56:29,969 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2020-04-17 04:56:31,214 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2020-04-17 04:56:31,631 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2020-04-17 04:56:32,412 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2020-04-17 04:56:32,412 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2020-04-17 04:56:33,196 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:ca5fa3da651c ip:172.22.0.7
datanode_1  | 2020-04-17 04:56:33,674 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2020-04-17 04:56:33,716 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1  | 2020-04-17 04:56:33,717 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2020-04-17 04:56:33,746 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2020-04-17 04:56:33,845 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2020-04-17 04:56:38,061 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2020-04-17 04:56:38,298 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1  | 2020-04-17 04:56:38,647 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1  | 2020-04-17 04:56:38,669 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  | 2020-04-17 04:56:38,672 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-17 04:56:38,676 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1  | 2020-04-17 04:56:38,677 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2020-04-17 04:56:40,048 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-04-17 04:56:40,835 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2020-04-17 04:56:41,057 [main] INFO util.log: Logging initialized @15625ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2020-04-17 04:56:41,423 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2020-04-17 04:56:41,438 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2020-04-17 04:56:41,442 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2020-04-17 04:56:41,460 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1  | 2020-04-17 04:56:41,461 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1  | 2020-04-17 04:56:41,461 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1  | 2020-04-17 04:56:41,572 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2020-04-17 04:56:41,578 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1  | 2020-04-17 04:56:41,733 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  | 2020-04-17 04:56:41,733 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2020-04-17 04:56:41,741 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1  | 2020-04-17 04:56:41,790 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f76c2cc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2020-04-17 04:56:41,804 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@441b8382{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2020-04-17 04:56:42,163 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@673c4f6e{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-3216959700513744985.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1  | 2020-04-17 04:56:42,241 [main] INFO server.AbstractConnector: Started ServerConnector@1491344a{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1  | 2020-04-17 04:56:42,244 [main] INFO server.Server: Started @16812ms
datanode_1  | 2020-04-17 04:56:42,268 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2020-04-17 04:56:42,268 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2020-04-17 04:56:42,274 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1  | 2020-04-17 04:56:42,417 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@701d9f0b] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2020-04-17 04:56:43,104 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1  | 2020-04-17 04:56:45,445 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.22.0.6:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-04-17 04:56:45,700 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 2020-04-17 04:56:45,701 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1  | 2020-04-17 04:56:45,701 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis f71fab23-81a9-41d8-ab04-2a8824f1aeaa at port 9858
datanode_1  | 2020-04-17 04:56:45,776 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: start RPC server
datanode_1  | 2020-04-17 04:56:45,940 [Datanode State Machine Thread - 0] INFO server.GrpcService: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1  | 2020-04-17 04:56:49,431 [Command processor thread] INFO impl.RaftServerProxy: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: addNew group-D9F6E51256A2:[f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858] returns group-D9F6E51256A2:java.util.concurrent.CompletableFuture@4f1f4635[Not completed]
datanode_2  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2020-04-17 04:56:26,980 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = 711de6e6b939/172.22.0.2
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 3.2.0
datanode_3  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2020-04-17 04:56:30,368 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = 84e959ce1a08/172.22.0.4
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 3.2.0
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_2  | STARTUP_MSG:   java = 11.0.6
datanode_2  | ************************************************************/
datanode_2  | 2020-04-17 04:56:26,998 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2020-04-17 04:56:28,374 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2020-04-17 04:56:28,861 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2020-04-17 04:56:29,840 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2020-04-17 04:56:29,841 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2020-04-17 04:56:30,647 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:711de6e6b939 ip:172.22.0.2
datanode_2  | 2020-04-17 04:56:31,207 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2  | 2020-04-17 04:56:31,242 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2  | 2020-04-17 04:56:31,249 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2020-04-17 04:56:31,319 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2  | 2020-04-17 04:56:31,366 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2020-04-17 04:56:36,268 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-04-17 04:56:36,472 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2020-04-17 04:56:36,746 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2  | 2020-04-17 04:56:36,756 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2  | 2020-04-17 04:56:36,757 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-17 04:56:36,763 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2  | 2020-04-17 04:56:36,764 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-04-17 04:56:37,731 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-17 04:56:38,476 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 2020-04-17 04:56:38,573 [main] INFO util.log: Logging initialized @14991ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | 2020-04-17 04:56:39,129 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2020-04-17 04:56:39,164 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2020-04-17 04:56:39,185 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2020-04-17 04:56:39,191 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2  | 2020-04-17 04:56:39,209 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2  | 2020-04-17 04:56:39,209 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2  | 2020-04-17 04:56:39,356 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2020-04-17 04:56:39,360 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2  | 2020-04-17 04:56:39,532 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2020-04-17 04:56:39,533 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2020-04-17 04:56:39,534 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2  | 2020-04-17 04:56:39,557 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f76c2cc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2020-04-17 04:56:39,567 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@441b8382{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2020-04-17 04:56:39,954 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@673c4f6e{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-5495024781796315418.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 2020-04-17 04:56:40,005 [main] INFO server.AbstractConnector: Started ServerConnector@1491344a{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2  | 2020-04-17 04:56:40,016 [main] INFO server.Server: Started @16434ms
datanode_2  | 2020-04-17 04:56:40,041 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2020-04-17 04:56:40,041 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2020-04-17 04:56:40,071 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2020-04-17 04:56:40,125 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5b439b05] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2020-04-17 04:56:40,805 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2  | 2020-04-17 04:56:43,393 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.22.0.6:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-04-17 04:56:44,393 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.22.0.6:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-04-17 04:56:45,394 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.22.0.6:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-04-17 04:56:45,709 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2020-04-17 04:56:45,710 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2  | 2020-04-17 04:56:45,710 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 3aa95a42-0392-4192-8556-ef4d57f7b5c9 at port 9858
datanode_2  | 2020-04-17 04:56:45,767 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: start RPC server
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_3  | STARTUP_MSG:   java = 11.0.6
datanode_3  | ************************************************************/
datanode_3  | 2020-04-17 04:56:30,436 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2020-04-17 04:56:32,070 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2020-04-17 04:56:32,508 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2020-04-17 04:56:33,540 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2020-04-17 04:56:33,544 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2020-04-17 04:56:34,327 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:84e959ce1a08 ip:172.22.0.4
datanode_3  | 2020-04-17 04:56:34,751 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3  | 2020-04-17 04:56:34,761 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3  | 2020-04-17 04:56:34,765 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2020-04-17 04:56:34,784 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2020-04-17 04:56:34,964 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2020-04-17 04:56:39,109 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-04-17 04:56:39,322 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3  | 2020-04-17 04:56:39,647 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3  | 2020-04-17 04:56:39,647 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3  | 2020-04-17 04:56:39,648 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-17 04:56:39,668 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3  | 2020-04-17 04:56:39,669 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-04-17 04:56:40,831 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-17 04:56:41,227 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2020-04-17 04:56:41,290 [main] INFO util.log: Logging initialized @15128ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2020-04-17 04:56:41,628 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2020-04-17 04:56:41,637 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2020-04-17 04:56:41,651 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2020-04-17 04:56:41,668 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3  | 2020-04-17 04:56:41,669 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3  | 2020-04-17 04:56:41,669 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3  | 2020-04-17 04:56:41,762 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2020-04-17 04:56:41,769 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3  | 2020-04-17 04:56:41,897 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2020-04-17 04:56:41,900 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 2020-04-17 04:56:41,901 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_3  | 2020-04-17 04:56:41,922 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f76c2cc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2020-04-17 04:56:41,923 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@441b8382{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2020-04-17 04:56:42,320 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@673c4f6e{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-9266301091912490693.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2020-04-17 04:56:42,371 [main] INFO server.AbstractConnector: Started ServerConnector@1491344a{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3  | 2020-04-17 04:56:42,376 [main] INFO server.Server: Started @16215ms
datanode_3  | 2020-04-17 04:56:42,535 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2020-04-17 04:56:42,535 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2020-04-17 04:56:42,560 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3  | 2020-04-17 04:56:42,677 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1174369] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2020-04-17 04:56:43,309 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3  | 2020-04-17 04:56:45,706 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/172.22.0.6:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-04-17 04:56:45,800 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3  | 2020-04-17 04:56:45,801 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3  | 2020-04-17 04:56:45,802 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis ed3d0f0e-4614-480f-aff0-1706334f678b at port 9858
datanode_3  | 2020-04-17 04:56:45,875 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: ed3d0f0e-4614-480f-aff0-1706334f678b: start RPC server
datanode_3  | 2020-04-17 04:56:46,173 [Datanode State Machine Thread - 0] INFO server.GrpcService: ed3d0f0e-4614-480f-aff0-1706334f678b: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3  | 2020-04-17 04:56:49,701 [Command processor thread] INFO impl.RaftServerProxy: ed3d0f0e-4614-480f-aff0-1706334f678b: addNew group-CCD74131E2C6:[ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] returns group-CCD74131E2C6:java.util.concurrent.CompletableFuture@7b682c86[Not completed]
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-04-17 04:56:29,337 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-04-17 04:56:33,638 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-04-17 04:56:33,856 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.22.0.8:9862
om_1        | 2020-04-17 04:56:33,856 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-04-17 04:56:33,884 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-17 04:56:35,858 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.6:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-17 04:56:36,859 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.6:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-17 04:56:37,860 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.6:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-17 04:56:38,860 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.6:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-17 04:56:39,861 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.6:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-17 04:56:40,862 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.6:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-17 04:56:41,862 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.6:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-17 04:56:42,863 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.6:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-17 04:56:43,864 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.6:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-17 04:56:44,865 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.6:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-17 04:56:44,867 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-bc1e19f5-e932-4360-bf0f-5d36458447e6
om_1        | 2020-04-17 04:56:50,047 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1        | /************************************************************
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at 0f1b5f718ebe/172.22.0.8
om_1        | ************************************************************/
om_1        | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-04-17 04:56:52,973 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = 0f1b5f718ebe/172.22.0.8
om_1        | STARTUP_MSG:   args = []
om_1        | STARTUP_MSG:   version = 3.2.0
datanode_1  | 2020-04-17 04:56:49,478 [pool-69-thread-1] INFO impl.RaftServerImpl: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: new RaftServerImpl for group-D9F6E51256A2:[f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-04-17 04:56:49,484 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-04-17 04:56:49,489 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-04-17 04:56:49,489 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-04-17 04:56:49,489 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-04-17 04:56:49,490 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-04-17 04:56:49,498 [pool-69-thread-1] INFO impl.RaftServerImpl: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2: ConfigurationManager, init=-1: [f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-04-17 04:56:49,501 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-04-17 04:56:49,520 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-04-17 04:56:49,521 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/0e400dd7-6b0f-46e3-b517-d9f6e51256a2 does not exist. Creating ...
datanode_1  | 2020-04-17 04:56:49,535 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/0e400dd7-6b0f-46e3-b517-d9f6e51256a2/in_use.lock acquired by nodename 6@ca5fa3da651c
datanode_1  | 2020-04-17 04:56:49,537 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/0e400dd7-6b0f-46e3-b517-d9f6e51256a2 has been successfully formatted.
datanode_1  | 2020-04-17 04:56:49,555 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-D9F6E51256A2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-04-17 04:56:49,555 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-04-17 04:56:49,564 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-04-17 04:56:49,579 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-04-17 04:56:49,579 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-17 04:56:49,580 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-17 04:56:49,586 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.f71fab23-81a9-41d8-ab04-2a8824f1aeaa
datanode_1  | 2020-04-17 04:56:49,599 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-04-17 04:56:49,623 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/0e400dd7-6b0f-46e3-b517-d9f6e51256a2
datanode_1  | 2020-04-17 04:56:49,626 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-04-17 04:56:49,626 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-04-17 04:56:49,627 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-17 04:56:49,627 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-04-17 04:56:49,630 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-04-17 04:56:49,632 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-04-17 04:56:49,633 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-04-17 04:56:49,634 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-04-17 04:56:49,634 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-04-17 04:56:49,688 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-04-17 04:56:49,724 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-04-17 04:56:49,740 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-04-17 04:56:49,752 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-04-17 04:56:49,756 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-04-17 04:56:49,757 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-04-17 04:56:49,798 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2
datanode_1  | 2020-04-17 04:56:49,806 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2
datanode_1  | 2020-04-17 04:56:49,813 [pool-69-thread-1] INFO impl.RaftServerImpl: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2: start as a follower, conf=-1: [f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858], old=null
datanode_1  | 2020-04-17 04:56:49,813 [pool-69-thread-1] INFO impl.RaftServerImpl: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-04-17 04:56:49,822 [pool-69-thread-1] INFO impl.RoleInfo: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: start FollowerState
datanode_1  | 2020-04-17 04:56:49,837 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D9F6E51256A2,id=f71fab23-81a9-41d8-ab04-2a8824f1aeaa
datanode_1  | 2020-04-17 04:56:49,838 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2
datanode_1  | 2020-04-17 04:56:49,869 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "0e400dd7-6b0f-46e3-b517-d9f6e51256a2"
datanode_1  | .
datanode_1  | 2020-04-17 04:56:49,875 [Command processor thread] INFO impl.RaftServerProxy: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: addNew group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] returns group-83CC33444ED1:java.util.concurrent.CompletableFuture@e8672d[Not completed]
datanode_1  | 2020-04-17 04:56:49,904 [pool-69-thread-1] INFO impl.RaftServerImpl: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: new RaftServerImpl for group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-04-17 04:56:49,913 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-04-17 04:56:52,983 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-04-17 04:56:53,661 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-04-17 04:56:53,706 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.22.0.8:9862
om_1        | 2020-04-17 04:56:53,706 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-04-17 04:56:53,709 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-17 04:56:53,811 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-17 04:56:54,347 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-17 04:56:54,605 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2020-04-17 04:56:54,621 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1        | 2020-04-17 04:56:54,937 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | 2020-04-17 04:56:55,150 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2020-04-17 04:56:55,150 [main] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1        | 2020-04-17 04:56:55,421 [main] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.22.0.8:9862
om_1        | 2020-04-17 04:56:55,497 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1        | 2020-04-17 04:56:55,677 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1        | 2020-04-17 04:56:55,775 [main] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1        | 2020-04-17 04:56:55,808 [main] INFO util.log: Logging initialized @5421ms to org.eclipse.jetty.util.log.Slf4jLog
om_1        | 2020-04-17 04:56:55,924 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1        | 2020-04-17 04:56:55,929 [main] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1        | 2020-04-17 04:56:55,942 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1        | 2020-04-17 04:56:55,951 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1        | 2020-04-17 04:56:55,951 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
om_1        | 2020-04-17 04:56:55,951 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
om_1        | 2020-04-17 04:56:55,972 [main] INFO http.HttpServer2: Jetty bound to port 9874
datanode_1  | 2020-04-17 04:56:49,913 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-04-17 04:56:49,913 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-04-17 04:56:49,913 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-04-17 04:56:49,913 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-04-17 04:56:49,914 [pool-69-thread-1] INFO impl.RaftServerImpl: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1: ConfigurationManager, init=-1: [3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-04-17 04:56:49,914 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-04-17 04:56:49,915 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-04-17 04:56:49,928 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/263564e8-3154-417e-9806-83cc33444ed1 does not exist. Creating ...
datanode_1  | 2020-04-17 04:56:49,940 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/263564e8-3154-417e-9806-83cc33444ed1/in_use.lock acquired by nodename 6@ca5fa3da651c
datanode_1  | 2020-04-17 04:56:49,944 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/263564e8-3154-417e-9806-83cc33444ed1 has been successfully formatted.
datanode_1  | 2020-04-17 04:56:49,945 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-83CC33444ED1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-04-17 04:56:49,949 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-04-17 04:56:49,949 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-04-17 04:56:49,949 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-04-17 04:56:49,951 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-17 04:56:49,951 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-17 04:56:49,955 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-04-17 04:56:49,955 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/263564e8-3154-417e-9806-83cc33444ed1
datanode_1  | 2020-04-17 04:56:49,956 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-04-17 04:56:49,956 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-04-17 04:56:49,956 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-17 04:56:49,956 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-04-17 04:56:49,956 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-04-17 04:56:49,956 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-04-17 04:56:49,957 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-04-17 04:56:49,957 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-04-17 04:56:49,957 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-04-17 04:56:49,958 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-04-17 04:56:49,959 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-04-17 04:56:49,960 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-04-17 04:56:49,960 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-04-17 04:56:49,963 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-04-17 04:56:49,963 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-04-17 04:56:49,964 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1
datanode_1  | 2020-04-17 04:56:49,964 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1
datanode_1  | 2020-04-17 04:56:49,965 [pool-69-thread-1] INFO impl.RaftServerImpl: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1: start as a follower, conf=-1: [3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858], old=null
datanode_1  | 2020-04-17 04:56:49,965 [pool-69-thread-1] INFO impl.RaftServerImpl: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-04-17 04:56:49,966 [pool-69-thread-1] INFO impl.RoleInfo: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: start FollowerState
datanode_1  | 2020-04-17 04:56:49,978 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-83CC33444ED1,id=f71fab23-81a9-41d8-ab04-2a8824f1aeaa
datanode_1  | 2020-04-17 04:56:49,979 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1
datanode_1  | 2020-04-17 04:56:51,531 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "263564e8-3154-417e-9806-83cc33444ed1"
datanode_1  | .
datanode_1  | 2020-04-17 04:56:51,746 [grpc-default-executor-0] WARN impl.RaftServerProxy: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: Failed groupAdd* GroupManagementRequest:client-C565F318B20E->f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1, cid=1, seq=0, RW, null, Add:group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858]
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: Failed to add group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] since the group already exists in the map.
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | 2020-04-17 04:56:49,812 [pool-69-thread-1] INFO impl.RaftServerImpl: ed3d0f0e-4614-480f-aff0-1706334f678b: new RaftServerImpl for group-CCD74131E2C6:[ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-04-17 04:56:49,813 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-04-17 04:56:49,815 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-04-17 04:56:49,815 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-04-17 04:56:49,815 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-04-17 04:56:49,820 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-17 04:56:49,836 [pool-69-thread-1] INFO impl.RaftServerImpl: ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6: ConfigurationManager, init=-1: [ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-04-17 04:56:49,836 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-17 04:56:49,848 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-04-17 04:56:49,849 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f33c3219-c272-4ab5-b490-ccd74131e2c6 does not exist. Creating ...
datanode_3  | 2020-04-17 04:56:49,865 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f33c3219-c272-4ab5-b490-ccd74131e2c6/in_use.lock acquired by nodename 9@84e959ce1a08
datanode_3  | 2020-04-17 04:56:49,870 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f33c3219-c272-4ab5-b490-ccd74131e2c6 has been successfully formatted.
datanode_3  | 2020-04-17 04:56:49,873 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-CCD74131E2C6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-04-17 04:56:49,873 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-04-17 04:56:49,923 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-04-17 04:56:49,926 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-04-17 04:56:49,943 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-17 04:56:49,944 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-17 04:56:49,963 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.ed3d0f0e-4614-480f-aff0-1706334f678b
datanode_3  | 2020-04-17 04:56:50,010 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-04-17 04:56:50,031 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/f33c3219-c272-4ab5-b490-ccd74131e2c6
datanode_3  | 2020-04-17 04:56:50,047 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-04-17 04:56:50,049 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-04-17 04:56:50,063 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-17 04:56:50,063 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-04-17 04:56:50,064 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-04-17 04:56:50,064 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-04-17 04:56:50,065 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-04-17 04:56:50,084 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-04-17 04:56:50,084 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-04-17 04:56:50,141 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-04-17 04:56:50,163 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-04-17 04:56:50,190 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-04-17 04:56:50,191 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-04-17 04:56:50,213 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-04-17 04:56:50,214 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-04-17 04:56:50,286 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6
datanode_3  | 2020-04-17 04:56:50,300 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6
datanode_3  | 2020-04-17 04:56:50,301 [pool-69-thread-1] INFO impl.RaftServerImpl: ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6: start as a follower, conf=-1: [ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858], old=null
datanode_3  | 2020-04-17 04:56:50,301 [pool-69-thread-1] INFO impl.RaftServerImpl: ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-04-17 04:56:50,302 [pool-69-thread-1] INFO impl.RoleInfo: ed3d0f0e-4614-480f-aff0-1706334f678b: start FollowerState
datanode_3  | 2020-04-17 04:56:50,340 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CCD74131E2C6,id=ed3d0f0e-4614-480f-aff0-1706334f678b
datanode_3  | 2020-04-17 04:56:50,341 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6
datanode_3  | 2020-04-17 04:56:50,387 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "f33c3219-c272-4ab5-b490-ccd74131e2c6"
datanode_3  | .
datanode_3  | 2020-04-17 04:56:50,393 [Command processor thread] INFO impl.RaftServerProxy: ed3d0f0e-4614-480f-aff0-1706334f678b: addNew group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] returns group-83CC33444ED1:java.util.concurrent.CompletableFuture@24ecbb44[Not completed]
datanode_3  | 2020-04-17 04:56:50,452 [pool-69-thread-1] INFO impl.RaftServerImpl: ed3d0f0e-4614-480f-aff0-1706334f678b: new RaftServerImpl for group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-04-17 04:56:50,453 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
s3g3_1      | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
s3g3_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g3_1      | 2020-04-17 04:56:31,862 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g3_1      | 2020-04-17 04:56:31,976 [main] INFO util.log: Logging initialized @6187ms to org.eclipse.jetty.util.log.Slf4jLog
s3g3_1      | 2020-04-17 04:56:32,534 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g3_1      | 2020-04-17 04:56:32,915 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g3_1      | 2020-04-17 04:56:32,959 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g3_1      | 2020-04-17 04:56:32,978 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g3_1      | 2020-04-17 04:56:32,987 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
s3g3_1      | 2020-04-17 04:56:32,992 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
s3g3_1      | 2020-04-17 04:56:33,098 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g3_1      | 2020-04-17 04:56:33,126 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g3_1      | 2020-04-17 04:56:33,137 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
s3g3_1      | 2020-04-17 04:56:33,419 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g3_1      | 2020-04-17 04:56:33,419 [main] INFO server.session: No SessionScavenger set, using defaults
s3g3_1      | 2020-04-17 04:56:33,442 [main] INFO server.session: node0 Scavenging every 600000ms
s3g3_1      | 2020-04-17 04:56:33,497 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3af0a9da{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g3_1      | 2020-04-17 04:56:33,504 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@54eb2b70{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g3_1      | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
s3g3_1      | WARNING: An illegal reflective access operation has occurred
s3g3_1      | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g3_1      | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g3_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g3_1      | WARNING: All illegal access operations will be denied in a future release
s3g3_1      | Apr 17, 2020 4:56:44 AM org.glassfish.jersey.internal.Errors logErrors
s3g3_1      | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g3_1      | 
s3g3_1      | 2020-04-17 04:56:44,207 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5c48b72c{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-0_6_0-SNAPSHOT_jar-_-any-14279150045492959884.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g3_1      | 2020-04-17 04:56:44,223 [main] INFO server.AbstractConnector: Started ServerConnector@1869fbd2{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
s3g3_1      | 2020-04-17 04:56:44,224 [main] INFO server.Server: Started @18435ms
s3g3_1      | 2020-04-17 04:56:44,228 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
datanode_2  | 2020-04-17 04:56:45,944 [Datanode State Machine Thread - 0] INFO server.GrpcService: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2  | 2020-04-17 04:56:49,196 [Command processor thread] INFO impl.RaftServerProxy: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: addNew group-8DE8D0E3CCBA:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858] returns group-8DE8D0E3CCBA:java.util.concurrent.CompletableFuture@3547eddb[Not completed]
datanode_2  | 2020-04-17 04:56:49,221 [pool-69-thread-1] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: new RaftServerImpl for group-8DE8D0E3CCBA:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-04-17 04:56:49,227 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-04-17 04:56:49,228 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-04-17 04:56:49,228 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-04-17 04:56:49,228 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-04-17 04:56:49,229 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-04-17 04:56:49,232 [pool-69-thread-1] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA: ConfigurationManager, init=-1: [3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-04-17 04:56:49,233 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-17 04:56:49,236 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-04-17 04:56:49,237 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e96c8dbd-d490-4fd2-8087-8de8d0e3ccba does not exist. Creating ...
datanode_2  | 2020-04-17 04:56:49,243 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e96c8dbd-d490-4fd2-8087-8de8d0e3ccba/in_use.lock acquired by nodename 6@711de6e6b939
datanode_2  | 2020-04-17 04:56:49,245 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e96c8dbd-d490-4fd2-8087-8de8d0e3ccba has been successfully formatted.
datanode_2  | 2020-04-17 04:56:49,248 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-8DE8D0E3CCBA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-04-17 04:56:49,255 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-04-17 04:56:49,260 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-04-17 04:56:49,263 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-04-17 04:56:49,265 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-17 04:56:49,269 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-17 04:56:49,271 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.3aa95a42-0392-4192-8556-ef4d57f7b5c9
datanode_2  | 2020-04-17 04:56:49,285 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-04-17 04:56:49,300 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/e96c8dbd-d490-4fd2-8087-8de8d0e3ccba
datanode_2  | 2020-04-17 04:56:49,301 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-04-17 04:56:49,304 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-04-17 04:56:49,305 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-17 04:56:49,306 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-04-17 04:56:49,306 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-04-17 04:56:49,310 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-04-17 04:56:49,311 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-04-17 04:56:49,311 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-04-17 04:56:49,311 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-04-17 04:56:49,343 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-04-17 04:56:49,350 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-04-17 04:56:49,358 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-04-17 04:56:49,367 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-04-17 04:56:49,370 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-04-17 04:56:49,380 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-04-17 04:56:49,413 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA
datanode_2  | 2020-04-17 04:56:49,418 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA
datanode_2  | 2020-04-17 04:56:49,419 [pool-69-thread-1] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA: start as a follower, conf=-1: [3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858], old=null
datanode_2  | 2020-04-17 04:56:49,421 [pool-69-thread-1] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-04-17 04:56:49,425 [pool-69-thread-1] INFO impl.RoleInfo: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: start FollowerState
datanode_2  | 2020-04-17 04:56:49,433 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8DE8D0E3CCBA,id=3aa95a42-0392-4192-8556-ef4d57f7b5c9
datanode_2  | 2020-04-17 04:56:49,434 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA
datanode_2  | 2020-04-17 04:56:49,452 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "e96c8dbd-d490-4fd2-8087-8de8d0e3ccba"
datanode_2  | .
datanode_2  | 2020-04-17 04:56:49,452 [Command processor thread] INFO impl.RaftServerProxy: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: addNew group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] returns group-83CC33444ED1:java.util.concurrent.CompletableFuture@13605407[Not completed]
datanode_2  | 2020-04-17 04:56:49,457 [pool-69-thread-1] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: new RaftServerImpl for group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-04-17 04:56:49,457 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-04-17 04:56:49,457 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-04-17 04:56:49,458 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-04-17 04:56:49,458 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-04-17 04:56:49,458 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-04-17 04:56:49,458 [pool-69-thread-1] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1: ConfigurationManager, init=-1: [3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-04-17 04:56:49,458 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-17 04:56:49,459 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-04-17 04:56:49,459 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/263564e8-3154-417e-9806-83cc33444ed1 does not exist. Creating ...
datanode_2  | 2020-04-17 04:56:49,468 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/263564e8-3154-417e-9806-83cc33444ed1/in_use.lock acquired by nodename 6@711de6e6b939
datanode_2  | 2020-04-17 04:56:49,470 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/263564e8-3154-417e-9806-83cc33444ed1 has been successfully formatted.
datanode_2  | 2020-04-17 04:56:49,471 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-83CC33444ED1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-04-17 04:56:49,471 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-04-17 04:56:49,471 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-04-17 04:56:49,471 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-04-17 04:56:49,471 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-17 04:56:49,471 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-17 04:56:49,472 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-04-17 04:56:49,472 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/263564e8-3154-417e-9806-83cc33444ed1
datanode_2  | 2020-04-17 04:56:49,472 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-04-17 04:56:49,479 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-04-17 04:56:49,479 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-17 04:56:49,479 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-04-17 04:56:49,479 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-04-17 04:56:49,479 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-04-17 04:56:49,479 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-04-17 04:56:49,479 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-04-17 04:56:49,480 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-04-17 04:56:49,480 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-04-17 04:56:49,480 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-04-17 04:56:49,481 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-04-17 04:56:49,481 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-04-17 04:56:49,481 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-04-17 04:56:49,482 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-04-17 04:56:49,482 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1
datanode_2  | 2020-04-17 04:56:49,482 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1
datanode_2  | 2020-04-17 04:56:49,482 [pool-69-thread-1] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1: start as a follower, conf=-1: [3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858], old=null
datanode_2  | 2020-04-17 04:56:49,482 [pool-69-thread-1] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-04-17 04:56:49,483 [pool-69-thread-1] INFO impl.RoleInfo: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: start FollowerState
datanode_2  | 2020-04-17 04:56:49,483 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-83CC33444ED1,id=3aa95a42-0392-4192-8556-ef4d57f7b5c9
datanode_2  | 2020-04-17 04:56:49,484 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1
datanode_2  | 2020-04-17 04:56:51,017 [grpc-default-executor-0] WARN impl.RaftServerProxy: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: Failed groupAdd* GroupManagementRequest:client-6F888E4C861B->3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1, cid=0, seq=0, RW, null, Add:group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858]
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: Failed to add group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] since the group already exists in the map.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 	... 13 more
datanode_1  | 2020-04-17 04:56:51,923 [grpc-default-executor-0] WARN impl.RaftServerProxy: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: Failed groupAdd* GroupManagementRequest:client-403BF15EE250->f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1, cid=1, seq=0, RW, null, Add:group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858]
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: Failed to add group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] since the group already exists in the map.
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: Failed to add group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] since the group already exists in the map.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 	... 13 more
datanode_1  | 2020-04-17 04:56:54,666 [grpc-default-executor-0] INFO impl.RaftServerImpl: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:3aa95a42-0392-4192-8556-ef4d57f7b5c9
datanode_1  | 2020-04-17 04:56:54,667 [grpc-default-executor-0] INFO impl.RoleInfo: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: shutdown FollowerState
datanode_1  | 2020-04-17 04:56:54,667 [grpc-default-executor-0] INFO impl.RoleInfo: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: start FollowerState
datanode_1  | 2020-04-17 04:56:54,667 [Thread-25] INFO impl.FollowerState: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1  | 2020-04-17 04:56:54,949 [Thread-23] INFO impl.FollowerState: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-FollowerState: change to CANDIDATE, lastRpcTime:5128ms, electionTimeout:5106ms
datanode_1  | 2020-04-17 04:56:54,950 [Thread-23] INFO impl.RoleInfo: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: shutdown FollowerState
datanode_1  | 2020-04-17 04:56:54,951 [Thread-23] INFO impl.RaftServerImpl: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2020-04-17 04:56:54,952 [Thread-23] INFO impl.RoleInfo: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: start LeaderElection
datanode_1  | 2020-04-17 04:56:54,977 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-83CC33444ED1 with new leaderId: 3aa95a42-0392-4192-8556-ef4d57f7b5c9
datanode_1  | 2020-04-17 04:56:54,983 [grpc-default-executor-0] INFO impl.RaftServerImpl: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1: change Leader from null to 3aa95a42-0392-4192-8556-ef4d57f7b5c9 at term 1 for appendEntries, leader elected after 5028ms
datanode_1  | 2020-04-17 04:56:54,985 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO impl.LeaderElection: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1: begin an election at term 1 for -1: [f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858], old=null
om_1        | 2020-04-17 04:56:55,973 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1        | 2020-04-17 04:56:56,008 [main] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 2020-04-17 04:56:56,009 [main] INFO server.session: No SessionScavenger set, using defaults
om_1        | 2020-04-17 04:56:56,010 [main] INFO server.session: node0 Scavenging every 600000ms
om_1        | 2020-04-17 04:56:56,017 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@47406941{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 2020-04-17 04:56:56,022 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@44784e2f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | 2020-04-17 04:56:56,207 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@12ad1b2a{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-17808680532924074879.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1        | 2020-04-17 04:56:56,223 [main] INFO server.AbstractConnector: Started ServerConnector@462e1e64{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1        | 2020-04-17 04:56:56,223 [main] INFO server.Server: Started @5844ms
om_1        | 2020-04-17 04:56:56,233 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2020-04-17 04:56:56,233 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 2020-04-17 04:56:56,240 [main] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1        | 2020-04-17 04:57:00,582 [IPC Server handler 1 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-05027 for user:hadoop
om_1        | 2020-04-17 04:57:00,596 [IPC Server handler 24 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-75399 for user:hadoop
om_1        | 2020-04-17 04:57:00,605 [IPC Server handler 29 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-23168 for user:hadoop
om_1        | 2020-04-17 04:57:00,613 [IPC Server handler 40 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-41892 for user:hadoop
om_1        | 2020-04-17 04:57:00,617 [IPC Server handler 43 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-19918 for user:hadoop
datanode_3  | 2020-04-17 04:56:50,453 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-04-17 04:56:50,454 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-04-17 04:56:50,456 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-04-17 04:56:50,456 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-17 04:56:50,456 [pool-69-thread-1] INFO impl.RaftServerImpl: ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1: ConfigurationManager, init=-1: [3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-04-17 04:56:50,456 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-17 04:56:50,457 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-04-17 04:56:50,457 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/263564e8-3154-417e-9806-83cc33444ed1 does not exist. Creating ...
datanode_3  | 2020-04-17 04:56:50,472 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/263564e8-3154-417e-9806-83cc33444ed1/in_use.lock acquired by nodename 9@84e959ce1a08
datanode_3  | 2020-04-17 04:56:50,478 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/263564e8-3154-417e-9806-83cc33444ed1 has been successfully formatted.
datanode_3  | 2020-04-17 04:56:50,479 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-83CC33444ED1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-04-17 04:56:50,479 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-04-17 04:56:50,480 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-04-17 04:56:50,480 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-04-17 04:56:50,480 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-17 04:56:50,480 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-17 04:56:50,480 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-04-17 04:56:50,480 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/263564e8-3154-417e-9806-83cc33444ed1
datanode_3  | 2020-04-17 04:56:50,480 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-04-17 04:56:50,480 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-04-17 04:56:50,480 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-17 04:56:50,481 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-04-17 04:56:50,481 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-04-17 04:56:50,481 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-04-17 04:56:50,481 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-04-17 04:56:50,481 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-04-17 04:56:50,483 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-04-17 04:56:50,484 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-04-17 04:56:50,487 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-04-17 04:56:50,501 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-04-17 04:56:50,501 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-04-17 04:56:50,501 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-04-17 04:56:50,501 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-04-17 04:56:50,502 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1
datanode_3  | 2020-04-17 04:56:50,502 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1
datanode_3  | 2020-04-17 04:56:50,502 [pool-69-thread-1] INFO impl.RaftServerImpl: ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1: start as a follower, conf=-1: [3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858], old=null
datanode_3  | 2020-04-17 04:56:50,502 [pool-69-thread-1] INFO impl.RaftServerImpl: ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-04-17 04:56:50,503 [pool-69-thread-1] INFO impl.RoleInfo: ed3d0f0e-4614-480f-aff0-1706334f678b: start FollowerState
datanode_3  | 2020-04-17 04:56:50,517 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-83CC33444ED1,id=ed3d0f0e-4614-480f-aff0-1706334f678b
datanode_3  | 2020-04-17 04:56:50,517 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1
datanode_3  | 2020-04-17 04:56:51,361 [grpc-default-executor-0] WARN impl.RaftServerProxy: ed3d0f0e-4614-480f-aff0-1706334f678b: Failed groupAdd* GroupManagementRequest:client-AC6F3A08A5ED->ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1, cid=1, seq=0, RW, null, Add:group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858]
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: ed3d0f0e-4614-480f-aff0-1706334f678b: Failed to add group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] since the group already exists in the map.
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: ed3d0f0e-4614-480f-aff0-1706334f678b: Failed to add group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] since the group already exists in the map.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3  | 	... 13 more
datanode_3  | 2020-04-17 04:56:51,373 [grpc-default-executor-1] WARN impl.RaftServerProxy: ed3d0f0e-4614-480f-aff0-1706334f678b: Failed groupAdd* GroupManagementRequest:client-DB7B3B38A929->ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1, cid=0, seq=0, RW, null, Add:group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858]
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: ed3d0f0e-4614-480f-aff0-1706334f678b: Failed to add group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] since the group already exists in the map.
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: ed3d0f0e-4614-480f-aff0-1706334f678b: Failed to add group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] since the group already exists in the map.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3  | 	... 13 more
datanode_3  | 2020-04-17 04:56:51,966 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "263564e8-3154-417e-9806-83cc33444ed1"
datanode_3  | .
datanode_3  | 2020-04-17 04:56:54,648 [grpc-default-executor-1] INFO impl.RaftServerImpl: ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:3aa95a42-0392-4192-8556-ef4d57f7b5c9
datanode_3  | 2020-04-17 04:56:54,649 [grpc-default-executor-1] INFO impl.RoleInfo: ed3d0f0e-4614-480f-aff0-1706334f678b: shutdown FollowerState
datanode_3  | 2020-04-17 04:56:54,651 [grpc-default-executor-1] INFO impl.RoleInfo: ed3d0f0e-4614-480f-aff0-1706334f678b: start FollowerState
datanode_3  | 2020-04-17 04:56:54,651 [Thread-25] INFO impl.FollowerState: ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3  | 2020-04-17 04:56:54,993 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-83CC33444ED1 with new leaderId: 3aa95a42-0392-4192-8556-ef4d57f7b5c9
datanode_3  | 2020-04-17 04:56:54,995 [grpc-default-executor-1] INFO impl.RaftServerImpl: ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1: change Leader from null to 3aa95a42-0392-4192-8556-ef4d57f7b5c9 at term 1 for appendEntries, leader elected after 4513ms
datanode_3  | 2020-04-17 04:56:55,024 [grpc-default-executor-1] INFO impl.RaftServerImpl: ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1: set configuration 0: [3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858], old=null at 0
datanode_3  | 2020-04-17 04:56:55,053 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-04-17 04:56:55,465 [Thread-23] INFO impl.FollowerState: ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-FollowerState: change to CANDIDATE, lastRpcTime:5163ms, electionTimeout:5154ms
datanode_3  | 2020-04-17 04:56:55,476 [Thread-23] INFO impl.RoleInfo: ed3d0f0e-4614-480f-aff0-1706334f678b: shutdown FollowerState
datanode_3  | 2020-04-17 04:56:55,476 [Thread-23] INFO impl.RaftServerImpl: ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: Failed to add group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] since the group already exists in the map.
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: Failed to add group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] since the group already exists in the map.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2  | 	... 13 more
datanode_2  | 2020-04-17 04:56:51,596 [grpc-default-executor-0] WARN impl.RaftServerProxy: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: Failed groupAdd* GroupManagementRequest:client-BE8FB4AAB4F2->3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1, cid=0, seq=0, RW, null, Add:group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858]
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: Failed to add group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] since the group already exists in the map.
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: Failed to add group-83CC33444ED1:[3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858] since the group already exists in the map.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2  | 	... 13 more
datanode_2  | 2020-04-17 04:56:51,806 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "263564e8-3154-417e-9806-83cc33444ed1"
datanode_2  | .
datanode_2  | 2020-04-17 04:56:54,567 [Thread-25] INFO impl.FollowerState: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-FollowerState: change to CANDIDATE, lastRpcTime:5084ms, electionTimeout:5082ms
datanode_2  | 2020-04-17 04:56:54,573 [Thread-25] INFO impl.RoleInfo: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: shutdown FollowerState
datanode_2  | 2020-04-17 04:56:54,573 [Thread-25] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-04-17 04:56:54,575 [Thread-25] INFO impl.RoleInfo: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: start LeaderElection
datanode_2  | 2020-04-17 04:56:54,587 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO impl.LeaderElection: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1: begin an election at term 1 for -1: [3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858], old=null
datanode_2  | 2020-04-17 04:56:54,624 [Thread-23] INFO impl.FollowerState: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-FollowerState: change to CANDIDATE, lastRpcTime:5202ms, electionTimeout:5194ms
datanode_2  | 2020-04-17 04:56:54,625 [Thread-23] INFO impl.RoleInfo: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: shutdown FollowerState
datanode_2  | 2020-04-17 04:56:54,625 [Thread-23] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-04-17 04:56:54,625 [Thread-23] INFO impl.RoleInfo: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: start LeaderElection
datanode_3  | 2020-04-17 04:56:55,518 [Thread-23] INFO impl.RoleInfo: ed3d0f0e-4614-480f-aff0-1706334f678b: start LeaderElection
datanode_3  | 2020-04-17 04:56:55,589 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO impl.LeaderElection: ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1: begin an election at term 1 for -1: [ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858], old=null
datanode_3  | 2020-04-17 04:56:55,590 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO impl.RoleInfo: ed3d0f0e-4614-480f-aff0-1706334f678b: shutdown LeaderElection
datanode_3  | 2020-04-17 04:56:55,590 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO impl.RaftServerImpl: ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-04-17 04:56:55,590 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CCD74131E2C6 with new leaderId: ed3d0f0e-4614-480f-aff0-1706334f678b
datanode_3  | 2020-04-17 04:56:55,591 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO impl.RaftServerImpl: ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6: change Leader from null to ed3d0f0e-4614-480f-aff0-1706334f678b at term 1 for becomeLeader, leader elected after 5717ms
datanode_3  | 2020-04-17 04:56:55,627 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-04-17 04:56:55,627 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-04-17 04:56:55,632 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6
datanode_3  | 2020-04-17 04:56:55,642 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-04-17 04:56:55,642 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-04-17 04:56:55,652 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ed3d0f0e-4614-480f-aff0-1706334f678b@group-83CC33444ED1-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/263564e8-3154-417e-9806-83cc33444ed1/current/log_inprogress_0
datanode_3  | 2020-04-17 04:56:55,671 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-04-17 04:56:55,672 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-04-17 04:56:55,673 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-04-17 04:56:55,698 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO impl.RoleInfo: ed3d0f0e-4614-480f-aff0-1706334f678b: start LeaderState
datanode_3  | 2020-04-17 04:56:55,703 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-04-17 04:56:55,706 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f33c3219-c272-4ab5-b490-ccd74131e2c6/current/log_inprogress_0
datanode_3  | 2020-04-17 04:56:55,710 [ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6-LeaderElection1] INFO impl.RaftServerImpl: ed3d0f0e-4614-480f-aff0-1706334f678b@group-CCD74131E2C6: set configuration 0: [ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858], old=null at 0
datanode_1  | 2020-04-17 04:56:54,986 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO impl.RoleInfo: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: shutdown LeaderElection
datanode_1  | 2020-04-17 04:56:54,992 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO impl.RaftServerImpl: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2020-04-17 04:56:54,992 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D9F6E51256A2 with new leaderId: f71fab23-81a9-41d8-ab04-2a8824f1aeaa
datanode_1  | 2020-04-17 04:56:54,993 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO impl.RaftServerImpl: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2: change Leader from null to f71fab23-81a9-41d8-ab04-2a8824f1aeaa at term 1 for becomeLeader, leader elected after 5437ms
datanode_1  | 2020-04-17 04:56:55,015 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2020-04-17 04:56:55,015 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2020-04-17 04:56:55,020 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2
datanode_1  | 2020-04-17 04:56:55,033 [grpc-default-executor-0] INFO impl.RaftServerImpl: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1: set configuration 0: [3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858], old=null at 0
datanode_1  | 2020-04-17 04:56:55,041 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2020-04-17 04:56:55,044 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1  | 2020-04-17 04:56:55,051 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2020-04-17 04:56:55,068 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2020-04-17 04:56:55,069 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2020-04-17 04:56:55,074 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-04-17 04:56:55,139 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO impl.RoleInfo: f71fab23-81a9-41d8-ab04-2a8824f1aeaa: start LeaderState
datanode_1  | 2020-04-17 04:56:55,158 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-04-17 04:56:55,160 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-LeaderElection1] INFO impl.RaftServerImpl: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2: set configuration 0: [f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858], old=null at 0
datanode_1  | 2020-04-17 04:56:55,295 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-D9F6E51256A2-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0e400dd7-6b0f-46e3-b517-d9f6e51256a2/current/log_inprogress_0
datanode_1  | 2020-04-17 04:56:55,346 [f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f71fab23-81a9-41d8-ab04-2a8824f1aeaa@group-83CC33444ED1-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/263564e8-3154-417e-9806-83cc33444ed1/current/log_inprogress_0
s3g_1       | [NOTICE] 107/045622 (1) : New worker #1 (7) forked
s3g1_1      | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
s3g1_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g1_1      | 2020-04-17 04:56:30,258 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g1_1      | 2020-04-17 04:56:30,380 [main] INFO util.log: Logging initialized @5938ms to org.eclipse.jetty.util.log.Slf4jLog
s3g1_1      | 2020-04-17 04:56:30,941 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g1_1      | 2020-04-17 04:56:31,263 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g1_1      | 2020-04-17 04:56:31,340 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g1_1      | 2020-04-17 04:56:31,345 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g1_1      | 2020-04-17 04:56:31,345 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
s3g1_1      | 2020-04-17 04:56:31,345 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
s3g1_1      | 2020-04-17 04:56:31,523 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g1_1      | 2020-04-17 04:56:31,563 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g1_1      | 2020-04-17 04:56:31,569 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
s3g1_1      | 2020-04-17 04:56:31,689 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g1_1      | 2020-04-17 04:56:31,689 [main] INFO server.session: No SessionScavenger set, using defaults
s3g1_1      | 2020-04-17 04:56:31,690 [main] INFO server.session: node0 Scavenging every 660000ms
s3g1_1      | 2020-04-17 04:56:31,728 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3af0a9da{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g1_1      | 2020-04-17 04:56:31,740 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@54eb2b70{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g1_1      | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
s3g1_1      | WARNING: An illegal reflective access operation has occurred
s3g1_1      | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g1_1      | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g1_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g1_1      | WARNING: All illegal access operations will be denied in a future release
s3g1_1      | Apr 17, 2020 4:56:43 AM org.glassfish.jersey.internal.Errors logErrors
s3g1_1      | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g1_1      | 
s3g1_1      | 2020-04-17 04:56:43,866 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5c48b72c{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-0_6_0-SNAPSHOT_jar-_-any-14426930374549113202.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g1_1      | 2020-04-17 04:56:43,893 [main] INFO server.AbstractConnector: Started ServerConnector@1869fbd2{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
s3g1_1      | 2020-04-17 04:56:43,895 [main] INFO server.Server: Started @19453ms
s3g1_1      | 2020-04-17 04:56:43,904 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g2_1      | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
s3g2_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g2_1      | 2020-04-17 04:56:23,633 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g2_1      | 2020-04-17 04:56:23,689 [main] INFO util.log: Logging initialized @1104ms to org.eclipse.jetty.util.log.Slf4jLog
s3g2_1      | 2020-04-17 04:56:23,961 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g2_1      | 2020-04-17 04:56:24,044 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g2_1      | 2020-04-17 04:56:24,086 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g2_1      | 2020-04-17 04:56:24,089 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g2_1      | 2020-04-17 04:56:24,089 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
s3g2_1      | 2020-04-17 04:56:24,089 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
s3g2_1      | 2020-04-17 04:56:24,150 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g2_1      | 2020-04-17 04:56:24,167 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g2_1      | 2020-04-17 04:56:24,172 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
s3g2_1      | 2020-04-17 04:56:24,262 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g2_1      | 2020-04-17 04:56:24,265 [main] INFO server.session: No SessionScavenger set, using defaults
s3g2_1      | 2020-04-17 04:56:24,281 [main] INFO server.session: node0 Scavenging every 660000ms
s3g2_1      | 2020-04-17 04:56:24,325 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3af0a9da{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g2_1      | 2020-04-17 04:56:24,326 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@54eb2b70{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g2_1      | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
s3g2_1      | WARNING: An illegal reflective access operation has occurred
s3g2_1      | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g2_1      | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g2_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g2_1      | WARNING: All illegal access operations will be denied in a future release
s3g2_1      | Apr 17, 2020 4:56:38 AM org.glassfish.jersey.internal.Errors logErrors
s3g2_1      | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g2_1      | 
s3g2_1      | 2020-04-17 04:56:38,323 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5c48b72c{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-0_6_0-SNAPSHOT_jar-_-any-3516241779139371516.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g2_1      | 2020-04-17 04:56:38,418 [main] INFO server.AbstractConnector: Started ServerConnector@1869fbd2{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
s3g2_1      | 2020-04-17 04:56:38,427 [main] INFO server.Server: Started @15842ms
s3g2_1      | 2020-04-17 04:56:38,439 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
datanode_2  | 2020-04-17 04:56:54,677 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO impl.LeaderElection: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2: begin an election at term 1 for -1: [3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858], old=null
datanode_2  | 2020-04-17 04:56:54,678 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO impl.RoleInfo: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: shutdown LeaderElection
datanode_2  | 2020-04-17 04:56:54,684 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-04-17 04:56:54,685 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8DE8D0E3CCBA with new leaderId: 3aa95a42-0392-4192-8556-ef4d57f7b5c9
datanode_2  | 2020-04-17 04:56:54,685 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA: change Leader from null to 3aa95a42-0392-4192-8556-ef4d57f7b5c9 at term 1 for becomeLeader, leader elected after 5436ms
datanode_2  | 2020-04-17 04:56:54,706 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-04-17 04:56:54,706 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2020-04-17 04:56:54,706 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO impl.LeaderElection: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1: Election PASSED; received 1 response(s) [3aa95a42-0392-4192-8556-ef4d57f7b5c9<-f71fab23-81a9-41d8-ab04-2a8824f1aeaa#0:OK-t1] and 0 exception(s); 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1:t1, leader=null, voted=3aa95a42-0392-4192-8556-ef4d57f7b5c9, raftlog=3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858], old=null
datanode_2  | 2020-04-17 04:56:54,707 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO impl.RoleInfo: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: shutdown LeaderElection
datanode_2  | 2020-04-17 04:56:54,707 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-04-17 04:56:54,707 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-83CC33444ED1 with new leaderId: 3aa95a42-0392-4192-8556-ef4d57f7b5c9
datanode_2  | 2020-04-17 04:56:54,707 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1: change Leader from null to 3aa95a42-0392-4192-8556-ef4d57f7b5c9 at term 1 for becomeLeader, leader elected after 5236ms
datanode_2  | 2020-04-17 04:56:54,708 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-04-17 04:56:54,709 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2020-04-17 04:56:54,727 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1
datanode_2  | 2020-04-17 04:56:54,728 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2020-04-17 04:56:54,728 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-04-17 04:56:54,734 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-04-17 04:56:54,744 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA
datanode_2  | 2020-04-17 04:56:54,755 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2020-04-17 04:56:54,756 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-04-17 04:56:54,756 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-04-17 04:56:54,756 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-04-17 04:56:54,757 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2020-04-17 04:56:54,745 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-04-17 04:56:54,760 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2020-04-17 04:56:54,763 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO impl.RoleInfo: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: start LeaderState
datanode_2  | 2020-04-17 04:56:54,776 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2  | 2020-04-17 04:56:54,784 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-17 04:56:54,784 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2  | 2020-04-17 04:56:54,789 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2  | 2020-04-17 04:56:54,795 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-04-17 04:56:54,795 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-04-17 04:56:54,806 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2  | 2020-04-17 04:56:54,810 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-17 04:56:54,810 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2  | 2020-04-17 04:56:54,810 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2  | 2020-04-17 04:56:54,810 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-04-17 04:56:54,810 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-04-17 04:56:54,811 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO impl.RoleInfo: 3aa95a42-0392-4192-8556-ef4d57f7b5c9: start LeaderState
datanode_2  | 2020-04-17 04:56:54,816 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-04-17 04:56:54,816 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-04-17 04:56:54,857 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-LeaderElection2] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA: set configuration 0: [3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858], old=null at 0
datanode_2  | 2020-04-17 04:56:54,876 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-LeaderElection1] INFO impl.RaftServerImpl: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1: set configuration 0: [3aa95a42-0392-4192-8556-ef4d57f7b5c9:172.22.0.2:9858, f71fab23-81a9-41d8-ab04-2a8824f1aeaa:172.22.0.7:9858, ed3d0f0e-4614-480f-aff0-1706334f678b:172.22.0.4:9858], old=null at 0
datanode_2  | 2020-04-17 04:56:55,144 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-83CC33444ED1-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/263564e8-3154-417e-9806-83cc33444ed1/current/log_inprogress_0
datanode_2  | 2020-04-17 04:56:55,147 [3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3aa95a42-0392-4192-8556-ef4d57f7b5c9@group-8DE8D0E3CCBA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e96c8dbd-d490-4fd2-8087-8de8d0e3ccba/current/log_inprogress_0
scm_1       | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-04-17 04:56:33,704 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = 67d300e0e199/172.22.0.6
scm_1       | STARTUP_MSG:   args = [--init]
scm_1       | STARTUP_MSG:   version = 3.2.0
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-04-17 04:56:33,758 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-04-17 04:56:34,533 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-17 04:56:34,885 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-bc1e19f5-e932-4360-bf0f-5d36458447e6
scm_1       | 2020-04-17 04:56:34,975 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at 67d300e0e199/172.22.0.6
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-04-17 04:56:42,736 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = 67d300e0e199/172.22.0.6
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 3.2.0
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-04-17 04:56:42,771 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-04-17 04:56:43,027 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-17 04:56:43,049 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-17 04:56:43,699 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@3336e6b6
scm_1       | 2020-04-17 04:56:43,704 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1       | 2020-04-17 04:56:44,022 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1       | 2020-04-17 04:56:44,193 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       | 2020-04-17 04:56:44,197 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-17 04:56:44,238 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1       | 2020-04-17 04:56:44,241 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-17 04:56:44,338 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2020-04-17 04:56:44,342 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1       | 2020-04-17 04:56:44,409 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1       | 2020-04-17 04:56:44,873 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-04-17 04:56:44,889 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2020-04-17 04:56:44,911 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-04-17 04:56:44,912 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1       | 2020-04-17 04:56:44,920 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-04-17 04:56:44,921 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1       | 2020-04-17 04:56:44,938 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1       | 2020-04-17 04:56:44,958 [main] INFO util.log: Logging initialized @8769ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       | 2020-04-17 04:56:45,117 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2020-04-17 04:56:45,126 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1       | 2020-04-17 04:56:45,135 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       | 2020-04-17 04:56:45,136 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1       | 2020-04-17 04:56:45,136 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
scm_1       | 2020-04-17 04:56:45,136 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1       | 2020-04-17 04:56:45,157 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1       | 2020-04-17 04:56:45,197 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | 2020-04-17 04:56:45,221 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1       | 2020-04-17 04:56:45,221 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1       | 2020-04-17 04:56:45,361 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1       | 2020-04-17 04:56:45,364 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-04-17 04:56:45,367 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1       | 2020-04-17 04:56:45,426 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1       | 2020-04-17 04:56:45,433 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1       | 2020-04-17 04:56:45,436 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-04-17 04:56:45,436 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1       | 2020-04-17 04:56:45,483 [main] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1       | 2020-04-17 04:56:45,483 [main] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1       | 2020-04-17 04:56:45,484 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-04-17 04:56:45,484 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1       | 2020-04-17 04:56:45,527 [main] INFO http.HttpServer2: Jetty bound to port 9876
scm_1       | 2020-04-17 04:56:45,528 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1       | 2020-04-17 04:56:45,583 [main] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1       | 2020-04-17 04:56:45,583 [main] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2020-04-17 04:56:45,585 [main] INFO server.session: node0 Scavenging every 660000ms
scm_1       | 2020-04-17 04:56:45,603 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@25b5c5e3{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1       | 2020-04-17 04:56:45,604 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2c708440{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | 2020-04-17 04:56:46,155 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@bc042d5{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-3081294660538146525.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
scm_1       | 2020-04-17 04:56:46,226 [main] INFO server.AbstractConnector: Started ServerConnector@507d20bb{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1       | 2020-04-17 04:56:46,229 [main] INFO server.Server: Started @10040ms
scm_1       | 2020-04-17 04:56:46,266 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | 2020-04-17 04:56:46,266 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1       | 2020-04-17 04:56:46,277 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1       | 2020-04-17 04:56:46,291 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@242b6e1a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2020-04-17 04:56:46,310 [IPC Server handler 3 on 9861] INFO net.NetworkTopology: Added a new node: /default-rack/3aa95a42-0392-4192-8556-ef4d57f7b5c9
scm_1       | 2020-04-17 04:56:46,311 [IPC Server handler 3 on 9861] INFO node.SCMNodeManager: Registered Data node : 3aa95a42-0392-4192-8556-ef4d57f7b5c9{ip: 172.22.0.2, host: ozones3-haproxy_datanode_2.ozones3-haproxy_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-04-17 04:56:46,325 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1       | 2020-04-17 04:56:46,325 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-04-17 04:56:46,356 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e96c8dbd-d490-4fd2-8087-8de8d0e3ccba to datanode:3aa95a42-0392-4192-8556-ef4d57f7b5c9
scm_1       | 2020-04-17 04:56:46,368 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e96c8dbd-d490-4fd2-8087-8de8d0e3ccba, Nodes: 3aa95a42-0392-4192-8556-ef4d57f7b5c9{ip: 172.22.0.2, host: ozones3-haproxy_datanode_2.ozones3-haproxy_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-17T04:56:46.355674Z]
scm_1       | 2020-04-17 04:56:46,380 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 1 nodes. Healthy nodes 1
scm_1       | 2020-04-17 04:56:46,391 [IPC Server handler 4 on 9861] INFO net.NetworkTopology: Added a new node: /default-rack/f71fab23-81a9-41d8-ab04-2a8824f1aeaa
scm_1       | 2020-04-17 04:56:46,393 [IPC Server handler 4 on 9861] INFO node.SCMNodeManager: Registered Data node : f71fab23-81a9-41d8-ab04-2a8824f1aeaa{ip: 172.22.0.7, host: ozones3-haproxy_datanode_1.ozones3-haproxy_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-04-17 04:56:46,393 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1       | 2020-04-17 04:56:46,394 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-04-17 04:56:46,411 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=0e400dd7-6b0f-46e3-b517-d9f6e51256a2 to datanode:f71fab23-81a9-41d8-ab04-2a8824f1aeaa
scm_1       | 2020-04-17 04:56:46,412 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 0e400dd7-6b0f-46e3-b517-d9f6e51256a2, Nodes: f71fab23-81a9-41d8-ab04-2a8824f1aeaa{ip: 172.22.0.7, host: ozones3-haproxy_datanode_1.ozones3-haproxy_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-17T04:56:46.411624Z]
scm_1       | 2020-04-17 04:56:46,413 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
scm_1       | 2020-04-17 04:56:46,674 [IPC Server handler 1 on 9861] INFO net.NetworkTopology: Added a new node: /default-rack/ed3d0f0e-4614-480f-aff0-1706334f678b
scm_1       | 2020-04-17 04:56:46,674 [IPC Server handler 1 on 9861] INFO node.SCMNodeManager: Registered Data node : ed3d0f0e-4614-480f-aff0-1706334f678b{ip: 172.22.0.4, host: ozones3-haproxy_datanode_3.ozones3-haproxy_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-04-17 04:56:46,675 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f33c3219-c272-4ab5-b490-ccd74131e2c6 to datanode:ed3d0f0e-4614-480f-aff0-1706334f678b
scm_1       | 2020-04-17 04:56:46,675 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1       | 2020-04-17 04:56:46,679 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-04-17 04:56:46,679 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2020-04-17 04:56:46,679 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1       | 2020-04-17 04:56:46,680 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: f33c3219-c272-4ab5-b490-ccd74131e2c6, Nodes: ed3d0f0e-4614-480f-aff0-1706334f678b{ip: 172.22.0.4, host: ozones3-haproxy_datanode_3.ozones3-haproxy_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-17T04:56:46.675370Z]
scm_1       | 2020-04-17 04:56:46,680 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-17 04:56:46,681 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-17 04:56:46,683 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=263564e8-3154-417e-9806-83cc33444ed1 to datanode:3aa95a42-0392-4192-8556-ef4d57f7b5c9
scm_1       | 2020-04-17 04:56:46,683 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=263564e8-3154-417e-9806-83cc33444ed1 to datanode:ed3d0f0e-4614-480f-aff0-1706334f678b
scm_1       | 2020-04-17 04:56:46,684 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=263564e8-3154-417e-9806-83cc33444ed1 to datanode:f71fab23-81a9-41d8-ab04-2a8824f1aeaa
scm_1       | 2020-04-17 04:56:46,684 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 263564e8-3154-417e-9806-83cc33444ed1, Nodes: 3aa95a42-0392-4192-8556-ef4d57f7b5c9{ip: 172.22.0.2, host: ozones3-haproxy_datanode_2.ozones3-haproxy_default, networkLocation: /default-rack, certSerialId: null}ed3d0f0e-4614-480f-aff0-1706334f678b{ip: 172.22.0.4, host: ozones3-haproxy_datanode_3.ozones3-haproxy_default, networkLocation: /default-rack, certSerialId: null}f71fab23-81a9-41d8-ab04-2a8824f1aeaa{ip: 172.22.0.7, host: ozones3-haproxy_datanode_1.ozones3-haproxy_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-17T04:56:46.683809Z]
scm_1       | 2020-04-17 04:56:46,685 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-17 04:56:49,382 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: e96c8dbd-d490-4fd2-8087-8de8d0e3ccba, Nodes: 3aa95a42-0392-4192-8556-ef4d57f7b5c9{ip: 172.22.0.2, host: ozones3-haproxy_datanode_2.ozones3-haproxy_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:3aa95a42-0392-4192-8556-ef4d57f7b5c9, CreationTimestamp2020-04-17T04:56:46.355674Z] moved to OPEN state
scm_1       | 2020-04-17 04:56:49,400 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-04-17 04:56:49,401 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-04-17 04:56:49,792 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 0e400dd7-6b0f-46e3-b517-d9f6e51256a2, Nodes: f71fab23-81a9-41d8-ab04-2a8824f1aeaa{ip: 172.22.0.7, host: ozones3-haproxy_datanode_1.ozones3-haproxy_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:f71fab23-81a9-41d8-ab04-2a8824f1aeaa, CreationTimestamp2020-04-17T04:56:46.411624Z] moved to OPEN state
scm_1       | 2020-04-17 04:56:49,800 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-04-17 04:56:49,800 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-04-17 04:56:50,213 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: f33c3219-c272-4ab5-b490-ccd74131e2c6, Nodes: ed3d0f0e-4614-480f-aff0-1706334f678b{ip: 172.22.0.4, host: ozones3-haproxy_datanode_3.ozones3-haproxy_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:ed3d0f0e-4614-480f-aff0-1706334f678b, CreationTimestamp2020-04-17T04:56:46.675370Z] moved to OPEN state
scm_1       | 2020-04-17 04:56:50,220 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-04-17 04:56:50,220 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-04-17 04:56:54,710 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 263564e8-3154-417e-9806-83cc33444ed1, Nodes: 3aa95a42-0392-4192-8556-ef4d57f7b5c9{ip: 172.22.0.2, host: ozones3-haproxy_datanode_2.ozones3-haproxy_default, networkLocation: /default-rack, certSerialId: null}ed3d0f0e-4614-480f-aff0-1706334f678b{ip: 172.22.0.4, host: ozones3-haproxy_datanode_3.ozones3-haproxy_default, networkLocation: /default-rack, certSerialId: null}f71fab23-81a9-41d8-ab04-2a8824f1aeaa{ip: 172.22.0.7, host: ozones3-haproxy_datanode_1.ozones3-haproxy_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:3aa95a42-0392-4192-8556-ef4d57f7b5c9, CreationTimestamp2020-04-17T04:56:46.683809Z] moved to OPEN state
scm_1       | 2020-04-17 04:56:54,710 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1       | 2020-04-17 04:56:54,710 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-04-17 04:56:54,711 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1       | 2020-04-17 04:56:54,711 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1       | 2020-04-17 04:56:54,711 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
