Attaching to ozone_datanode_1, ozone_recon_1, ozone_datanode_2, ozone_datanode_3, ozone_s3g_1, ozone_om_1, ozone_scm_1
datanode_2  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2020-04-17 04:38:20,012 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = c32cd3ca432b/172.21.0.7
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 3.2.0
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_2  | STARTUP_MSG:   java = 11.0.6
datanode_2  | ************************************************************/
datanode_2  | 2020-04-17 04:38:20,061 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2020-04-17 04:38:21,755 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2020-04-17 04:38:22,157 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2020-04-17 04:38:22,937 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2020-04-17 04:38:22,953 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2020-04-17 04:38:23,836 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:c32cd3ca432b ip:172.21.0.7
datanode_2  | 2020-04-17 04:38:24,103 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2  | 2020-04-17 04:38:24,112 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2  | 2020-04-17 04:38:24,113 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2020-04-17 04:38:24,146 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2  | 2020-04-17 04:38:24,217 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2020-04-17 04:38:27,790 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-04-17 04:38:27,934 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2020-04-17 04:38:28,191 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2  | 2020-04-17 04:38:28,201 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2  | 2020-04-17 04:38:28,212 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-17 04:38:28,215 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2  | 2020-04-17 04:38:28,217 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-04-17 04:38:28,885 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-17 04:38:29,307 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 2020-04-17 04:38:29,394 [main] INFO util.log: Logging initialized @13571ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | 2020-04-17 04:38:29,713 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2020-04-17 04:38:29,723 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2020-04-17 04:38:29,730 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2020-04-17 04:38:29,731 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2  | 2020-04-17 04:38:29,731 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2  | 2020-04-17 04:38:29,731 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2  | 2020-04-17 04:38:29,832 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2020-04-17 04:38:29,833 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2  | 2020-04-17 04:38:29,921 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2020-04-17 04:38:29,921 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2020-04-17 04:38:29,922 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_2  | 2020-04-17 04:38:29,934 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f76c2cc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2020-04-17 04:38:29,935 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@441b8382{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2020-04-17 04:38:30,197 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@673c4f6e{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-6446481619818335010.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 2020-04-17 04:38:30,225 [main] INFO server.AbstractConnector: Started ServerConnector@1491344a{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2  | 2020-04-17 04:38:30,225 [main] INFO server.Server: Started @14402ms
datanode_2  | 2020-04-17 04:38:30,242 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2020-04-17 04:38:30,242 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2020-04-17 04:38:30,255 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2020-04-17 04:38:30,318 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@a7d4b5f] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2020-04-17 04:38:30,544 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.21.0.3:9891
datanode_2  | 2020-04-17 04:38:30,711 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2  | 2020-04-17 04:38:33,504 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_2  | java.net.SocketTimeoutException: Call From c32cd3ca432b/172.21.0.7 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.7:56754 remote=recon/172.21.0.3:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_2  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_2  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.7:56754 remote=recon/172.21.0.3:9891]
datanode_2  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_2  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_2  | 2020-04-17 04:38:33,557 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2020-04-17 04:38:33,559 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2  | 2020-04-17 04:38:33,560 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis fc51ec5f-ce44-4742-ab67-704c0b8112cf at port 9858
datanode_2  | 2020-04-17 04:38:33,663 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: fc51ec5f-ce44-4742-ab67-704c0b8112cf: start RPC server
datanode_2  | 2020-04-17 04:38:33,911 [Datanode State Machine Thread - 1] INFO server.GrpcService: fc51ec5f-ce44-4742-ab67-704c0b8112cf: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2  | 2020-04-17 04:38:37,329 [Command processor thread] INFO impl.RaftServerProxy: fc51ec5f-ce44-4742-ab67-704c0b8112cf: addNew group-4611EEAF8837:[fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] returns group-4611EEAF8837:java.util.concurrent.CompletableFuture@2646af51[Not completed]
datanode_2  | 2020-04-17 04:38:37,397 [pool-69-thread-1] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf: new RaftServerImpl for group-4611EEAF8837:[fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-04-17 04:38:37,409 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-04-17 04:38:37,414 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-04-17 04:38:37,414 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-04-17 04:38:37,414 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-04-17 04:38:37,415 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-04-17 04:38:37,419 [pool-69-thread-1] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837: ConfigurationManager, init=-1: [fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-04-17 04:38:37,427 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-17 04:38:37,431 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-04-17 04:38:37,440 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e279ebb1-cd90-4587-ade9-4611eeaf8837 does not exist. Creating ...
datanode_2  | 2020-04-17 04:38:37,456 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e279ebb1-cd90-4587-ade9-4611eeaf8837/in_use.lock acquired by nodename 6@c32cd3ca432b
datanode_2  | 2020-04-17 04:38:37,464 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e279ebb1-cd90-4587-ade9-4611eeaf8837 has been successfully formatted.
datanode_2  | 2020-04-17 04:38:37,468 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-4611EEAF8837: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-04-17 04:38:37,468 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-04-17 04:38:37,473 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-04-17 04:38:37,477 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-04-17 04:38:37,478 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-17 04:38:37,480 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-17 04:38:37,489 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.fc51ec5f-ce44-4742-ab67-704c0b8112cf
datanode_2  | 2020-04-17 04:38:37,498 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-04-17 04:38:37,524 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/e279ebb1-cd90-4587-ade9-4611eeaf8837
datanode_2  | 2020-04-17 04:38:37,529 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-04-17 04:38:37,529 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-04-17 04:38:37,530 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-17 04:38:37,530 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-04-17 04:38:37,531 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-04-17 04:38:37,531 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-04-17 04:38:37,532 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-04-17 04:38:37,543 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-04-17 04:38:37,543 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-04-17 04:38:37,601 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-04-17 04:38:37,620 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-04-17 04:38:37,638 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-04-17 04:38:37,655 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-04-17 04:38:37,658 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-04-17 04:38:37,659 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-04-17 04:38:37,770 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837
datanode_2  | 2020-04-17 04:38:37,806 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837
datanode_2  | 2020-04-17 04:38:37,811 [pool-69-thread-1] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837: start as a follower, conf=-1: [fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null
datanode_2  | 2020-04-17 04:38:37,812 [pool-69-thread-1] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-04-17 04:38:37,818 [pool-69-thread-1] INFO impl.RoleInfo: fc51ec5f-ce44-4742-ab67-704c0b8112cf: start FollowerState
datanode_2  | 2020-04-17 04:38:37,835 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4611EEAF8837,id=fc51ec5f-ce44-4742-ab67-704c0b8112cf
datanode_2  | 2020-04-17 04:38:37,840 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837
datanode_2  | 2020-04-17 04:38:37,866 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "e279ebb1-cd90-4587-ade9-4611eeaf8837"
datanode_2  | .
datanode_2  | 2020-04-17 04:38:37,868 [Command processor thread] INFO impl.RaftServerProxy: fc51ec5f-ce44-4742-ab67-704c0b8112cf: addNew group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] returns group-D5E9801835C4:java.util.concurrent.CompletableFuture@2915bb27[Not completed]
datanode_2  | 2020-04-17 04:38:37,871 [pool-69-thread-1] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf: new RaftServerImpl for group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-04-17 04:38:37,876 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-04-17 04:38:37,876 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-04-17 04:38:37,876 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-04-17 04:38:37,876 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-04-17 04:38:37,876 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-04-17 04:38:37,877 [pool-69-thread-1] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4: ConfigurationManager, init=-1: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-04-17 04:38:37,877 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-17 04:38:37,877 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-04-17 04:38:37,882 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ccbeff08-efe2-46c5-b724-d5e9801835c4 does not exist. Creating ...
datanode_2  | 2020-04-17 04:38:37,886 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ccbeff08-efe2-46c5-b724-d5e9801835c4/in_use.lock acquired by nodename 6@c32cd3ca432b
datanode_2  | 2020-04-17 04:38:37,889 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ccbeff08-efe2-46c5-b724-d5e9801835c4 has been successfully formatted.
datanode_2  | 2020-04-17 04:38:37,889 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-D5E9801835C4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-04-17 04:38:37,890 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-04-17 04:38:37,897 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-04-17 04:38:37,898 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-04-17 04:38:37,900 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-17 04:38:37,900 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-17 04:38:37,900 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-04-17 04:38:37,900 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/ccbeff08-efe2-46c5-b724-d5e9801835c4
datanode_2  | 2020-04-17 04:38:37,900 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-04-17 04:38:37,900 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-04-17 04:38:37,900 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-17 04:38:37,900 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-04-17 04:38:37,900 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-04-17 04:38:37,901 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-04-17 04:38:37,903 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2020-04-17 04:38:18,463 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = d8db8a674ee8/172.21.0.8
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 3.2.0
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1  | STARTUP_MSG:   java = 11.0.6
datanode_1  | ************************************************************/
datanode_1  | 2020-04-17 04:38:18,499 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2020-04-17 04:38:19,885 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2020-04-17 04:38:20,421 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2020-04-17 04:38:21,503 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2020-04-17 04:38:21,504 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2020-04-17 04:38:22,209 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:d8db8a674ee8 ip:172.21.0.8
datanode_1  | 2020-04-17 04:38:22,587 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2020-04-17 04:38:22,601 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1  | 2020-04-17 04:38:22,607 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2020-04-17 04:38:22,612 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2020-04-17 04:38:22,786 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2020-04-17 04:38:26,771 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2020-04-17 04:38:26,926 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1  | 2020-04-17 04:38:27,172 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1  | 2020-04-17 04:38:27,173 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  | 2020-04-17 04:38:27,175 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-17 04:38:27,177 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1  | 2020-04-17 04:38:27,189 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2020-04-17 04:38:28,409 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-04-17 04:38:28,975 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2020-04-17 04:38:29,285 [main] INFO util.log: Logging initialized @14872ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2020-04-17 04:38:29,617 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2020-04-17 04:38:29,634 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2020-04-17 04:38:29,645 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2020-04-17 04:38:29,652 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1  | 2020-04-17 04:38:29,656 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1  | 2020-04-17 04:38:29,656 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1  | 2020-04-17 04:38:29,734 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2020-04-17 04:38:29,740 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1  | 2020-04-17 04:38:29,980 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  | 2020-04-17 04:38:29,990 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2020-04-17 04:38:29,992 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_1  | 2020-04-17 04:38:30,047 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7e7f3cfd{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2020-04-17 04:38:30,056 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@34b9eb03{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2020-04-17 04:38:30,306 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@51ab1ee3{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-11319998211331761719.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1  | 2020-04-17 04:38:30,338 [main] INFO server.AbstractConnector: Started ServerConnector@737db7f8{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1  | 2020-04-17 04:38:30,340 [main] INFO server.Server: Started @15927ms
datanode_1  | 2020-04-17 04:38:30,342 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2020-04-17 04:38:30,342 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2020-04-17 04:38:30,350 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1  | 2020-04-17 04:38:30,399 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2f419c5a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2020-04-17 04:38:30,624 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.21.0.3:9891
datanode_1  | 2020-04-17 04:38:30,738 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1  | 2020-04-17 04:38:33,546 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 2020-04-17 04:38:33,547 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1  | 2020-04-17 04:38:33,547 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis e02419d7-5832-4f5c-83d3-3bf12f7aa2ad at port 9858
datanode_1  | 2020-04-17 04:38:33,607 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_1  | java.net.SocketTimeoutException: Call From d8db8a674ee8/172.21.0.8 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.8:33104 remote=recon/172.21.0.3:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2020-04-17 04:38:14,720 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = bf065be64798/172.21.0.4
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 3.2.0
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_1  | 	at com.sun.proxy.$Proxy40.submitRequest(Unknown Source)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.8:33104 remote=recon/172.21.0.3:9891]
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_1  | 2020-04-17 04:38:33,650 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: start RPC server
datanode_1  | 2020-04-17 04:38:34,013 [Datanode State Machine Thread - 1] INFO server.GrpcService: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1  | 2020-04-17 04:38:37,405 [Command processor thread] INFO impl.RaftServerProxy: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: addNew group-94E709D62531:[e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858] returns group-94E709D62531:java.util.concurrent.CompletableFuture@7d78969a[Not completed]
datanode_1  | 2020-04-17 04:38:37,433 [pool-69-thread-1] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: new RaftServerImpl for group-94E709D62531:[e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-04-17 04:38:37,434 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-04-17 04:38:37,447 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-04-17 04:38:37,447 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-04-17 04:38:37,448 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-04-17 04:38:37,448 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-04-17 04:38:37,465 [pool-69-thread-1] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531: ConfigurationManager, init=-1: [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-04-17 04:38:37,467 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-04-17 04:38:37,478 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-04-17 04:38:37,493 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/143e2e4e-7906-4522-90b9-94e709d62531 does not exist. Creating ...
datanode_1  | 2020-04-17 04:38:37,511 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/143e2e4e-7906-4522-90b9-94e709d62531/in_use.lock acquired by nodename 6@d8db8a674ee8
datanode_1  | 2020-04-17 04:38:37,517 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/143e2e4e-7906-4522-90b9-94e709d62531 has been successfully formatted.
datanode_1  | 2020-04-17 04:38:37,538 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-94E709D62531: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-04-17 04:38:37,543 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-04-17 04:38:37,544 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-04-17 04:38:37,554 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-04-17 04:38:37,555 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-17 04:38:37,563 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-17 04:38:37,569 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.e02419d7-5832-4f5c-83d3-3bf12f7aa2ad
datanode_1  | 2020-04-17 04:38:37,599 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-04-17 04:38:37,618 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/143e2e4e-7906-4522-90b9-94e709d62531
datanode_1  | 2020-04-17 04:38:37,628 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-04-17 04:38:37,628 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-04-17 04:38:37,629 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-17 04:38:37,629 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-04-17 04:38:37,903 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-04-17 04:38:37,903 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-04-17 04:38:37,903 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-04-17 04:38:37,904 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-04-17 04:38:37,904 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-04-17 04:38:37,909 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-04-17 04:38:37,911 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-04-17 04:38:37,912 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-04-17 04:38:37,913 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4
datanode_2  | 2020-04-17 04:38:37,914 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4
datanode_2  | 2020-04-17 04:38:37,915 [pool-69-thread-1] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4: start as a follower, conf=-1: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null
datanode_2  | 2020-04-17 04:38:37,917 [pool-69-thread-1] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-04-17 04:38:37,917 [pool-69-thread-1] INFO impl.RoleInfo: fc51ec5f-ce44-4742-ab67-704c0b8112cf: start FollowerState
datanode_2  | 2020-04-17 04:38:37,920 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D5E9801835C4,id=fc51ec5f-ce44-4742-ab67-704c0b8112cf
datanode_2  | 2020-04-17 04:38:37,920 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4
datanode_2  | 2020-04-17 04:38:39,086 [grpc-default-executor-0] WARN impl.RaftServerProxy: fc51ec5f-ce44-4742-ab67-704c0b8112cf: Failed groupAdd* GroupManagementRequest:client-D637C98A22E3->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=0, seq=0, RW, null, Add:group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858]
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: fc51ec5f-ce44-4742-ab67-704c0b8112cf: Failed to add group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] since the group already exists in the map.
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: fc51ec5f-ce44-4742-ab67-704c0b8112cf: Failed to add group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] since the group already exists in the map.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2  | 	... 13 more
datanode_2  | 2020-04-17 04:38:39,760 [grpc-default-executor-0] WARN impl.RaftServerProxy: fc51ec5f-ce44-4742-ab67-704c0b8112cf: Failed groupAdd* GroupManagementRequest:client-0A7403143769->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=0, seq=0, RW, null, Add:group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858]
datanode_2  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: fc51ec5f-ce44-4742-ab67-704c0b8112cf: Failed to add group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] since the group already exists in the map.
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_2  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_2  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_2  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: fc51ec5f-ce44-4742-ab67-704c0b8112cf: Failed to add group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] since the group already exists in the map.
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_2  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_2  | 	... 13 more
datanode_2  | 2020-04-17 04:38:39,920 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "ccbeff08-efe2-46c5-b724-d5e9801835c4"
datanode_2  | .
datanode_2  | 2020-04-17 04:38:42,907 [Thread-25] INFO impl.FollowerState: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-FollowerState: change to CANDIDATE, lastRpcTime:5093ms, electionTimeout:5082ms
datanode_2  | 2020-04-17 04:38:42,908 [Thread-25] INFO impl.RoleInfo: fc51ec5f-ce44-4742-ab67-704c0b8112cf: shutdown FollowerState
datanode_2  | 2020-04-17 04:38:42,909 [Thread-25] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-04-17 04:38:42,910 [Thread-25] INFO impl.RoleInfo: fc51ec5f-ce44-4742-ab67-704c0b8112cf: start LeaderElection
datanode_2  | 2020-04-17 04:38:42,922 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO impl.LeaderElection: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1: begin an election at term 1 for -1: [fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null
datanode_2  | 2020-04-17 04:38:42,923 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO impl.RoleInfo: fc51ec5f-ce44-4742-ab67-704c0b8112cf: shutdown LeaderElection
datanode_2  | 2020-04-17 04:38:42,925 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-04-17 04:38:42,926 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4611EEAF8837 with new leaderId: fc51ec5f-ce44-4742-ab67-704c0b8112cf
datanode_2  | 2020-04-17 04:38:42,926 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837: change Leader from null to fc51ec5f-ce44-4742-ab67-704c0b8112cf at term 1 for becomeLeader, leader elected after 5457ms
datanode_2  | 2020-04-17 04:38:42,934 [Thread-27] INFO impl.FollowerState: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-FollowerState: change to CANDIDATE, lastRpcTime:5016ms, electionTimeout:5010ms
datanode_2  | 2020-04-17 04:38:42,935 [Thread-27] INFO impl.RoleInfo: fc51ec5f-ce44-4742-ab67-704c0b8112cf: shutdown FollowerState
datanode_2  | 2020-04-17 04:38:42,935 [Thread-27] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-04-17 04:38:42,935 [Thread-27] INFO impl.RoleInfo: fc51ec5f-ce44-4742-ab67-704c0b8112cf: start LeaderElection
datanode_2  | 2020-04-17 04:38:42,936 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-04-17 04:38:42,936 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2020-04-17 04:38:42,941 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837
datanode_2  | 2020-04-17 04:38:42,964 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2020-04-17 04:38:42,970 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-04-17 04:38:42,983 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-04-17 04:38:42,981 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO impl.LeaderElection: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2: begin an election at term 1 for -1: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null
datanode_2  | 2020-04-17 04:38:42,994 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-04-17 04:38:42,994 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2020-04-17 04:38:43,021 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO impl.RoleInfo: fc51ec5f-ce44-4742-ab67-704c0b8112cf: start LeaderState
datanode_2  | 2020-04-17 04:38:43,123 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-04-17 04:38:43,162 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO impl.LeaderElection: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2: Election PASSED; received 1 response(s) [fc51ec5f-ce44-4742-ab67-704c0b8112cf<-691d8703-820d-4600-8b2e-4f7b2116a3a9#0:OK-t1] and 0 exception(s); fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4:t1, leader=null, voted=fc51ec5f-ce44-4742-ab67-704c0b8112cf, raftlog=fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null
datanode_2  | 2020-04-17 04:38:43,166 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO impl.RoleInfo: fc51ec5f-ce44-4742-ab67-704c0b8112cf: shutdown LeaderElection
datanode_2  | 2020-04-17 04:38:43,166 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-04-17 04:38:43,167 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D5E9801835C4 with new leaderId: fc51ec5f-ce44-4742-ab67-704c0b8112cf
datanode_2  | 2020-04-17 04:38:43,175 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4: change Leader from null to fc51ec5f-ce44-4742-ab67-704c0b8112cf at term 1 for becomeLeader, leader elected after 5277ms
datanode_2  | 2020-04-17 04:38:43,217 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-LeaderElection1] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837: set configuration 0: [fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null at 0
datanode_2  | 2020-04-17 04:38:43,227 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-04-17 04:38:43,232 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2020-04-17 04:38:43,232 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4
datanode_2  | 2020-04-17 04:38:43,232 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2020-04-17 04:38:43,233 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-04-17 04:38:43,233 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-04-17 04:38:43,233 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-04-17 04:38:43,235 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2020-04-17 04:38:43,238 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2  | 2020-04-17 04:38:43,238 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-17 04:38:43,238 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2  | 2020-04-17 04:38:43,241 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2  | 2020-04-17 04:38:43,244 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-04-17 04:38:43,244 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-04-17 04:38:43,256 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2  | 2020-04-17 04:38:43,257 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-17 04:38:43,257 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2  | 2020-04-17 04:38:43,257 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2  | 2020-04-17 04:38:43,257 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-04-17 04:38:43,257 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-04-17 04:38:43,258 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO impl.RoleInfo: fc51ec5f-ce44-4742-ab67-704c0b8112cf: start LeaderState
datanode_2  | 2020-04-17 04:38:43,264 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-04-17 04:38:43,278 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-LeaderElection2] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4: set configuration 0: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null at 0
datanode_2  | 2020-04-17 04:38:43,286 [grpc-default-executor-0] INFO impl.RaftServerImpl: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-   LEADER: Withhold vote from candidate e02419d7-5832-4f5c-83d3-3bf12f7aa2ad with term 1. State: leader=fc51ec5f-ce44-4742-ab67-704c0b8112cf, term=1, lastRpcElapsed=null
datanode_2  | 2020-04-17 04:38:43,402 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ccbeff08-efe2-46c5-b724-d5e9801835c4/current/log_inprogress_0
datanode_2  | 2020-04-17 04:38:43,406 [fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-4611EEAF8837-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e279ebb1-cd90-4587-ade9-4611eeaf8837/current/log_inprogress_0
datanode_1  | 2020-04-17 04:38:37,630 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-04-17 04:38:37,630 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-04-17 04:38:37,631 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-04-17 04:38:37,636 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-04-17 04:38:37,636 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-04-17 04:38:37,706 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-04-17 04:38:37,710 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-04-17 04:38:37,738 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-04-17 04:38:37,740 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-04-17 04:38:37,741 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-04-17 04:38:37,742 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-04-17 04:38:37,800 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531
datanode_1  | 2020-04-17 04:38:37,802 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531
datanode_1  | 2020-04-17 04:38:37,811 [pool-69-thread-1] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531: start as a follower, conf=-1: [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858], old=null
datanode_1  | 2020-04-17 04:38:37,812 [pool-69-thread-1] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-04-17 04:38:37,813 [pool-69-thread-1] INFO impl.RoleInfo: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: start FollowerState
datanode_1  | 2020-04-17 04:38:37,827 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-94E709D62531,id=e02419d7-5832-4f5c-83d3-3bf12f7aa2ad
datanode_1  | 2020-04-17 04:38:37,829 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531
datanode_1  | 2020-04-17 04:38:37,869 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "143e2e4e-7906-4522-90b9-94e709d62531"
datanode_1  | .
datanode_1  | 2020-04-17 04:38:37,872 [Command processor thread] INFO impl.RaftServerProxy: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: addNew group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] returns group-D5E9801835C4:java.util.concurrent.CompletableFuture@369e260e[Not completed]
datanode_1  | 2020-04-17 04:38:37,902 [pool-69-thread-1] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: new RaftServerImpl for group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-04-17 04:38:37,903 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-04-17 04:38:37,903 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-04-17 04:38:37,905 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-04-17 04:38:37,912 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-04-17 04:38:37,913 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-04-17 04:38:37,913 [pool-69-thread-1] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4: ConfigurationManager, init=-1: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-04-17 04:38:37,914 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-04-17 04:38:37,915 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-04-17 04:38:37,915 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ccbeff08-efe2-46c5-b724-d5e9801835c4 does not exist. Creating ...
datanode_1  | 2020-04-17 04:38:37,917 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ccbeff08-efe2-46c5-b724-d5e9801835c4/in_use.lock acquired by nodename 6@d8db8a674ee8
datanode_1  | 2020-04-17 04:38:37,923 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ccbeff08-efe2-46c5-b724-d5e9801835c4 has been successfully formatted.
datanode_1  | 2020-04-17 04:38:37,927 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-D5E9801835C4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-04-17 04:38:37,927 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-04-17 04:38:37,927 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-04-17 04:38:37,927 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-04-17 04:38:37,933 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-17 04:38:37,935 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-17 04:38:37,937 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-04-17 04:38:37,937 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/ccbeff08-efe2-46c5-b724-d5e9801835c4
datanode_1  | 2020-04-17 04:38:37,938 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-04-17 04:38:37,938 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-04-17 04:38:37,938 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-17 04:38:37,938 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-04-17 04:38:37,938 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-04-17 04:38:37,941 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-04-17 04:39:43,361 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1,entriesCount=1,lastEntry=(t:1, i:0)
datanode_2  | 2020-04-17 04:39:49,016 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4,entriesCount=1,lastEntry=(t:1, i:1)
datanode_2  | 2020-04-17 04:39:49,033 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5,entriesCount=1,lastEntry=(t:1, i:2)
datanode_2  | 2020-04-17 04:39:49,848 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6,entriesCount=1,lastEntry=(t:1, i:3)
om_1        | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-04-17 04:38:21,132 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = 5d36c7734787/172.21.0.6
om_1        | STARTUP_MSG:   args = [--init]
om_1        | STARTUP_MSG:   version = 3.2.0
datanode_1  | 2020-04-17 04:38:37,942 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-04-17 04:38:37,942 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-04-17 04:38:37,942 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-04-17 04:38:37,942 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-04-17 04:38:37,942 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-04-17 04:38:37,945 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-04-17 04:38:37,948 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-04-17 04:38:37,948 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-04-17 04:38:37,948 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-04-17 04:38:37,948 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4
datanode_1  | 2020-04-17 04:38:37,949 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4
datanode_1  | 2020-04-17 04:38:37,949 [pool-69-thread-1] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4: start as a follower, conf=-1: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null
datanode_1  | 2020-04-17 04:38:37,949 [pool-69-thread-1] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-04-17 04:38:37,950 [pool-69-thread-1] INFO impl.RoleInfo: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: start FollowerState
datanode_1  | 2020-04-17 04:38:37,951 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D5E9801835C4,id=e02419d7-5832-4f5c-83d3-3bf12f7aa2ad
datanode_1  | 2020-04-17 04:38:37,953 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4
datanode_1  | 2020-04-17 04:38:39,707 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "ccbeff08-efe2-46c5-b724-d5e9801835c4"
datanode_1  | .
datanode_1  | 2020-04-17 04:38:39,871 [grpc-default-executor-0] WARN impl.RaftServerProxy: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: Failed groupAdd* GroupManagementRequest:client-A432DA4CBE51->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4, cid=1, seq=0, RW, null, Add:group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858]
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: Failed to add group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] since the group already exists in the map.
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: Failed to add group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] since the group already exists in the map.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 	... 13 more
datanode_1  | 2020-04-17 04:38:39,907 [grpc-default-executor-0] WARN impl.RaftServerProxy: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: Failed groupAdd* GroupManagementRequest:client-733EF87F3418->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4, cid=1, seq=0, RW, null, Add:group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858]
datanode_1  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: Failed to add group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] since the group already exists in the map.
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_1  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-04-17 04:38:21,161 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-04-17 04:38:25,200 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-04-17 04:38:25,378 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.21.0.6:9862
om_1        | 2020-04-17 04:38:25,386 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-04-17 04:38:25,421 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-17 04:38:27,470 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-17 04:38:28,471 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-17 04:38:29,472 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-17 04:38:30,472 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-17 04:38:31,473 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-17 04:38:32,474 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-2e963381-9138-401f-8b68-ec8bcbe4bb3e
om_1        | 2020-04-17 04:38:33,527 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1        | /************************************************************
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at 5d36c7734787/172.21.0.6
om_1        | ************************************************************/
om_1        | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-04-17 04:38:35,021 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = 5d36c7734787/172.21.0.6
om_1        | STARTUP_MSG:   args = []
om_1        | STARTUP_MSG:   version = 3.2.0
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_3  | STARTUP_MSG:   java = 11.0.6
datanode_3  | ************************************************************/
datanode_3  | 2020-04-17 04:38:14,731 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2020-04-17 04:38:16,096 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2020-04-17 04:38:16,636 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2020-04-17 04:38:17,756 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2020-04-17 04:38:17,756 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2020-04-17 04:38:18,662 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:bf065be64798 ip:172.21.0.4
datanode_3  | 2020-04-17 04:38:19,094 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3  | 2020-04-17 04:38:19,097 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3  | 2020-04-17 04:38:19,098 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2020-04-17 04:38:19,128 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2020-04-17 04:38:19,236 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2020-04-17 04:38:23,074 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-04-17 04:38:23,264 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3  | 2020-04-17 04:38:23,618 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3  | 2020-04-17 04:38:23,619 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3  | 2020-04-17 04:38:23,620 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-17 04:38:23,620 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3  | 2020-04-17 04:38:23,621 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-04-17 04:38:24,675 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-17 04:38:25,498 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2020-04-17 04:38:25,607 [main] INFO util.log: Logging initialized @13011ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2020-04-17 04:38:25,944 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2020-04-17 04:38:25,955 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2020-04-17 04:38:25,985 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2020-04-17 04:38:25,987 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3  | 2020-04-17 04:38:25,993 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3  | 2020-04-17 04:38:25,994 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3  | 2020-04-17 04:38:26,119 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2020-04-17 04:38:26,124 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3  | 2020-04-17 04:38:26,286 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2020-04-17 04:38:26,286 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 2020-04-17 04:38:26,294 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_3  | 2020-04-17 04:38:26,568 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f76c2cc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2020-04-17 04:38:26,570 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@441b8382{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2020-04-17 04:38:26,987 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@673c4f6e{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-16204156580387689667.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2020-04-17 04:38:27,028 [main] INFO server.AbstractConnector: Started ServerConnector@1491344a{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3  | 2020-04-17 04:38:27,036 [main] INFO server.Server: Started @14440ms
datanode_3  | 2020-04-17 04:38:27,054 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2020-04-17 04:38:27,054 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2020-04-17 04:38:27,059 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3  | 2020-04-17 04:38:27,190 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3793d316] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2020-04-17 04:38:27,631 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.21.0.3:9891
datanode_3  | 2020-04-17 04:38:27,945 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3  | 2020-04-17 04:38:30,253 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-04-17 04:38:31,253 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-04-17 04:38:32,256 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-04-17 04:38:33,274 [Datanode State Machine Thread - 1] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_3  | java.net.SocketTimeoutException: Call From bf065be64798/172.21.0.4 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.4:36860 remote=scm/172.21.0.5:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: Failed to add group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] since the group already exists in the map.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_1  | 	... 13 more
datanode_1  | 2020-04-17 04:38:42,994 [Thread-25] INFO impl.FollowerState: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-FollowerState: change to CANDIDATE, lastRpcTime:5181ms, electionTimeout:5177ms
datanode_1  | 2020-04-17 04:38:42,996 [Thread-25] INFO impl.RoleInfo: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: shutdown FollowerState
datanode_1  | 2020-04-17 04:38:42,996 [Thread-25] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2020-04-17 04:38:42,998 [Thread-25] INFO impl.RoleInfo: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: start LeaderElection
datanode_1  | 2020-04-17 04:38:43,003 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO impl.LeaderElection: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1: begin an election at term 1 for -1: [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858], old=null
datanode_1  | 2020-04-17 04:38:43,004 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO impl.RoleInfo: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: shutdown LeaderElection
datanode_1  | 2020-04-17 04:38:43,004 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2020-04-17 04:38:43,004 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-94E709D62531 with new leaderId: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad
datanode_1  | 2020-04-17 04:38:43,005 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531: change Leader from null to e02419d7-5832-4f5c-83d3-3bf12f7aa2ad at term 1 for becomeLeader, leader elected after 5466ms
datanode_1  | 2020-04-17 04:38:43,014 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2020-04-17 04:38:43,014 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2020-04-17 04:38:43,016 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531
datanode_1  | 2020-04-17 04:38:43,018 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2020-04-17 04:38:43,022 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1  | 2020-04-17 04:38:43,029 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2020-04-17 04:38:43,029 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2020-04-17 04:38:43,029 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2020-04-17 04:38:43,041 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO impl.RoleInfo: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: start LeaderState
datanode_1  | 2020-04-17 04:38:43,056 [Thread-27] INFO impl.FollowerState: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4-FollowerState: change to CANDIDATE, lastRpcTime:5106ms, electionTimeout:5062ms
datanode_1  | 2020-04-17 04:38:43,067 [Thread-27] INFO impl.RoleInfo: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: shutdown FollowerState
datanode_1  | 2020-04-17 04:38:43,067 [Thread-27] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2020-04-17 04:38:43,067 [Thread-27] INFO impl.RoleInfo: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: start LeaderElection
datanode_1  | 2020-04-17 04:38:43,082 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-04-17 04:38:43,085 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4-LeaderElection2] INFO impl.LeaderElection: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4-LeaderElection2: begin an election at term 1 for -1: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null
datanode_1  | 2020-04-17 04:38:43,127 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-LeaderElection1] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531: set configuration 0: [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858], old=null at 0
datanode_1  | 2020-04-17 04:38:43,331 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4-LeaderElection2] INFO impl.LeaderElection: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4-LeaderElection2: Election REJECTED; received 2 response(s) [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad<-691d8703-820d-4600-8b2e-4f7b2116a3a9#0:FAIL-t1, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad<-fc51ec5f-ce44-4742-ab67-704c0b8112cf#0:FAIL-t1] and 0 exception(s); e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4:t1, leader=null, voted=e02419d7-5832-4f5c-83d3-3bf12f7aa2ad, raftlog=e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-04-17 04:38:35,025 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-04-17 04:38:35,586 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-04-17 04:38:35,616 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.21.0.6:9862
om_1        | 2020-04-17 04:38:35,616 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-04-17 04:38:35,620 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-17 04:38:35,693 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-17 04:38:36,256 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-17 04:38:36,852 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2020-04-17 04:38:36,862 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1        | 2020-04-17 04:38:36,970 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | 2020-04-17 04:38:37,028 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2020-04-17 04:38:37,028 [main] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1        | 2020-04-17 04:38:37,077 [main] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.21.0.6:9862
om_1        | 2020-04-17 04:38:37,098 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1        | 2020-04-17 04:38:37,099 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1        | 2020-04-17 04:38:37,328 [main] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1        | 2020-04-17 04:38:37,384 [main] INFO util.log: Logging initialized @3600ms to org.eclipse.jetty.util.log.Slf4jLog
om_1        | 2020-04-17 04:38:37,592 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1        | 2020-04-17 04:38:37,606 [main] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1        | 2020-04-17 04:38:37,639 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1        | 2020-04-17 04:38:37,649 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1        | 2020-04-17 04:38:37,652 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
om_1        | 2020-04-17 04:38:37,652 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
om_1        | 2020-04-17 04:38:37,726 [main] INFO http.HttpServer2: Jetty bound to port 9874
om_1        | 2020-04-17 04:38:37,729 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1        | 2020-04-17 04:38:37,807 [main] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 2020-04-17 04:38:37,807 [main] INFO server.session: No SessionScavenger set, using defaults
om_1        | 2020-04-17 04:38:37,816 [main] INFO server.session: node0 Scavenging every 660000ms
om_1        | 2020-04-17 04:38:37,826 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@b112b13{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 2020-04-17 04:38:37,834 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5fbe155{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_3  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_3  | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.4:36860 remote=scm/172.21.0.5:9861]
datanode_3  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_3  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_3  | 2020-04-17 04:38:33,549 [Datanode State Machine Thread - 3] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3  | 2020-04-17 04:38:33,554 [Datanode State Machine Thread - 3] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3  | 2020-04-17 04:38:33,555 [Datanode State Machine Thread - 3] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 691d8703-820d-4600-8b2e-4f7b2116a3a9 at port 9858
datanode_3  | 2020-04-17 04:38:33,667 [Datanode State Machine Thread - 3] INFO impl.RaftServerProxy: 691d8703-820d-4600-8b2e-4f7b2116a3a9: start RPC server
datanode_3  | 2020-04-17 04:38:33,904 [Datanode State Machine Thread - 3] INFO server.GrpcService: 691d8703-820d-4600-8b2e-4f7b2116a3a9: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3  | 2020-04-17 04:38:38,216 [Command processor thread] INFO impl.RaftServerProxy: 691d8703-820d-4600-8b2e-4f7b2116a3a9: addNew group-8DBE46B93727:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858] returns group-8DBE46B93727:java.util.concurrent.CompletableFuture@2a5d3e45[Not completed]
datanode_3  | 2020-04-17 04:38:38,289 [pool-69-thread-1] INFO impl.RaftServerImpl: 691d8703-820d-4600-8b2e-4f7b2116a3a9: new RaftServerImpl for group-8DBE46B93727:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-04-17 04:38:38,294 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-04-17 04:38:38,295 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-04-17 04:38:38,295 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-04-17 04:38:38,297 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-04-17 04:38:38,299 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-17 04:38:38,313 [pool-69-thread-1] INFO impl.RaftServerImpl: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727: ConfigurationManager, init=-1: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-04-17 04:38:38,319 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-17 04:38:38,339 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-04-17 04:38:38,343 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/31b6fc2a-f132-4fb3-beba-8dbe46b93727 does not exist. Creating ...
datanode_3  | 2020-04-17 04:38:38,360 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/31b6fc2a-f132-4fb3-beba-8dbe46b93727/in_use.lock acquired by nodename 6@bf065be64798
datanode_3  | 2020-04-17 04:38:38,370 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/31b6fc2a-f132-4fb3-beba-8dbe46b93727 has been successfully formatted.
datanode_3  | 2020-04-17 04:38:38,388 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-8DBE46B93727: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-04-17 04:38:38,389 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-04-17 04:38:38,400 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-04-17 04:38:38,424 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-04-17 04:38:38,426 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-17 04:38:38,441 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-17 04:38:38,451 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.691d8703-820d-4600-8b2e-4f7b2116a3a9
datanode_3  | 2020-04-17 04:38:38,520 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-04-17 04:38:43,343 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4-LeaderElection2] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
datanode_1  | 2020-04-17 04:38:43,343 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4-LeaderElection2] INFO impl.RoleInfo: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: shutdown LeaderElection
datanode_1  | 2020-04-17 04:38:43,343 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4-LeaderElection2] INFO impl.RoleInfo: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad: start FollowerState
datanode_1  | 2020-04-17 04:38:43,372 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D5E9801835C4 with new leaderId: fc51ec5f-ce44-4742-ab67-704c0b8112cf
datanode_1  | 2020-04-17 04:38:43,376 [grpc-default-executor-0] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4: change Leader from null to fc51ec5f-ce44-4742-ab67-704c0b8112cf at term 1 for appendEntries, leader elected after 5445ms
datanode_1  | 2020-04-17 04:38:43,415 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-94E709D62531-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/143e2e4e-7906-4522-90b9-94e709d62531/current/log_inprogress_0
datanode_1  | 2020-04-17 04:38:43,416 [grpc-default-executor-0] INFO impl.RaftServerImpl: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4: set configuration 0: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null at 0
datanode_1  | 2020-04-17 04:38:43,416 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-04-17 04:38:43,424 [e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ccbeff08-efe2-46c5-b724-d5e9801835c4/current/log_inprogress_0
datanode_1  | 2020-04-17 04:43:13,689 [Thread-292] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-A8B611D82B9F->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4, cid=99, seq=0, Watch-ALL_COMMITTED(129), Message:<EMPTY>, reply=RaftClientReply:client-A8B611D82B9F->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4, cid=99, FAILED org.apache.ratis.protocol.NotLeaderException: Server e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4 is not the leader fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858, logIndex=0, commits[e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127, 691d8703-820d-4600-8b2e-4f7b2116a3a9:c130, fc51ec5f-ce44-4742-ab67-704c0b8112cf:c130]
datanode_1  | 2020-04-17 04:52:22,684 [Thread-553] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-A8B611D82B9F->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4, cid=99, seq=0, Watch-ALL_COMMITTED(129), Message:<EMPTY>, reply=RaftClientReply:client-A8B611D82B9F->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4, cid=99, FAILED org.apache.ratis.protocol.NotLeaderException: Server e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4 is not the leader fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858, logIndex=0, commits[e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127, 691d8703-820d-4600-8b2e-4f7b2116a3a9:c141, fc51ec5f-ce44-4742-ab67-704c0b8112cf:c141]
datanode_1  | 2020-04-17 04:55:25,682 [Thread-638] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-A8B611D82B9F->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4, cid=99, seq=0, Watch-ALL_COMMITTED(129), Message:<EMPTY>, reply=RaftClientReply:client-A8B611D82B9F->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4, cid=99, FAILED org.apache.ratis.protocol.NotLeaderException: Server e02419d7-5832-4f5c-83d3-3bf12f7aa2ad@group-D5E9801835C4 is not the leader fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858, logIndex=0, commits[e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127, 691d8703-820d-4600-8b2e-4f7b2116a3a9:c145, fc51ec5f-ce44-4742-ab67-704c0b8112cf:c145]
datanode_2  | 2020-04-17 04:39:49,894 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=7,entriesCount=1,lastEntry=(t:1, i:4)
datanode_2  | 2020-04-17 04:39:52,491 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=9,entriesCount=1,lastEntry=(t:1, i:5)
datanode_2  | 2020-04-17 04:39:52,499 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=10,entriesCount=1,lastEntry=(t:1, i:6)
datanode_2  | 2020-04-17 04:39:52,505 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=11,entriesCount=1,lastEntry=(t:1, i:7)
datanode_2  | 2020-04-17 04:39:52,532 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=12,entriesCount=1,lastEntry=(t:1, i:8)
datanode_2  | 2020-04-17 04:39:55,093 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=14,entriesCount=1,lastEntry=(t:1, i:9)
datanode_2  | 2020-04-17 04:39:55,096 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=15,entriesCount=1,lastEntry=(t:1, i:10)
datanode_2  | 2020-04-17 04:39:55,105 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=16,entriesCount=1,lastEntry=(t:1, i:11)
datanode_2  | 2020-04-17 04:39:55,111 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=17,entriesCount=1,lastEntry=(t:1, i:12)
datanode_2  | 2020-04-17 04:39:57,654 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=19,entriesCount=1,lastEntry=(t:1, i:13)
datanode_2  | 2020-04-17 04:39:57,668 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=20,entriesCount=1,lastEntry=(t:1, i:14)
datanode_2  | 2020-04-17 04:39:57,676 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=21,entriesCount=1,lastEntry=(t:1, i:15)
datanode_2  | 2020-04-17 04:39:57,681 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=22,entriesCount=1,lastEntry=(t:1, i:16)
datanode_2  | 2020-04-17 04:40:00,218 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=24,entriesCount=1,lastEntry=(t:1, i:17)
datanode_2  | 2020-04-17 04:40:00,227 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=25,entriesCount=1,lastEntry=(t:1, i:18)
datanode_2  | 2020-04-17 04:40:00,236 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=26,entriesCount=1,lastEntry=(t:1, i:19)
datanode_2  | 2020-04-17 04:40:00,255 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=27,entriesCount=1,lastEntry=(t:1, i:20)
datanode_2  | 2020-04-17 04:40:02,814 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=29,entriesCount=1,lastEntry=(t:1, i:21)
datanode_2  | 2020-04-17 04:40:02,822 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=30,entriesCount=1,lastEntry=(t:1, i:22)
datanode_2  | 2020-04-17 04:40:02,836 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=31,entriesCount=1,lastEntry=(t:1, i:23)
datanode_2  | 2020-04-17 04:40:02,852 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=32,entriesCount=1,lastEntry=(t:1, i:24)
datanode_2  | 2020-04-17 04:40:05,384 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=34,entriesCount=1,lastEntry=(t:1, i:25)
datanode_2  | 2020-04-17 04:40:05,394 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=35,entriesCount=1,lastEntry=(t:1, i:26)
datanode_3  | 2020-04-17 04:38:38,523 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/31b6fc2a-f132-4fb3-beba-8dbe46b93727
datanode_3  | 2020-04-17 04:38:38,545 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-04-17 04:38:38,546 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-04-17 04:38:38,546 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-17 04:38:38,547 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-04-17 04:38:38,547 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-04-17 04:38:38,547 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-04-17 04:38:38,549 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-04-17 04:38:38,555 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-04-17 04:38:38,556 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-04-17 04:38:38,592 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-04-17 04:38:38,621 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-04-17 04:38:38,626 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-04-17 04:38:38,633 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-04-17 04:38:38,634 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-04-17 04:38:38,634 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-04-17 04:38:38,655 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727
datanode_3  | 2020-04-17 04:38:38,657 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727
datanode_3  | 2020-04-17 04:38:38,660 [pool-69-thread-1] INFO impl.RaftServerImpl: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727: start as a follower, conf=-1: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858], old=null
datanode_3  | 2020-04-17 04:38:38,665 [pool-69-thread-1] INFO impl.RaftServerImpl: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-04-17 04:38:38,673 [pool-69-thread-1] INFO impl.RoleInfo: 691d8703-820d-4600-8b2e-4f7b2116a3a9: start FollowerState
datanode_3  | 2020-04-17 04:38:38,687 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8DBE46B93727,id=691d8703-820d-4600-8b2e-4f7b2116a3a9
datanode_3  | 2020-04-17 04:38:38,688 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727
datanode_3  | 2020-04-17 04:38:38,721 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "31b6fc2a-f132-4fb3-beba-8dbe46b93727"
datanode_3  | .
datanode_3  | 2020-04-17 04:38:38,728 [Command processor thread] INFO impl.RaftServerProxy: 691d8703-820d-4600-8b2e-4f7b2116a3a9: addNew group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] returns group-D5E9801835C4:java.util.concurrent.CompletableFuture@319f82ba[Not completed]
datanode_3  | 2020-04-17 04:38:38,743 [pool-69-thread-1] INFO impl.RaftServerImpl: 691d8703-820d-4600-8b2e-4f7b2116a3a9: new RaftServerImpl for group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-04-17 04:38:38,743 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-04-17 04:38:38,743 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-04-17 04:38:38,743 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-04-17 04:38:38,744 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-04-17 04:38:38,744 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-17 04:38:38,744 [pool-69-thread-1] INFO impl.RaftServerImpl: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4: ConfigurationManager, init=-1: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-04-17 04:38:38,744 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-17 04:38:38,744 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-04-17 04:38:38,744 [pool-69-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ccbeff08-efe2-46c5-b724-d5e9801835c4 does not exist. Creating ...
datanode_3  | 2020-04-17 04:38:38,746 [pool-69-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ccbeff08-efe2-46c5-b724-d5e9801835c4/in_use.lock acquired by nodename 6@bf065be64798
datanode_3  | 2020-04-17 04:38:38,752 [pool-69-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ccbeff08-efe2-46c5-b724-d5e9801835c4 has been successfully formatted.
datanode_3  | 2020-04-17 04:38:38,752 [pool-69-thread-1] INFO ratis.ContainerStateMachine: group-D5E9801835C4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-04-17 04:38:38,753 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-04-17 04:38:38,753 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-04-17 04:38:38,753 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-04-17 04:38:38,753 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-17 04:38:38,753 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-17 04:38:38,753 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-04-17 04:38:38,753 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: new 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/ccbeff08-efe2-46c5-b724-d5e9801835c4
om_1        | 2020-04-17 04:38:38,365 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2676dc05{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-17388869253274475187.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1        | 2020-04-17 04:38:38,377 [main] INFO server.AbstractConnector: Started ServerConnector@696b4a95{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1        | 2020-04-17 04:38:38,377 [main] INFO server.Server: Started @4593ms
om_1        | 2020-04-17 04:38:38,384 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2020-04-17 04:38:38,384 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 2020-04-17 04:38:38,391 [main] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1        | 2020-04-17 04:38:47,682 [IPC Server handler 1 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-90199 for user:hadoop
om_1        | 2020-04-17 04:38:47,705 [IPC Server handler 0 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-98976 for user:hadoop
om_1        | 2020-04-17 04:38:47,710 [IPC Server handler 7 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-21723 for user:hadoop
om_1        | 2020-04-17 04:38:47,714 [IPC Server handler 6 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-25890 for user:hadoop
om_1        | 2020-04-17 04:38:47,723 [IPC Server handler 10 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-33045 for user:hadoop
om_1        | 2020-04-17 04:39:33,750 [qtp100048427-136] INFO om.OMDBCheckpointServlet: Received request to obtain OM DB checkpoint snapshot
om_1        | 2020-04-17 04:39:33,763 [qtp100048427-136] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1587098373751 in 12 milliseconds
om_1        | 2020-04-17 04:39:33,782 [qtp100048427-136] INFO om.OMDBCheckpointServlet: Time taken to write the checkpoint to response output stream: 17 milliseconds
om_1        | 2020-04-17 04:39:33,782 [qtp100048427-136] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1587098373751
om_1        | 2020-04-17 04:43:48,551 [IPC Server handler 11 on 9862] INFO volume.OMVolumeCreateRequest: created volume:81344-rpcwoport for user:hadoop
om_1        | 2020-04-17 04:46:47,134 [IPC Server handler 65 on 9862] INFO volume.OMVolumeCreateRequest: created volume:81344-rpcwoport2 for user:hadoop
om_1        | 2020-04-17 04:47:01,893 [IPC Server handler 32 on 9862] ERROR acl.OMBucketAddAclRequest: Add acl [user:superuser1:rwxy[ACCESS]] to path /81344-rpcwoport2/bb1 failed, because acl already exist
om_1        | 2020-04-17 04:50:11,815 [IPC Server handler 16 on 9862] INFO volume.OMVolumeCreateRequest: created volume:81344-rpcwport for user:hadoop
om_1        | 2020-04-17 04:53:11,695 [IPC Server handler 5 on 9862] INFO volume.OMVolumeCreateRequest: created volume:81344-rpcwoscheme for user:hadoop
datanode_3  | 2020-04-17 04:38:38,753 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-04-17 04:38:38,754 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-04-17 04:38:38,754 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-17 04:38:38,754 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-04-17 04:38:38,754 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-04-17 04:38:38,754 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-04-17 04:38:38,754 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-04-17 04:38:38,754 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-04-17 04:38:38,754 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-04-17 04:38:38,755 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-04-17 04:38:38,759 [pool-69-thread-1] INFO segmented.SegmentedRaftLogWorker: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-04-17 04:38:38,769 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-04-17 04:38:38,769 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-04-17 04:38:38,770 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-04-17 04:38:38,770 [pool-69-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-04-17 04:38:38,770 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4
datanode_3  | 2020-04-17 04:38:38,770 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4
datanode_3  | 2020-04-17 04:38:38,771 [pool-69-thread-1] INFO impl.RaftServerImpl: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4: start as a follower, conf=-1: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null
datanode_3  | 2020-04-17 04:38:38,771 [pool-69-thread-1] INFO impl.RaftServerImpl: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-04-17 04:38:38,771 [pool-69-thread-1] INFO impl.RoleInfo: 691d8703-820d-4600-8b2e-4f7b2116a3a9: start FollowerState
datanode_3  | 2020-04-17 04:38:38,785 [pool-69-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D5E9801835C4,id=691d8703-820d-4600-8b2e-4f7b2116a3a9
datanode_3  | 2020-04-17 04:38:38,785 [pool-69-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4
datanode_3  | 2020-04-17 04:38:39,585 [grpc-default-executor-0] WARN impl.RaftServerProxy: 691d8703-820d-4600-8b2e-4f7b2116a3a9: Failed groupAdd* GroupManagementRequest:client-9723EC74B214->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=0, seq=0, RW, null, Add:group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858]
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 691d8703-820d-4600-8b2e-4f7b2116a3a9: Failed to add group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] since the group already exists in the map.
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 691d8703-820d-4600-8b2e-4f7b2116a3a9: Failed to add group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] since the group already exists in the map.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3  | 	... 13 more
datanode_3  | 2020-04-17 04:38:39,601 [grpc-default-executor-1] WARN impl.RaftServerProxy: 691d8703-820d-4600-8b2e-4f7b2116a3a9: Failed groupAdd* GroupManagementRequest:client-E534CD6F83A8->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=1, seq=0, RW, null, Add:group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858]
datanode_3  | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 691d8703-820d-4600-8b2e-4f7b2116a3a9: Failed to add group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] since the group already exists in the map.
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
s3g_1       | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
s3g_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1       | 2020-04-17 04:38:16,241 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1       | 2020-04-17 04:38:16,339 [main] INFO util.log: Logging initialized @3769ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1       | 2020-04-17 04:38:16,921 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 2020-04-17 04:38:17,236 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1       | 2020-04-17 04:38:17,283 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1       | 2020-04-17 04:38:17,305 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g_1       | 2020-04-17 04:38:17,305 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1       | 2020-04-17 04:38:17,305 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1       | 2020-04-17 04:38:17,471 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1       | 2020-04-17 04:38:17,519 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1       | 2020-04-17 04:38:17,530 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
s3g_1       | 2020-04-17 04:38:17,623 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1       | 2020-04-17 04:38:17,636 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1       | 2020-04-17 04:38:17,637 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1       | 2020-04-17 04:38:17,696 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3af0a9da{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 2020-04-17 04:38:17,704 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@54eb2b70{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
s3g_1       | WARNING: An illegal reflective access operation has occurred
s3g_1       | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1       | WARNING: All illegal access operations will be denied in a future release
s3g_1       | Apr 17, 2020 4:38:29 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1       | 
s3g_1       | 2020-04-17 04:38:29,935 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5c48b72c{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-0_6_0-SNAPSHOT_jar-_-any-16690154472303270965.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1       | 2020-04-17 04:38:29,983 [main] INFO server.AbstractConnector: Started ServerConnector@1869fbd2{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
s3g_1       | 2020-04-17 04:38:29,983 [main] INFO server.Server: Started @17413ms
s3g_1       | 2020-04-17 04:38:30,007 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
datanode_2  | 2020-04-17 04:40:05,407 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=36,entriesCount=1,lastEntry=(t:1, i:27)
datanode_2  | 2020-04-17 04:40:05,421 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=37,entriesCount=1,lastEntry=(t:1, i:28)
datanode_2  | 2020-04-17 04:40:07,971 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=39,entriesCount=1,lastEntry=(t:1, i:29)
datanode_2  | 2020-04-17 04:40:07,980 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=40,entriesCount=1,lastEntry=(t:1, i:30)
datanode_2  | 2020-04-17 04:40:07,980 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=41,entriesCount=1,lastEntry=(t:1, i:31)
datanode_2  | 2020-04-17 04:40:07,995 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=42,entriesCount=1,lastEntry=(t:1, i:32)
datanode_2  | 2020-04-17 04:40:10,538 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=44,entriesCount=1,lastEntry=(t:1, i:33)
datanode_2  | 2020-04-17 04:40:10,538 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=45,entriesCount=1,lastEntry=(t:1, i:34)
datanode_2  | 2020-04-17 04:40:10,550 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=46,entriesCount=1,lastEntry=(t:1, i:35)
datanode_2  | 2020-04-17 04:40:10,559 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=47,entriesCount=1,lastEntry=(t:1, i:36)
datanode_2  | 2020-04-17 04:40:13,098 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=49,entriesCount=1,lastEntry=(t:1, i:37)
datanode_2  | 2020-04-17 04:40:13,110 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=50,entriesCount=1,lastEntry=(t:1, i:38)
datanode_2  | 2020-04-17 04:40:13,128 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=51,entriesCount=1,lastEntry=(t:1, i:39)
datanode_2  | 2020-04-17 04:40:13,132 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=52,entriesCount=1,lastEntry=(t:1, i:40)
datanode_2  | 2020-04-17 04:40:15,667 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=54,entriesCount=1,lastEntry=(t:1, i:41)
datanode_2  | 2020-04-17 04:40:15,678 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=55,entriesCount=1,lastEntry=(t:1, i:42)
datanode_2  | 2020-04-17 04:40:15,679 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=56,entriesCount=1,lastEntry=(t:1, i:43)
datanode_2  | 2020-04-17 04:40:15,687 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=57,entriesCount=1,lastEntry=(t:1, i:44)
datanode_2  | 2020-04-17 04:40:18,229 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=59,entriesCount=1,lastEntry=(t:1, i:45)
datanode_2  | 2020-04-17 04:40:18,230 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=60,entriesCount=1,lastEntry=(t:1, i:46)
datanode_2  | 2020-04-17 04:40:18,242 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=61,entriesCount=1,lastEntry=(t:1, i:47)
datanode_2  | 2020-04-17 04:40:18,257 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=62,entriesCount=1,lastEntry=(t:1, i:48)
datanode_2  | 2020-04-17 04:40:20,792 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=64,entriesCount=1,lastEntry=(t:1, i:49)
datanode_2  | 2020-04-17 04:40:20,801 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=65,entriesCount=1,lastEntry=(t:1, i:50)
datanode_2  | 2020-04-17 04:40:20,814 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=66,entriesCount=1,lastEntry=(t:1, i:51)
datanode_2  | 2020-04-17 04:40:20,822 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=67,entriesCount=1,lastEntry=(t:1, i:52)
datanode_2  | 2020-04-17 04:40:23,358 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=69,entriesCount=1,lastEntry=(t:1, i:53)
datanode_2  | 2020-04-17 04:40:23,370 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=70,entriesCount=1,lastEntry=(t:1, i:54)
datanode_2  | 2020-04-17 04:40:23,377 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=71,entriesCount=1,lastEntry=(t:1, i:55)
datanode_2  | 2020-04-17 04:40:23,380 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=72,entriesCount=1,lastEntry=(t:1, i:56)
datanode_2  | 2020-04-17 04:40:25,919 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=74,entriesCount=1,lastEntry=(t:1, i:57)
datanode_2  | 2020-04-17 04:40:25,925 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=75,entriesCount=1,lastEntry=(t:1, i:58)
datanode_2  | 2020-04-17 04:40:25,931 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=76,entriesCount=1,lastEntry=(t:1, i:59)
datanode_2  | 2020-04-17 04:40:25,940 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=77,entriesCount=1,lastEntry=(t:1, i:60)
datanode_2  | 2020-04-17 04:40:28,485 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=79,entriesCount=1,lastEntry=(t:1, i:61)
datanode_2  | 2020-04-17 04:40:28,488 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=80,entriesCount=1,lastEntry=(t:1, i:62)
datanode_2  | 2020-04-17 04:40:28,505 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=81,entriesCount=1,lastEntry=(t:1, i:63)
datanode_2  | 2020-04-17 04:40:28,505 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=82,entriesCount=1,lastEntry=(t:1, i:64)
datanode_2  | 2020-04-17 04:40:31,044 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=84,entriesCount=1,lastEntry=(t:1, i:65)
datanode_2  | 2020-04-17 04:40:31,049 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=85,entriesCount=1,lastEntry=(t:1, i:66)
datanode_2  | 2020-04-17 04:40:31,060 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=86,entriesCount=1,lastEntry=(t:1, i:67)
datanode_2  | 2020-04-17 04:40:33,612 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=88,entriesCount=1,lastEntry=(t:1, i:68)
datanode_2  | 2020-04-17 04:40:33,619 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=89,entriesCount=1,lastEntry=(t:1, i:69)
datanode_2  | 2020-04-17 04:40:33,625 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=90,entriesCount=1,lastEntry=(t:1, i:70)
datanode_2  | 2020-04-17 04:40:33,639 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=91,entriesCount=1,lastEntry=(t:1, i:71)
datanode_2  | 2020-04-17 04:40:36,171 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=93,entriesCount=1,lastEntry=(t:1, i:72)
datanode_2  | 2020-04-17 04:40:36,179 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=94,entriesCount=1,lastEntry=(t:1, i:73)
datanode_2  | 2020-04-17 04:40:36,193 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=95,entriesCount=1,lastEntry=(t:1, i:74)
datanode_2  | 2020-04-17 04:40:36,200 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=96,entriesCount=1,lastEntry=(t:1, i:75)
datanode_2  | 2020-04-17 04:40:38,734 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=98,entriesCount=1,lastEntry=(t:1, i:76)
datanode_2  | 2020-04-17 04:40:38,741 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=99,entriesCount=1,lastEntry=(t:1, i:77)
datanode_2  | 2020-04-17 04:40:38,746 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=100,entriesCount=1,lastEntry=(t:1, i:78)
datanode_2  | 2020-04-17 04:40:38,755 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=101,entriesCount=1,lastEntry=(t:1, i:79)
datanode_2  | 2020-04-17 04:40:41,289 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=103,entriesCount=1,lastEntry=(t:1, i:80)
datanode_2  | 2020-04-17 04:40:41,298 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=104,entriesCount=1,lastEntry=(t:1, i:81)
datanode_2  | 2020-04-17 04:40:41,301 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=105,entriesCount=1,lastEntry=(t:1, i:82)
datanode_2  | 2020-04-17 04:40:43,857 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=107,entriesCount=1,lastEntry=(t:1, i:83)
datanode_2  | 2020-04-17 04:40:43,864 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=108,entriesCount=1,lastEntry=(t:1, i:84)
datanode_2  | 2020-04-17 04:40:43,865 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=109,entriesCount=1,lastEntry=(t:1, i:85)
datanode_2  | 2020-04-17 04:40:43,878 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=110,entriesCount=1,lastEntry=(t:1, i:86)
datanode_2  | 2020-04-17 04:40:46,417 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=112,entriesCount=1,lastEntry=(t:1, i:87)
datanode_2  | 2020-04-17 04:40:46,424 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=113,entriesCount=1,lastEntry=(t:1, i:88)
datanode_2  | 2020-04-17 04:40:46,430 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=114,entriesCount=1,lastEntry=(t:1, i:89)
datanode_2  | 2020-04-17 04:40:46,438 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=115,entriesCount=1,lastEntry=(t:1, i:90)
datanode_2  | 2020-04-17 04:40:48,974 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=117,entriesCount=1,lastEntry=(t:1, i:91)
datanode_2  | 2020-04-17 04:40:48,982 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=118,entriesCount=1,lastEntry=(t:1, i:92)
datanode_2  | 2020-04-17 04:40:48,986 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=119,entriesCount=1,lastEntry=(t:1, i:93)
datanode_2  | 2020-04-17 04:40:48,996 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=120,entriesCount=1,lastEntry=(t:1, i:94)
datanode_2  | 2020-04-17 04:40:51,536 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=122,entriesCount=1,lastEntry=(t:1, i:95)
datanode_2  | 2020-04-17 04:40:51,541 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=123,entriesCount=1,lastEntry=(t:1, i:96)
datanode_2  | 2020-04-17 04:40:51,546 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=124,entriesCount=1,lastEntry=(t:1, i:97)
datanode_2  | 2020-04-17 04:40:51,558 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=125,entriesCount=1,lastEntry=(t:1, i:98)
datanode_2  | 2020-04-17 04:40:54,095 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=127,entriesCount=1,lastEntry=(t:1, i:99)
datanode_2  | 2020-04-17 04:40:54,100 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=128,entriesCount=1,lastEntry=(t:1, i:100)
datanode_2  | 2020-04-17 04:40:54,108 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=129,entriesCount=1,lastEntry=(t:1, i:101)
datanode_2  | 2020-04-17 04:40:54,120 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=130,entriesCount=1,lastEntry=(t:1, i:102)
datanode_2  | 2020-04-17 04:40:56,652 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=132,entriesCount=1,lastEntry=(t:1, i:103)
datanode_2  | 2020-04-17 04:40:56,657 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=133,entriesCount=1,lastEntry=(t:1, i:104)
datanode_2  | 2020-04-17 04:40:56,668 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=134,entriesCount=1,lastEntry=(t:1, i:105)
datanode_2  | 2020-04-17 04:40:56,674 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=135,entriesCount=1,lastEntry=(t:1, i:106)
datanode_2  | 2020-04-17 04:40:59,212 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=137,entriesCount=1,lastEntry=(t:1, i:107)
datanode_2  | 2020-04-17 04:40:59,212 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=138,entriesCount=1,lastEntry=(t:1, i:108)
datanode_2  | 2020-04-17 04:40:59,221 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=139,entriesCount=1,lastEntry=(t:1, i:109)
datanode_2  | 2020-04-17 04:40:59,232 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=140,entriesCount=1,lastEntry=(t:1, i:110)
datanode_2  | 2020-04-17 04:41:01,766 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=142,entriesCount=1,lastEntry=(t:1, i:111)
datanode_2  | 2020-04-17 04:41:01,769 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=143,entriesCount=1,lastEntry=(t:1, i:112)
datanode_2  | 2020-04-17 04:41:01,779 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=144,entriesCount=1,lastEntry=(t:1, i:113)
datanode_2  | 2020-04-17 04:41:01,790 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=145,entriesCount=1,lastEntry=(t:1, i:114)
datanode_2  | 2020-04-17 04:41:04,319 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=147,entriesCount=1,lastEntry=(t:1, i:115)
datanode_2  | 2020-04-17 04:41:04,321 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=148,entriesCount=1,lastEntry=(t:1, i:116)
datanode_2  | 2020-04-17 04:41:04,333 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=149,entriesCount=1,lastEntry=(t:1, i:117)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
datanode_3  | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
datanode_3  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 691d8703-820d-4600-8b2e-4f7b2116a3a9: Failed to add group-D5E9801835C4:[691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858] since the group already exists in the map.
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
datanode_3  | 	... 13 more
datanode_3  | 2020-04-17 04:38:39,944 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "ccbeff08-efe2-46c5-b724-d5e9801835c4"
datanode_3  | .
datanode_3  | 2020-04-17 04:38:43,089 [grpc-default-executor-0] INFO impl.RaftServerImpl: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:fc51ec5f-ce44-4742-ab67-704c0b8112cf
datanode_3  | 2020-04-17 04:38:43,096 [grpc-default-executor-0] INFO impl.RoleInfo: 691d8703-820d-4600-8b2e-4f7b2116a3a9: shutdown FollowerState
datanode_3  | 2020-04-17 04:38:43,096 [grpc-default-executor-0] INFO impl.RoleInfo: 691d8703-820d-4600-8b2e-4f7b2116a3a9: start FollowerState
datanode_3  | 2020-04-17 04:38:43,100 [Thread-27] INFO impl.FollowerState: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3  | 2020-04-17 04:38:43,316 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D5E9801835C4 with new leaderId: fc51ec5f-ce44-4742-ab67-704c0b8112cf
datanode_3  | 2020-04-17 04:38:43,316 [grpc-default-executor-0] INFO impl.RaftServerImpl: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4: change Leader from null to fc51ec5f-ce44-4742-ab67-704c0b8112cf at term 1 for appendEntries, leader elected after 4563ms
datanode_3  | 2020-04-17 04:38:43,369 [grpc-default-executor-0] INFO impl.RaftServerImpl: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4: set configuration 0: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:172.21.0.8:9858, fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858], old=null at 0
datanode_3  | 2020-04-17 04:38:43,376 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-04-17 04:38:43,475 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ccbeff08-efe2-46c5-b724-d5e9801835c4/current/log_inprogress_0
datanode_3  | 2020-04-17 04:38:43,863 [Thread-25] INFO impl.FollowerState: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-FollowerState: change to CANDIDATE, lastRpcTime:5190ms, electionTimeout:5180ms
datanode_3  | 2020-04-17 04:38:43,864 [Thread-25] INFO impl.RoleInfo: 691d8703-820d-4600-8b2e-4f7b2116a3a9: shutdown FollowerState
datanode_3  | 2020-04-17 04:38:43,864 [Thread-25] INFO impl.RaftServerImpl: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2020-04-17 04:38:43,866 [Thread-25] INFO impl.RoleInfo: 691d8703-820d-4600-8b2e-4f7b2116a3a9: start LeaderElection
datanode_3  | 2020-04-17 04:38:43,869 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO impl.LeaderElection: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1: begin an election at term 1 for -1: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858], old=null
datanode_3  | 2020-04-17 04:38:43,870 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO impl.RoleInfo: 691d8703-820d-4600-8b2e-4f7b2116a3a9: shutdown LeaderElection
datanode_3  | 2020-04-17 04:38:43,870 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO impl.RaftServerImpl: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-04-17 04:38:43,870 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8DBE46B93727 with new leaderId: 691d8703-820d-4600-8b2e-4f7b2116a3a9
datanode_3  | 2020-04-17 04:38:43,873 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO impl.RaftServerImpl: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727: change Leader from null to 691d8703-820d-4600-8b2e-4f7b2116a3a9 at term 1 for becomeLeader, leader elected after 5481ms
datanode_3  | 2020-04-17 04:38:43,874 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-04-17 04:38:43,876 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-04-17 04:38:43,878 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727
datanode_3  | 2020-04-17 04:38:43,885 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-04-17 04:38:43,885 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-04-17 04:38:43,889 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-04-17 04:41:04,351 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=150,entriesCount=1,lastEntry=(t:1, i:118)
datanode_2  | 2020-04-17 04:41:06,888 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=152,entriesCount=1,lastEntry=(t:1, i:119)
datanode_2  | 2020-04-17 04:41:06,893 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=153,entriesCount=1,lastEntry=(t:1, i:120)
datanode_2  | 2020-04-17 04:41:06,893 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=154,entriesCount=1,lastEntry=(t:1, i:121)
datanode_2  | 2020-04-17 04:41:06,930 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=155,entriesCount=1,lastEntry=(t:1, i:122)
datanode_2  | 2020-04-17 04:41:09,465 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=157,entriesCount=1,lastEntry=(t:1, i:123)
datanode_2  | 2020-04-17 04:41:09,469 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=158,entriesCount=1,lastEntry=(t:1, i:124)
datanode_2  | 2020-04-17 04:41:09,477 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=159,entriesCount=1,lastEntry=(t:1, i:125)
datanode_2  | 2020-04-17 04:41:09,478 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=160,entriesCount=1,lastEntry=(t:1, i:126)
datanode_2  | 2020-04-17 04:41:12,016 [java.util.concurrent.ThreadPoolExecutor$Worker@31e501d7[State = -1, empty queue]] WARN server.GrpcLogAppender: fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4->e02419d7-5832-4f5c-83d3-3bf12f7aa2ad-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=162,entriesCount=1,lastEntry=(t:1, i:127)
datanode_2  | 2020-04-17 04:43:12,664 [Thread-159] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-A8B611D82B9F->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=99, seq=0, Watch-ALL_COMMITTED(129), Message:<EMPTY>, reply=RaftClientReply:client-A8B611D82B9F->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=99, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 99 and log index 129 is not yet replicated to ALL_COMMITTED, logIndex=129, commits[fc51ec5f-ce44-4742-ab67-704c0b8112cf:c130, 691d8703-820d-4600-8b2e-4f7b2116a3a9:c130, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127]
datanode_2  | 2020-04-17 04:46:15,663 [Thread-178] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-A8B611D82B9F->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=99, seq=0, Watch-ALL_COMMITTED(129), Message:<EMPTY>, reply=RaftClientReply:client-A8B611D82B9F->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=99, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 99 and log index 129 is not yet replicated to ALL_COMMITTED, logIndex=129, commits[fc51ec5f-ce44-4742-ab67-704c0b8112cf:c133, 691d8703-820d-4600-8b2e-4f7b2116a3a9:c133, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127]
datanode_2  | 2020-04-17 04:47:02,663 [Thread-184] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-5EB8D2CDDE33->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=3, seq=0, Watch-ALL_COMMITTED(132), Message:<EMPTY>, reply=RaftClientReply:client-5EB8D2CDDE33->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=3, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 3 and log index 132 is not yet replicated to ALL_COMMITTED, logIndex=132, commits[fc51ec5f-ce44-4742-ab67-704c0b8112cf:c133, 691d8703-820d-4600-8b2e-4f7b2116a3a9:c133, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127]
datanode_2  | 2020-04-17 04:49:18,663 [Thread-196] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-A8B611D82B9F->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=99, seq=0, Watch-ALL_COMMITTED(129), Message:<EMPTY>, reply=RaftClientReply:client-A8B611D82B9F->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=99, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 99 and log index 129 is not yet replicated to ALL_COMMITTED, logIndex=129, commits[fc51ec5f-ce44-4742-ab67-704c0b8112cf:c137, 691d8703-820d-4600-8b2e-4f7b2116a3a9:c137, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127]
datanode_2  | 2020-04-17 04:50:05,663 [Thread-201] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-5EB8D2CDDE33->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=3, seq=0, Watch-ALL_COMMITTED(132), Message:<EMPTY>, reply=RaftClientReply:client-5EB8D2CDDE33->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=3, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 3 and log index 132 is not yet replicated to ALL_COMMITTED, logIndex=132, commits[fc51ec5f-ce44-4742-ab67-704c0b8112cf:c137, 691d8703-820d-4600-8b2e-4f7b2116a3a9:c137, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127]
datanode_2  | 2020-04-17 04:50:11,663 [Thread-202] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-6DA4ADF58690->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=3, seq=0, Watch-ALL_COMMITTED(135), Message:<EMPTY>, reply=RaftClientReply:client-6DA4ADF58690->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=3, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 3 and log index 135 is not yet replicated to ALL_COMMITTED, logIndex=135, commits[fc51ec5f-ce44-4742-ab67-704c0b8112cf:c137, 691d8703-820d-4600-8b2e-4f7b2116a3a9:c137, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127]
datanode_2  | 2020-04-17 04:52:21,663 [Thread-216] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-A8B611D82B9F->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=99, seq=0, Watch-ALL_COMMITTED(129), Message:<EMPTY>, reply=RaftClientReply:client-A8B611D82B9F->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=99, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 99 and log index 129 is not yet replicated to ALL_COMMITTED, logIndex=129, commits[fc51ec5f-ce44-4742-ab67-704c0b8112cf:c141, 691d8703-820d-4600-8b2e-4f7b2116a3a9:c141, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127]
datanode_3  | 2020-04-17 04:38:43,889 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-04-17 04:38:43,889 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-04-17 04:38:43,898 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO impl.RoleInfo: 691d8703-820d-4600-8b2e-4f7b2116a3a9: start LeaderState
datanode_3  | 2020-04-17 04:38:43,906 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-04-17 04:38:43,913 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/31b6fc2a-f132-4fb3-beba-8dbe46b93727/current/log_inprogress_0
datanode_3  | 2020-04-17 04:38:43,922 [691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727-LeaderElection1] INFO impl.RaftServerImpl: 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-8DBE46B93727: set configuration 0: [691d8703-820d-4600-8b2e-4f7b2116a3a9:172.21.0.4:9858], old=null at 0
datanode_3  | 2020-04-17 04:39:29,249 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: recon/172.21.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=60000 MILLISECONDS)
datanode_3  | 2020-04-17 04:46:16,695 [Thread-381] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-A8B611D82B9F->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=99, seq=0, Watch-ALL_COMMITTED(129), Message:<EMPTY>, reply=RaftClientReply:client-A8B611D82B9F->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=99, FAILED org.apache.ratis.protocol.NotLeaderException: Server 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4 is not the leader fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858, logIndex=0, commits[691d8703-820d-4600-8b2e-4f7b2116a3a9:c133, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127, fc51ec5f-ce44-4742-ab67-704c0b8112cf:c133]
datanode_3  | 2020-04-17 04:47:03,700 [Thread-406] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-5EB8D2CDDE33->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=3, seq=0, Watch-ALL_COMMITTED(132), Message:<EMPTY>, reply=RaftClientReply:client-5EB8D2CDDE33->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=3, FAILED org.apache.ratis.protocol.NotLeaderException: Server 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4 is not the leader fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858, logIndex=0, commits[691d8703-820d-4600-8b2e-4f7b2116a3a9:c133, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127, fc51ec5f-ce44-4742-ab67-704c0b8112cf:c133]
datanode_3  | 2020-04-17 04:49:19,678 [Thread-473] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-A8B611D82B9F->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=99, seq=0, Watch-ALL_COMMITTED(129), Message:<EMPTY>, reply=RaftClientReply:client-A8B611D82B9F->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=99, FAILED org.apache.ratis.protocol.NotLeaderException: Server 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4 is not the leader fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858, logIndex=0, commits[691d8703-820d-4600-8b2e-4f7b2116a3a9:c137, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127, fc51ec5f-ce44-4742-ab67-704c0b8112cf:c137]
datanode_3  | 2020-04-17 04:50:06,697 [Thread-497] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-5EB8D2CDDE33->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=3, seq=0, Watch-ALL_COMMITTED(132), Message:<EMPTY>, reply=RaftClientReply:client-5EB8D2CDDE33->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=3, FAILED org.apache.ratis.protocol.NotLeaderException: Server 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4 is not the leader fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858, logIndex=0, commits[691d8703-820d-4600-8b2e-4f7b2116a3a9:c137, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127, fc51ec5f-ce44-4742-ab67-704c0b8112cf:c137]
datanode_3  | 2020-04-17 04:50:12,686 [Thread-500] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-6DA4ADF58690->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=3, seq=0, Watch-ALL_COMMITTED(135), Message:<EMPTY>, reply=RaftClientReply:client-6DA4ADF58690->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=3, FAILED org.apache.ratis.protocol.NotLeaderException: Server 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4 is not the leader fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858, logIndex=0, commits[691d8703-820d-4600-8b2e-4f7b2116a3a9:c137, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127, fc51ec5f-ce44-4742-ab67-704c0b8112cf:c137]
datanode_3  | 2020-04-17 04:53:09,705 [Thread-587] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-5EB8D2CDDE33->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=3, seq=0, Watch-ALL_COMMITTED(132), Message:<EMPTY>, reply=RaftClientReply:client-5EB8D2CDDE33->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=3, FAILED org.apache.ratis.protocol.NotLeaderException: Server 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4 is not the leader fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858, logIndex=0, commits[691d8703-820d-4600-8b2e-4f7b2116a3a9:c141, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127, fc51ec5f-ce44-4742-ab67-704c0b8112cf:c141]
datanode_3  | 2020-04-17 04:53:15,713 [Thread-591] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-6DA4ADF58690->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=3, seq=0, Watch-ALL_COMMITTED(135), Message:<EMPTY>, reply=RaftClientReply:client-6DA4ADF58690->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=3, FAILED org.apache.ratis.protocol.NotLeaderException: Server 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4 is not the leader fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858, logIndex=0, commits[691d8703-820d-4600-8b2e-4f7b2116a3a9:c141, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127, fc51ec5f-ce44-4742-ab67-704c0b8112cf:c141]
datanode_3  | 2020-04-17 04:53:26,691 [Thread-601] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-B2CB51CD1688->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=3, seq=0, Watch-ALL_COMMITTED(140), Message:<EMPTY>, reply=RaftClientReply:client-B2CB51CD1688->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=3, FAILED org.apache.ratis.protocol.NotLeaderException: Server 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4 is not the leader fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858, logIndex=0, commits[691d8703-820d-4600-8b2e-4f7b2116a3a9:c144, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127, fc51ec5f-ce44-4742-ab67-704c0b8112cf:c144]
datanode_3  | 2020-04-17 04:56:12,695 [Thread-679] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-5EB8D2CDDE33->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=3, seq=0, Watch-ALL_COMMITTED(132), Message:<EMPTY>, reply=RaftClientReply:client-5EB8D2CDDE33->691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4, cid=3, FAILED org.apache.ratis.protocol.NotLeaderException: Server 691d8703-820d-4600-8b2e-4f7b2116a3a9@group-D5E9801835C4 is not the leader fc51ec5f-ce44-4742-ab67-704c0b8112cf:172.21.0.7:9858, logIndex=0, commits[691d8703-820d-4600-8b2e-4f7b2116a3a9:c145, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127, fc51ec5f-ce44-4742-ab67-704c0b8112cf:c145]
recon_1     | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
recon_1     | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1     | WARNING: An illegal reflective access operation has occurred
recon_1     | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
recon_1     | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | WARNING: All illegal access operations will be denied in a future release
recon_1     | 2020-04-17 04:38:20,079 [main] INFO recon.ReconRestServletModule: rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1     | 2020-04-17 04:38:21,502 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1     | 2020-04-17 04:38:24,671 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1     | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
recon_1     | 2020-04-17 04:38:27,387 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1     | 2020-04-17 04:38:27,436 [main] INFO util.log: Logging initialized @12672ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1     | 2020-04-17 04:38:27,807 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1     | 2020-04-17 04:38:27,837 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1     | 2020-04-17 04:38:27,921 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1     | 2020-04-17 04:38:27,949 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context recon
recon_1     | 2020-04-17 04:38:27,955 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
recon_1     | 2020-04-17 04:38:27,956 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
recon_1     | 2020-04-17 04:38:28,462 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1     | 2020-04-17 04:38:29,596 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1     | 2020-04-17 04:38:30,995 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-17 04:38:30,996 [main] INFO Configuration.deprecation: No unit for recon.om.connection.request.timeout(5000) assuming MILLISECONDS
recon_1     | 2020-04-17 04:38:31,246 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-17 04:38:31,256 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@1dcedc93
recon_1     | 2020-04-17 04:38:31,257 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1     | 2020-04-17 04:38:31,325 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1     | 2020-04-17 04:38:31,340 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-17 04:38:31,372 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1     | 2020-04-17 04:38:31,420 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1     | 2020-04-17 04:38:31,431 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1     | 2020-04-17 04:38:31,485 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-17 04:38:31,492 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
recon_1     | 2020-04-17 04:38:31,494 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-17 04:38:31,537 [main] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1     | 2020-04-17 04:38:31,546 [main] INFO scm.ReconScmTask: Registered MissingContainerTask task 
recon_1     | 2020-04-17 04:38:31,546 [main] INFO recon.ReconServer: Recon server initialized successfully!
recon_1     | 2020-04-17 04:38:31,546 [main] INFO recon.ReconServer: Starting Recon server
recon_1     | 2020-04-17 04:38:31,603 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1     | 2020-04-17 04:38:31,658 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1     | 2020-04-17 04:38:31,658 [main] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1     | 2020-04-17 04:38:31,847 [main] INFO http.HttpServer2: Jetty bound to port 9888
recon_1     | 2020-04-17 04:38:31,847 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
recon_1     | 2020-04-17 04:38:31,885 [main] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1     | 2020-04-17 04:38:31,885 [main] INFO server.session: No SessionScavenger set, using defaults
recon_1     | 2020-04-17 04:38:31,886 [main] INFO server.session: node0 Scavenging every 600000ms
recon_1     | 2020-04-17 04:38:31,899 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@10fbbdb{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1     | 2020-04-17 04:38:31,904 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@204e90f7{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1     | 2020-04-17 04:38:33,568 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@121cf6f4{recon,/,file:///tmp/jetty-0_0_0_0-9888-hadoop-ozone-recon-0_6_0-SNAPSHOT_jar-_-any-1915063518552584699.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar!/webapps/recon}
recon_1     | 2020-04-17 04:38:33,596 [main] INFO server.AbstractConnector: Started ServerConnector@671facee{HTTP/1.1,[http/1.1]}{0.0.0.0:9888}
recon_1     | 2020-04-17 04:38:33,597 [main] INFO server.Server: Started @18833ms
recon_1     | 2020-04-17 04:38:33,602 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1     | 2020-04-17 04:38:33,602 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1     | 2020-04-17 04:38:33,607 [main] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1     | 2020-04-17 04:38:33,608 [main] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
scm_1       | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-04-17 04:38:16,686 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = 12c7e3339925/172.21.0.5
scm_1       | STARTUP_MSG:   args = [--init]
scm_1       | STARTUP_MSG:   version = 3.2.0
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-04-17 04:38:16,730 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-04-17 04:38:17,053 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-17 04:38:17,273 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-2e963381-9138-401f-8b68-ec8bcbe4bb3e
scm_1       | 2020-04-17 04:38:17,431 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at 12c7e3339925/172.21.0.5
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-04-17 04:38:27,954 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = 12c7e3339925/172.21.0.5
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 3.2.0
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.47.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-7c5b30d-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-04-17 04:38:28,005 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-04-17 04:38:28,538 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-17 04:38:28,609 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-17 04:38:29,682 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@3336e6b6
scm_1       | 2020-04-17 04:38:29,690 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1       | 2020-04-17 04:38:30,072 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1       | 2020-04-17 04:38:30,374 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       | 2020-04-17 04:38:30,384 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-17 04:38:30,454 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1       | 2020-04-17 04:38:30,457 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-17 04:38:30,654 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2020-04-17 04:38:30,657 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1       | 2020-04-17 04:38:30,762 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1       | 2020-04-17 04:38:31,479 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-04-17 04:38:31,515 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2020-04-17 04:38:31,567 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-04-17 04:38:31,567 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1       | 2020-04-17 04:38:31,577 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-04-17 04:38:31,584 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1       | 2020-04-17 04:38:31,606 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1       | 2020-04-17 04:38:31,633 [main] INFO util.log: Logging initialized @13144ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       | 2020-04-17 04:38:31,879 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2020-04-17 04:38:31,900 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1       | 2020-04-17 04:38:31,915 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       | 2020-04-17 04:38:31,918 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1       | 2020-04-17 04:38:31,919 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
scm_1       | 2020-04-17 04:38:31,919 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1       | 2020-04-17 04:38:31,968 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1       | 2020-04-17 04:38:32,048 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | 2020-04-17 04:38:32,123 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1       | 2020-04-17 04:38:32,123 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1       | 2020-04-17 04:38:32,410 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1       | 2020-04-17 04:38:32,414 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-04-17 04:38:32,466 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1       | 2020-04-17 04:38:32,824 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1       | 2020-04-17 04:38:32,842 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1       | 2020-04-17 04:38:32,863 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-04-17 04:38:32,863 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1       | 2020-04-17 04:38:33,084 [main] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1       | 2020-04-17 04:38:33,084 [main] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1       | 2020-04-17 04:38:33,094 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-04-17 04:38:33,104 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1       | 2020-04-17 04:38:33,287 [main] INFO http.HttpServer2: Jetty bound to port 9876
recon_1     | 2020-04-17 04:38:33,639 [main] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1     | 2020-04-17 04:38:33,665 [main] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1     | 2020-04-17 04:38:33,665 [main] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1     | 2020-04-17 04:38:33,666 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-17 04:38:33,666 [main] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1     | 2020-04-17 04:38:33,685 [main] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1     | 2020-04-17 04:38:33,927 [main] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1     | 2020-04-17 04:38:33,929 [main] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2020-04-17 04:38:33,930 [main] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1     | 2020-04-17 04:38:33,951 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1     | 2020-04-17 04:38:33,932 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1     | 2020-04-17 04:38:34,145 [main] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1     | 2020-04-17 04:38:34,152 [main] INFO scm.ReconScmTask: Starting MissingContainerTask Thread.
recon_1     | 2020-04-17 04:38:34,209 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2020-04-17 04:38:34,220 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 65 milliseconds.
recon_1     | 2020-04-17 04:38:34,236 [MissingContainerTask] INFO fsck.MissingContainerTask: Missing Container task Thread took 37 milliseconds for processing 0 containers.
recon_1     | 2020-04-17 04:38:34,428 [IPC Server handler 1 on 9891] WARN ipc.Server: IPC Server handler 1 on 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.21.0.7:56754: output error
recon_1     | 2020-04-17 04:38:34,433 [IPC Server handler 1 on 9891] INFO ipc.Server: IPC Server handler 1 on 9891 caught an exception
recon_1     | java.nio.channels.AsynchronousCloseException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1     | 2020-04-17 04:38:34,434 [IPC Server handler 0 on 9891] WARN ipc.Server: IPC Server handler 0 on 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.21.0.8:33104: output error
recon_1     | 2020-04-17 04:38:34,434 [IPC Server handler 0 on 9891] INFO ipc.Server: IPC Server handler 0 on 9891 caught an exception
recon_1     | java.nio.channels.AsynchronousCloseException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1     | 2020-04-17 04:38:36,315 [IPC Server handler 2 on 9891] INFO net.NetworkTopology: Added a new node: /default-rack/fc51ec5f-ce44-4742-ab67-704c0b8112cf
recon_1     | 2020-04-17 04:38:36,315 [IPC Server handler 2 on 9891] INFO node.SCMNodeManager: Registered Data node : fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-17 04:38:36,349 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node fc51ec5f-ce44-4742-ab67-704c0b8112cf to Node DB.
recon_1     | 2020-04-17 04:38:36,393 [IPC Server handler 3 on 9891] INFO net.NetworkTopology: Added a new node: /default-rack/e02419d7-5832-4f5c-83d3-3bf12f7aa2ad
recon_1     | 2020-04-17 04:38:36,393 [IPC Server handler 3 on 9891] INFO node.SCMNodeManager: Registered Data node : e02419d7-5832-4f5c-83d3-3bf12f7aa2ad{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-17 04:38:36,394 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node e02419d7-5832-4f5c-83d3-3bf12f7aa2ad to Node DB.
recon_1     | 2020-04-17 04:38:37,740 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=143e2e4e-7906-4522-90b9-94e709d62531. Trying to get from SCM.
recon_1     | 2020-04-17 04:38:37,750 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 143e2e4e-7906-4522-90b9-94e709d62531, Nodes: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:e02419d7-5832-4f5c-83d3-3bf12f7aa2ad, CreationTimestamp2020-04-17T04:38:34.447Z] to Recon pipeline metadata.
recon_1     | 2020-04-17 04:38:37,758 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 143e2e4e-7906-4522-90b9-94e709d62531, Nodes: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:e02419d7-5832-4f5c-83d3-3bf12f7aa2ad, CreationTimestamp2020-04-17T04:38:34.447Z]
recon_1     | 2020-04-17 04:38:37,769 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=e279ebb1-cd90-4587-ade9-4611eeaf8837. Trying to get from SCM.
datanode_2  | 2020-04-17 04:53:08,663 [Thread-219] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-5EB8D2CDDE33->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=3, seq=0, Watch-ALL_COMMITTED(132), Message:<EMPTY>, reply=RaftClientReply:client-5EB8D2CDDE33->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=3, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 3 and log index 132 is not yet replicated to ALL_COMMITTED, logIndex=132, commits[fc51ec5f-ce44-4742-ab67-704c0b8112cf:c141, 691d8703-820d-4600-8b2e-4f7b2116a3a9:c141, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127]
datanode_2  | 2020-04-17 04:53:14,663 [Thread-220] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-6DA4ADF58690->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=3, seq=0, Watch-ALL_COMMITTED(135), Message:<EMPTY>, reply=RaftClientReply:client-6DA4ADF58690->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=3, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 3 and log index 135 is not yet replicated to ALL_COMMITTED, logIndex=135, commits[fc51ec5f-ce44-4742-ab67-704c0b8112cf:c141, 691d8703-820d-4600-8b2e-4f7b2116a3a9:c141, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127]
datanode_2  | 2020-04-17 04:53:25,663 [Thread-226] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-B2CB51CD1688->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=3, seq=0, Watch-ALL_COMMITTED(140), Message:<EMPTY>, reply=RaftClientReply:client-B2CB51CD1688->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=3, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 3 and log index 140 is not yet replicated to ALL_COMMITTED, logIndex=140, commits[fc51ec5f-ce44-4742-ab67-704c0b8112cf:c145, 691d8703-820d-4600-8b2e-4f7b2116a3a9:c144, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127]
datanode_2  | 2020-04-17 04:55:24,663 [Thread-235] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-A8B611D82B9F->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=99, seq=0, Watch-ALL_COMMITTED(129), Message:<EMPTY>, reply=RaftClientReply:client-A8B611D82B9F->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=99, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 99 and log index 129 is not yet replicated to ALL_COMMITTED, logIndex=129, commits[fc51ec5f-ce44-4742-ab67-704c0b8112cf:c145, 691d8703-820d-4600-8b2e-4f7b2116a3a9:c145, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127]
datanode_2  | 2020-04-17 04:56:11,664 [Thread-238] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-5EB8D2CDDE33->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=3, seq=0, Watch-ALL_COMMITTED(132), Message:<EMPTY>, reply=RaftClientReply:client-5EB8D2CDDE33->fc51ec5f-ce44-4742-ab67-704c0b8112cf@group-D5E9801835C4, cid=3, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 3 and log index 132 is not yet replicated to ALL_COMMITTED, logIndex=132, commits[fc51ec5f-ce44-4742-ab67-704c0b8112cf:c145, 691d8703-820d-4600-8b2e-4f7b2116a3a9:c145, e02419d7-5832-4f5c-83d3-3bf12f7aa2ad:c127]
scm_1       | 2020-04-17 04:38:33,288 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1       | 2020-04-17 04:38:33,310 [IPC Server handler 2 on 9861] INFO ipc.Server: IPC Server handler 2 on 9861: skipped Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.21.0.4:36860
scm_1       | 2020-04-17 04:38:33,462 [main] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1       | 2020-04-17 04:38:33,462 [main] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2020-04-17 04:38:33,472 [main] INFO server.session: node0 Scavenging every 660000ms
scm_1       | 2020-04-17 04:38:33,513 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@486bc9a4{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1       | 2020-04-17 04:38:33,515 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1237e0be{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | 2020-04-17 04:38:34,282 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4d21c56e{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-9659631458656427833.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
scm_1       | 2020-04-17 04:38:34,295 [main] INFO server.AbstractConnector: Started ServerConnector@4992613f{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1       | 2020-04-17 04:38:34,295 [main] INFO server.Server: Started @15811ms
scm_1       | 2020-04-17 04:38:34,308 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | 2020-04-17 04:38:34,315 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1       | 2020-04-17 04:38:34,319 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1       | 2020-04-17 04:38:34,355 [IPC Server handler 0 on 9861] INFO net.NetworkTopology: Added a new node: /default-rack/fc51ec5f-ce44-4742-ab67-704c0b8112cf
scm_1       | 2020-04-17 04:38:34,364 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@43af351a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2020-04-17 04:38:34,355 [IPC Server handler 0 on 9861] INFO node.SCMNodeManager: Registered Data node : fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-04-17 04:38:34,370 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1       | 2020-04-17 04:38:34,370 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-04-17 04:38:34,412 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e279ebb1-cd90-4587-ade9-4611eeaf8837 to datanode:fc51ec5f-ce44-4742-ab67-704c0b8112cf
scm_1       | 2020-04-17 04:38:34,422 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e279ebb1-cd90-4587-ade9-4611eeaf8837, Nodes: fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-17T04:38:34.411417Z]
scm_1       | 2020-04-17 04:38:34,441 [IPC Server handler 1 on 9861] INFO net.NetworkTopology: Added a new node: /default-rack/e02419d7-5832-4f5c-83d3-3bf12f7aa2ad
scm_1       | 2020-04-17 04:38:34,443 [IPC Server handler 1 on 9861] INFO node.SCMNodeManager: Registered Data node : e02419d7-5832-4f5c-83d3-3bf12f7aa2ad{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-04-17 04:38:34,444 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1       | 2020-04-17 04:38:34,447 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=143e2e4e-7906-4522-90b9-94e709d62531 to datanode:e02419d7-5832-4f5c-83d3-3bf12f7aa2ad
scm_1       | 2020-04-17 04:38:34,448 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 143e2e4e-7906-4522-90b9-94e709d62531, Nodes: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-17T04:38:34.447657Z]
scm_1       | 2020-04-17 04:38:34,448 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-04-17 04:38:34,448 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
scm_1       | 2020-04-17 04:38:35,213 [IPC Server handler 45 on 9861] INFO net.NetworkTopology: Added a new node: /default-rack/691d8703-820d-4600-8b2e-4f7b2116a3a9
scm_1       | 2020-04-17 04:38:35,213 [IPC Server handler 45 on 9861] INFO node.SCMNodeManager: Registered Data node : 691d8703-820d-4600-8b2e-4f7b2116a3a9{ip: 172.21.0.4, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-04-17 04:38:35,213 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-04-17 04:38:35,214 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1       | 2020-04-17 04:38:35,215 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2020-04-17 04:38:35,216 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1       | 2020-04-17 04:38:35,216 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=31b6fc2a-f132-4fb3-beba-8dbe46b93727 to datanode:691d8703-820d-4600-8b2e-4f7b2116a3a9
scm_1       | 2020-04-17 04:38:35,217 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 31b6fc2a-f132-4fb3-beba-8dbe46b93727, Nodes: 691d8703-820d-4600-8b2e-4f7b2116a3a9{ip: 172.21.0.4, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-17T04:38:35.216745Z]
scm_1       | 2020-04-17 04:38:35,223 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-17 04:38:35,230 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ccbeff08-efe2-46c5-b724-d5e9801835c4 to datanode:fc51ec5f-ce44-4742-ab67-704c0b8112cf
scm_1       | 2020-04-17 04:38:35,232 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ccbeff08-efe2-46c5-b724-d5e9801835c4 to datanode:691d8703-820d-4600-8b2e-4f7b2116a3a9
scm_1       | 2020-04-17 04:38:35,232 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ccbeff08-efe2-46c5-b724-d5e9801835c4 to datanode:e02419d7-5832-4f5c-83d3-3bf12f7aa2ad
recon_1     | 2020-04-17 04:38:37,775 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: e279ebb1-cd90-4587-ade9-4611eeaf8837, Nodes: fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-17T04:38:34.411Z] to Recon pipeline metadata.
recon_1     | 2020-04-17 04:38:37,775 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e279ebb1-cd90-4587-ade9-4611eeaf8837, Nodes: fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-17T04:38:34.411Z]
recon_1     | 2020-04-17 04:38:37,775 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline ONE PipelineID=e279ebb1-cd90-4587-ade9-4611eeaf8837 reported by fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-17 04:38:37,775 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: e279ebb1-cd90-4587-ade9-4611eeaf8837, Nodes: fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:fc51ec5f-ce44-4742-ab67-704c0b8112cf, CreationTimestamp2020-04-17T04:38:34.411Z] moved to OPEN state
recon_1     | 2020-04-17 04:38:37,895 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=ccbeff08-efe2-46c5-b724-d5e9801835c4. Trying to get from SCM.
recon_1     | 2020-04-17 04:38:37,898 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: ccbeff08-efe2-46c5-b724-d5e9801835c4, Nodes: fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}691d8703-820d-4600-8b2e-4f7b2116a3a9{ip: 172.21.0.4, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}e02419d7-5832-4f5c-83d3-3bf12f7aa2ad{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-17T04:38:35.230Z] to Recon pipeline metadata.
recon_1     | 2020-04-17 04:38:37,899 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: ccbeff08-efe2-46c5-b724-d5e9801835c4, Nodes: fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}691d8703-820d-4600-8b2e-4f7b2116a3a9{ip: 172.21.0.4, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}e02419d7-5832-4f5c-83d3-3bf12f7aa2ad{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-17T04:38:35.230Z]
recon_1     | 2020-04-17 04:38:37,899 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=ccbeff08-efe2-46c5-b724-d5e9801835c4 reported by fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-17 04:38:37,929 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=ccbeff08-efe2-46c5-b724-d5e9801835c4 reported by e02419d7-5832-4f5c-83d3-3bf12f7aa2ad{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-17 04:38:42,929 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=ccbeff08-efe2-46c5-b724-d5e9801835c4 reported by fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-17 04:38:43,006 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=ccbeff08-efe2-46c5-b724-d5e9801835c4 reported by e02419d7-5832-4f5c-83d3-3bf12f7aa2ad{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-17 04:38:43,228 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=ccbeff08-efe2-46c5-b724-d5e9801835c4 reported by fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-17 04:38:49,535 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ozone_datanode_2.ozone_default.
recon_1     | 2020-04-17 04:38:49,584 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1     | 2020-04-17 04:39:33,680 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:39:33,681 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1     | 2020-04-17 04:39:33,838 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1587098373681
recon_1     | 2020-04-17 04:39:33,867 [pool-8-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1587098373681.
recon_1     | 2020-04-17 04:39:33,881 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
recon_1     | 2020-04-17 04:39:33,887 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1     | 2020-04-17 04:39:33,928 [pool-9-thread-1] INFO impl.ContainerDBServiceProviderImpl: Creating new Recon Container DB at /data/metadata/recon/recon-container-key.db_1587098373887
recon_1     | 2020-04-17 04:39:33,928 [pool-9-thread-1] INFO impl.ContainerDBServiceProviderImpl: Cleaning up old Recon Container DB at /data/metadata/recon/recon-container-key.db_1587098302303.
recon_1     | 2020-04-17 04:39:33,959 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
recon_1     | 2020-04-17 04:39:33,959 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.072 seconds to process 17 keys.
recon_1     | 2020-04-17 04:39:34,099 [pool-9-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
recon_1     | 2020-04-17 04:39:49,828 [IPC Server handler 7 on 9891] INFO net.NetworkTopology: Added a new node: /default-rack/691d8703-820d-4600-8b2e-4f7b2116a3a9
recon_1     | 2020-04-17 04:39:49,828 [IPC Server handler 7 on 9891] INFO node.SCMNodeManager: Registered Data node : 691d8703-820d-4600-8b2e-4f7b2116a3a9{ip: 172.21.0.4, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-17 04:39:49,828 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=ccbeff08-efe2-46c5-b724-d5e9801835c4 reported by 691d8703-820d-4600-8b2e-4f7b2116a3a9{ip: 172.21.0.4, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-17 04:39:49,828 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: ccbeff08-efe2-46c5-b724-d5e9801835c4, Nodes: fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}691d8703-820d-4600-8b2e-4f7b2116a3a9{ip: 172.21.0.4, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}e02419d7-5832-4f5c-83d3-3bf12f7aa2ad{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:fc51ec5f-ce44-4742-ab67-704c0b8112cf, CreationTimestamp2020-04-17T04:38:35.230Z] moved to OPEN state
recon_1     | 2020-04-17 04:39:49,828 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 691d8703-820d-4600-8b2e-4f7b2116a3a9 to Node DB.
recon_1     | 2020-04-17 04:39:49,829 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=31b6fc2a-f132-4fb3-beba-8dbe46b93727. Trying to get from SCM.
recon_1     | 2020-04-17 04:39:49,843 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 31b6fc2a-f132-4fb3-beba-8dbe46b93727, Nodes: 691d8703-820d-4600-8b2e-4f7b2116a3a9{ip: 172.21.0.4, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:691d8703-820d-4600-8b2e-4f7b2116a3a9, CreationTimestamp2020-04-17T04:38:35.216Z] to Recon pipeline metadata.
recon_1     | 2020-04-17 04:39:49,843 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 31b6fc2a-f132-4fb3-beba-8dbe46b93727, Nodes: 691d8703-820d-4600-8b2e-4f7b2116a3a9{ip: 172.21.0.4, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:691d8703-820d-4600-8b2e-4f7b2116a3a9, CreationTimestamp2020-04-17T04:38:35.216Z]
recon_1     | 2020-04-17 04:40:34,103 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:40:34,105 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-17 04:40:34,218 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 15 OM DB update event(s).
recon_1     | 2020-04-17 04:40:34,296 [pool-9-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-17 04:41:34,300 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:41:34,300 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-17 04:42:34,310 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:42:34,310 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-17 04:43:34,246 [MissingContainerTask] INFO fsck.MissingContainerTask: Missing Container task Thread took 9 milliseconds for processing 1 containers.
recon_1     | 2020-04-17 04:43:34,322 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:43:34,322 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-17 04:44:34,332 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:44:34,332 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-17 04:44:34,342 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2020-04-17 04:44:34,418 [pool-9-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-17 04:45:34,422 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:45:34,423 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-17 04:46:34,431 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:46:34,432 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-17 04:47:34,442 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:47:34,442 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-17 04:47:34,454 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2020-04-17 04:47:34,493 [pool-9-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-17 04:48:34,251 [MissingContainerTask] INFO fsck.MissingContainerTask: Missing Container task Thread took 5 milliseconds for processing 1 containers.
recon_1     | 2020-04-17 04:48:34,277 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
recon_1     | 2020-04-17 04:48:34,278 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 9 milliseconds.
recon_1     | 2020-04-17 04:48:34,502 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:48:34,502 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-17 04:49:34,510 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:49:34,511 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-17 04:50:34,519 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:50:34,519 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-17 04:50:34,530 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2020-04-17 04:50:34,573 [pool-9-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-17 04:51:34,579 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:51:34,580 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-17 04:52:34,592 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:52:34,593 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-17 04:53:34,255 [MissingContainerTask] INFO fsck.MissingContainerTask: Missing Container task Thread took 3 milliseconds for processing 1 containers.
recon_1     | 2020-04-17 04:53:34,604 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:53:34,605 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-17 04:53:34,616 [pool-9-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2020-04-17 04:53:34,658 [pool-9-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-17 04:54:34,662 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2020-04-17 04:38:35,233 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: ccbeff08-efe2-46c5-b724-d5e9801835c4, Nodes: fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}691d8703-820d-4600-8b2e-4f7b2116a3a9{ip: 172.21.0.4, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}e02419d7-5832-4f5c-83d3-3bf12f7aa2ad{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-17T04:38:35.230854Z]
scm_1       | 2020-04-17 04:38:35,233 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-17 04:38:37,725 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 143e2e4e-7906-4522-90b9-94e709d62531, Nodes: e02419d7-5832-4f5c-83d3-3bf12f7aa2ad{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:e02419d7-5832-4f5c-83d3-3bf12f7aa2ad, CreationTimestamp2020-04-17T04:38:34.447657Z] moved to OPEN state
scm_1       | 2020-04-17 04:38:37,733 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-04-17 04:38:37,791 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: e279ebb1-cd90-4587-ade9-4611eeaf8837, Nodes: fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:fc51ec5f-ce44-4742-ab67-704c0b8112cf, CreationTimestamp2020-04-17T04:38:34.411417Z] moved to OPEN state
scm_1       | 2020-04-17 04:38:37,803 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-04-17 04:38:37,803 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-04-17 04:38:37,803 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-04-17 04:38:38,617 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 31b6fc2a-f132-4fb3-beba-8dbe46b93727, Nodes: 691d8703-820d-4600-8b2e-4f7b2116a3a9{ip: 172.21.0.4, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:691d8703-820d-4600-8b2e-4f7b2116a3a9, CreationTimestamp2020-04-17T04:38:35.216745Z] moved to OPEN state
scm_1       | 2020-04-17 04:38:38,617 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-04-17 04:38:38,617 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-04-17 04:38:43,181 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: ccbeff08-efe2-46c5-b724-d5e9801835c4, Nodes: fc51ec5f-ce44-4742-ab67-704c0b8112cf{ip: 172.21.0.7, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}691d8703-820d-4600-8b2e-4f7b2116a3a9{ip: 172.21.0.4, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}e02419d7-5832-4f5c-83d3-3bf12f7aa2ad{ip: 172.21.0.8, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:fc51ec5f-ce44-4742-ab67-704c0b8112cf, CreationTimestamp2020-04-17T04:38:35.230854Z] moved to OPEN state
scm_1       | 2020-04-17 04:38:43,181 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1       | 2020-04-17 04:38:43,181 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-04-17 04:38:43,182 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1       | 2020-04-17 04:38:43,182 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1       | 2020-04-17 04:38:43,182 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1       | 2020-04-17 04:40:30,775 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-17 04:40:30,776 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-17 04:42:30,778 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-17 04:42:30,778 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-17 04:43:43,194 [Thread-338] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1       | 2020-04-17 04:43:43,202 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 5 milliseconds for processing 1 containers.
scm_1       | 2020-04-17 04:44:30,779 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-17 04:44:30,781 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-17 04:46:30,782 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-17 04:46:30,782 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-17 04:48:30,785 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-17 04:48:30,785 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-17 04:48:43,203 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2020-04-17 04:50:30,787 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-17 04:50:30,788 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-17 04:52:30,789 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-17 04:52:30,789 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-17 04:53:43,204 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2020-04-17 04:54:30,790 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-17 04:54:30,791 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
recon_1     | 2020-04-17 04:54:34,663 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-17 04:55:34,672 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-17 04:55:34,673 [pool-8-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
