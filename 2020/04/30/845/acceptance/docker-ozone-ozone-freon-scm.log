Attaching to ozone_datanode_1, ozone_scm_1, ozone_datanode_2, ozone_s3g_1, ozone_datanode_3, ozone_recon_1, ozone_om_1
datanode_1  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2020-04-30 10:17:06,179 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = 21867f67e0c4/172.21.0.7
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 3.2.0
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_1  | STARTUP_MSG:   java = 11.0.6
datanode_1  | ************************************************************/
datanode_1  | 2020-04-30 10:17:06,231 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2020-04-30 10:17:07,812 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2020-04-30 10:17:08,471 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2020-04-30 10:17:09,661 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2020-04-30 10:17:09,674 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2020-04-30 10:17:10,092 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:21867f67e0c4 ip:172.21.0.7
datanode_1  | 2020-04-30 10:17:10,431 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2020-04-30 10:17:10,451 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1  | 2020-04-30 10:17:10,452 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2020-04-30 10:17:10,492 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2020-04-30 10:17:10,564 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2020-04-30 10:17:15,087 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2020-04-30 10:17:15,347 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1  | 2020-04-30 10:17:15,730 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1  | 2020-04-30 10:17:15,750 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  | 2020-04-30 10:17:15,758 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-30 10:17:15,764 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1  | 2020-04-30 10:17:15,766 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2020-04-30 10:17:16,931 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-04-30 10:17:17,759 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2020-04-30 10:17:17,895 [main] INFO util.log: Logging initialized @16667ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2020-04-30 10:17:18,403 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2020-04-30 10:17:18,428 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2020-04-30 10:17:18,475 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2020-04-30 10:17:18,483 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1  | 2020-04-30 10:17:18,490 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1  | 2020-04-30 10:17:18,491 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1  | 2020-04-30 10:17:18,703 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2020-04-30 10:17:18,711 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1  | 2020-04-30 10:17:18,859 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  | 2020-04-30 10:17:18,862 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2020-04-30 10:17:18,868 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_1  | 2020-04-30 10:17:18,931 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6cff61fc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2020-04-30 10:17:18,943 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7cbeac65{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2020-04-30 10:17:19,387 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@78b612c6{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-16994352361885955505.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1  | 2020-04-30 10:17:19,427 [main] INFO server.AbstractConnector: Started ServerConnector@45acdd11{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1  | 2020-04-30 10:17:19,438 [main] INFO server.Server: Started @18211ms
datanode_1  | 2020-04-30 10:17:19,449 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2020-04-30 10:17:19,449 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2020-04-30 10:17:19,465 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1  | 2020-04-30 10:17:19,554 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@eb236d0] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2020-04-30 10:17:20,077 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.21.0.4:9891
datanode_1  | 2020-04-30 10:17:20,489 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1  | 2020-04-30 10:17:22,654 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-04-30 10:17:22,685 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_1  | java.net.SocketTimeoutException: Call From 21867f67e0c4/172.21.0.7 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.7:57344 remote=recon/172.21.0.4:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_3  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2020-04-30 10:17:04,954 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = 3884077e218b/172.21.0.6
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 3.2.0
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_3  | STARTUP_MSG:   java = 11.0.6
datanode_3  | ************************************************************/
datanode_3  | 2020-04-30 10:17:05,021 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2020-04-30 10:17:06,814 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2020-04-30 10:17:07,357 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2020-04-30 10:17:08,374 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2020-04-30 10:17:08,378 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2020-04-30 10:17:08,753 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:3884077e218b ip:172.21.0.6
datanode_3  | 2020-04-30 10:17:09,068 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3  | 2020-04-30 10:17:09,107 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3  | 2020-04-30 10:17:09,127 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2020-04-30 10:17:09,179 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2020-04-30 10:17:09,464 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2020-04-30 10:17:14,151 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-04-30 10:17:14,420 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3  | 2020-04-30 10:17:14,806 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3  | 2020-04-30 10:17:14,815 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3  | 2020-04-30 10:17:14,816 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-30 10:17:14,816 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3  | 2020-04-30 10:17:14,817 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-04-30 10:17:15,794 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-30 10:17:16,345 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2020-04-30 10:17:16,492 [main] INFO util.log: Logging initialized @16546ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2020-04-30 10:17:16,958 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2020-04-30 10:17:16,970 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2020-04-30 10:17:16,986 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2020-04-30 10:17:16,987 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3  | 2020-04-30 10:17:16,987 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3  | 2020-04-30 10:17:16,988 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3  | 2020-04-30 10:17:17,224 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2020-04-30 10:17:17,225 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3  | 2020-04-30 10:17:17,336 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2020-04-30 10:17:17,336 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 2020-04-30 10:17:17,338 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_3  | 2020-04-30 10:17:17,377 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6cc86152{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2020-04-30 10:17:17,379 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6c3659be{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2020-04-30 10:17:17,767 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@69d23296{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-16644847861525437987.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2020-04-30 10:17:17,808 [main] INFO server.AbstractConnector: Started ServerConnector@7b948f3e{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3  | 2020-04-30 10:17:17,808 [main] INFO server.Server: Started @17862ms
datanode_3  | 2020-04-30 10:17:17,828 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2020-04-30 10:17:17,828 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2020-04-30 10:17:17,832 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3  | 2020-04-30 10:17:18,156 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@eb236d0] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2020-04-30 10:17:18,728 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.21.0.4:9891
datanode_3  | 2020-04-30 10:17:18,961 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3  | 2020-04-30 10:17:21,335 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-04-30 10:17:22,336 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-04-30 10:17:23,384 [Datanode State Machine Thread - 1] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_3  | java.net.SocketTimeoutException: Call From 3884077e218b/172.21.0.6 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.6:50766 remote=scm/172.21.0.5:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_3  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.7:57344 remote=recon/172.21.0.4:9891]
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_1  | 2020-04-30 10:17:23,659 [Datanode State Machine Thread - 1] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_1  | java.net.SocketTimeoutException: Call From 21867f67e0c4/172.21.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.7:42618 remote=scm/172.21.0.5:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_1  | 	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.7:42618 remote=scm/172.21.0.5:9861]
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_1  | 2020-04-30 10:17:24,231 [Datanode State Machine Thread - 2] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 2020-04-30 10:17:24,232 [Datanode State Machine Thread - 2] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1  | 2020-04-30 10:17:24,232 [Datanode State Machine Thread - 2] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 177f1f21-a347-43d4-8009-d9e07ad63890 at port 9858
datanode_1  | 2020-04-30 10:17:24,273 [Datanode State Machine Thread - 2] INFO impl.RaftServerProxy: 177f1f21-a347-43d4-8009-d9e07ad63890: start RPC server
datanode_1  | 2020-04-30 10:17:24,553 [Datanode State Machine Thread - 2] INFO server.GrpcService: 177f1f21-a347-43d4-8009-d9e07ad63890: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1  | 2020-04-30 10:17:28,606 [Command processor thread] INFO impl.RaftServerProxy: 177f1f21-a347-43d4-8009-d9e07ad63890: addNew group-22E561BC8D3A:[177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858] returns group-22E561BC8D3A:java.util.concurrent.CompletableFuture@45f552dc[Not completed]
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_3  | 	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.6:50766 remote=scm/172.21.0.5:9861]
datanode_3  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_3  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_3  | 2020-04-30 10:17:24,305 [Datanode State Machine Thread - 3] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3  | 2020-04-30 10:17:24,308 [Datanode State Machine Thread - 3] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3  | 2020-04-30 10:17:24,310 [Datanode State Machine Thread - 3] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 2808343e-73e1-468b-b9f7-baa519ba89e8 at port 9858
datanode_3  | 2020-04-30 10:17:24,425 [Datanode State Machine Thread - 3] INFO impl.RaftServerProxy: 2808343e-73e1-468b-b9f7-baa519ba89e8: start RPC server
datanode_3  | 2020-04-30 10:17:24,782 [Datanode State Machine Thread - 3] INFO server.GrpcService: 2808343e-73e1-468b-b9f7-baa519ba89e8: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3  | 2020-04-30 10:17:29,233 [Command processor thread] INFO impl.RaftServerProxy: 2808343e-73e1-468b-b9f7-baa519ba89e8: addNew group-30DDCC8A9052:[2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858] returns group-30DDCC8A9052:java.util.concurrent.CompletableFuture@53438540[Not completed]
datanode_3  | 2020-04-30 10:17:29,342 [pool-19-thread-1] INFO impl.RaftServerImpl: 2808343e-73e1-468b-b9f7-baa519ba89e8: new RaftServerImpl for group-30DDCC8A9052:[2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-04-30 10:17:29,344 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-04-30 10:17:29,350 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-04-30 10:17:29,350 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-04-30 10:17:29,351 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-04-30 10:17:29,355 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-30 10:17:29,374 [pool-19-thread-1] INFO impl.RaftServerImpl: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052: ConfigurationManager, init=-1: [2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-04-30 10:17:29,386 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-30 10:17:29,393 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-04-30 10:17:29,403 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fee5605e-9a0b-45e1-9a0c-30ddcc8a9052 does not exist. Creating ...
datanode_3  | 2020-04-30 10:17:29,419 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fee5605e-9a0b-45e1-9a0c-30ddcc8a9052/in_use.lock acquired by nodename 6@3884077e218b
datanode_3  | 2020-04-30 10:17:29,443 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fee5605e-9a0b-45e1-9a0c-30ddcc8a9052 has been successfully formatted.
datanode_3  | 2020-04-30 10:17:29,457 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-30DDCC8A9052: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-04-30 10:17:29,466 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-04-30 10:17:29,578 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-04-30 10:17:29,590 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-04-30 10:17:29,613 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-30 10:17:29,615 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-30 10:17:29,624 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.2808343e-73e1-468b-b9f7-baa519ba89e8
datanode_3  | 2020-04-30 10:17:29,708 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-04-30 10:17:29,746 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/fee5605e-9a0b-45e1-9a0c-30ddcc8a9052
datanode_3  | 2020-04-30 10:17:29,762 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-04-30 10:17:29,763 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-04-30 10:17:29,764 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-30 10:17:29,764 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-04-30 10:17:29,765 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-04-30 10:17:29,765 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-04-30 10:17:29,766 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-04-30 10:17:29,790 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-04-30 10:17:29,798 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-04-30 10:17:29,885 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-04-30 10:17:29,942 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-04-30 10:17:29,993 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-04-30 10:17:29,997 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-04-30 10:17:29,998 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-04-30 10:17:29,998 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-04-30 10:17:30,002 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-04-30 10:17:30,082 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052
datanode_3  | 2020-04-30 10:17:30,105 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052
datanode_3  | 2020-04-30 10:17:30,127 [pool-19-thread-1] INFO impl.RaftServerImpl: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052: start as a follower, conf=-1: [2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858], old=null
datanode_3  | 2020-04-30 10:17:30,134 [pool-19-thread-1] INFO impl.RaftServerImpl: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-04-30 10:17:30,139 [pool-19-thread-1] INFO impl.RoleInfo: 2808343e-73e1-468b-b9f7-baa519ba89e8: start FollowerState
datanode_3  | 2020-04-30 10:17:30,152 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-30DDCC8A9052,id=2808343e-73e1-468b-b9f7-baa519ba89e8
datanode_3  | 2020-04-30 10:17:30,160 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052
datanode_3  | 2020-04-30 10:17:30,228 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "fee5605e-9a0b-45e1-9a0c-30ddcc8a9052"
datanode_3  | .
datanode_3  | 2020-04-30 10:17:30,231 [Command processor thread] INFO impl.RaftServerProxy: 2808343e-73e1-468b-b9f7-baa519ba89e8: addNew group-E1C5363FAFA0:[5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858] returns group-E1C5363FAFA0:java.util.concurrent.CompletableFuture@15c35587[Not completed]
datanode_3  | 2020-04-30 10:17:30,278 [pool-19-thread-1] INFO impl.RaftServerImpl: 2808343e-73e1-468b-b9f7-baa519ba89e8: new RaftServerImpl for group-E1C5363FAFA0:[5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-04-30 10:17:30,278 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-04-30 10:17:28,639 [pool-19-thread-1] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890: new RaftServerImpl for group-22E561BC8D3A:[177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-04-30 10:17:28,652 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-04-30 10:17:28,653 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-04-30 10:17:28,654 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-04-30 10:17:28,655 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-04-30 10:17:28,655 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-04-30 10:17:28,668 [pool-19-thread-1] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A: ConfigurationManager, init=-1: [177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-04-30 10:17:28,669 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-04-30 10:17:28,675 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-04-30 10:17:28,676 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/0ff20aa4-ed8d-4e89-83fd-22e561bc8d3a does not exist. Creating ...
datanode_1  | 2020-04-30 10:17:28,689 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/0ff20aa4-ed8d-4e89-83fd-22e561bc8d3a/in_use.lock acquired by nodename 6@21867f67e0c4
datanode_1  | 2020-04-30 10:17:28,695 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/0ff20aa4-ed8d-4e89-83fd-22e561bc8d3a has been successfully formatted.
datanode_1  | 2020-04-30 10:17:28,702 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-22E561BC8D3A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-04-30 10:17:28,703 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-04-30 10:17:28,715 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-04-30 10:17:28,723 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-04-30 10:17:28,730 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-30 10:17:28,731 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-30 10:17:28,734 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.177f1f21-a347-43d4-8009-d9e07ad63890
datanode_1  | 2020-04-30 10:17:28,777 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-04-30 10:17:28,781 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/0ff20aa4-ed8d-4e89-83fd-22e561bc8d3a
datanode_1  | 2020-04-30 10:17:28,791 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-04-30 10:17:28,792 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-04-30 10:17:28,793 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-30 10:17:28,799 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-04-30 10:17:28,799 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-04-30 10:17:28,800 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-04-30 10:17:28,801 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-04-30 10:17:28,802 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-04-30 10:17:28,803 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-04-30 10:17:28,896 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-04-30 10:17:28,905 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-04-30 10:17:28,922 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-04-30 10:17:28,925 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-04-30 10:17:28,926 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-04-30 10:17:28,931 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-04-30 10:17:28,931 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-04-30 10:17:28,992 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A
datanode_1  | 2020-04-30 10:17:28,998 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A
datanode_1  | 2020-04-30 10:17:29,032 [pool-19-thread-1] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A: start as a follower, conf=-1: [177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858], old=null
datanode_1  | 2020-04-30 10:17:29,037 [pool-19-thread-1] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-04-30 10:17:29,043 [pool-19-thread-1] INFO impl.RoleInfo: 177f1f21-a347-43d4-8009-d9e07ad63890: start FollowerState
datanode_1  | 2020-04-30 10:17:29,082 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-22E561BC8D3A,id=177f1f21-a347-43d4-8009-d9e07ad63890
datanode_1  | 2020-04-30 10:17:29,084 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A
datanode_1  | 2020-04-30 10:17:29,148 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "0ff20aa4-ed8d-4e89-83fd-22e561bc8d3a"
datanode_1  | .
datanode_1  | 2020-04-30 10:17:29,148 [Command processor thread] INFO impl.RaftServerProxy: 177f1f21-a347-43d4-8009-d9e07ad63890: addNew group-E1C5363FAFA0:[5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858] returns group-E1C5363FAFA0:java.util.concurrent.CompletableFuture@fb94598[Not completed]
datanode_2  | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2020-04-30 10:17:06,013 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = 507cf04d9352/172.21.0.8
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 3.2.0
datanode_1  | 2020-04-30 10:17:29,156 [pool-19-thread-1] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890: new RaftServerImpl for group-E1C5363FAFA0:[5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-04-30 10:17:29,161 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-04-30 10:17:29,163 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-04-30 10:17:29,163 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-04-30 10:17:29,164 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-04-30 10:17:29,164 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-04-30 10:17:29,164 [pool-19-thread-1] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0: ConfigurationManager, init=-1: [5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-04-30 10:17:29,164 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-04-30 10:17:29,164 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-04-30 10:17:29,164 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/dd308256-9ce4-4caf-8c14-e1c5363fafa0 does not exist. Creating ...
datanode_1  | 2020-04-30 10:17:29,167 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/dd308256-9ce4-4caf-8c14-e1c5363fafa0/in_use.lock acquired by nodename 6@21867f67e0c4
datanode_1  | 2020-04-30 10:17:29,175 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/dd308256-9ce4-4caf-8c14-e1c5363fafa0 has been successfully formatted.
datanode_1  | 2020-04-30 10:17:29,179 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-E1C5363FAFA0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-04-30 10:17:29,179 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-04-30 10:17:29,179 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-04-30 10:17:29,179 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-04-30 10:17:29,179 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-30 10:17:29,179 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-30 10:17:29,180 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-04-30 10:17:29,180 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/dd308256-9ce4-4caf-8c14-e1c5363fafa0
datanode_1  | 2020-04-30 10:17:29,180 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-04-30 10:17:29,180 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-04-30 10:17:29,180 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-04-30 10:17:29,180 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-04-30 10:17:29,180 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-04-30 10:17:29,180 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-04-30 10:17:29,180 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-04-30 10:17:29,181 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-04-30 10:17:29,184 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-04-30 10:17:29,185 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-04-30 10:17:29,185 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-04-30 10:17:29,191 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-04-30 10:17:29,191 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-04-30 10:17:29,191 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-04-30 10:17:29,191 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-04-30 10:17:29,191 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-04-30 10:17:29,192 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0
datanode_1  | 2020-04-30 10:17:29,192 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0
datanode_1  | 2020-04-30 10:17:29,193 [pool-19-thread-1] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0: start as a follower, conf=-1: [5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858], old=null
datanode_1  | 2020-04-30 10:17:29,193 [pool-19-thread-1] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-04-30 10:17:29,193 [pool-19-thread-1] INFO impl.RoleInfo: 177f1f21-a347-43d4-8009-d9e07ad63890: start FollowerState
datanode_1  | 2020-04-30 10:17:29,202 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E1C5363FAFA0,id=177f1f21-a347-43d4-8009-d9e07ad63890
datanode_1  | 2020-04-30 10:17:29,203 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0
datanode_1  | 2020-04-30 10:17:32,156 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "dd308256-9ce4-4caf-8c14-e1c5363fafa0"
datanode_1  | .
datanode_1  | 2020-04-30 10:17:34,227 [Thread-24] INFO impl.FollowerState: 177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-FollowerState: change to CANDIDATE, lastRpcTime:5183ms, electionTimeout:5172ms
datanode_1  | 2020-04-30 10:17:34,228 [Thread-24] INFO impl.RoleInfo: 177f1f21-a347-43d4-8009-d9e07ad63890: shutdown FollowerState
datanode_1  | 2020-04-30 10:17:34,229 [Thread-24] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2020-04-30 10:17:34,231 [Thread-24] INFO impl.RoleInfo: 177f1f21-a347-43d4-8009-d9e07ad63890: start LeaderElection
datanode_3  | 2020-04-30 10:17:30,279 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-04-30 10:17:30,279 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-04-30 10:17:30,279 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-04-30 10:17:30,279 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-04-30 10:17:30,279 [pool-19-thread-1] INFO impl.RaftServerImpl: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-E1C5363FAFA0: ConfigurationManager, init=-1: [5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-04-30 10:17:30,282 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-04-30 10:17:30,283 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-04-30 10:17:30,283 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/dd308256-9ce4-4caf-8c14-e1c5363fafa0 does not exist. Creating ...
datanode_3  | 2020-04-30 10:17:30,299 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/dd308256-9ce4-4caf-8c14-e1c5363fafa0/in_use.lock acquired by nodename 6@3884077e218b
datanode_3  | 2020-04-30 10:17:30,301 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/dd308256-9ce4-4caf-8c14-e1c5363fafa0 has been successfully formatted.
datanode_3  | 2020-04-30 10:17:30,303 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-E1C5363FAFA0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-04-30 10:17:30,310 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-04-30 10:17:30,310 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-04-30 10:17:30,311 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-04-30 10:17:30,311 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-04-30 10:17:30,311 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-30 10:17:30,311 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-04-30 10:17:30,311 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 2808343e-73e1-468b-b9f7-baa519ba89e8@group-E1C5363FAFA0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/dd308256-9ce4-4caf-8c14-e1c5363fafa0
datanode_3  | 2020-04-30 10:17:30,311 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-04-30 10:17:30,311 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-04-30 10:17:30,311 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-04-30 10:17:30,311 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
datanode_2  | STARTUP_MSG:   java = 11.0.6
datanode_2  | ************************************************************/
datanode_2  | 2020-04-30 10:17:06,297 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2020-04-30 10:17:07,761 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2020-04-30 10:17:08,357 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2020-04-30 10:17:09,510 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2020-04-30 10:17:09,511 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2020-04-30 10:17:09,883 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:507cf04d9352 ip:172.21.0.8
datanode_2  | 2020-04-30 10:17:10,236 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2  | 2020-04-30 10:17:10,261 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2  | 2020-04-30 10:17:10,265 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2020-04-30 10:17:10,308 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2  | 2020-04-30 10:17:10,584 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2020-04-30 10:17:14,895 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-04-30 10:17:15,129 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2020-04-30 10:17:15,519 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2  | 2020-04-30 10:17:15,521 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2  | 2020-04-30 10:17:15,522 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-30 10:17:15,527 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2  | 2020-04-30 10:17:15,530 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-04-30 10:17:16,779 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-30 10:17:17,797 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 2020-04-30 10:17:17,989 [main] INFO util.log: Logging initialized @17012ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | 2020-04-30 10:17:18,893 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2020-04-30 10:17:18,896 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2020-04-30 10:17:18,900 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2020-04-30 10:17:18,911 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2  | 2020-04-30 10:17:18,912 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2  | 2020-04-30 10:17:18,913 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2  | 2020-04-30 10:17:19,139 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2020-04-30 10:17:19,140 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2  | 2020-04-30 10:17:19,272 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2020-04-30 10:17:19,279 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2020-04-30 10:17:19,281 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_2  | 2020-04-30 10:17:19,376 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@467b684d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2020-04-30 10:17:19,377 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@50850539{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2020-04-30 10:17:19,909 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@22752544{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-4343069499847998823.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 2020-04-30 10:17:19,977 [main] INFO server.AbstractConnector: Started ServerConnector@237f7970{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2  | 2020-04-30 10:17:19,977 [main] INFO server.Server: Started @19014ms
datanode_2  | 2020-04-30 10:17:20,020 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2020-04-30 10:17:20,021 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2020-04-30 10:17:20,026 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2020-04-30 10:17:20,369 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6cbacba7] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2020-04-30 10:17:20,888 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.21.0.4:9891
datanode_2  | 2020-04-30 10:17:21,179 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2  | 2020-04-30 10:17:23,537 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_2  | java.net.SocketTimeoutException: Call From 507cf04d9352/172.21.0.8 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.8:36114 remote=recon/172.21.0.4:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_2  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_1  | 2020-04-30 10:17:34,238 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO impl.LeaderElection: 177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1: begin an election at term 1 for -1: [177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858], old=null
datanode_1  | 2020-04-30 10:17:34,239 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO impl.RoleInfo: 177f1f21-a347-43d4-8009-d9e07ad63890: shutdown LeaderElection
datanode_1  | 2020-04-30 10:17:34,239 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2020-04-30 10:17:34,239 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-22E561BC8D3A with new leaderId: 177f1f21-a347-43d4-8009-d9e07ad63890
datanode_1  | 2020-04-30 10:17:34,241 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A: change Leader from null to 177f1f21-a347-43d4-8009-d9e07ad63890 at term 1 for becomeLeader, leader elected after 5536ms
datanode_1  | 2020-04-30 10:17:34,247 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2020-04-30 10:17:34,247 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2020-04-30 10:17:34,248 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A
datanode_1  | 2020-04-30 10:17:34,250 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2020-04-30 10:17:34,250 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1  | 2020-04-30 10:17:34,269 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2020-04-30 10:17:34,269 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2020-04-30 10:17:34,270 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2020-04-30 10:17:34,281 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO impl.RoleInfo: 177f1f21-a347-43d4-8009-d9e07ad63890: start LeaderState
datanode_1  | 2020-04-30 10:17:34,293 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-04-30 10:17:34,301 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-LeaderElection1] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A: set configuration 0: [177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858], old=null at 0
datanode_1  | 2020-04-30 10:17:34,352 [177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 177f1f21-a347-43d4-8009-d9e07ad63890@group-22E561BC8D3A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0ff20aa4-ed8d-4e89-83fd-22e561bc8d3a/current/log_inprogress_0
datanode_1  | 2020-04-30 10:17:34,391 [Thread-26] INFO impl.FollowerState: 177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-FollowerState: change to CANDIDATE, lastRpcTime:5198ms, electionTimeout:5180ms
datanode_1  | 2020-04-30 10:17:34,391 [Thread-26] INFO impl.RoleInfo: 177f1f21-a347-43d4-8009-d9e07ad63890: shutdown FollowerState
datanode_1  | 2020-04-30 10:17:34,392 [Thread-26] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2020-04-30 10:17:34,392 [Thread-26] INFO impl.RoleInfo: 177f1f21-a347-43d4-8009-d9e07ad63890: start LeaderElection
datanode_1  | 2020-04-30 10:17:34,394 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO impl.LeaderElection: 177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2: begin an election at term 1 for -1: [5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858], old=null
datanode_1  | 2020-04-30 10:17:34,458 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO impl.LeaderElection: 177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2: Election PASSED; received 1 response(s) [177f1f21-a347-43d4-8009-d9e07ad63890<-5b89f441-5e0e-47be-bcfd-d3bb16f51446#0:OK-t1] and 0 exception(s); 177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0:t1, leader=null, voted=177f1f21-a347-43d4-8009-d9e07ad63890, raftlog=177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858], old=null
datanode_1  | 2020-04-30 10:17:34,458 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO impl.RoleInfo: 177f1f21-a347-43d4-8009-d9e07ad63890: shutdown LeaderElection
datanode_1  | 2020-04-30 10:17:34,458 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2020-04-30 10:17:34,458 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-E1C5363FAFA0 with new leaderId: 177f1f21-a347-43d4-8009-d9e07ad63890
datanode_1  | 2020-04-30 10:17:34,459 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0: change Leader from null to 177f1f21-a347-43d4-8009-d9e07ad63890 at term 1 for becomeLeader, leader elected after 5279ms
datanode_1  | 2020-04-30 10:17:34,463 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2020-04-30 10:17:34,466 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2020-04-30 10:17:34,466 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0
datanode_1  | 2020-04-30 10:17:34,467 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2020-04-30 10:17:34,472 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1  | 2020-04-30 10:17:34,472 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2020-04-30 10:17:34,473 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2020-04-30 10:17:34,473 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2020-04-30 10:17:34,479 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2020-04-30 10:17:34,480 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-30 10:17:34,482 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1  | 2020-04-30 10:17:34,485 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 2020-04-30 10:17:34,488 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2020-04-30 10:17:34,492 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-04-30 10:17:34,498 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2020-04-30 10:17:34,498 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-04-30 10:17:34,498 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1  | 2020-04-30 10:17:34,499 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 2020-04-30 10:17:34,499 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2020-04-30 10:17:34,499 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-04-30 10:17:34,500 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO impl.RoleInfo: 177f1f21-a347-43d4-8009-d9e07ad63890: start LeaderState
datanode_1  | 2020-04-30 10:17:34,500 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-04-30 10:17:34,502 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/dd308256-9ce4-4caf-8c14-e1c5363fafa0/current/log_inprogress_0
datanode_1  | 2020-04-30 10:17:34,507 [177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0-LeaderElection2] INFO impl.RaftServerImpl: 177f1f21-a347-43d4-8009-d9e07ad63890@group-E1C5363FAFA0: set configuration 0: [5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858], old=null at 0
datanode_1  | 2020-04-30 10:19:06,568 [grpc-default-executor-2] WARN client.GrpcClientProtocolService: 4-OrderedRequestStreamObserver4: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2020-04-30 10:20:34,778 [grpc-default-executor-2] WARN client.GrpcClientProtocolService: 9-OrderedRequestStreamObserver9: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1  | 2020-04-30 10:21:17,809 [grpc-default-executor-2] WARN client.GrpcClientProtocolService: 12-OrderedRequestStreamObserver12: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_2  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.8:36114 remote=recon/172.21.0.4:9891]
datanode_2  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_2  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_2  | 2020-04-30 10:17:23,537 [Datanode State Machine Thread - 1] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2  | java.net.SocketTimeoutException: Call From 507cf04d9352/172.21.0.8 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.8:35534 remote=scm/172.21.0.5:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
datanode_2  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
datanode_2  | 	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.21.0.8:35534 remote=scm/172.21.0.5:9861]
datanode_2  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
datanode_2  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
datanode_2  | 2020-04-30 10:17:24,451 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2020-04-30 10:17:24,452 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2  | 2020-04-30 10:17:24,452 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 5b89f441-5e0e-47be-bcfd-d3bb16f51446 at port 9858
datanode_2  | 2020-04-30 10:17:24,489 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 5b89f441-5e0e-47be-bcfd-d3bb16f51446: start RPC server
datanode_2  | 2020-04-30 10:17:24,748 [Datanode State Machine Thread - 1] INFO server.GrpcService: 5b89f441-5e0e-47be-bcfd-d3bb16f51446: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2  | 2020-04-30 10:17:29,413 [Command processor thread] INFO impl.RaftServerProxy: 5b89f441-5e0e-47be-bcfd-d3bb16f51446: addNew group-FA85FC79629E:[5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858] returns group-FA85FC79629E:java.util.concurrent.CompletableFuture@4d94d99a[Not completed]
om_1        | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-04-30 10:17:02,354 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = ad9d1435c569/172.21.0.3
om_1        | STARTUP_MSG:   args = [--init]
om_1        | STARTUP_MSG:   version = 3.2.0
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
datanode_3  | 2020-04-30 10:17:30,311 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-04-30 10:17:30,312 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-04-30 10:17:30,312 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-04-30 10:17:30,312 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-04-30 10:17:30,312 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-04-30 10:17:30,315 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-04-30 10:17:30,315 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-E1C5363FAFA0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-04-30 10:17:30,327 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-04-30 10:17:30,327 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-04-30 10:17:30,340 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-04-30 10:17:30,340 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-04-30 10:17:30,341 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-04-30 10:17:30,341 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.2808343e-73e1-468b-b9f7-baa519ba89e8@group-E1C5363FAFA0
datanode_3  | 2020-04-30 10:17:30,341 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.2808343e-73e1-468b-b9f7-baa519ba89e8@group-E1C5363FAFA0
datanode_3  | 2020-04-30 10:17:30,342 [pool-19-thread-1] INFO impl.RaftServerImpl: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-E1C5363FAFA0: start as a follower, conf=-1: [5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858], old=null
datanode_3  | 2020-04-30 10:17:30,342 [pool-19-thread-1] INFO impl.RaftServerImpl: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-E1C5363FAFA0: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-04-30 10:17:30,342 [pool-19-thread-1] INFO impl.RoleInfo: 2808343e-73e1-468b-b9f7-baa519ba89e8: start FollowerState
datanode_3  | 2020-04-30 10:17:30,361 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E1C5363FAFA0,id=2808343e-73e1-468b-b9f7-baa519ba89e8
datanode_3  | 2020-04-30 10:17:30,361 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.2808343e-73e1-468b-b9f7-baa519ba89e8@group-E1C5363FAFA0
datanode_3  | 2020-04-30 10:17:32,159 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "dd308256-9ce4-4caf-8c14-e1c5363fafa0"
datanode_3  | .
datanode_3  | 2020-04-30 10:17:34,452 [grpc-default-executor-0] INFO impl.RaftServerImpl: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-E1C5363FAFA0: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:177f1f21-a347-43d4-8009-d9e07ad63890
datanode_3  | 2020-04-30 10:17:34,453 [grpc-default-executor-0] INFO impl.RoleInfo: 2808343e-73e1-468b-b9f7-baa519ba89e8: shutdown FollowerState
datanode_3  | 2020-04-30 10:17:34,453 [Thread-24] INFO impl.FollowerState: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-E1C5363FAFA0-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3  | 2020-04-30 10:17:34,456 [grpc-default-executor-0] INFO impl.RoleInfo: 2808343e-73e1-468b-b9f7-baa519ba89e8: start FollowerState
datanode_3  | 2020-04-30 10:17:34,536 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-E1C5363FAFA0 with new leaderId: 177f1f21-a347-43d4-8009-d9e07ad63890
datanode_3  | 2020-04-30 10:17:34,537 [grpc-default-executor-0] INFO impl.RaftServerImpl: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-E1C5363FAFA0: change Leader from null to 177f1f21-a347-43d4-8009-d9e07ad63890 at term 1 for appendEntries, leader elected after 4233ms
datanode_3  | 2020-04-30 10:17:34,558 [grpc-default-executor-0] INFO impl.RaftServerImpl: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-E1C5363FAFA0: set configuration 0: [5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858], old=null at 0
datanode_3  | 2020-04-30 10:17:34,574 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-E1C5363FAFA0-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-04-30 10:17:34,645 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-E1C5363FAFA0-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-E1C5363FAFA0-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/dd308256-9ce4-4caf-8c14-e1c5363fafa0/current/log_inprogress_0
datanode_3  | 2020-04-30 10:17:35,216 [Thread-22] INFO impl.FollowerState: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-FollowerState: change to CANDIDATE, lastRpcTime:5077ms, electionTimeout:5076ms
datanode_3  | 2020-04-30 10:17:35,217 [Thread-22] INFO impl.RoleInfo: 2808343e-73e1-468b-b9f7-baa519ba89e8: shutdown FollowerState
datanode_3  | 2020-04-30 10:17:35,217 [Thread-22] INFO impl.RaftServerImpl: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2020-04-30 10:17:35,219 [Thread-22] INFO impl.RoleInfo: 2808343e-73e1-468b-b9f7-baa519ba89e8: start LeaderElection
datanode_3  | 2020-04-30 10:17:35,223 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO impl.LeaderElection: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1: begin an election at term 1 for -1: [2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858], old=null
datanode_3  | 2020-04-30 10:17:35,225 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO impl.RoleInfo: 2808343e-73e1-468b-b9f7-baa519ba89e8: shutdown LeaderElection
datanode_3  | 2020-04-30 10:17:35,225 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO impl.RaftServerImpl: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-04-30 10:17:35,226 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-30DDCC8A9052 with new leaderId: 2808343e-73e1-468b-b9f7-baa519ba89e8
datanode_3  | 2020-04-30 10:17:35,226 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO impl.RaftServerImpl: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052: change Leader from null to 2808343e-73e1-468b-b9f7-baa519ba89e8 at term 1 for becomeLeader, leader elected after 5762ms
datanode_3  | 2020-04-30 10:17:35,228 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-04-30 10:17:35,228 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-04-30 10:17:35,230 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052
datanode_3  | 2020-04-30 10:17:35,245 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-04-30 10:17:35,246 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-04-30 10:17:35,259 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-04-30 10:17:35,259 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-04-30 10:17:35,260 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-04-30 10:17:35,273 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO impl.RoleInfo: 2808343e-73e1-468b-b9f7-baa519ba89e8: start LeaderState
datanode_3  | 2020-04-30 10:17:35,283 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-04-30 10:17:35,286 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fee5605e-9a0b-45e1-9a0c-30ddcc8a9052/current/log_inprogress_0
datanode_3  | 2020-04-30 10:17:35,296 [2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052-LeaderElection1] INFO impl.RaftServerImpl: 2808343e-73e1-468b-b9f7-baa519ba89e8@group-30DDCC8A9052: set configuration 0: [2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858], old=null at 0
datanode_3  | 2020-04-30 10:18:20,335 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: recon/172.21.0.4:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=60000 MILLISECONDS)
datanode_2  | 2020-04-30 10:17:29,614 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b89f441-5e0e-47be-bcfd-d3bb16f51446: new RaftServerImpl for group-FA85FC79629E:[5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-04-30 10:17:29,676 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-04-30 10:17:29,676 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-04-30 10:17:29,676 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-04-30 10:17:29,676 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-04-30 10:17:29,677 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-04-30 10:17:29,710 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E: ConfigurationManager, init=-1: [5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-04-30 10:17:29,720 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-30 10:17:29,726 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-04-30 10:17:29,750 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/69428426-33f6-4e5b-8e95-fa85fc79629e does not exist. Creating ...
datanode_2  | 2020-04-30 10:17:29,782 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/69428426-33f6-4e5b-8e95-fa85fc79629e/in_use.lock acquired by nodename 6@507cf04d9352
datanode_2  | 2020-04-30 10:17:29,793 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/69428426-33f6-4e5b-8e95-fa85fc79629e has been successfully formatted.
datanode_2  | 2020-04-30 10:17:29,817 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-FA85FC79629E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-04-30 10:17:29,821 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-04-30 10:17:29,943 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-04-30 10:17:29,954 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-04-30 10:17:29,987 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-30 10:17:30,011 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-30 10:17:30,041 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.5b89f441-5e0e-47be-bcfd-d3bb16f51446
datanode_2  | 2020-04-30 10:17:30,090 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-04-30 10:17:30,098 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/69428426-33f6-4e5b-8e95-fa85fc79629e
datanode_2  | 2020-04-30 10:17:30,119 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-04-30 10:17:30,127 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-04-30 10:17:30,128 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-30 10:17:30,134 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-04-30 10:17:30,137 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-04-30 10:17:30,138 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-04-30 10:17:30,139 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-04-30 10:17:30,140 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-04-30 10:17:30,140 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-04-30 10:17:30,202 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-04-30 10:17:30,225 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-04-30 10:17:30,289 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-04-30 10:17:30,294 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-04-30 10:17:30,299 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-04-30 10:17:30,301 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-04-30 10:17:30,302 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-04-30 10:17:30,354 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E
datanode_2  | 2020-04-30 10:17:30,360 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E
datanode_2  | 2020-04-30 10:17:30,364 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E: start as a follower, conf=-1: [5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858], old=null
datanode_2  | 2020-04-30 10:17:30,365 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-04-30 10:17:30,366 [pool-19-thread-1] INFO impl.RoleInfo: 5b89f441-5e0e-47be-bcfd-d3bb16f51446: start FollowerState
datanode_2  | 2020-04-30 10:17:30,375 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FA85FC79629E,id=5b89f441-5e0e-47be-bcfd-d3bb16f51446
datanode_2  | 2020-04-30 10:17:30,377 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E
datanode_2  | 2020-04-30 10:17:30,403 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "69428426-33f6-4e5b-8e95-fa85fc79629e"
datanode_2  | .
datanode_2  | 2020-04-30 10:17:30,404 [Command processor thread] INFO impl.RaftServerProxy: 5b89f441-5e0e-47be-bcfd-d3bb16f51446: addNew group-E1C5363FAFA0:[5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858] returns group-E1C5363FAFA0:java.util.concurrent.CompletableFuture@7c089d4c[Not completed]
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-04-30 10:17:02,396 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-04-30 10:17:07,080 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-04-30 10:17:07,369 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.21.0.3:9862
om_1        | 2020-04-30 10:17:07,370 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-04-30 10:17:07,401 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-30 10:17:09,788 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-30 10:17:10,789 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-30 10:17:11,790 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-30 10:17:12,791 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-30 10:17:13,791 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-30 10:17:14,792 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-30 10:17:15,793 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-30 10:17:16,794 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-30 10:17:17,795 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-30 10:17:18,796 [main] INFO ipc.Client: Retrying connect to server: scm/172.21.0.5:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-04-30 10:17:18,798 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-da400cca-81f9-4a84-bd36-216e6c9f1a0f
om_1        | 2020-04-30 10:17:24,241 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1        | /************************************************************
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at ad9d1435c569/172.21.0.3
om_1        | ************************************************************/
om_1        | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-04-30 10:17:26,053 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = ad9d1435c569/172.21.0.3
om_1        | STARTUP_MSG:   args = []
om_1        | STARTUP_MSG:   version = 3.2.0
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-04-30 10:17:26,059 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-04-30 10:17:26,832 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-04-30 10:17:26,860 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.21.0.3:9862
om_1        | 2020-04-30 10:17:26,860 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-04-30 10:17:26,864 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-30 10:17:26,940 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-30 10:17:27,864 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-04-30 10:17:28,277 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2020-04-30 10:17:28,286 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1        | 2020-04-30 10:17:28,602 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | 2020-04-30 10:17:28,768 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2020-04-30 10:17:28,768 [main] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1        | 2020-04-30 10:17:28,869 [main] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.21.0.3:9862
om_1        | 2020-04-30 10:17:28,917 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1        | 2020-04-30 10:17:28,975 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1        | 2020-04-30 10:17:29,463 [main] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1        | 2020-04-30 10:17:29,560 [main] INFO util.log: Logging initialized @5011ms to org.eclipse.jetty.util.log.Slf4jLog
om_1        | 2020-04-30 10:17:30,374 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1        | 2020-04-30 10:17:30,390 [main] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1        | 2020-04-30 10:17:30,421 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1        | 2020-04-30 10:17:30,422 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1        | 2020-04-30 10:17:30,422 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
om_1        | 2020-04-30 10:17:30,422 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
om_1        | 2020-04-30 10:17:30,540 [main] INFO http.HttpServer2: Jetty bound to port 9874
om_1        | 2020-04-30 10:17:30,547 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1        | 2020-04-30 10:17:30,666 [main] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 2020-04-30 10:17:30,666 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2020-04-30 10:17:30,420 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b89f441-5e0e-47be-bcfd-d3bb16f51446: new RaftServerImpl for group-E1C5363FAFA0:[5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-04-30 10:17:30,431 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-04-30 10:17:30,431 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-04-30 10:17:30,431 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-04-30 10:17:30,431 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-04-30 10:17:30,432 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-04-30 10:17:30,432 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-E1C5363FAFA0: ConfigurationManager, init=-1: [5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-04-30 10:17:30,432 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-04-30 10:17:30,432 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-04-30 10:17:30,444 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/dd308256-9ce4-4caf-8c14-e1c5363fafa0 does not exist. Creating ...
datanode_2  | 2020-04-30 10:17:30,446 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/dd308256-9ce4-4caf-8c14-e1c5363fafa0/in_use.lock acquired by nodename 6@507cf04d9352
datanode_2  | 2020-04-30 10:17:30,448 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/dd308256-9ce4-4caf-8c14-e1c5363fafa0 has been successfully formatted.
datanode_2  | 2020-04-30 10:17:30,448 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-E1C5363FAFA0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-04-30 10:17:30,449 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-04-30 10:17:30,452 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-04-30 10:17:30,453 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-04-30 10:17:30,453 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-04-30 10:17:30,454 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-30 10:17:30,454 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-04-30 10:17:30,454 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-E1C5363FAFA0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/dd308256-9ce4-4caf-8c14-e1c5363fafa0
datanode_2  | 2020-04-30 10:17:30,454 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-04-30 10:17:30,454 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-04-30 10:17:30,454 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-04-30 10:17:30,455 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-04-30 10:17:30,455 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-04-30 10:17:30,455 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-04-30 10:17:30,455 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-04-30 10:17:30,455 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-04-30 10:17:30,455 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-04-30 10:17:30,458 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-04-30 10:17:30,458 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-E1C5363FAFA0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-04-30 10:17:30,458 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-04-30 10:17:30,459 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-04-30 10:17:30,459 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-04-30 10:17:30,459 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-04-30 10:17:30,461 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-04-30 10:17:30,461 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-E1C5363FAFA0
datanode_2  | 2020-04-30 10:17:30,462 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-E1C5363FAFA0
datanode_2  | 2020-04-30 10:17:30,463 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-E1C5363FAFA0: start as a follower, conf=-1: [5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858], old=null
datanode_2  | 2020-04-30 10:17:30,463 [pool-19-thread-1] INFO impl.RaftServerImpl: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-E1C5363FAFA0: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-04-30 10:17:30,464 [pool-19-thread-1] INFO impl.RoleInfo: 5b89f441-5e0e-47be-bcfd-d3bb16f51446: start FollowerState
datanode_2  | 2020-04-30 10:17:30,470 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E1C5363FAFA0,id=5b89f441-5e0e-47be-bcfd-d3bb16f51446
datanode_2  | 2020-04-30 10:17:30,473 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-E1C5363FAFA0
datanode_2  | 2020-04-30 10:17:32,062 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "dd308256-9ce4-4caf-8c14-e1c5363fafa0"
datanode_2  | .
datanode_2  | 2020-04-30 10:17:34,432 [grpc-default-executor-1] INFO impl.RaftServerImpl: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-E1C5363FAFA0: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:177f1f21-a347-43d4-8009-d9e07ad63890
datanode_2  | 2020-04-30 10:17:34,432 [grpc-default-executor-1] INFO impl.RoleInfo: 5b89f441-5e0e-47be-bcfd-d3bb16f51446: shutdown FollowerState
datanode_2  | 2020-04-30 10:17:34,433 [grpc-default-executor-1] INFO impl.RoleInfo: 5b89f441-5e0e-47be-bcfd-d3bb16f51446: start FollowerState
datanode_2  | 2020-04-30 10:17:34,433 [Thread-26] INFO impl.FollowerState: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-E1C5363FAFA0-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
om_1        | 2020-04-30 10:17:30,668 [main] INFO server.session: node0 Scavenging every 600000ms
om_1        | 2020-04-30 10:17:30,722 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3a26ec8d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 2020-04-30 10:17:30,728 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@64d4f7c7{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | 2020-04-30 10:17:31,506 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5114b7c7{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-6685109420189777094.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1        | 2020-04-30 10:17:31,558 [main] INFO server.AbstractConnector: Started ServerConnector@3078cac{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1        | 2020-04-30 10:17:31,559 [main] INFO server.Server: Started @7009ms
om_1        | 2020-04-30 10:17:31,586 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2020-04-30 10:17:31,586 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 2020-04-30 10:17:31,590 [main] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1        | 2020-04-30 10:17:41,885 [IPC Server handler 0 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-38151 for user:hadoop
om_1        | 2020-04-30 10:17:41,900 [IPC Server handler 2 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-67152 for user:hadoop
om_1        | 2020-04-30 10:17:41,906 [IPC Server handler 7 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-84169 for user:hadoop
om_1        | 2020-04-30 10:17:41,913 [IPC Server handler 5 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-17125 for user:hadoop
om_1        | 2020-04-30 10:17:41,917 [IPC Server handler 8 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-34116 for user:hadoop
om_1        | 2020-04-30 10:18:24,132 [qtp140040372-132] INFO om.OMDBCheckpointServlet: Received request to obtain OM DB checkpoint snapshot
om_1        | 2020-04-30 10:18:24,147 [qtp140040372-132] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1588241904133 in 13 milliseconds
om_1        | 2020-04-30 10:18:24,169 [qtp140040372-132] INFO om.OMDBCheckpointServlet: Time taken to write the checkpoint to response output stream: 20 milliseconds
om_1        | 2020-04-30 10:18:24,171 [qtp140040372-132] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1588241904133
om_1        | 2020-04-30 10:18:36,911 [IPC Server handler 40 on 9862] INFO volume.OMVolumeCreateRequest: created volume:79307-rpcwoport for user:hadoop
om_1        | 2020-04-30 10:19:18,609 [IPC Server handler 25 on 9862] INFO volume.OMVolumeCreateRequest: created volume:79307-rpcwoport2 for user:hadoop
om_1        | 2020-04-30 10:19:36,543 [IPC Server handler 20 on 9862] ERROR acl.OMBucketAddAclRequest: Add acl [user:superuser1:rwxy[ACCESS]] to path /79307-rpcwoport2/bb1 failed, because acl already exist
om_1        | 2020-04-30 10:20:04,583 [IPC Server handler 28 on 9862] INFO volume.OMVolumeCreateRequest: created volume:79307-rpcwport for user:hadoop
om_1        | 2020-04-30 10:20:48,408 [IPC Server handler 6 on 9862] INFO volume.OMVolumeCreateRequest: created volume:79307-rpcwoscheme for user:hadoop
om_1        | 2020-04-30 10:21:33,950 [IPC Server handler 46 on 9862] INFO volume.OMVolumeCreateRequest: created volume:ikjvz for user:hadoop
om_1        | 2020-04-30 10:22:21,699 [IPC Server handler 33 on 9862] INFO volume.OMVolumeCreateRequest: created volume:fstest for user:hadoop
om_1        | 2020-04-30 10:22:23,363 [IPC Server handler 2 on 9862] INFO volume.OMVolumeCreateRequest: created volume:fstest2 for user:hadoop
om_1        | 2020-04-30 10:25:05,362 [IPC Server handler 2 on 9862] ERROR proto.OzoneManagerProtocolProtos$S3CreateBucketRequest: S3Bucket Creation Failed for userName: 7c35ba70126b04fca007e4dbfab9c47c, s3BucketName bucket-34018, VolumeName s37c35ba70126b04fca007e4dbfab9c47c
om_1        | 2020-04-30 10:25:22,486 [IPC Server handler 18 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om_1        | 2020-04-30 10:25:22,487 [IPC Server handler 18 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey2 in Volume/Bucket s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436
om_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: s37c35ba70126b04fca007e4dbfab9c47cbucket: bucket-94436key: multipartKey2
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:242)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:240)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:131)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:99)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2020-04-30 10:25:22,493 [IPC Server handler 18 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s37c35ba70126b04fca007e4dbfab9c47c"
om_1        |   bucketName: "bucket-94436"
om_1        |   keyName: "multipartKey2"
om_1        |   multipartUploadID: "f9bdf219-96d1-4eed-86ef-2de0a0ca76fb-104087048738111639"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "hadoop"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   acls {
om_1        |     type: GROUP
om_1        |     name: "users"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1588242322485
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 1
om_1        |   partName: "/s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436/multipartKey2104087048771928216"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "/s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436/multipartKey2104087048810463385"
om_1        | }
om_1        | 
recon_1     | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
recon_1     | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1     | WARNING: An illegal reflective access operation has occurred
recon_1     | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
recon_1     | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | WARNING: All illegal access operations will be denied in a future release
recon_1     | 2020-04-30 10:17:06,108 [main] INFO recon.ReconRestServletModule: rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1     | 2020-04-30 10:17:07,795 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1     | 2020-04-30 10:17:11,368 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1     | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
recon_1     | 2020-04-30 10:17:14,717 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1     | 2020-04-30 10:17:14,777 [main] INFO util.log: Logging initialized @15243ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1     | 2020-04-30 10:17:15,327 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1     | 2020-04-30 10:17:15,361 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1     | 2020-04-30 10:17:15,398 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1     | 2020-04-30 10:17:15,428 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context recon
recon_1     | 2020-04-30 10:17:15,434 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
recon_1     | 2020-04-30 10:17:15,438 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
recon_1     | 2020-04-30 10:17:16,087 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1     | 2020-04-30 10:17:18,132 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1     | 2020-04-30 10:17:20,346 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-30 10:17:20,359 [main] INFO Configuration.deprecation: No unit for recon.om.connection.request.timeout(5000) assuming MILLISECONDS
recon_1     | 2020-04-30 10:17:20,915 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-30 10:17:20,952 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@664212ab
recon_1     | 2020-04-30 10:17:20,953 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1     | 2020-04-30 10:17:21,177 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-30 10:17:21,275 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1     | 2020-04-30 10:17:21,283 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-30 10:17:21,313 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1     | 2020-04-30 10:17:21,365 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1     | 2020-04-30 10:17:21,406 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1     | 2020-04-30 10:17:21,513 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
recon_1     | 2020-04-30 10:17:21,601 [main] INFO recon.ReconServer: Recon server initialized successfully!
recon_1     | 2020-04-30 10:17:21,601 [main] INFO recon.ReconServer: Starting Recon server
recon_1     | 2020-04-30 10:17:21,690 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1     | 2020-04-30 10:17:21,762 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1     | 2020-04-30 10:17:21,764 [main] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1     | 2020-04-30 10:17:22,142 [main] INFO http.HttpServer2: Jetty bound to port 9888
recon_1     | 2020-04-30 10:17:22,154 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
recon_1     | 2020-04-30 10:17:22,217 [main] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1     | 2020-04-30 10:17:22,219 [main] INFO server.session: No SessionScavenger set, using defaults
recon_1     | 2020-04-30 10:17:22,221 [main] INFO server.session: node0 Scavenging every 660000ms
recon_1     | 2020-04-30 10:17:22,237 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@10895b16{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1     | 2020-04-30 10:17:22,247 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3b9632d1{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1     | 2020-04-30 10:17:23,988 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5abbb273{recon,/,file:///tmp/jetty-0_0_0_0-9888-hadoop-ozone-recon-0_6_0-SNAPSHOT_jar-_-any-8416157238327976670.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar!/webapps/recon}
recon_1     | 2020-04-30 10:17:24,026 [main] INFO server.AbstractConnector: Started ServerConnector@4422dd48{HTTP/1.1,[http/1.1]}{0.0.0.0:9888}
recon_1     | 2020-04-30 10:17:24,027 [main] INFO server.Server: Started @24493ms
recon_1     | 2020-04-30 10:17:24,032 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1     | 2020-04-30 10:17:24,032 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1     | 2020-04-30 10:17:24,038 [main] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1     | 2020-04-30 10:17:24,038 [main] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1     | 2020-04-30 10:17:24,048 [main] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1     | 2020-04-30 10:17:24,064 [main] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1     | 2020-04-30 10:17:24,064 [main] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
om_1        | 2020-04-30 10:25:23,474 [IPC Server handler 21 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om_1        | partName: "etag1"
om_1        | , partNumber: 2
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2020-04-30 10:25:23,475 [IPC Server handler 21 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s37c35ba70126b04fca007e4dbfab9c47cbucket: bucket-94436key: multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:182)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:240)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:131)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:99)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2020-04-30 10:25:23,476 [IPC Server handler 21 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s37c35ba70126b04fca007e4dbfab9c47c"
om_1        |   bucketName: "bucket-94436"
om_1        |   keyName: "multipartKey3"
om_1        |   multipartUploadID: "cbfa8d32-f982-41ea-831c-28ccd21f2013-104087048877768858"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "hadoop"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   acls {
om_1        |     type: GROUP
om_1        |     name: "users"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1588242323474
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 1
om_1        |   partName: "etag1"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "etag2"
om_1        | }
om_1        | 
om_1        | 2020-04-30 10:25:23,927 [IPC Server handler 69 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om_1        | partName: "etag1"
om_1        | , partNumber: 1
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2020-04-30 10:25:23,928 [IPC Server handler 69 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s37c35ba70126b04fca007e4dbfab9c47cbucket: bucket-94436key: multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:182)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:240)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:131)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:99)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2020-04-30 10:25:23,930 [IPC Server handler 69 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s37c35ba70126b04fca007e4dbfab9c47c"
om_1        |   bucketName: "bucket-94436"
om_1        |   keyName: "multipartKey3"
om_1        |   multipartUploadID: "cbfa8d32-f982-41ea-831c-28ccd21f2013-104087048877768858"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "hadoop"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   acls {
om_1        |     type: GROUP
om_1        |     name: "users"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1588242323926
datanode_2  | 2020-04-30 10:17:34,530 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-E1C5363FAFA0 with new leaderId: 177f1f21-a347-43d4-8009-d9e07ad63890
datanode_2  | 2020-04-30 10:17:34,530 [grpc-default-executor-1] INFO impl.RaftServerImpl: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-E1C5363FAFA0: change Leader from null to 177f1f21-a347-43d4-8009-d9e07ad63890 at term 1 for appendEntries, leader elected after 4080ms
datanode_2  | 2020-04-30 10:17:34,564 [grpc-default-executor-1] INFO impl.RaftServerImpl: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-E1C5363FAFA0: set configuration 0: [5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858, 177f1f21-a347-43d4-8009-d9e07ad63890:172.21.0.7:9858, 2808343e-73e1-468b-b9f7-baa519ba89e8:172.21.0.6:9858], old=null at 0
datanode_2  | 2020-04-30 10:17:34,574 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-E1C5363FAFA0-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-04-30 10:17:34,659 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-E1C5363FAFA0-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-E1C5363FAFA0-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/dd308256-9ce4-4caf-8c14-e1c5363fafa0/current/log_inprogress_0
datanode_2  | 2020-04-30 10:17:35,589 [Thread-24] INFO impl.FollowerState: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-FollowerState: change to CANDIDATE, lastRpcTime:5223ms, electionTimeout:5196ms
datanode_2  | 2020-04-30 10:17:35,590 [Thread-24] INFO impl.RoleInfo: 5b89f441-5e0e-47be-bcfd-d3bb16f51446: shutdown FollowerState
datanode_2  | 2020-04-30 10:17:35,590 [Thread-24] INFO impl.RaftServerImpl: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-04-30 10:17:35,592 [Thread-24] INFO impl.RoleInfo: 5b89f441-5e0e-47be-bcfd-d3bb16f51446: start LeaderElection
datanode_2  | 2020-04-30 10:17:35,599 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO impl.LeaderElection: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1: begin an election at term 1 for -1: [5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858], old=null
datanode_2  | 2020-04-30 10:17:35,600 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO impl.RoleInfo: 5b89f441-5e0e-47be-bcfd-d3bb16f51446: shutdown LeaderElection
datanode_2  | 2020-04-30 10:17:35,602 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO impl.RaftServerImpl: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-04-30 10:17:35,602 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-FA85FC79629E with new leaderId: 5b89f441-5e0e-47be-bcfd-d3bb16f51446
datanode_2  | 2020-04-30 10:17:35,602 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO impl.RaftServerImpl: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E: change Leader from null to 5b89f441-5e0e-47be-bcfd-d3bb16f51446 at term 1 for becomeLeader, leader elected after 5784ms
datanode_2  | 2020-04-30 10:17:35,605 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-04-30 10:17:35,605 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2020-04-30 10:17:35,608 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E
datanode_2  | 2020-04-30 10:17:35,615 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2020-04-30 10:17:35,618 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-04-30 10:17:35,622 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-04-30 10:17:35,622 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-04-30 10:17:35,623 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2020-04-30 10:17:35,632 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO impl.RoleInfo: 5b89f441-5e0e-47be-bcfd-d3bb16f51446: start LeaderState
datanode_2  | 2020-04-30 10:17:35,636 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-04-30 10:17:35,638 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/69428426-33f6-4e5b-8e95-fa85fc79629e/current/log_inprogress_0
datanode_2  | 2020-04-30 10:17:35,639 [5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E-LeaderElection1] INFO impl.RaftServerImpl: 5b89f441-5e0e-47be-bcfd-d3bb16f51446@group-FA85FC79629E: set configuration 0: [5b89f441-5e0e-47be-bcfd-d3bb16f51446:172.21.0.8:9858], old=null at 0
recon_1     | 2020-04-30 10:17:24,065 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-04-30 10:17:24,065 [main] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1     | 2020-04-30 10:17:24,066 [main] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1     | 2020-04-30 10:17:24,861 [main] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1     | 2020-04-30 10:17:24,862 [main] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2020-04-30 10:17:24,865 [main] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1     | 2020-04-30 10:17:24,874 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1     | 2020-04-30 10:17:24,936 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1     | 2020-04-30 10:17:24,967 [main] INFO scm.ReconScmTask: Registered MissingContainerTask task 
recon_1     | 2020-04-30 10:17:24,978 [main] INFO scm.ReconScmTask: Starting MissingContainerTask Thread.
recon_1     | 2020-04-30 10:17:24,987 [IPC Server handler 0 on 9891] INFO ipc.Server: IPC Server handler 0 on 9891: skipped Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.21.0.7:57344
recon_1     | 2020-04-30 10:17:24,988 [IPC Server handler 2 on 9891] INFO ipc.Server: IPC Server handler 2 on 9891: skipped Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.21.0.7:57380
recon_1     | 2020-04-30 10:17:24,988 [IPC Server handler 1 on 9891] INFO ipc.Server: IPC Server handler 1 on 9891: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.21.0.8:36114
recon_1     | 2020-04-30 10:17:25,042 [main] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1     | 2020-04-30 10:17:25,046 [main] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1     | 2020-04-30 10:17:25,095 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2020-04-30 10:17:25,095 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 6 milliseconds.
recon_1     | 2020-04-30 10:17:25,112 [MissingContainerTask] INFO fsck.MissingContainerTask: Missing Container task Thread took 98 milliseconds for processing 0 containers.
recon_1     | 2020-04-30 10:17:25,414 [IPC Server handler 3 on 9891] WARN ipc.Server: IPC Server handler 3 on 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 172.21.0.8:36138: output error
recon_1     | 2020-04-30 10:17:25,419 [IPC Server handler 3 on 9891] INFO ipc.Server: IPC Server handler 3 on 9891 caught an exception
recon_1     | java.nio.channels.AsynchronousCloseException
recon_1     | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1     | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
recon_1     | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
recon_1     | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
recon_1     | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
recon_1     | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1     | 2020-04-30 10:17:27,606 [IPC Server handler 4 on 9891] INFO net.NetworkTopology: Added a new node: /default-rack/177f1f21-a347-43d4-8009-d9e07ad63890
recon_1     | 2020-04-30 10:17:27,607 [IPC Server handler 4 on 9891] INFO node.SCMNodeManager: Registered Data node : 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-30 10:17:27,646 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 177f1f21-a347-43d4-8009-d9e07ad63890 to Node DB.
recon_1     | 2020-04-30 10:17:28,370 [IPC Server handler 3 on 9891] INFO net.NetworkTopology: Added a new node: /default-rack/5b89f441-5e0e-47be-bcfd-d3bb16f51446
recon_1     | 2020-04-30 10:17:28,374 [IPC Server handler 3 on 9891] INFO node.SCMNodeManager: Registered Data node : 5b89f441-5e0e-47be-bcfd-d3bb16f51446{ip: 172.21.0.8, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-30 10:17:28,374 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 5b89f441-5e0e-47be-bcfd-d3bb16f51446 to Node DB.
recon_1     | 2020-04-30 10:17:29,089 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=0ff20aa4-ed8d-4e89-83fd-22e561bc8d3a. Trying to get from SCM.
recon_1     | 2020-04-30 10:17:29,103 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 0ff20aa4-ed8d-4e89-83fd-22e561bc8d3a, Nodes: 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-30T10:17:25.653Z] to Recon pipeline metadata.
recon_1     | 2020-04-30 10:17:29,113 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 0ff20aa4-ed8d-4e89-83fd-22e561bc8d3a, Nodes: 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-30T10:17:25.653Z]
recon_1     | 2020-04-30 10:17:29,114 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline ONE PipelineID=0ff20aa4-ed8d-4e89-83fd-22e561bc8d3a reported by 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-30 10:17:29,117 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 0ff20aa4-ed8d-4e89-83fd-22e561bc8d3a, Nodes: 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:177f1f21-a347-43d4-8009-d9e07ad63890, CreationTimestamp2020-04-30T10:17:25.653Z] moved to OPEN state
recon_1     | 2020-04-30 10:17:29,187 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=dd308256-9ce4-4caf-8c14-e1c5363fafa0. Trying to get from SCM.
recon_1     | 2020-04-30 10:17:29,193 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: dd308256-9ce4-4caf-8c14-e1c5363fafa0, Nodes: 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}2808343e-73e1-468b-b9f7-baa519ba89e8{ip: 172.21.0.6, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}5b89f441-5e0e-47be-bcfd-d3bb16f51446{ip: 172.21.0.8, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-30T10:17:26.416Z] to Recon pipeline metadata.
recon_1     | 2020-04-30 10:17:29,195 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: dd308256-9ce4-4caf-8c14-e1c5363fafa0, Nodes: 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}2808343e-73e1-468b-b9f7-baa519ba89e8{ip: 172.21.0.6, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}5b89f441-5e0e-47be-bcfd-d3bb16f51446{ip: 172.21.0.8, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-30T10:17:26.416Z]
recon_1     | 2020-04-30 10:17:29,196 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=dd308256-9ce4-4caf-8c14-e1c5363fafa0 reported by 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-30 10:17:30,292 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=69428426-33f6-4e5b-8e95-fa85fc79629e. Trying to get from SCM.
recon_1     | 2020-04-30 10:17:30,295 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 69428426-33f6-4e5b-8e95-fa85fc79629e, Nodes: 5b89f441-5e0e-47be-bcfd-d3bb16f51446{ip: 172.21.0.8, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:5b89f441-5e0e-47be-bcfd-d3bb16f51446, CreationTimestamp2020-04-30T10:17:26.400Z] to Recon pipeline metadata.
recon_1     | 2020-04-30 10:17:30,296 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 69428426-33f6-4e5b-8e95-fa85fc79629e, Nodes: 5b89f441-5e0e-47be-bcfd-d3bb16f51446{ip: 172.21.0.8, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:5b89f441-5e0e-47be-bcfd-d3bb16f51446, CreationTimestamp2020-04-30T10:17:26.400Z]
recon_1     | 2020-04-30 10:17:30,453 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=dd308256-9ce4-4caf-8c14-e1c5363fafa0 reported by 5b89f441-5e0e-47be-bcfd-d3bb16f51446{ip: 172.21.0.8, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-30 10:17:34,242 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=dd308256-9ce4-4caf-8c14-e1c5363fafa0 reported by 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-30 10:17:34,465 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=dd308256-9ce4-4caf-8c14-e1c5363fafa0 reported by 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-30 10:17:35,609 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=dd308256-9ce4-4caf-8c14-e1c5363fafa0 reported by 5b89f441-5e0e-47be-bcfd-d3bb16f51446{ip: 172.21.0.8, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-30 10:17:44,003 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ozone_datanode_2.ozone_default.
recon_1     | 2020-04-30 10:17:44,051 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1     | 2020-04-30 10:18:24,066 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-30 10:18:24,066 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1     | 2020-04-30 10:18:24,204 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1588241904067
recon_1     | 2020-04-30 10:18:24,234 [pool-10-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1588241904067.
recon_1     | 2020-04-30 10:18:24,249 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
recon_1     | 2020-04-30 10:18:24,250 [pool-11-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1     | 2020-04-30 10:18:24,277 [pool-11-thread-1] INFO impl.ContainerDBServiceProviderImpl: Creating new Recon Container DB at /data/metadata/recon/recon-container-key.db_1588241904250
recon_1     | 2020-04-30 10:18:24,278 [pool-11-thread-1] INFO impl.ContainerDBServiceProviderImpl: Cleaning up old Recon Container DB at /data/metadata/recon/recon-container-key.db_1588241828964.
recon_1     | 2020-04-30 10:18:24,329 [pool-11-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
recon_1     | 2020-04-30 10:18:24,329 [pool-11-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.079 seconds to process 102 keys.
recon_1     | 2020-04-30 10:18:24,505 [pool-11-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
recon_1     | 2020-04-30 10:18:44,002 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=dd308256-9ce4-4caf-8c14-e1c5363fafa0 reported by 5b89f441-5e0e-47be-bcfd-d3bb16f51446{ip: 172.21.0.8, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-30 10:18:44,073 [IPC Server handler 5 on 9891] INFO net.NetworkTopology: Added a new node: /default-rack/2808343e-73e1-468b-b9f7-baa519ba89e8
recon_1     | 2020-04-30 10:18:44,073 [IPC Server handler 5 on 9891] INFO node.SCMNodeManager: Registered Data node : 2808343e-73e1-468b-b9f7-baa519ba89e8{ip: 172.21.0.6, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-30 10:18:44,073 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 2808343e-73e1-468b-b9f7-baa519ba89e8 to Node DB.
recon_1     | 2020-04-30 10:18:44,073 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=dd308256-9ce4-4caf-8c14-e1c5363fafa0 reported by 2808343e-73e1-468b-b9f7-baa519ba89e8{ip: 172.21.0.6, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-04-30 10:18:44,073 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: dd308256-9ce4-4caf-8c14-e1c5363fafa0, Nodes: 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}2808343e-73e1-468b-b9f7-baa519ba89e8{ip: 172.21.0.6, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}5b89f441-5e0e-47be-bcfd-d3bb16f51446{ip: 172.21.0.8, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:177f1f21-a347-43d4-8009-d9e07ad63890, CreationTimestamp2020-04-30T10:17:26.416Z] moved to OPEN state
scm_1       | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-04-30 10:17:03,054 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = ce7a7b0cae2c/172.21.0.5
scm_1       | STARTUP_MSG:   args = [--init]
scm_1       | STARTUP_MSG:   version = 3.2.0
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
s3g_1       | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
s3g_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1       | 2020-04-30 10:17:02,690 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1       | 2020-04-30 10:17:02,844 [main] INFO util.log: Logging initialized @5043ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1       | 2020-04-30 10:17:03,616 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 2020-04-30 10:17:03,778 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1       | 2020-04-30 10:17:03,832 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1       | 2020-04-30 10:17:03,833 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g_1       | 2020-04-30 10:17:03,833 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1       | 2020-04-30 10:17:03,833 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1       | 2020-04-30 10:17:04,021 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1       | 2020-04-30 10:17:04,087 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1       | 2020-04-30 10:17:04,088 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
s3g_1       | 2020-04-30 10:17:04,435 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1       | 2020-04-30 10:17:04,435 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1       | 2020-04-30 10:17:04,469 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1       | 2020-04-30 10:17:04,560 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5efa40fe{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 2020-04-30 10:17:04,574 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6e2aa843{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
s3g_1       | WARNING: An illegal reflective access operation has occurred
s3g_1       | WARNING: Illegal reflective access by org.jboss.classfilewriter.ClassFile$1 (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int)
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.jboss.classfilewriter.ClassFile$1
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1       | WARNING: All illegal access operations will be denied in a future release
s3g_1       | Apr 30, 2020 10:17:19 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1       | 
s3g_1       | 2020-04-30 10:17:19,381 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2180e789{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-0_6_0-SNAPSHOT_jar-_-any-1673388862910601883.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1       | 2020-04-30 10:17:19,412 [main] INFO server.AbstractConnector: Started ServerConnector@7905a0b8{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
s3g_1       | 2020-04-30 10:17:19,416 [main] INFO server.Server: Started @21623ms
s3g_1       | 2020-04-30 10:17:19,424 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1       | 2020-04-30 10:24:58,766 [qtp243194708-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-04-30 10:24:58,826 [qtp243194708-19] INFO endpoint.BucketEndpoint: Location is /bucket-75602
s3g_1       | 2020-04-30 10:24:59,936 [qtp243194708-14] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1       | 2020-04-30 10:24:59,974 [qtp243194708-14] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1       | 2020-04-30 10:24:59,975 [qtp243194708-14] INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
s3g_1       | 2020-04-30 10:24:59,978 [qtp243194708-14] WARN impl.MetricsSystemImpl: Sink prometheus already exists!
s3g_1       | 2020-04-30 10:25:04,904 [qtp243194708-16] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-04-30 10:25:04,913 [qtp243194708-16] INFO endpoint.BucketEndpoint: Location is /bucket-34018
s3g_1       | 2020-04-30 10:25:05,360 [qtp243194708-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-04-30 10:25:05,366 [qtp243194708-18] INFO endpoint.BucketEndpoint: Location is /bucket-34018
s3g_1       | 2020-04-30 10:25:05,815 [qtp243194708-16] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-04-30 10:25:05,817 [qtp243194708-16] ERROR endpoint.BucketEndpoint: Error in Create Bucket Request for bucket: bucket_1
s3g_1       | INVALID_BUCKET_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Invalid bucket name: bucket_1
s3g_1       | 	at org.apache.hadoop.ozone.OmUtils.validateBucketName(OmUtils.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createS3Bucket(RpcClient.java:781)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientInvocationHandler.invoke(OzoneClientInvocationHandler.java:54)
s3g_1       | 	at com.sun.proxy.$Proxy88.createS3Bucket(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.client.ObjectStore.createS3Bucket(ObjectStore.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.createS3Bucket(EndpointBase.java:114)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:208)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
recon_1     | 2020-04-30 10:18:44,074 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=fee5605e-9a0b-45e1-9a0c-30ddcc8a9052. Trying to get from SCM.
recon_1     | 2020-04-30 10:18:44,097 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: fee5605e-9a0b-45e1-9a0c-30ddcc8a9052, Nodes: 2808343e-73e1-468b-b9f7-baa519ba89e8{ip: 172.21.0.6, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:2808343e-73e1-468b-b9f7-baa519ba89e8, CreationTimestamp2020-04-30T10:17:26.227Z] to Recon pipeline metadata.
recon_1     | 2020-04-30 10:18:44,098 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: fee5605e-9a0b-45e1-9a0c-30ddcc8a9052, Nodes: 2808343e-73e1-468b-b9f7-baa519ba89e8{ip: 172.21.0.6, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:2808343e-73e1-468b-b9f7-baa519ba89e8, CreationTimestamp2020-04-30T10:17:26.227Z]
recon_1     | 2020-04-30 10:19:24,509 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-30 10:19:24,511 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-30 10:19:24,664 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 56
recon_1     | 2020-04-30 10:19:24,734 [pool-11-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 27 OM DB update event(s).
recon_1     | 2020-04-30 10:19:24,853 [pool-11-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-30 10:20:24,861 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-30 10:20:24,861 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-30 10:20:24,876 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 17
recon_1     | 2020-04-30 10:20:24,885 [pool-11-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
recon_1     | 2020-04-30 10:20:25,005 [pool-11-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-30 10:21:25,013 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-30 10:21:25,014 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-30 10:21:25,026 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 11
recon_1     | 2020-04-30 10:21:25,040 [pool-11-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 7 OM DB update event(s).
recon_1     | 2020-04-30 10:21:25,184 [pool-11-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-30 10:22:25,122 [MissingContainerTask] INFO fsck.MissingContainerTask: Missing Container task Thread took 6 milliseconds for processing 1 containers.
recon_1     | 2020-04-30 10:22:25,194 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-30 10:22:25,194 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-30 10:22:25,204 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 23
recon_1     | 2020-04-30 10:22:25,216 [pool-11-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 8 OM DB update event(s).
recon_1     | 2020-04-30 10:22:25,297 [pool-11-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-30 10:23:25,306 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-30 10:23:25,306 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-30 10:23:25,315 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 25
recon_1     | 2020-04-30 10:23:25,337 [pool-11-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 23 OM DB update event(s).
recon_1     | 2020-04-30 10:23:25,461 [pool-11-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-30 10:24:25,480 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-30 10:24:25,480 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-30 10:24:25,491 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 20
recon_1     | 2020-04-30 10:24:25,498 [pool-11-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 18 OM DB update event(s).
recon_1     | 2020-04-30 10:24:25,545 [pool-11-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-30 10:25:25,550 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-30 10:25:25,551 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-30 10:25:25,564 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 40
recon_1     | 2020-04-30 10:25:25,570 [pool-11-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
recon_1     | 2020-04-30 10:25:25,709 [pool-11-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-30 10:26:25,715 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-30 10:26:25,715 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-30 10:26:25,733 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 87
recon_1     | 2020-04-30 10:26:25,759 [pool-11-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 23 OM DB update event(s).
recon_1     | 2020-04-30 10:26:25,864 [pool-11-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-30 10:26:42,451 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #4 got from ozone_datanode_2.ozone_default.
recon_1     | 2020-04-30 10:26:42,462 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #4 to Recon.
recon_1     | 2020-04-30 10:26:42,519 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #2 got from ozone_datanode_3.ozone_default.
recon_1     | 2020-04-30 10:26:42,525 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1     | 2020-04-30 10:26:42,539 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #3 got from ozone_datanode_1.ozone_default.
recon_1     | 2020-04-30 10:26:42,548 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #3 to Recon.
recon_1     | 2020-04-30 10:27:25,128 [MissingContainerTask] INFO fsck.MissingContainerTask: Missing Container task Thread took 5 milliseconds for processing 4 containers.
recon_1     | 2020-04-30 10:27:25,869 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-04-30 10:27:25,869 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-04-30 10:27:25,875 [pool-10-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 19
recon_1     | 2020-04-30 10:27:25,896 [pool-11-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 10 OM DB update event(s).
recon_1     | 2020-04-30 10:27:25,944 [pool-11-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-04-30 10:27:26,104 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
recon_1     | 2020-04-30 10:27:26,105 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 5 milliseconds.
recon_1     | 2020-04-30 10:27:38,739 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #5 got from ozone_datanode_1.ozone_default.
recon_1     | 2020-04-30 10:27:38,746 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Exception while adding container #5 .
recon_1     | java.io.IOException: Pipeline PipelineID=b5a658ea-1128-4e03-800b-83352d01698b not found. Cannot add container #5
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.addNewContainer(ReconContainerManager.java:117)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.checkAndAddNewContainer(ReconContainerManager.java:91)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconIncrementalContainerReportHandler.onMessage(ReconIncrementalContainerReportHandler.java:68)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconIncrementalContainerReportHandler.onMessage(ReconIncrementalContainerReportHandler.java:39)
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-04-30 10:27:38,747 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] ERROR scm.ReconIncrementalContainerReportHandler: Exception while checking and adding new container.
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=b5a658ea-1128-4e03-800b-83352d01698b not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removeContainerFromPipeline(PipelineStateMap.java:352)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removeContainerFromPipeline(PipelineStateManager.java:111)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removeContainerFromPipeline(SCMPipelineManager.java:350)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.addNewContainer(ReconContainerManager.java:124)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.checkAndAddNewContainer(ReconContainerManager.java:91)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconIncrementalContainerReportHandler.onMessage(ReconIncrementalContainerReportHandler.java:68)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-04-30 10:25:08,354 [qtp243194708-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-04-30 10:25:08,363 [qtp243194708-18] INFO endpoint.BucketEndpoint: Location is /bucket-96347
s3g_1       | 2020-04-30 10:25:09,299 [qtp243194708-18] ERROR endpoint.BucketEndpoint: Exception occurred in headBucket
s3g_1       | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:107)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:81)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:256)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "etag1"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 1
om_1        |   partName: "etag2"
om_1        | }
om_1        | 
om_1        | 2020-04-30 10:25:29,862 [IPC Server handler 66 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s37c35ba70126b04fca007e4dbfab9c47cbucket: bucket-94436key: multipartKey3. Provided Part info is { etag1, 1}, where as OM has partName /s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436/multipartKey3104087048977711259
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:240)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:131)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:99)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2020-04-30 10:25:29,863 [IPC Server handler 66 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s37c35ba70126b04fca007e4dbfab9c47c"
om_1        |   bucketName: "bucket-94436"
om_1        |   keyName: "multipartKey3"
om_1        |   multipartUploadID: "cbfa8d32-f982-41ea-831c-28ccd21f2013-104087048877768858"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "hadoop"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   acls {
om_1        |     type: GROUP
om_1        |     name: "users"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1588242329861
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 1
om_1        |   partName: "etag1"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "etag2"
om_1        | }
om_1        | 
om_1        | 2020-04-30 10:25:30,316 [IPC Server handler 98 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s37c35ba70126b04fca007e4dbfab9c47cbucket: bucket-94436key: multipartKey3. Provided Part info is { etag2, 2}, where as OM has partName /s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436/multipartKey3104087049077129372
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:240)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:131)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:99)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2020-04-30 10:25:30,319 [IPC Server handler 98 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s37c35ba70126b04fca007e4dbfab9c47c"
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-04-30 10:17:03,140 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-04-30 10:17:03,764 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-30 10:17:04,144 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-da400cca-81f9-4a84-bd36-216e6c9f1a0f
scm_1       | 2020-04-30 10:17:04,242 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at ce7a7b0cae2c/172.21.0.5
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are used. Adding safer GC settings to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-04-30 10:17:15,863 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = ce7a7b0cae2c/172.21.0.5
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 3.2.0
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-04-30 10:17:15,916 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-04-30 10:17:16,906 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-30 10:17:18,643 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-04-30 10:17:19,380 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@6f15d60e
scm_1       | 2020-04-30 10:17:19,388 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1       | 2020-04-30 10:17:19,893 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1       | 2020-04-30 10:17:20,337 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       | 2020-04-30 10:17:20,390 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1       | 2020-04-30 10:17:20,569 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2020-04-30 10:17:20,577 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1       | 2020-04-30 10:17:20,750 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1       | 2020-04-30 10:17:21,920 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-04-30 10:17:21,970 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2020-04-30 10:17:22,050 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-04-30 10:17:22,053 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1       | 2020-04-30 10:17:22,077 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-04-30 10:17:22,089 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1       | 2020-04-30 10:17:22,101 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1       | 2020-04-30 10:17:22,144 [main] INFO util.log: Logging initialized @16600ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       | 2020-04-30 10:17:22,292 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2020-04-30 10:17:22,321 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1       | 2020-04-30 10:17:22,327 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       | 2020-04-30 10:17:22,328 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1       | 2020-04-30 10:17:22,328 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
scm_1       | 2020-04-30 10:17:22,328 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1       | 2020-04-30 10:17:22,601 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1       | 2020-04-30 10:17:22,787 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | 2020-04-30 10:17:22,903 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1       | 2020-04-30 10:17:22,903 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1       | 2020-04-30 10:17:23,329 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1       | 2020-04-30 10:17:23,339 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-04-30 10:17:23,358 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1       | 2020-04-30 10:17:23,592 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1       | 2020-04-30 10:17:23,593 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1       | 2020-04-30 10:17:23,605 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-04-30 10:17:23,617 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1       | 2020-04-30 10:17:23,713 [main] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1       | 2020-04-30 10:17:23,713 [main] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1       | 2020-04-30 10:17:23,724 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1       | 2020-04-30 10:17:23,728 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-04-30 10:17:23,860 [main] INFO http.HttpServer2: Jetty bound to port 9876
scm_1       | 2020-04-30 10:17:23,861 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1       | 2020-04-30 10:17:24,061 [main] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1       | 2020-04-30 10:17:24,061 [main] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2020-04-30 10:17:24,067 [main] INFO server.session: node0 Scavenging every 660000ms
scm_1       | 2020-04-30 10:17:24,117 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77b9d0c7{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1       | 2020-04-30 10:17:24,119 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6a2eea2a{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | 2020-04-30 10:17:24,151 [IPC Server handler 5 on 9861] WARN ipc.Server: IPC Server handler 5 on 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.21.0.7:42618: output error
scm_1       | 2020-04-30 10:17:24,153 [IPC Server handler 5 on 9861] INFO ipc.Server: IPC Server handler 5 on 9861 caught an exception
scm_1       | java.nio.channels.AsynchronousCloseException
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1       | 2020-04-30 10:17:24,155 [IPC Server handler 0 on 9861] WARN ipc.Server: IPC Server handler 0 on 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.21.0.6:50766: output error
scm_1       | 2020-04-30 10:17:24,155 [IPC Server handler 0 on 9861] INFO ipc.Server: IPC Server handler 0 on 9861 caught an exception
scm_1       | java.nio.channels.AsynchronousCloseException
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-04-30 10:25:11,597 [qtp243194708-16] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-04-30 10:25:11,608 [qtp243194708-16] INFO endpoint.BucketEndpoint: Location is /bucket-81102
s3g_1       | 2020-04-30 10:25:12,077 [qtp243194708-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-04-30 10:25:14,418 [qtp243194708-16] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-04-30 10:25:14,437 [qtp243194708-16] INFO endpoint.BucketEndpoint: Location is /bucket-94436
s3g_1       | 2020-04-30 10:25:22,494 [qtp243194708-18] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-94436, , key: multipartKey2
s3g_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: s37c35ba70126b04fca007e4dbfab9c47cbucket: bucket-94436key: multipartKey2
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:822)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1194)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:938)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
om_1        |   bucketName: "bucket-94436"
om_1        |   keyName: "multipartKey3"
om_1        |   multipartUploadID: "cbfa8d32-f982-41ea-831c-28ccd21f2013-104087048877768858"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "hadoop"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   acls {
om_1        |     type: GROUP
om_1        |     name: "users"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1588242330315
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 1
om_1        |   partName: "/s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436/multipartKey3104087048977711259"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "etag2"
om_1        | }
om_1        | 
om_1        | 2020-04-30 10:25:30,782 [IPC Server handler 55 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436/multipartKey3
om_1        | 2020-04-30 10:25:30,783 [IPC Server handler 55 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436
om_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s37c35ba70126b04fca007e4dbfab9c47cbucket: bucket-94436key: multipartKey3because parts are in Invalid order.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:199)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:240)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:131)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:99)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2020-04-30 10:25:30,784 [IPC Server handler 55 on 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s37c35ba70126b04fca007e4dbfab9c47c"
om_1        |   bucketName: "bucket-94436"
om_1        |   keyName: "multipartKey3"
om_1        |   multipartUploadID: "cbfa8d32-f982-41ea-831c-28ccd21f2013-104087048877768858"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "hadoop"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   acls {
om_1        |     type: GROUP
om_1        |     name: "users"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1588242330782
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 4
om_1        |   partName: "/s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436/multipartKey3104087048977711259"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "etag2"
om_1        | }
om_1        | 
om_1        | 2020-04-30 10:25:33,360 [IPC Server handler 8 on 9862] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName multipartKey5 in VolumeName/Bucket s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s37c35ba70126b04fca007e4dbfab9c47cbucket: bucket-94436key: multipartKey5
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:121)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:240)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:131)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:99)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1       | 2020-04-30 10:17:24,179 [IPC Server handler 4 on 9861] WARN ipc.Server: IPC Server handler 4 on 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.21.0.8:35534: output error
scm_1       | 2020-04-30 10:17:24,180 [IPC Server handler 4 on 9861] INFO ipc.Server: IPC Server handler 4 on 9861 caught an exception
scm_1       | java.nio.channels.AsynchronousCloseException
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1       | 2020-04-30 10:17:25,334 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1e469dfd{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-14153606400948146838.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
scm_1       | 2020-04-30 10:17:25,371 [main] INFO server.AbstractConnector: Started ServerConnector@59546cfe{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1       | 2020-04-30 10:17:25,372 [main] INFO server.Server: Started @19833ms
scm_1       | 2020-04-30 10:17:25,383 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | 2020-04-30 10:17:25,383 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1       | 2020-04-30 10:17:25,387 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1       | 2020-04-30 10:17:25,411 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7b6860f9] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2020-04-30 10:17:25,618 [IPC Server handler 3 on 9861] INFO net.NetworkTopology: Added a new node: /default-rack/177f1f21-a347-43d4-8009-d9e07ad63890
scm_1       | 2020-04-30 10:17:25,619 [IPC Server handler 3 on 9861] INFO node.SCMNodeManager: Registered Data node : 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-04-30 10:17:25,625 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1       | 2020-04-30 10:17:25,626 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-04-30 10:17:25,655 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=0ff20aa4-ed8d-4e89-83fd-22e561bc8d3a to datanode:177f1f21-a347-43d4-8009-d9e07ad63890
scm_1       | 2020-04-30 10:17:25,668 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 0ff20aa4-ed8d-4e89-83fd-22e561bc8d3a, Nodes: 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-30T10:17:25.653372Z]
scm_1       | 2020-04-30 10:17:25,671 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 1 nodes. Healthy nodes 1
scm_1       | 2020-04-30 10:17:26,217 [IPC Server handler 6 on 9861] INFO net.NetworkTopology: Added a new node: /default-rack/2808343e-73e1-468b-b9f7-baa519ba89e8
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2020-04-30 10:25:33,361 [IPC Server handler 8 on 9862] ERROR multipart.S3MultipartUploadAbortRequest: Unrecognized Result for S3MultipartUploadAbortRequest: keyArgs {
om_1        |   volumeName: "s37c35ba70126b04fca007e4dbfab9c47c"
om_1        |   bucketName: "bucket-94436"
om_1        |   keyName: "multipartKey5"
om_1        |   multipartUploadID: "random"
om_1        |   modificationTime: 1588242333359
om_1        | }
om_1        | 
om_1        | 2020-04-30 10:25:33,816 [IPC Server handler 63 on 9862] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s37c35ba70126b04fca007e4dbfab9c47c, Bucket:bucket-94436, KeymultipartKey. Exception:{}
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:372)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:314)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:217)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:240)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:131)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:99)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2020-04-30 10:26:20,578 [IPC Server handler 58 on 9862] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s37c35ba70126b04fca007e4dbfab9c47c, Bucket:bucket-67158, Keymultidelete/f4. Exception:{}
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:135)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:240)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:211)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:131)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:99)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
om_1        | 2020-04-30 10:26:41,146 [IPC Server handler 23 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-53212 for user:hadoop
om_1        | 2020-04-30 10:27:37,758 [IPC Server handler 70 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-60219 for user:hadoop
om_1        | 2020-04-30 10:27:44,914 [IPC Server handler 89 on 9862] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:hadoop
scm_1       | 2020-04-30 10:17:26,218 [IPC Server handler 6 on 9861] INFO node.SCMNodeManager: Registered Data node : 2808343e-73e1-468b-b9f7-baa519ba89e8{ip: 172.21.0.6, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-04-30 10:17:26,219 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1       | 2020-04-30 10:17:26,219 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-04-30 10:17:26,227 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fee5605e-9a0b-45e1-9a0c-30ddcc8a9052 to datanode:2808343e-73e1-468b-b9f7-baa519ba89e8
scm_1       | 2020-04-30 10:17:26,229 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: fee5605e-9a0b-45e1-9a0c-30ddcc8a9052, Nodes: 2808343e-73e1-468b-b9f7-baa519ba89e8{ip: 172.21.0.6, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-30T10:17:26.227647Z]
scm_1       | 2020-04-30 10:17:26,231 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
scm_1       | 2020-04-30 10:17:26,396 [IPC Server handler 3 on 9861] INFO net.NetworkTopology: Added a new node: /default-rack/5b89f441-5e0e-47be-bcfd-d3bb16f51446
scm_1       | 2020-04-30 10:17:26,396 [IPC Server handler 3 on 9861] INFO node.SCMNodeManager: Registered Data node : 5b89f441-5e0e-47be-bcfd-d3bb16f51446{ip: 172.21.0.8, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-04-30 10:17:26,397 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1       | 2020-04-30 10:17:26,397 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-04-30 10:17:26,398 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2020-04-30 10:17:26,398 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1       | 2020-04-30 10:17:26,401 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=69428426-33f6-4e5b-8e95-fa85fc79629e to datanode:5b89f441-5e0e-47be-bcfd-d3bb16f51446
scm_1       | 2020-04-30 10:17:26,402 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 69428426-33f6-4e5b-8e95-fa85fc79629e, Nodes: 5b89f441-5e0e-47be-bcfd-d3bb16f51446{ip: 172.21.0.8, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-30T10:17:26.400856Z]
scm_1       | 2020-04-30 10:17:26,403 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-30 10:17:26,416 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=dd308256-9ce4-4caf-8c14-e1c5363fafa0 to datanode:177f1f21-a347-43d4-8009-d9e07ad63890
scm_1       | 2020-04-30 10:17:26,416 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=dd308256-9ce4-4caf-8c14-e1c5363fafa0 to datanode:2808343e-73e1-468b-b9f7-baa519ba89e8
scm_1       | 2020-04-30 10:17:26,417 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=dd308256-9ce4-4caf-8c14-e1c5363fafa0 to datanode:5b89f441-5e0e-47be-bcfd-d3bb16f51446
scm_1       | 2020-04-30 10:17:26,418 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: dd308256-9ce4-4caf-8c14-e1c5363fafa0, Nodes: 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}2808343e-73e1-468b-b9f7-baa519ba89e8{ip: 172.21.0.6, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}5b89f441-5e0e-47be-bcfd-d3bb16f51446{ip: 172.21.0.8, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-04-30T10:17:26.416342Z]
scm_1       | 2020-04-30 10:17:26,418 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-30 10:17:29,111 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 0ff20aa4-ed8d-4e89-83fd-22e561bc8d3a, Nodes: 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:177f1f21-a347-43d4-8009-d9e07ad63890, CreationTimestamp2020-04-30T10:17:25.653372Z] moved to OPEN state
scm_1       | 2020-04-30 10:17:29,122 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-04-30 10:17:29,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-04-30 10:17:30,100 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: fee5605e-9a0b-45e1-9a0c-30ddcc8a9052, Nodes: 2808343e-73e1-468b-b9f7-baa519ba89e8{ip: 172.21.0.6, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:2808343e-73e1-468b-b9f7-baa519ba89e8, CreationTimestamp2020-04-30T10:17:26.227647Z] moved to OPEN state
scm_1       | 2020-04-30 10:17:30,101 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-04-30 10:17:30,101 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-04-30 10:17:30,290 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 69428426-33f6-4e5b-8e95-fa85fc79629e, Nodes: 5b89f441-5e0e-47be-bcfd-d3bb16f51446{ip: 172.21.0.8, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:5b89f441-5e0e-47be-bcfd-d3bb16f51446, CreationTimestamp2020-04-30T10:17:26.400856Z] moved to OPEN state
scm_1       | 2020-04-30 10:17:30,293 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-04-30 10:17:30,294 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconIncrementalContainerReportHandler.onMessage(ReconIncrementalContainerReportHandler.java:39)
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 2020-04-30 10:17:34,476 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: dd308256-9ce4-4caf-8c14-e1c5363fafa0, Nodes: 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}2808343e-73e1-468b-b9f7-baa519ba89e8{ip: 172.21.0.6, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}5b89f441-5e0e-47be-bcfd-d3bb16f51446{ip: 172.21.0.8, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:177f1f21-a347-43d4-8009-d9e07ad63890, CreationTimestamp2020-04-30T10:17:26.416342Z] moved to OPEN state
scm_1       | 2020-04-30 10:17:34,477 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-04-30 10:17:34,477 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1       | 2020-04-30 10:17:34,478 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1       | 2020-04-30 10:17:34,478 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1       | 2020-04-30 10:17:34,478 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1       | 2020-04-30 10:19:20,760 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-30 10:19:20,761 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-30 10:19:29,368 [IPC Server handler 12 on 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
scm_1       | 2020-04-30 10:19:29,369 [IPC Server handler 12 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087023227306109 bcsId: 0
scm_1       | 2020-04-30 10:21:20,762 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-30 10:21:20,762 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-30 10:21:29,392 [IPC Server handler 11 on 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
scm_1       | 2020-04-30 10:21:29,393 [IPC Server handler 11 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087031842734208 bcsId: 0
scm_1       | 2020-04-30 10:21:29,393 [IPC Server handler 11 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087028981825663 bcsId: 0
scm_1       | 2020-04-30 10:22:29,410 [IPC Server handler 38 on 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 4 blocks
scm_1       | 2020-04-30 10:22:29,411 [IPC Server handler 38 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087034225688705 bcsId: 0
scm_1       | 2020-04-30 10:22:29,411 [IPC Server handler 38 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087034908639362 bcsId: 0
scm_1       | 2020-04-30 10:22:29,411 [IPC Server handler 38 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087035598602371 bcsId: 0
scm_1       | 2020-04-30 10:22:29,412 [IPC Server handler 38 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087036279980164 bcsId: 0
scm_1       | 2020-04-30 10:22:34,491 [EventQueue-Delayed safe mode statusForReplicationManager] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1       | 2020-04-30 10:22:34,510 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 15 milliseconds for processing 1 containers.
scm_1       | 2020-04-30 10:23:20,763 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-30 10:23:20,765 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-30 10:23:29,416 [IPC Server handler 38 on 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
scm_1       | 2020-04-30 10:23:29,417 [IPC Server handler 38 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087038066229381 bcsId: 0
scm_1       | 2020-04-30 10:23:29,418 [IPC Server handler 38 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087038530945158 bcsId: 0
scm_1       | 2020-04-30 10:23:29,419 [IPC Server handler 38 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087039412076679 bcsId: 0
scm_1       | 2020-04-30 10:25:20,767 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-30 10:25:20,768 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-30 10:25:29,423 [IPC Server handler 38 on 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
scm_1       | 2020-04-30 10:25:29,424 [IPC Server handler 38 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087048423800976 bcsId: 0
scm_1       | 2020-04-30 10:26:29,427 [IPC Server handler 11 on 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 9 blocks
scm_1       | 2020-04-30 10:26:29,427 [IPC Server handler 11 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087051828002982 bcsId: 0
scm_1       | 2020-04-30 10:26:29,428 [IPC Server handler 11 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087052037914791 bcsId: 0
scm_1       | 2020-04-30 10:26:29,428 [IPC Server handler 11 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087052192252072 bcsId: 0
scm_1       | 2020-04-30 10:26:29,428 [IPC Server handler 11 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087052525895849 bcsId: 0
scm_1       | 2020-04-30 10:26:29,428 [IPC Server handler 11 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087052557942954 bcsId: 0
scm_1       | 2020-04-30 10:26:29,428 [IPC Server handler 11 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087050058924187 bcsId: 0,conID: 1 locID: 104087050063904925 bcsId: 0,conID: 1 locID: 104087050063773852 bcsId: 0
scm_1       | 2020-04-30 10:26:29,428 [IPC Server handler 11 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087049077457047 bcsId: 0
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-04-30 10:25:23,477 [qtp243194708-18] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-94436, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s37c35ba70126b04fca007e4dbfab9c47cbucket: bucket-94436key: multipartKey3
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:822)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1194)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:938)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
scm_1       | 2020-04-30 10:26:29,428 [IPC Server handler 11 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087049655550105 bcsId: 0
scm_1       | 2020-04-30 10:26:29,428 [IPC Server handler 11 on 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104087049869656218 bcsId: 0
scm_1       | 2020-04-30 10:27:20,771 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-04-30 10:27:20,772 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-04-30 10:27:34,510 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 4 containers.
scm_1       | 2020-04-30 10:27:37,791 [IPC Server handler 67 on 9863] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: b5a658ea-1128-4e03-800b-83352d01698b, Nodes: 177f1f21-a347-43d4-8009-d9e07ad63890{ip: 172.21.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN, leaderId:null, CreationTimestamp2020-04-30T10:27:37.791141Z]
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-04-30 10:25:23,932 [qtp243194708-16] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-94436, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s37c35ba70126b04fca007e4dbfab9c47cbucket: bucket-94436key: multipartKey3
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:822)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1194)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:938)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-04-30 10:25:29,865 [qtp243194708-18] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-94436, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s37c35ba70126b04fca007e4dbfab9c47cbucket: bucket-94436key: multipartKey3. Provided Part info is { etag1, 1}, where as OM has partName /s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436/multipartKey3104087048977711259
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:822)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1194)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:938)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-04-30 10:25:30,323 [qtp243194708-18] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-94436, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s37c35ba70126b04fca007e4dbfab9c47cbucket: bucket-94436key: multipartKey3. Provided Part info is { etag2, 2}, where as OM has partName /s37c35ba70126b04fca007e4dbfab9c47c/bucket-94436/multipartKey3104087049077129372
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:822)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1194)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:938)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-04-30 10:25:30,786 [qtp243194708-16] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-94436, , key: multipartKey3
s3g_1       | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s37c35ba70126b04fca007e4dbfab9c47cbucket: bucket-94436key: multipartKey3because parts are in Invalid order.
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:822)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:1194)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:938)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1626)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-04-30 10:25:59,804 [qtp243194708-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-04-30 10:25:59,809 [qtp243194708-18] INFO endpoint.BucketEndpoint: Location is /bucket-14482
s3g_1       | 2020-04-30 10:26:00,254 [qtp243194708-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-04-30 10:26:00,264 [qtp243194708-20] INFO endpoint.BucketEndpoint: Location is /destbucket-45454
s3g_1       | 2020-04-30 10:26:07,514 [qtp243194708-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-04-30 10:26:07,518 [qtp243194708-20] INFO endpoint.BucketEndpoint: Location is /bucket-43629
s3g_1       | 2020-04-30 10:26:18,159 [qtp243194708-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-04-30 10:26:18,164 [qtp243194708-18] INFO endpoint.BucketEndpoint: Location is /bucket-67158
s3g_1       | 2020-04-30 10:26:23,334 [qtp243194708-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-04-30 10:26:23,390 [qtp243194708-20] INFO endpoint.BucketEndpoint: Location is /bucket-90970
s3g_1       | 2020-04-30 10:26:35,232 [qtp243194708-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-04-30 10:26:35,237 [qtp243194708-18] INFO endpoint.BucketEndpoint: Location is /bucket-79296
