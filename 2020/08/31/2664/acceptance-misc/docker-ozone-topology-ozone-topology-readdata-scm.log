Attaching to ozone-topology_datanode_4_1, ozone-topology_datanode_5_1, ozone-topology_datanode_6_1, ozone-topology_datanode_2_1, ozone-topology_scm_1, ozone-topology_om_1, ozone-topology_datanode_3_1, ozone-topology_datanode_1_1
datanode_2_1  | Enabled profiling in kernel
datanode_2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2_1  | 2020-08-31 09:11:33,628 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2_1  | /************************************************************
datanode_2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2_1  | STARTUP_MSG:   host = d58915730696/10.5.0.5
datanode_2_1  | STARTUP_MSG:   args = []
datanode_2_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_2_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/0ec1a8a011043711372c3f3a48ee4035beed641f ; compiled by 'runner' on 2020-08-31T08:37Z
datanode_2_1  | STARTUP_MSG:   java = 11.0.7
datanode_2_1  | ************************************************************/
datanode_2_1  | 2020-08-31 09:11:33,736 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2_1  | 2020-08-31 09:11:36,362 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2_1  | 2020-08-31 09:11:37,376 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2_1  | 2020-08-31 09:11:38,542 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2_1  | 2020-08-31 09:11:38,542 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2_1  | 2020-08-31 09:11:39,372 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:d58915730696 ip:10.5.0.5
datanode_2_1  | 2020-08-31 09:11:40,654 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2_1  | 2020-08-31 09:11:40,658 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2_1  | 2020-08-31 09:11:40,668 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2_1  | 2020-08-31 09:11:40,724 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2_1  | 2020-08-31 09:11:41,119 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2_1  | 2020-08-31 09:11:41,785 [Thread-6] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_2_1  | 2020-08-31 09:11:41,809 [Thread-6] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_2_1  | 2020-08-31 09:11:41,811 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_2_1  | 2020-08-31 09:11:50,063 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2_1  | 2020-08-31 09:11:50,680 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2_1  | 2020-08-31 09:11:51,656 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2_1  | 2020-08-31 09:11:51,672 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2_1  | 2020-08-31 09:11:51,685 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-08-31 09:11:51,687 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2_1  | 2020-08-31 09:11:51,688 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-08-31 09:11:54,609 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-08-31 09:11:54,641 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2_1  | 2020-08-31 09:11:56,193 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2_1  | 2020-08-31 09:11:56,522 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2_1  | 2020-08-31 09:11:56,770 [main] INFO util.log: Logging initialized @31624ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2_1  | 2020-08-31 09:11:57,683 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2_1  | 2020-08-31 09:11:57,810 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2_1  | 2020-08-31 09:11:57,863 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2_1  | 2020-08-31 09:11:57,871 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2_1  | 2020-08-31 09:11:57,897 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2_1  | 2020-08-31 09:11:57,897 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2_1  | 2020-08-31 09:11:58,250 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2_1  | 2020-08-31 09:11:58,354 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2_1  | 2020-08-31 09:11:58,362 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_2_1  | 2020-08-31 09:11:58,591 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2_1  | 2020-08-31 09:11:58,606 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2_1  | 2020-08-31 09:11:58,608 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2_1  | 2020-08-31 09:11:58,703 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77ff14ce{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2_1  | 2020-08-31 09:11:58,717 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6caa4dc5{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2_1  | 2020-08-31 09:11:59,654 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4a520f05{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-9410517674899037758.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2_1  | 2020-08-31 09:11:59,714 [main] INFO server.AbstractConnector: Started ServerConnector@4c030fe1{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2_1  | 2020-08-31 09:11:59,715 [main] INFO server.Server: Started @34568ms
datanode_2_1  | 2020-08-31 09:11:59,757 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2_1  | 2020-08-31 09:11:59,757 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2_1  | 2020-08-31 09:11:59,782 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2_1  | 2020-08-31 09:11:59,991 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7f77294d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2_1  | 2020-08-31 09:12:01,506 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2_1  | 2020-08-31 09:12:03,575 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-08-31 09:12:04,576 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-08-31 09:12:05,577 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-08-31 09:12:06,578 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-08-31 09:12:07,580 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-08-31 09:12:08,240 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 2 seconds.
datanode_2_1  | 2020-08-31 09:12:08,623 [Datanode State Machine Task Thread - 1] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2_1  | java.net.SocketTimeoutException: Call From d58915730696/10.5.0.5 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:57074 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_2_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:57074 remote=scm/10.5.0.71:9861]
datanode_2_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_2_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_2_1  | 2020-08-31 09:12:09,982 [Datanode State Machine Task Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2_1  | 2020-08-31 09:12:09,985 [Datanode State Machine Task Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2_1  | 2020-08-31 09:12:10,011 [Datanode State Machine Task Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa at port 9858
datanode_2_1  | 2020-08-31 09:12:10,197 [Datanode State Machine Task Thread - 0] INFO impl.RaftServerProxy: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: start RPC server
datanode_2_1  | 2020-08-31 09:12:10,789 [Datanode State Machine Task Thread - 0] INFO server.GrpcService: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2_1  | 2020-08-31 09:12:15,409 [Command processor thread] INFO impl.RaftServerProxy: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: addNew group-6B2584A28C31:[9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858] returns group-6B2584A28C31:java.util.concurrent.CompletableFuture@55bd5dc[Not completed]
datanode_2_1  | 2020-08-31 09:12:15,551 [pool-19-thread-1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: new RaftServerImpl for group-6B2584A28C31:[9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-08-31 09:12:15,564 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-08-31 09:12:15,589 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-08-31 09:12:15,589 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-08-31 09:12:15,601 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-08-31 09:12:15,601 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-08-31 09:12:15,679 [pool-19-thread-1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31: ConfigurationManager, init=-1: [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-08-31 09:12:15,679 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-08-31 09:12:15,798 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-08-31 09:12:16,114 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/32735a0c-b4d9-4bc0-babf-6b2584a28c31 does not exist. Creating ...
datanode_2_1  | 2020-08-31 09:12:16,205 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/32735a0c-b4d9-4bc0-babf-6b2584a28c31/in_use.lock acquired by nodename 6@d58915730696
datanode_2_1  | 2020-08-31 09:12:16,243 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/32735a0c-b4d9-4bc0-babf-6b2584a28c31 has been successfully formatted.
datanode_2_1  | 2020-08-31 09:12:16,273 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-6B2584A28C31: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-08-31 09:12:16,274 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2_1  | 2020-08-31 09:12:16,285 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_2_1  | java.lang.InterruptedException: sleep interrupted
datanode_2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | 2020-08-31 09:12:16,292 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-08-31 09:12:16,371 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-08-31 09:12:16,406 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31
datanode_4_1  | Enabled profiling in kernel
datanode_4_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_4_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_4_1  | 2020-08-31 09:11:36,218 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_4_1  | /************************************************************
datanode_4_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_4_1  | STARTUP_MSG:   host = f7156b6193a5/10.5.0.7
datanode_4_1  | STARTUP_MSG:   args = []
datanode_4_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_4_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_4_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/0ec1a8a011043711372c3f3a48ee4035beed641f ; compiled by 'runner' on 2020-08-31T08:37Z
datanode_4_1  | STARTUP_MSG:   java = 11.0.7
datanode_4_1  | ************************************************************/
datanode_4_1  | 2020-08-31 09:11:36,314 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_4_1  | 2020-08-31 09:11:38,192 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_4_1  | 2020-08-31 09:11:39,211 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_4_1  | 2020-08-31 09:11:40,325 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_4_1  | 2020-08-31 09:11:40,325 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_4_1  | 2020-08-31 09:11:41,170 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:f7156b6193a5 ip:10.5.0.7
datanode_4_1  | 2020-08-31 09:11:42,475 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_4_1  | 2020-08-31 09:11:42,517 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_4_1  | 2020-08-31 09:11:42,554 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_4_1  | 2020-08-31 09:11:42,632 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_4_1  | 2020-08-31 09:11:42,969 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_4_1  | 2020-08-31 09:11:43,718 [Thread-6] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_4_1  | 2020-08-31 09:11:43,725 [Thread-6] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_4_1  | 2020-08-31 09:11:43,725 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_4_1  | 2020-08-31 09:11:52,665 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4_1  | 2020-08-31 09:11:53,403 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_4_1  | 2020-08-31 09:11:54,366 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_4_1  | 2020-08-31 09:11:54,373 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_4_1  | 2020-08-31 09:11:54,374 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-08-31 09:11:54,386 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_4_1  | 2020-08-31 09:11:54,389 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 2020-08-31 09:11:57,023 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-08-31 09:11:57,077 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4_1  | 2020-08-31 09:11:58,900 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_4_1  | 2020-08-31 09:11:59,154 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_4_1  | 2020-08-31 09:11:59,508 [main] INFO util.log: Logging initialized @32382ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_4_1  | 2020-08-31 09:12:00,533 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_4_1  | 2020-08-31 09:12:00,573 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_4_1  | 2020-08-31 09:12:00,631 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_4_1  | 2020-08-31 09:12:00,638 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_4_1  | 2020-08-31 09:12:00,661 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_4_1  | 2020-08-31 09:12:00,662 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_4_1  | 2020-08-31 09:12:01,014 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_4_1  | 2020-08-31 09:12:01,063 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_4_1  | 2020-08-31 09:12:01,072 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_4_1  | 2020-08-31 09:12:01,334 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_4_1  | 2020-08-31 09:12:01,340 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_4_1  | 2020-08-31 09:12:01,342 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_4_1  | 2020-08-31 09:12:01,413 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@10b87ff6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_4_1  | 2020-08-31 09:12:01,432 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@41938e1e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_4_1  | 2020-08-31 09:12:02,139 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@595ec862{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-3165913741126805608.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_4_1  | 2020-08-31 09:12:02,269 [main] INFO server.AbstractConnector: Started ServerConnector@105dc04d{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_4_1  | 2020-08-31 09:12:02,277 [main] INFO server.Server: Started @35152ms
datanode_4_1  | 2020-08-31 09:12:02,288 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_4_1  | 2020-08-31 09:12:02,298 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_4_1  | 2020-08-31 09:12:02,303 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_4_1  | 2020-08-31 09:12:02,503 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@ec5ecac] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_4_1  | 2020-08-31 09:12:03,602 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_4_1  | 2020-08-31 09:12:05,793 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-08-31 09:12:06,794 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-08-31 09:12:07,795 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-08-31 09:12:08,821 [Datanode State Machine Task Thread - 1] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_4_1  | java.net.SocketTimeoutException: Call From f7156b6193a5/10.5.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:51910 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_4_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_4_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_4_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:51910 remote=scm/10.5.0.71:9861]
datanode_4_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_4_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_4_1  | 2020-08-31 09:12:09,958 [Datanode State Machine Task Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_4_1  | 2020-08-31 09:12:09,976 [Datanode State Machine Task Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_4_1  | 2020-08-31 09:12:09,981 [Datanode State Machine Task Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051 at port 9858
datanode_4_1  | 2020-08-31 09:12:10,150 [Datanode State Machine Task Thread - 0] INFO impl.RaftServerProxy: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: start RPC server
datanode_4_1  | 2020-08-31 09:12:10,753 [Datanode State Machine Task Thread - 0] INFO server.GrpcService: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_4_1  | 2020-08-31 09:12:16,093 [Command processor thread] INFO impl.RaftServerProxy: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: addNew group-923D69527124:[1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858] returns group-923D69527124:java.util.concurrent.CompletableFuture@46e829c5[Not completed]
datanode_4_1  | 2020-08-31 09:12:16,440 [pool-19-thread-1] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: new RaftServerImpl for group-923D69527124:[1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-08-31 09:12:16,482 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-08-31 09:12:16,483 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-08-31 09:12:16,484 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-08-31 09:12:16,485 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-08-31 09:12:16,489 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-08-31 09:12:16,535 [pool-19-thread-1] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124: ConfigurationManager, init=-1: [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-08-31 09:12:16,562 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-08-31 09:12:16,576 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-08-31 09:12:16,601 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a40e8651-2594-4500-a3cd-923d69527124 does not exist. Creating ...
datanode_4_1  | 2020-08-31 09:12:16,649 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a40e8651-2594-4500-a3cd-923d69527124/in_use.lock acquired by nodename 6@f7156b6193a5
datanode_4_1  | 2020-08-31 09:12:16,669 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a40e8651-2594-4500-a3cd-923d69527124 has been successfully formatted.
datanode_4_1  | 2020-08-31 09:12:16,701 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-923D69527124: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-08-31 09:12:16,709 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_4_1  | 2020-08-31 09:12:16,714 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-08-31 09:12:16,732 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_4_1  | java.lang.InterruptedException: sleep interrupted
datanode_4_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_5_1  | Enabled profiling in kernel
datanode_5_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_5_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_5_1  | 2020-08-31 09:11:34,905 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_5_1  | /************************************************************
datanode_5_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_5_1  | STARTUP_MSG:   host = 8bb706c33d66/10.5.0.8
datanode_5_1  | STARTUP_MSG:   args = []
datanode_5_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_5_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_5_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/0ec1a8a011043711372c3f3a48ee4035beed641f ; compiled by 'runner' on 2020-08-31T08:37Z
datanode_5_1  | STARTUP_MSG:   java = 11.0.7
datanode_5_1  | ************************************************************/
datanode_5_1  | 2020-08-31 09:11:35,002 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_5_1  | 2020-08-31 09:11:37,155 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_5_1  | 2020-08-31 09:11:38,237 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_5_1  | 2020-08-31 09:11:39,929 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_5_1  | 2020-08-31 09:11:39,929 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_5_1  | 2020-08-31 09:11:40,917 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:8bb706c33d66 ip:10.5.0.8
datanode_5_1  | 2020-08-31 09:11:42,482 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_5_1  | 2020-08-31 09:11:42,541 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_5_1  | 2020-08-31 09:11:42,567 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_5_1  | 2020-08-31 09:11:42,635 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_5_1  | 2020-08-31 09:11:43,145 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_5_1  | 2020-08-31 09:11:43,706 [Thread-6] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_5_1  | 2020-08-31 09:11:43,707 [Thread-6] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_5_1  | 2020-08-31 09:11:43,716 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_5_1  | 2020-08-31 09:11:51,975 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5_1  | 2020-08-31 09:11:52,575 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_5_1  | 2020-08-31 09:11:53,601 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_5_1  | 2020-08-31 09:11:53,610 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_5_1  | 2020-08-31 09:11:53,614 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-08-31 09:11:53,637 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_5_1  | 2020-08-31 09:11:53,641 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-08-31 09:11:55,979 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-08-31 09:11:56,049 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5_1  | 2020-08-31 09:11:57,717 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_5_1  | 2020-08-31 09:11:57,876 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_5_1  | 2020-08-31 09:11:58,210 [main] INFO util.log: Logging initialized @32196ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_5_1  | 2020-08-31 09:11:59,280 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_5_1  | 2020-08-31 09:11:59,326 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_5_1  | 2020-08-31 09:11:59,391 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_5_1  | 2020-08-31 09:11:59,403 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_5_1  | 2020-08-31 09:11:59,403 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_5_1  | 2020-08-31 09:11:59,403 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_5_1  | 2020-08-31 09:11:59,762 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_5_1  | 2020-08-31 09:11:59,800 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_5_1  | 2020-08-31 09:11:59,818 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_5_1  | 2020-08-31 09:12:00,085 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_5_1  | 2020-08-31 09:12:00,085 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_5_1  | 2020-08-31 09:12:00,102 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_5_1  | 2020-08-31 09:12:00,182 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1f0e2bdc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_5_1  | 2020-08-31 09:12:00,192 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@134c38{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_5_1  | 2020-08-31 09:12:01,201 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@629cbb1{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-8276318036974304750.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_5_1  | 2020-08-31 09:12:01,283 [main] INFO server.AbstractConnector: Started ServerConnector@59d5c537{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_5_1  | 2020-08-31 09:12:01,285 [main] INFO server.Server: Started @35272ms
datanode_5_1  | 2020-08-31 09:12:01,317 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_5_1  | 2020-08-31 09:12:01,317 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_5_1  | 2020-08-31 09:12:01,325 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_5_1  | 2020-08-31 09:12:01,547 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5882ea97] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_5_1  | 2020-08-31 09:12:02,954 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_5_1  | 2020-08-31 09:12:04,983 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-08-31 09:12:05,984 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | Enabled profiling in kernel
datanode_1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1_1  | 2020-08-31 09:11:33,727 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1_1  | /************************************************************
datanode_1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1_1  | STARTUP_MSG:   host = e2f9588ed766/10.5.0.4
datanode_1_1  | STARTUP_MSG:   args = []
datanode_1_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_1_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/0ec1a8a011043711372c3f3a48ee4035beed641f ; compiled by 'runner' on 2020-08-31T08:37Z
datanode_1_1  | STARTUP_MSG:   java = 11.0.7
datanode_1_1  | ************************************************************/
datanode_1_1  | 2020-08-31 09:11:33,847 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1_1  | 2020-08-31 09:11:35,890 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1_1  | 2020-08-31 09:11:36,843 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1_1  | 2020-08-31 09:11:38,611 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1_1  | 2020-08-31 09:11:38,611 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1_1  | 2020-08-31 09:11:39,476 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:e2f9588ed766 ip:10.5.0.4
datanode_1_1  | 2020-08-31 09:11:40,929 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1_1  | 2020-08-31 09:11:40,965 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1_1  | 2020-08-31 09:11:40,984 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1_1  | 2020-08-31 09:11:41,110 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1_1  | 2020-08-31 09:11:41,537 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1_1  | 2020-08-31 09:11:42,166 [Thread-6] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_1_1  | 2020-08-31 09:11:42,209 [Thread-6] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_1_1  | 2020-08-31 09:11:42,209 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_1_1  | 2020-08-31 09:11:51,222 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1_1  | 2020-08-31 09:11:51,666 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1_1  | 2020-08-31 09:11:52,228 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1_1  | 2020-08-31 09:11:52,256 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1_1  | 2020-08-31 09:11:52,260 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-08-31 09:11:52,265 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1_1  | 2020-08-31 09:11:52,270 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-08-31 09:11:54,053 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-08-31 09:11:54,094 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1_1  | 2020-08-31 09:11:56,025 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1_1  | 2020-08-31 09:11:56,175 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1_1  | 2020-08-31 09:11:56,442 [main] INFO util.log: Logging initialized @30947ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1_1  | 2020-08-31 09:11:57,252 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1_1  | 2020-08-31 09:11:57,313 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1_1  | 2020-08-31 09:11:57,359 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1_1  | 2020-08-31 09:11:57,385 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1_1  | 2020-08-31 09:11:57,393 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1_1  | 2020-08-31 09:11:57,393 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1_1  | 2020-08-31 09:11:57,670 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1_1  | 2020-08-31 09:11:57,707 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1_1  | 2020-08-31 09:11:57,756 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_1_1  | 2020-08-31 09:11:57,964 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1_1  | 2020-08-31 09:11:57,980 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1_1  | 2020-08-31 09:11:57,983 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_1_1  | 2020-08-31 09:11:58,107 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1f408ab6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1_1  | 2020-08-31 09:11:58,125 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@26463a6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1_1  | 2020-08-31 09:11:58,971 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7462ba4b{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-4155573512304151373.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1_1  | 2020-08-31 09:11:59,034 [main] INFO server.AbstractConnector: Started ServerConnector@23469199{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1_1  | 2020-08-31 09:11:59,037 [main] INFO server.Server: Started @33545ms
datanode_1_1  | 2020-08-31 09:11:59,084 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1_1  | 2020-08-31 09:11:59,084 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1_1  | 2020-08-31 09:11:59,089 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1_1  | 2020-08-31 09:11:59,474 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@178e67bc] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1_1  | 2020-08-31 09:12:01,041 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1_1  | 2020-08-31 09:12:02,884 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-08-31 09:12:03,886 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-08-31 09:12:04,887 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-08-31 09:12:05,889 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-08-31 09:12:06,890 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-08-31 09:12:07,569 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 2 seconds.
datanode_1_1  | 2020-08-31 09:12:07,891 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-08-31 09:12:08,911 [Datanode State Machine Task Thread - 1] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_1_1  | java.net.SocketTimeoutException: Call From e2f9588ed766/10.5.0.4 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.4:35534 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_1_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_1_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.4:35534 remote=scm/10.5.0.71:9861]
datanode_1_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2_1  | 2020-08-31 09:12:16,514 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-08-31 09:12:16,516 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-08-31 09:12:16,646 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-08-31 09:12:16,669 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/32735a0c-b4d9-4bc0-babf-6b2584a28c31
datanode_2_1  | 2020-08-31 09:12:16,720 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-08-31 09:12:16,721 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-08-31 09:12:16,721 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-08-31 09:12:16,722 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-08-31 09:12:16,722 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-08-31 09:12:16,744 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-08-31 09:12:16,756 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-08-31 09:12:16,756 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-08-31 09:12:16,757 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-08-31 09:12:16,831 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-08-31 09:12:16,895 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-08-31 09:12:16,895 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-08-31 09:12:16,922 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-08-31 09:12:16,922 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-08-31 09:12:16,923 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-08-31 09:12:16,940 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-08-31 09:12:16,940 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-08-31 09:12:17,195 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31
datanode_2_1  | 2020-08-31 09:12:17,222 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31
datanode_2_1  | 2020-08-31 09:12:17,244 [pool-19-thread-1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31: start as a follower, conf=-1: [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null
datanode_2_1  | 2020-08-31 09:12:17,318 [pool-19-thread-1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-08-31 09:12:17,322 [pool-19-thread-1] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: start FollowerState
datanode_2_1  | 2020-08-31 09:12:17,375 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6B2584A28C31,id=9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa
datanode_2_1  | 2020-08-31 09:12:17,382 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31
datanode_2_1  | 2020-08-31 09:12:17,563 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "32735a0c-b4d9-4bc0-babf-6b2584a28c31"
datanode_2_1  | uuid128 {
datanode_2_1  |   mostSigBits: 3635348334838369216
datanode_2_1  |   leastSigBits: -4990152053220013007
datanode_2_1  | }
datanode_2_1  | .
datanode_2_1  | 2020-08-31 09:12:17,579 [Command processor thread] INFO impl.RaftServerProxy: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: addNew group-691DB78430A7:[d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858] returns group-691DB78430A7:java.util.concurrent.CompletableFuture@340cd82b[Not completed]
datanode_2_1  | 2020-08-31 09:12:17,627 [pool-19-thread-1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: new RaftServerImpl for group-691DB78430A7:[d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-08-31 09:12:17,665 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-08-31 09:12:17,668 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-08-31 09:12:17,668 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-08-31 09:12:17,668 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-08-31 09:12:17,669 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-08-31 09:12:16,743 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-08-31 09:12:16,817 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124
datanode_4_1  | 2020-08-31 09:12:16,930 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-08-31 09:12:16,932 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-08-31 09:12:17,064 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-08-31 09:12:17,155 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/a40e8651-2594-4500-a3cd-923d69527124
datanode_4_1  | 2020-08-31 09:12:17,169 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-08-31 09:12:17,173 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-08-31 09:12:17,176 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-08-31 09:12:17,185 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-08-31 09:12:17,191 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-08-31 09:12:17,193 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-08-31 09:12:17,202 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-08-31 09:12:17,209 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-08-31 09:12:17,213 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-08-31 09:12:17,383 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-08-31 09:12:17,560 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-08-31 09:12:17,565 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-08-31 09:12:17,616 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-08-31 09:12:17,673 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-08-31 09:12:17,709 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-08-31 09:12:17,711 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-08-31 09:12:17,717 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-08-31 09:12:17,961 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124
datanode_4_1  | 2020-08-31 09:12:18,039 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124
datanode_4_1  | 2020-08-31 09:12:18,128 [pool-19-thread-1] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124: start as a follower, conf=-1: [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null
datanode_4_1  | 2020-08-31 09:12:18,133 [pool-19-thread-1] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-08-31 09:12:18,164 [pool-19-thread-1] INFO impl.RoleInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: start FollowerState
datanode_4_1  | 2020-08-31 09:12:18,228 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-923D69527124,id=1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051
datanode_4_1  | 2020-08-31 09:12:18,244 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124
datanode_4_1  | 2020-08-31 09:12:18,374 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "a40e8651-2594-4500-a3cd-923d69527124"
datanode_4_1  | uuid128 {
datanode_4_1  |   mostSigBits: -6625210318734473984
datanode_4_1  |   leastSigBits: -6643493082843942620
datanode_4_1  | }
datanode_4_1  | .
datanode_4_1  | 2020-08-31 09:12:18,377 [Command processor thread] INFO impl.RaftServerProxy: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: addNew group-C67C4A012799:[1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858] returns group-C67C4A012799:java.util.concurrent.CompletableFuture@3f97dd4a[Not completed]
datanode_4_1  | 2020-08-31 09:12:18,403 [pool-19-thread-1] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: new RaftServerImpl for group-C67C4A012799:[1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-08-31 09:12:18,415 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-08-31 09:12:18,416 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-08-31 09:12:18,416 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-08-31 09:12:18,416 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-08-31 09:12:18,416 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-08-31 09:12:18,437 [pool-19-thread-1] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799: ConfigurationManager, init=-1: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-08-31 09:12:18,437 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-08-31 09:12:18,441 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-08-31 09:12:18,441 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799 does not exist. Creating ...
datanode_4_1  | 2020-08-31 09:12:18,453 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799/in_use.lock acquired by nodename 6@f7156b6193a5
datanode_4_1  | 2020-08-31 09:12:18,465 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799 has been successfully formatted.
datanode_4_1  | 2020-08-31 09:12:18,465 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_4_1  | java.lang.InterruptedException: sleep interrupted
datanode_4_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-08-31 09:12:18,467 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-C67C4A012799: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-08-31 09:12:18,469 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_4_1  | 2020-08-31 09:12:18,473 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-08-31 09:12:18,497 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-08-31 09:12:18,497 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799
datanode_4_1  | 2020-08-31 09:12:18,498 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-08-31 09:12:18,498 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-08-31 09:12:18,499 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-08-31 09:12:18,499 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799
datanode_4_1  | 2020-08-31 09:12:18,499 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-08-31 09:12:18,499 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-08-31 09:12:18,499 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-08-31 09:12:18,500 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-08-31 09:12:18,500 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-08-31 09:12:18,500 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-08-31 09:12:18,500 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-08-31 09:12:18,500 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-08-31 09:12:18,501 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-08-31 09:12:18,502 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-08-31 09:12:18,515 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-08-31 09:12:18,537 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-08-31 09:12:18,537 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-08-31 09:12:18,541 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-08-31 09:12:18,545 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-08-31 09:12:18,548 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-08-31 09:12:18,548 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-08-31 09:12:18,549 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799
datanode_4_1  | 2020-08-31 09:12:18,550 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799
datanode_4_1  | 2020-08-31 09:12:18,551 [pool-19-thread-1] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799: start as a follower, conf=-1: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null
datanode_4_1  | 2020-08-31 09:12:18,551 [pool-19-thread-1] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-08-31 09:12:18,553 [pool-19-thread-1] INFO impl.RoleInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: start FollowerState
datanode_4_1  | 2020-08-31 09:12:18,557 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C67C4A012799,id=1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051
datanode_4_1  | 2020-08-31 09:12:18,561 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799
datanode_4_1  | 2020-08-31 09:12:23,141 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "2f48de6e-e67a-4c1b-a8d1-c67c4a012799"
datanode_4_1  | uuid128 {
datanode_4_1  |   mostSigBits: 3407217686000323611
datanode_4_1  |   leastSigBits: -6282021768085297255
datanode_4_1  | }
datanode_4_1  | .
datanode_4_1  | 2020-08-31 09:12:23,361 [Thread-23] INFO impl.FollowerState: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-FollowerState: change to CANDIDATE, lastRpcTime:5198ms, electionTimeout:5136ms
datanode_4_1  | 2020-08-31 09:12:23,364 [Thread-23] INFO impl.RoleInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: shutdown FollowerState
datanode_4_1  | 2020-08-31 09:12:23,365 [Thread-23] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4_1  | 2020-08-31 09:12:23,384 [Thread-23] INFO impl.RoleInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: start LeaderElection
datanode_4_1  | 2020-08-31 09:12:23,413 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO impl.LeaderElection: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1: begin an election at term 1 for -1: [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null
datanode_4_1  | 2020-08-31 09:12:23,415 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO impl.RoleInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: shutdown LeaderElection
datanode_2_1  | 2020-08-31 09:12:17,669 [pool-19-thread-1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: ConfigurationManager, init=-1: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-08-31 09:12:17,669 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-08-31 09:12:17,669 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-08-31 09:12:17,670 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7 does not exist. Creating ...
datanode_2_1  | 2020-08-31 09:12:17,681 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/in_use.lock acquired by nodename 6@d58915730696
datanode_2_1  | 2020-08-31 09:12:17,695 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7 has been successfully formatted.
datanode_2_1  | 2020-08-31 09:12:17,696 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_2_1  | java.lang.InterruptedException
datanode_2_1  | 	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
datanode_2_1  | 	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
datanode_2_1  | 	at java.base/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:458)
datanode_2_1  | 	at java.base/java.util.concurrent.ExecutorCompletionService.poll(ExecutorCompletionService.java:209)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:218)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:450)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:227)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | 2020-08-31 09:12:17,703 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-691DB78430A7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-08-31 09:12:17,706 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2_1  | 2020-08-31 09:12:17,707 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-08-31 09:12:17,713 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-08-31 09:12:17,717 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7
datanode_2_1  | 2020-08-31 09:12:17,721 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-08-31 09:12:17,723 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-08-31 09:12:17,726 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-08-31 09:12:17,727 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7
datanode_2_1  | 2020-08-31 09:12:17,729 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-08-31 09:12:17,729 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-08-31 09:12:17,731 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-08-31 09:12:17,737 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-08-31 09:12:17,740 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-08-31 09:12:17,741 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-08-31 09:12:17,741 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-08-31 09:12:17,741 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-08-31 09:12:17,743 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-08-31 09:12:17,746 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-08-31 09:12:17,749 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-08-31 09:12:17,752 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-08-31 09:12:17,753 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-08-31 09:12:17,753 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-08-31 09:12:17,761 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-08-31 09:12:17,763 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-08-31 09:12:17,763 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-08-31 09:12:17,763 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7
datanode_2_1  | 2020-08-31 09:12:17,764 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7
datanode_2_1  | 2020-08-31 09:12:17,770 [pool-19-thread-1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: start as a follower, conf=-1: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null
datanode_2_1  | 2020-08-31 09:12:17,777 [pool-19-thread-1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-08-31 09:12:17,778 [pool-19-thread-1] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: start FollowerState
datanode_2_1  | 2020-08-31 09:12:17,833 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-691DB78430A7,id=9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa
datanode_2_1  | 2020-08-31 09:12:17,854 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7
datanode_2_1  | 2020-08-31 09:12:22,537 [Thread-23] INFO impl.FollowerState: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-FollowerState: change to CANDIDATE, lastRpcTime:5215ms, electionTimeout:5153ms
datanode_2_1  | 2020-08-31 09:12:22,558 [Thread-23] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: shutdown FollowerState
datanode_2_1  | 2020-08-31 09:12:22,576 [Thread-23] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2_1  | 2020-08-31 09:12:22,620 [Thread-23] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: start LeaderElection
datanode_2_1  | 2020-08-31 09:12:22,718 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "15c51e9f-babe-4940-b6ca-691db78430a7"
datanode_2_1  | uuid128 {
datanode_2_1  |   mostSigBits: 1568693716590152000
datanode_2_1  |   leastSigBits: -5275288437157252953
datanode_2_1  | }
datanode_2_1  | .
datanode_2_1  | 2020-08-31 09:12:22,720 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO impl.LeaderElection: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1: begin an election at term 1 for -1: [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null
datanode_2_1  | 2020-08-31 09:12:22,726 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: shutdown LeaderElection
datanode_2_1  | 2020-08-31 09:12:22,732 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2_1  | 2020-08-31 09:12:22,742 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6B2584A28C31 with new leaderId: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa
datanode_2_1  | 2020-08-31 09:12:22,755 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31: change Leader from null to 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa at term 1 for becomeLeader, leader elected after 6468ms
datanode_2_1  | 2020-08-31 09:12:22,755 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_2_1  | java.lang.InterruptedException: sleep interrupted
datanode_2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | 2020-08-31 09:12:22,837 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2_1  | 2020-08-31 09:12:22,838 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2_1  | 2020-08-31 09:12:22,855 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31
datanode_2_1  | 2020-08-31 09:12:22,874 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2_1  | 2020-08-31 09:12:22,888 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2_1  | 2020-08-31 09:12:22,963 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2_1  | 2020-08-31 09:12:22,963 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2_1  | 2020-08-31 09:12:22,985 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2_1  | 2020-08-31 09:12:23,089 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: start LeaderState
datanode_2_1  | 2020-08-31 09:12:23,096 [Thread-25] INFO impl.FollowerState: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-FollowerState: change to CANDIDATE, lastRpcTime:5317ms, electionTimeout:5179ms
datanode_2_1  | 2020-08-31 09:12:23,125 [Thread-25] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: shutdown FollowerState
datanode_2_1  | 2020-08-31 09:12:23,125 [Thread-25] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2_1  | 2020-08-31 09:12:23,125 [Thread-25] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: start LeaderElection
datanode_2_1  | 2020-08-31 09:12:23,276 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-LeaderElection2] INFO impl.LeaderElection: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-LeaderElection2: begin an election at term 1 for -1: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null
datanode_2_1  | 2020-08-31 09:12:23,648 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-08-31 09:12:23,932 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31: set configuration 0: [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-08-31 09:12:24,103 [grpc-default-executor-2] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: changes role from CANDIDATE to FOLLOWER at term 1 for appendEntries
datanode_2_1  | 2020-08-31 09:12:24,137 [grpc-default-executor-2] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: shutdown LeaderElection
datanode_2_1  | 2020-08-31 09:12:24,137 [grpc-default-executor-2] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: start FollowerState
datanode_2_1  | 2020-08-31 09:12:24,141 [grpc-default-executor-2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-691DB78430A7 with new leaderId: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c
datanode_2_1  | 2020-08-31 09:12:24,164 [grpc-default-executor-2] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: change Leader from null to 2eef5031-1d72-43cd-9aec-f2fe042a3f3c at term 1 for appendEntries, leader elected after 6435ms
datanode_2_1  | 2020-08-31 09:12:24,430 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-LeaderElection2] INFO impl.LeaderElection: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-LeaderElection2: Election REJECTED; received 2 response(s) [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa<-d42a3350-8147-4d70-91a8-098b29431c2d#0:FAIL-t1, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa<-2eef5031-1d72-43cd-9aec-f2fe042a3f3c#0:FAIL-t1] and 0 exception(s); 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7:t1, leader=2eef5031-1d72-43cd-9aec-f2fe042a3f3c, voted=9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa, raftlog=9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null
datanode_5_1  | 2020-08-31 09:12:06,985 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-08-31 09:12:07,986 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-08-31 09:12:09,009 [Datanode State Machine Task Thread - 1] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_5_1  | java.net.SocketTimeoutException: Call From 8bb706c33d66/10.5.0.8 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.8:44470 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_5_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_5_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_5_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_5_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_5_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_5_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_5_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_5_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_5_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_5_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_5_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_5_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.8:44470 remote=scm/10.5.0.71:9861]
datanode_5_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_5_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_5_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_5_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_5_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_5_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_5_1  | 2020-08-31 09:12:10,272 [Datanode State Machine Task Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_5_1  | 2020-08-31 09:12:10,282 [Datanode State Machine Task Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_5_1  | 2020-08-31 09:12:10,283 [Datanode State Machine Task Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 2eef5031-1d72-43cd-9aec-f2fe042a3f3c at port 9858
datanode_5_1  | 2020-08-31 09:12:10,403 [Datanode State Machine Task Thread - 0] INFO impl.RaftServerProxy: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: start RPC server
datanode_5_1  | 2020-08-31 09:12:11,086 [Datanode State Machine Task Thread - 0] INFO server.GrpcService: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_5_1  | 2020-08-31 09:12:14,935 [Command processor thread] INFO impl.RaftServerProxy: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: addNew group-AB0BCD82E761:[2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858] returns group-AB0BCD82E761:java.util.concurrent.CompletableFuture@10be9cb0[Not completed]
datanode_5_1  | 2020-08-31 09:12:15,103 [pool-19-thread-1] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: new RaftServerImpl for group-AB0BCD82E761:[2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-08-31 09:12:15,126 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-08-31 09:12:15,145 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-08-31 09:12:15,146 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-08-31 09:12:15,146 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-08-31 09:12:15,147 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-08-31 09:12:15,194 [pool-19-thread-1] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761: ConfigurationManager, init=-1: [2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-08-31 09:12:15,206 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-08-31 09:12:15,213 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-08-31 09:12:15,259 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c16aa0e5-9758-42e0-b015-ab0bcd82e761 does not exist. Creating ...
datanode_5_1  | 2020-08-31 09:12:15,313 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c16aa0e5-9758-42e0-b015-ab0bcd82e761/in_use.lock acquired by nodename 6@8bb706c33d66
datanode_5_1  | 2020-08-31 09:12:15,338 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c16aa0e5-9758-42e0-b015-ab0bcd82e761 has been successfully formatted.
datanode_5_1  | 2020-08-31 09:12:15,505 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-AB0BCD82E761: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-08-31 09:12:15,505 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_5_1  | java.lang.InterruptedException: sleep interrupted
datanode_5_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-08-31 09:12:15,542 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_5_1  | 2020-08-31 09:12:15,570 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-08-31 09:12:15,718 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-08-31 09:12:15,764 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761
datanode_5_1  | 2020-08-31 09:12:15,991 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-08-31 09:12:16,059 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-08-31 09:12:16,198 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-08-31 09:12:16,279 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/c16aa0e5-9758-42e0-b015-ab0bcd82e761
datanode_5_1  | 2020-08-31 09:12:16,314 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-08-31 09:12:16,314 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-08-31 09:12:16,315 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-08-31 09:12:16,315 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-08-31 09:12:16,316 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-08-31 09:12:16,316 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-08-31 09:12:16,362 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-08-31 09:12:16,362 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-08-31 09:12:16,365 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-08-31 09:12:16,523 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-08-31 09:12:16,606 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-08-31 09:12:16,609 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-08-31 09:12:16,701 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-08-31 09:12:16,711 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-08-31 09:12:16,726 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-08-31 09:12:16,746 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-08-31 09:12:16,765 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-08-31 09:12:17,074 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761
datanode_5_1  | 2020-08-31 09:12:17,102 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761
datanode_5_1  | 2020-08-31 09:12:17,124 [pool-19-thread-1] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761: start as a follower, conf=-1: [2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858], old=null
datanode_5_1  | 2020-08-31 09:12:17,169 [pool-19-thread-1] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-08-31 09:12:17,171 [pool-19-thread-1] INFO impl.RoleInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: start FollowerState
datanode_5_1  | 2020-08-31 09:12:17,281 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AB0BCD82E761,id=2eef5031-1d72-43cd-9aec-f2fe042a3f3c
datanode_5_1  | 2020-08-31 09:12:17,283 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761
datanode_5_1  | 2020-08-31 09:12:17,455 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "c16aa0e5-9758-42e0-b015-ab0bcd82e761"
datanode_5_1  | uuid128 {
datanode_5_1  |   mostSigBits: -4509615168911031584
datanode_5_1  |   leastSigBits: -5758508481342412959
datanode_3_1  | Enabled profiling in kernel
datanode_3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3_1  | 2020-08-31 09:11:36,804 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3_1  | /************************************************************
datanode_3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3_1  | STARTUP_MSG:   host = 0e7bdc6ca2ae/10.5.0.6
datanode_3_1  | STARTUP_MSG:   args = []
datanode_3_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_3_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/0ec1a8a011043711372c3f3a48ee4035beed641f ; compiled by 'runner' on 2020-08-31T08:37Z
datanode_3_1  | STARTUP_MSG:   java = 11.0.7
datanode_3_1  | ************************************************************/
datanode_3_1  | 2020-08-31 09:11:36,905 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3_1  | 2020-08-31 09:11:38,979 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3_1  | 2020-08-31 09:11:39,959 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3_1  | 2020-08-31 09:11:41,155 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3_1  | 2020-08-31 09:11:41,155 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3_1  | 2020-08-31 09:11:41,733 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:0e7bdc6ca2ae ip:10.5.0.6
datanode_3_1  | 2020-08-31 09:11:43,002 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3_1  | 2020-08-31 09:11:43,036 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3_1  | 2020-08-31 09:11:43,039 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3_1  | 2020-08-31 09:11:43,199 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3_1  | 2020-08-31 09:11:43,709 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3_1  | 2020-08-31 09:11:44,220 [Thread-6] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_3_1  | 2020-08-31 09:11:44,229 [Thread-6] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_3_1  | 2020-08-31 09:11:44,229 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_3_1  | 2020-08-31 09:11:52,425 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3_1  | 2020-08-31 09:11:52,893 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3_1  | 2020-08-31 09:11:53,600 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3_1  | 2020-08-31 09:11:53,613 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3_1  | 2020-08-31 09:11:53,621 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-08-31 09:11:53,627 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3_1  | 2020-08-31 09:11:53,634 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-08-31 09:11:55,695 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-08-31 09:11:55,703 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3_1  | 2020-08-31 09:11:57,167 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3_1  | 2020-08-31 09:11:57,327 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3_1  | 2020-08-31 09:11:57,578 [main] INFO util.log: Logging initialized @31322ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3_1  | 2020-08-31 09:11:58,390 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3_1  | 2020-08-31 09:11:58,415 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3_1  | 2020-08-31 09:11:58,470 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3_1  | 2020-08-31 09:11:58,476 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3_1  | 2020-08-31 09:11:58,495 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3_1  | 2020-08-31 09:11:58,495 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3_1  | 2020-08-31 09:11:58,785 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_3_1  | 2020-08-31 09:11:58,868 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3_1  | 2020-08-31 09:11:58,896 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_3_1  | 2020-08-31 09:11:59,232 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3_1  | 2020-08-31 09:11:59,255 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3_1  | 2020-08-31 09:11:59,265 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_3_1  | 2020-08-31 09:11:59,378 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1f0e2bdc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3_1  | 2020-08-31 09:11:59,397 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@134c38{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3_1  | 2020-08-31 09:12:00,258 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@629cbb1{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-3804957646962043190.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3_1  | 2020-08-31 09:12:00,374 [main] INFO server.AbstractConnector: Started ServerConnector@59d5c537{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3_1  | 2020-08-31 09:12:00,374 [main] INFO server.Server: Started @34118ms
datanode_3_1  | 2020-08-31 09:12:00,405 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3_1  | 2020-08-31 09:12:00,405 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3_1  | 2020-08-31 09:12:00,419 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3_1  | 2020-08-31 09:12:00,603 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2344bdb5] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3_1  | 2020-08-31 09:12:02,336 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3_1  | 2020-08-31 09:12:04,040 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-08-31 09:12:05,041 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | Enabled profiling in kernel
datanode_6_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_6_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_6_1  | 2020-08-31 09:11:36,325 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_6_1  | /************************************************************
datanode_6_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_6_1  | STARTUP_MSG:   host = 4a45e335c821/10.5.0.9
datanode_6_1  | STARTUP_MSG:   args = []
datanode_6_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_6_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_6_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/0ec1a8a011043711372c3f3a48ee4035beed641f ; compiled by 'runner' on 2020-08-31T08:37Z
datanode_6_1  | STARTUP_MSG:   java = 11.0.7
datanode_6_1  | ************************************************************/
datanode_6_1  | 2020-08-31 09:11:36,426 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_6_1  | 2020-08-31 09:11:38,423 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_6_1  | 2020-08-31 09:11:39,287 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_6_1  | 2020-08-31 09:11:40,707 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_6_1  | 2020-08-31 09:11:40,707 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_6_1  | 2020-08-31 09:11:41,536 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:4a45e335c821 ip:10.5.0.9
datanode_6_1  | 2020-08-31 09:11:43,035 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_6_1  | 2020-08-31 09:11:43,060 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_6_1  | 2020-08-31 09:11:43,064 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_6_1  | 2020-08-31 09:11:43,216 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_6_1  | 2020-08-31 09:11:43,646 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_6_1  | 2020-08-31 09:11:44,306 [Thread-6] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_6_1  | 2020-08-31 09:11:44,307 [Thread-6] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_6_1  | 2020-08-31 09:11:44,307 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_6_1  | 2020-08-31 09:11:52,751 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_6_1  | 2020-08-31 09:11:53,122 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_6_1  | 2020-08-31 09:11:53,678 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_6_1  | 2020-08-31 09:11:53,679 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_6_1  | 2020-08-31 09:11:53,679 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-08-31 09:11:53,707 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_6_1  | 2020-08-31 09:11:53,708 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 2020-08-31 09:11:55,600 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-08-31 09:11:55,620 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_6_1  | 2020-08-31 09:11:56,801 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_6_1  | 2020-08-31 09:11:56,935 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_6_1  | 2020-08-31 09:11:57,177 [main] INFO util.log: Logging initialized @30135ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_6_1  | 2020-08-31 09:11:58,092 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_6_1  | 2020-08-31 09:11:58,152 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_6_1  | 2020-08-31 09:11:58,208 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_6_1  | 2020-08-31 09:11:58,212 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_6_1  | 2020-08-31 09:11:58,221 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_6_1  | 2020-08-31 09:11:58,221 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_6_1  | 2020-08-31 09:11:58,522 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_6_1  | 2020-08-31 09:11:58,555 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_6_1  | 2020-08-31 09:11:58,578 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_6_1  | 2020-08-31 09:11:58,866 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_6_1  | 2020-08-31 09:11:58,873 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_6_1  | 2020-08-31 09:11:58,875 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_6_1  | 2020-08-31 09:11:58,960 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@682266d8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_6_1  | 2020-08-31 09:11:58,985 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3d235635{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_6_1  | 2020-08-31 09:11:59,788 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@165aa43a{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-2668367924099112710.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_6_1  | 2020-08-31 09:11:59,906 [main] INFO server.AbstractConnector: Started ServerConnector@5464b97c{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_6_1  | 2020-08-31 09:11:59,909 [main] INFO server.Server: Started @32867ms
datanode_6_1  | 2020-08-31 09:11:59,947 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_6_1  | 2020-08-31 09:11:59,948 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_6_1  | 2020-08-31 09:11:59,962 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_6_1  | 2020-08-31 09:12:00,256 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@52036ca6] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_6_1  | 2020-08-31 09:12:02,000 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_6_1  | 2020-08-31 09:12:03,751 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-08-31 09:12:04,753 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-08-31 09:12:05,754 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-08-31 09:12:06,755 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-08-31 09:12:07,756 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-08-31 09:12:08,387 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 2 seconds.
datanode_6_1  | 2020-08-31 09:12:08,786 [Datanode State Machine Task Thread - 1] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_6_1  | java.net.SocketTimeoutException: Call From 4a45e335c821/10.5.0.9 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:33464 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_6_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_6_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_6_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_6_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:33464 remote=scm/10.5.0.71:9861]
datanode_6_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_6_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_6_1  | 2020-08-31 09:12:09,950 [Datanode State Machine Task Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_6_1  | 2020-08-31 09:12:09,965 [Datanode State Machine Task Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_6_1  | 2020-08-31 09:12:09,970 [Datanode State Machine Task Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 1ea02341-7f4f-4c0b-8dce-ac3c127598ca at port 9858
datanode_6_1  | 2020-08-31 09:12:10,140 [Datanode State Machine Task Thread - 0] INFO impl.RaftServerProxy: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca: start RPC server
datanode_6_1  | 2020-08-31 09:12:10,741 [Datanode State Machine Task Thread - 0] INFO server.GrpcService: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_6_1  | 2020-08-31 09:12:15,892 [Command processor thread] INFO impl.RaftServerProxy: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca: addNew group-E82389A92A2D:[1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858] returns group-E82389A92A2D:java.util.concurrent.CompletableFuture@66c1ee49[Not completed]
datanode_2_1  | 2020-08-31 09:12:24,551 [grpc-default-executor-2] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: set configuration 0: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-08-31 09:12:24,551 [grpc-default-executor-2] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-08-31 09:12:24,723 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/current/log_inprogress_0
datanode_2_1  | 2020-08-31 09:12:24,723 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/32735a0c-b4d9-4bc0-babf-6b2584a28c31/current/log_inprogress_0
datanode_2_1  | 2020-08-31 09:12:42,043 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_2_1  | java.lang.InterruptedException: sleep interrupted
datanode_2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | 2020-08-31 09:13:58,468 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_2_1  | java.lang.InterruptedException: sleep interrupted
datanode_2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | 2020-08-31 09:14:03,320 [SIGTERM handler] ERROR ozone.HddsDatanodeService: RECEIVED SIGNAL 15: SIGTERM
datanode_2_1  | 2020-08-31 09:14:03,347 [shutdown-hook-0] INFO ozone.HddsDatanodeService: SHUTDOWN_MSG: 
datanode_2_1  | /************************************************************
datanode_2_1  | SHUTDOWN_MSG: Shutting down HddsDatanodeService at d58915730696/10.5.0.5
datanode_2_1  | ************************************************************/
datanode_2_1  | Enabled profiling in kernel
datanode_2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2_1  | 2020-08-31 09:14:50,224 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2_1  | /************************************************************
datanode_2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2_1  | STARTUP_MSG:   host = d58915730696/10.5.0.5
datanode_2_1  | STARTUP_MSG:   args = []
datanode_2_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_2_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/0ec1a8a011043711372c3f3a48ee4035beed641f ; compiled by 'runner' on 2020-08-31T08:37Z
datanode_2_1  | STARTUP_MSG:   java = 11.0.7
datanode_2_1  | ************************************************************/
datanode_2_1  | 2020-08-31 09:14:50,250 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2_1  | 2020-08-31 09:14:51,176 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2_1  | 2020-08-31 09:14:52,019 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2_1  | 2020-08-31 09:14:52,671 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2_1  | 2020-08-31 09:14:52,671 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2_1  | 2020-08-31 09:14:53,319 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:d58915730696 ip:10.5.0.5
datanode_2_1  | 2020-08-31 09:14:54,337 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 8192 at 2020-08-31T09:14:03.342Z
datanode_2_1  | 2020-08-31 09:14:54,367 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2_1  | 2020-08-31 09:14:54,505 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2_1  | 2020-08-31 09:14:54,548 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2_1  | 2020-08-31 09:14:54,667 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2_1  | 2020-08-31 09:14:54,792 [Thread-5] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_2_1  | 2020-08-31 09:14:56,031 [Thread-5] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_2_1  | 2020-08-31 09:14:56,039 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 1s
datanode_2_1  | 2020-08-31 09:14:59,891 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2_1  | 2020-08-31 09:15:00,521 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2_1  | 2020-08-31 09:15:00,990 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2_1  | 2020-08-31 09:15:00,994 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2_1  | 2020-08-31 09:15:01,001 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-08-31 09:15:01,002 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2_1  | 2020-08-31 09:15:01,003 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-08-31 09:15:01,536 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-08-31 09:15:01,546 [main] INFO impl.RaftServerProxy: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: found a subdirectory /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7
datanode_2_1  | 2020-08-31 09:15:01,561 [main] INFO impl.RaftServerProxy: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: addNew group-691DB78430A7:[] returns group-691DB78430A7:java.util.concurrent.CompletableFuture@615db358[Not completed]
datanode_2_1  | 2020-08-31 09:15:01,561 [main] INFO impl.RaftServerProxy: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: found a subdirectory /data/metadata/ratis/32735a0c-b4d9-4bc0-babf-6b2584a28c31
datanode_2_1  | 2020-08-31 09:15:01,562 [main] INFO impl.RaftServerProxy: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: addNew group-6B2584A28C31:[] returns group-6B2584A28C31:java.util.concurrent.CompletableFuture@256bb5be[Not completed]
datanode_2_1  | 2020-08-31 09:15:01,563 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2_1  | 2020-08-31 09:15:01,814 [pool-19-thread-1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: new RaftServerImpl for group-691DB78430A7:[] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-08-31 09:15:01,823 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-08-31 09:15:01,832 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-08-31 09:15:01,832 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-08-31 09:15:01,833 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-08-31 09:15:01,835 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-08-31 09:15:01,848 [pool-19-thread-1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_1_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_1_1  | 2020-08-31 09:12:10,041 [Datanode State Machine Task Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1_1  | 2020-08-31 09:12:10,054 [Datanode State Machine Task Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1_1  | 2020-08-31 09:12:10,058 [Datanode State Machine Task Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis d42a3350-8147-4d70-91a8-098b29431c2d at port 9858
datanode_1_1  | 2020-08-31 09:12:10,215 [Datanode State Machine Task Thread - 1] INFO impl.RaftServerProxy: d42a3350-8147-4d70-91a8-098b29431c2d: start RPC server
datanode_1_1  | 2020-08-31 09:12:10,819 [Datanode State Machine Task Thread - 1] INFO server.GrpcService: d42a3350-8147-4d70-91a8-098b29431c2d: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1_1  | 2020-08-31 09:12:14,975 [Command processor thread] INFO impl.RaftServerProxy: d42a3350-8147-4d70-91a8-098b29431c2d: addNew group-3ED01864ACBE:[d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858] returns group-3ED01864ACBE:java.util.concurrent.CompletableFuture@512a2d1e[Not completed]
datanode_1_1  | 2020-08-31 09:12:15,214 [pool-19-thread-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d: new RaftServerImpl for group-3ED01864ACBE:[d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-08-31 09:12:15,237 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-08-31 09:12:15,266 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-08-31 09:12:15,281 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-08-31 09:12:15,282 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-08-31 09:12:15,285 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-08-31 09:12:15,345 [pool-19-thread-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE: ConfigurationManager, init=-1: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-08-31 09:12:15,350 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-08-31 09:12:15,398 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-08-31 09:12:15,413 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6f9997fb-d6dd-4645-9521-3ed01864acbe does not exist. Creating ...
datanode_1_1  | 2020-08-31 09:12:15,477 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6f9997fb-d6dd-4645-9521-3ed01864acbe/in_use.lock acquired by nodename 7@e2f9588ed766
datanode_1_1  | 2020-08-31 09:12:15,499 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6f9997fb-d6dd-4645-9521-3ed01864acbe has been successfully formatted.
datanode_1_1  | 2020-08-31 09:12:15,715 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-3ED01864ACBE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-08-31 09:12:15,716 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1_1  | 2020-08-31 09:12:15,725 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_1_1  | java.lang.InterruptedException: sleep interrupted
datanode_1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 2020-08-31 09:12:15,793 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-08-31 09:12:15,982 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-08-31 09:12:16,048 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE
datanode_1_1  | 2020-08-31 09:12:16,300 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-08-31 09:12:16,382 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-08-31 09:12:16,558 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-08-31 09:12:16,657 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/6f9997fb-d6dd-4645-9521-3ed01864acbe
datanode_1_1  | 2020-08-31 09:12:16,658 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-08-31 09:12:16,685 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-08-31 09:12:16,698 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-08-31 09:12:16,717 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-08-31 09:12:16,718 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-08-31 09:12:16,725 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-08-31 09:12:16,728 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-08-31 09:12:16,741 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-08-31 09:12:16,747 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-08-31 09:12:16,950 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-08-31 09:12:17,041 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-08-31 09:12:17,045 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-08-31 09:12:17,099 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-08-31 09:12:17,168 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-08-31 09:12:17,177 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-08-31 09:12:17,178 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-08-31 09:12:17,185 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-08-31 09:12:17,840 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE
datanode_1_1  | 2020-08-31 09:12:17,872 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE
datanode_1_1  | 2020-08-31 09:12:17,910 [pool-19-thread-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE: start as a follower, conf=-1: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858], old=null
datanode_1_1  | 2020-08-31 09:12:17,922 [pool-19-thread-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-08-31 09:12:17,929 [pool-19-thread-1] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: start FollowerState
datanode_1_1  | 2020-08-31 09:12:17,953 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3ED01864ACBE,id=d42a3350-8147-4d70-91a8-098b29431c2d
datanode_1_1  | 2020-08-31 09:12:17,968 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE
datanode_1_1  | 2020-08-31 09:12:18,154 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "6f9997fb-d6dd-4645-9521-3ed01864acbe"
datanode_1_1  | uuid128 {
datanode_1_1  |   mostSigBits: 8041625717544142405
datanode_1_1  |   leastSigBits: -7700804824343466818
datanode_1_1  | }
datanode_1_1  | .
datanode_1_1  | 2020-08-31 09:12:18,179 [Command processor thread] INFO impl.RaftServerProxy: d42a3350-8147-4d70-91a8-098b29431c2d: addNew group-691DB78430A7:[d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858] returns group-691DB78430A7:java.util.concurrent.CompletableFuture@69920ce0[Not completed]
datanode_1_1  | 2020-08-31 09:12:18,182 [pool-19-thread-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d: new RaftServerImpl for group-691DB78430A7:[d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-08-31 09:12:18,205 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-08-31 09:12:18,205 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-08-31 09:12:18,206 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-08-31 09:12:18,206 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-08-31 09:11:37,043 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 38eb103a130f/10.5.0.70
om_1          | STARTUP_MSG:   args = [--init]
om_1          | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_1_1  | 2020-08-31 09:12:18,212 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-08-31 09:12:18,222 [pool-19-thread-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: ConfigurationManager, init=-1: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-08-31 09:12:18,233 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-08-31 09:12:18,242 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-08-31 09:12:18,243 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7 does not exist. Creating ...
datanode_1_1  | 2020-08-31 09:12:18,257 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/in_use.lock acquired by nodename 7@e2f9588ed766
datanode_1_1  | 2020-08-31 09:12:18,270 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7 has been successfully formatted.
datanode_1_1  | 2020-08-31 09:12:18,270 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-691DB78430A7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-08-31 09:12:18,273 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1_1  | 2020-08-31 09:12:18,277 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-08-31 09:12:18,278 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-08-31 09:12:18,279 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7
datanode_1_1  | 2020-08-31 09:12:18,280 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-08-31 09:12:18,285 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-08-31 09:12:18,285 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_1_1  | java.lang.InterruptedException: sleep interrupted
datanode_1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 2020-08-31 09:12:18,289 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-08-31 09:12:18,305 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7
datanode_1_1  | 2020-08-31 09:12:18,305 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-08-31 09:12:18,309 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-08-31 09:12:18,321 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-08-31 09:12:18,321 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-08-31 09:12:18,321 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-08-31 09:12:18,321 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-08-31 09:12:18,321 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-08-31 09:12:18,322 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-08-31 09:12:18,322 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-08-31 09:12:18,326 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-08-31 09:12:18,337 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-08-31 09:12:18,342 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-08-31 09:12:18,365 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-08-31 09:12:18,365 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-08-31 09:12:18,365 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-08-31 09:12:18,365 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-08-31 09:12:18,365 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-08-31 09:12:18,366 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7
datanode_1_1  | 2020-08-31 09:12:18,366 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7
datanode_1_1  | 2020-08-31 09:12:18,367 [pool-19-thread-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: start as a follower, conf=-1: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null
datanode_1_1  | 2020-08-31 09:12:18,373 [pool-19-thread-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-08-31 09:12:18,374 [pool-19-thread-1] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: start FollowerState
datanode_1_1  | 2020-08-31 09:12:18,405 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-691DB78430A7,id=d42a3350-8147-4d70-91a8-098b29431c2d
datanode_1_1  | 2020-08-31 09:12:18,405 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7
datanode_1_1  | 2020-08-31 09:12:23,105 [Thread-23] INFO impl.FollowerState: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-FollowerState: change to CANDIDATE, lastRpcTime:5176ms, electionTimeout:5160ms
datanode_1_1  | 2020-08-31 09:12:23,108 [Thread-23] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: shutdown FollowerState
datanode_1_1  | 2020-08-31 09:12:23,108 [Thread-23] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_6_1  | 2020-08-31 09:12:16,302 [pool-19-thread-1] INFO impl.RaftServerImpl: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca: new RaftServerImpl for group-E82389A92A2D:[1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-08-31 09:12:16,393 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-08-31 09:12:16,420 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-08-31 09:12:16,422 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-08-31 09:12:16,429 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-08-31 09:12:16,430 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-08-31 09:12:16,453 [pool-19-thread-1] INFO impl.RaftServerImpl: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D: ConfigurationManager, init=-1: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-08-31 09:12:16,486 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-08-31 09:12:16,525 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-08-31 09:12:16,542 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/db19c46a-fcf4-4a0e-b4ad-e82389a92a2d does not exist. Creating ...
datanode_6_1  | 2020-08-31 09:12:16,593 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/db19c46a-fcf4-4a0e-b4ad-e82389a92a2d/in_use.lock acquired by nodename 7@4a45e335c821
datanode_6_1  | 2020-08-31 09:12:16,621 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/db19c46a-fcf4-4a0e-b4ad-e82389a92a2d has been successfully formatted.
datanode_6_1  | 2020-08-31 09:12:16,735 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-E82389A92A2D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-08-31 09:12:16,736 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_6_1  | 2020-08-31 09:12:16,750 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_6_1  | java.lang.InterruptedException: sleep interrupted
datanode_6_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-08-31 09:12:16,766 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-08-31 09:12:16,848 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-08-31 09:12:16,917 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D
datanode_6_1  | 2020-08-31 09:12:17,081 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-08-31 09:12:17,164 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-08-31 09:12:17,373 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-08-31 09:12:17,444 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/db19c46a-fcf4-4a0e-b4ad-e82389a92a2d
datanode_6_1  | 2020-08-31 09:12:17,454 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-08-31 09:12:17,456 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-08-31 09:12:17,474 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-08-31 09:12:17,475 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-08-31 09:12:17,477 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-08-31 09:12:17,481 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-08-31 09:12:17,500 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-08-31 09:12:17,528 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-08-31 09:12:17,560 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-08-31 09:12:17,740 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-08-31 09:12:17,821 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-08-31 09:12:17,847 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-08-31 09:12:17,861 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-08-31 09:12:17,932 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-08-31 09:12:17,947 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-08-31 09:12:17,950 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-08-31 09:12:17,973 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-08-31 09:12:18,496 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D
datanode_6_1  | 2020-08-31 09:12:18,571 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D
datanode_6_1  | 2020-08-31 09:12:18,600 [pool-19-thread-1] INFO impl.RaftServerImpl: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D: start as a follower, conf=-1: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858], old=null
datanode_6_1  | 2020-08-31 09:12:18,622 [pool-19-thread-1] INFO impl.RaftServerImpl: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-08-31 09:12:18,638 [pool-19-thread-1] INFO impl.RoleInfo: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca: start FollowerState
datanode_6_1  | 2020-08-31 09:12:18,661 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E82389A92A2D,id=1ea02341-7f4f-4c0b-8dce-ac3c127598ca
datanode_6_1  | 2020-08-31 09:12:18,663 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D
datanode_6_1  | 2020-08-31 09:12:18,761 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "db19c46a-fcf4-4a0e-b4ad-e82389a92a2d"
datanode_6_1  | uuid128 {
datanode_6_1  |   mostSigBits: -2658878141196121586
datanode_6_1  |   leastSigBits: -5427426736580515283
datanode_6_1  | }
datanode_6_1  | .
datanode_6_1  | 2020-08-31 09:12:18,772 [Command processor thread] INFO impl.RaftServerProxy: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca: addNew group-C67C4A012799:[1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858] returns group-C67C4A012799:java.util.concurrent.CompletableFuture@33206acc[Not completed]
datanode_6_1  | 2020-08-31 09:12:18,784 [pool-19-thread-1] INFO impl.RaftServerImpl: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca: new RaftServerImpl for group-C67C4A012799:[1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-08-31 09:12:18,792 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-08-31 09:12:18,796 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-08-31 09:12:18,797 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-08-31 09:12:18,798 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-08-31 09:12:18,801 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/0ec1a8a011043711372c3f3a48ee4035beed641f ; compiled by 'runner' on 2020-08-31T08:38Z
om_1          | STARTUP_MSG:   java = 11.0.7
om_1          | ************************************************************/
om_1          | 2020-08-31 09:11:37,168 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-08-31 09:11:45,396 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-08-31 09:11:45,941 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-08-31 09:11:45,941 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-08-31 09:11:46,101 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-08-31 09:11:50,288 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-08-31 09:11:51,290 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-08-31 09:11:52,291 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-08-31 09:11:53,292 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-08-31 09:11:54,293 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-08-31 09:11:55,294 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-08-31 09:11:56,296 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-08-31 09:11:57,297 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-08-31 09:11:58,299 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-08-31 09:11:59,301 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-08-31 09:11:59,303 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1          | 2020-08-31 09:12:05,310 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-08-31 09:12:06,312 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-08-31 09:12:07,313 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-08-31 09:12:08,314 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-e424131d-f9e4-4dcd-8e99-014ef902334f;layoutVersion=0
om_1          | 2020-08-31 09:12:09,407 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1          | /************************************************************
om_1          | SHUTDOWN_MSG: Shutting down OzoneManager at 38eb103a130f/10.5.0.70
om_1          | ************************************************************/
om_1          | Enabled profiling in kernel
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-08-31 09:12:18,028 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 38eb103a130f/10.5.0.70
om_1          | STARTUP_MSG:   args = []
om_1          | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/0ec1a8a011043711372c3f3a48ee4035beed641f ; compiled by 'runner' on 2020-08-31T08:38Z
om_1          | STARTUP_MSG:   java = 11.0.7
om_1          | ************************************************************/
om_1          | 2020-08-31 09:12:18,158 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-08-31 09:12:25,251 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-08-31 09:12:25,444 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-08-31 09:12:25,444 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-08-31 09:12:25,454 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-08-31 09:12:25,475 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-08-31 09:12:28,062 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-08-31 09:12:28,403 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om_1          | 2020-08-31 09:12:28,404 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om_1          | 2020-08-31 09:12:29,126 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
om_1          | 2020-08-31 09:12:29,184 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1          | 2020-08-31 09:12:29,227 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1          | 2020-08-31 09:12:29,698 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1          | 2020-08-31 09:12:29,843 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1          | 2020-08-31 09:12:29,843 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1          | 2020-08-31 09:12:29,972 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/10.5.0.70:9862
datanode_4_1  | 2020-08-31 09:12:23,422 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_4_1  | 2020-08-31 09:12:23,422 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-923D69527124 with new leaderId: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051
datanode_4_1  | 2020-08-31 09:12:23,425 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124: change Leader from null to 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051 at term 1 for becomeLeader, leader elected after 6713ms
datanode_4_1  | 2020-08-31 09:12:23,433 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_4_1  | java.lang.InterruptedException: sleep interrupted
datanode_4_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-08-31 09:12:23,465 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4_1  | 2020-08-31 09:12:23,467 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4_1  | 2020-08-31 09:12:23,471 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124
datanode_4_1  | 2020-08-31 09:12:23,500 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4_1  | 2020-08-31 09:12:23,511 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_4_1  | 2020-08-31 09:12:23,555 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4_1  | 2020-08-31 09:12:23,556 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4_1  | 2020-08-31 09:12:23,557 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4_1  | 2020-08-31 09:12:23,580 [Thread-25] INFO impl.FollowerState: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-FollowerState: change to CANDIDATE, lastRpcTime:5026ms, electionTimeout:5018ms
datanode_4_1  | 2020-08-31 09:12:23,590 [Thread-25] INFO impl.RoleInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: shutdown FollowerState
datanode_4_1  | 2020-08-31 09:12:23,591 [Thread-25] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4_1  | 2020-08-31 09:12:23,591 [Thread-25] INFO impl.RoleInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: start LeaderElection
datanode_4_1  | 2020-08-31 09:12:23,601 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO impl.RoleInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: start LeaderState
datanode_4_1  | 2020-08-31 09:12:23,620 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO impl.LeaderElection: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2: begin an election at term 1 for -1: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null
datanode_4_1  | 2020-08-31 09:12:24,085 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-08-31 09:12:24,184 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO impl.LeaderElection: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2: Election PASSED; received 1 response(s) [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051<-fb769711-6072-404d-8d33-36b40dabaa1b#0:OK-t1] and 0 exception(s); 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799:t1, leader=null, voted=1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051, raftlog=1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null
datanode_4_1  | 2020-08-31 09:12:24,195 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO impl.RoleInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: shutdown LeaderElection
datanode_4_1  | 2020-08-31 09:12:24,198 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_4_1  | 2020-08-31 09:12:24,198 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C67C4A012799 with new leaderId: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051
datanode_4_1  | 2020-08-31 09:12:24,199 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_4_1  | java.lang.InterruptedException: sleep interrupted
datanode_4_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-08-31 09:12:24,199 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799: change Leader from null to 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051 at term 1 for becomeLeader, leader elected after 5729ms
datanode_4_1  | 2020-08-31 09:12:24,297 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4_1  | 2020-08-31 09:12:24,298 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4_1  | 2020-08-31 09:12:24,298 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799
datanode_4_1  | 2020-08-31 09:12:24,298 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4_1  | 2020-08-31 09:12:24,298 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_4_1  | 2020-08-31 09:12:24,298 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4_1  | 2020-08-31 09:12:24,298 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5_1  | }
datanode_5_1  | .
datanode_5_1  | 2020-08-31 09:12:17,456 [Command processor thread] INFO impl.RaftServerProxy: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: addNew group-691DB78430A7:[d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858] returns group-691DB78430A7:java.util.concurrent.CompletableFuture@40f2ef6e[Not completed]
datanode_5_1  | 2020-08-31 09:12:17,510 [pool-19-thread-1] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: new RaftServerImpl for group-691DB78430A7:[d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-08-31 09:12:17,510 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-08-31 09:12:17,510 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-08-31 09:12:17,510 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-08-31 09:12:17,510 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-08-31 09:12:17,510 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-08-31 09:12:17,510 [pool-19-thread-1] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7: ConfigurationManager, init=-1: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-08-31 09:12:17,510 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-08-31 09:12:18,816 [pool-19-thread-1] INFO impl.RaftServerImpl: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799: ConfigurationManager, init=-1: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-08-31 09:12:18,830 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-08-31 09:12:18,832 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-08-31 09:12:18,833 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799 does not exist. Creating ...
datanode_6_1  | 2020-08-31 09:12:18,845 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799/in_use.lock acquired by nodename 7@4a45e335c821
datanode_6_1  | 2020-08-31 09:12:18,846 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799 has been successfully formatted.
datanode_6_1  | 2020-08-31 09:12:18,847 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_6_1  | java.lang.InterruptedException: sleep interrupted
datanode_6_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-08-31 09:12:18,850 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-C67C4A012799: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-08-31 09:12:18,857 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_6_1  | 2020-08-31 09:12:18,857 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-08-31 09:12:18,857 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-08-31 09:12:18,859 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799
datanode_6_1  | 2020-08-31 09:12:18,860 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-08-31 09:12:18,860 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-08-31 09:12:18,860 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-08-31 09:12:18,901 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799
datanode_6_1  | 2020-08-31 09:12:18,901 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-08-31 09:12:18,901 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-08-31 09:12:18,905 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-08-31 09:12:18,905 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-08-31 09:12:18,905 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-08-31 09:12:18,905 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-08-31 09:12:18,906 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-08-31 09:12:18,906 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-08-31 09:12:18,906 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-08-31 09:12:18,908 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-08-31 09:12:18,911 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-08-31 09:12:18,914 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-08-31 09:12:18,936 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-08-31 09:12:18,936 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-08-31 09:12:18,936 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-08-31 09:12:18,936 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-08-31 09:12:18,939 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-08-31 09:12:18,940 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799
datanode_6_1  | 2020-08-31 09:12:18,941 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799
datanode_6_1  | 2020-08-31 09:12:18,942 [pool-19-thread-1] INFO impl.RaftServerImpl: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799: start as a follower, conf=-1: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null
datanode_6_1  | 2020-08-31 09:12:18,942 [pool-19-thread-1] INFO impl.RaftServerImpl: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1          | 2020-08-31 09:12:30,150 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1          | 2020-08-31 09:12:30,151 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1          | 2020-08-31 09:12:30,213 [Listener at om/9862] INFO util.log: Logging initialized @20102ms to org.eclipse.jetty.util.log.Slf4jLog
om_1          | 2020-08-31 09:12:30,465 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1          | 2020-08-31 09:12:30,475 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1          | 2020-08-31 09:12:30,488 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1          | 2020-08-31 09:12:30,492 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1          | 2020-08-31 09:12:30,492 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1          | 2020-08-31 09:12:30,492 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1          | 2020-08-31 09:12:30,591 [Listener at om/9862] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1          | 2020-08-31 09:12:30,599 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1          | 2020-08-31 09:12:30,605 [Listener at om/9862] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
om_1          | 2020-08-31 09:12:30,678 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1          | 2020-08-31 09:12:30,678 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1          | 2020-08-31 09:12:30,687 [Listener at om/9862] INFO server.session: node0 Scavenging every 660000ms
om_1          | 2020-08-31 09:12:30,730 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@18b58c77{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1          | 2020-08-31 09:12:30,744 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3605ab16{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1          | 2020-08-31 09:12:30,950 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@8b1170f{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-1_1_0-SNAPSHOT_jar-_-any-14081840635644057185.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1          | 2020-08-31 09:12:30,957 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@6de9bba2{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1          | 2020-08-31 09:12:30,957 [Listener at om/9862] INFO server.Server: Started @20846ms
om_1          | 2020-08-31 09:12:30,959 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1          | 2020-08-31 09:12:30,959 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1          | 2020-08-31 09:12:30,967 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1          | 2020-08-31 09:12:30,973 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1          | 2020-08-31 09:12:30,976 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1          | 2020-08-31 09:12:31,151 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@416c1b0] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1          | 2020-08-31 09:12:37,406 [IPC Server handler 68 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-32736 for user:hadoop
om_1          | 2020-08-31 09:12:37,443 [IPC Server handler 3 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-78421 for user:hadoop
om_1          | 2020-08-31 09:12:37,458 [IPC Server handler 0 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-60125 for user:hadoop
om_1          | 2020-08-31 09:12:37,466 [IPC Server handler 5 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-59143 for user:hadoop
om_1          | 2020-08-31 09:12:37,477 [IPC Server handler 7 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-32297 for user:hadoop
om_1          | 2020-08-31 09:13:49,539 [IPC Server handler 22 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:topvol1 for user:hadoop
datanode_3_1  | 2020-08-31 09:12:06,043 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-08-31 09:12:07,045 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-08-31 09:12:08,047 [Datanode State Machine Task Thread - 1] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-08-31 09:12:08,709 [Datanode State Machine Thread - 0] WARN statemachine.StateContext: No available thread in pool for past 2 seconds.
datanode_3_1  | 2020-08-31 09:12:09,068 [Datanode State Machine Task Thread - 1] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_3_1  | java.net.SocketTimeoutException: Call From 0e7bdc6ca2ae/10.5.0.6 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:41970 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_3_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:41970 remote=scm/10.5.0.71:9861]
datanode_3_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_3_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_3_1  | 2020-08-31 09:12:09,926 [Datanode State Machine Task Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3_1  | 2020-08-31 09:12:09,938 [Datanode State Machine Task Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3_1  | 2020-08-31 09:12:09,941 [Datanode State Machine Task Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis fb769711-6072-404d-8d33-36b40dabaa1b at port 9858
datanode_3_1  | 2020-08-31 09:12:10,068 [Datanode State Machine Task Thread - 0] INFO impl.RaftServerProxy: fb769711-6072-404d-8d33-36b40dabaa1b: start RPC server
datanode_3_1  | 2020-08-31 09:12:10,654 [Datanode State Machine Task Thread - 0] INFO server.GrpcService: fb769711-6072-404d-8d33-36b40dabaa1b: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3_1  | 2020-08-31 09:12:16,235 [Command processor thread] INFO impl.RaftServerProxy: fb769711-6072-404d-8d33-36b40dabaa1b: addNew group-14AD5C02C389:[fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858] returns group-14AD5C02C389:java.util.concurrent.CompletableFuture@20736131[Not completed]
datanode_3_1  | 2020-08-31 09:12:16,894 [pool-19-thread-1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b: new RaftServerImpl for group-14AD5C02C389:[fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-08-31 09:12:16,902 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-08-31 09:12:16,913 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-08-31 09:12:16,932 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-08-31 09:12:16,933 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-08-31 09:12:16,946 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-08-31 09:12:16,968 [pool-19-thread-1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389: ConfigurationManager, init=-1: [fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-08-31 09:12:16,982 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-08-31 09:12:17,015 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-08-31 09:12:17,029 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7024b68f-1a89-45d9-8080-14ad5c02c389 does not exist. Creating ...
datanode_3_1  | 2020-08-31 09:12:17,061 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7024b68f-1a89-45d9-8080-14ad5c02c389/in_use.lock acquired by nodename 6@0e7bdc6ca2ae
datanode_4_1  | 2020-08-31 09:12:24,299 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4_1  | 2020-08-31 09:12:24,388 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_4_1  | 2020-08-31 09:12:24,388 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-08-31 09:12:24,473 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-LeaderElection1] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124: set configuration 0: [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null at 0
datanode_4_1  | 2020-08-31 09:12:24,474 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_4_1  | 2020-08-31 09:12:24,481 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_4_1  | 2020-08-31 09:12:24,760 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 2020-08-31 09:12:24,760 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-08-31 09:12:24,761 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799
datanode_4_1  | 2020-08-31 09:12:24,825 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_4_1  | 2020-08-31 09:12:24,825 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-08-31 09:12:24,829 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_4_1  | 2020-08-31 09:12:24,830 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_4_1  | 2020-08-31 09:12:24,838 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 2020-08-31 09:12:24,845 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-08-31 09:12:24,879 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO impl.RoleInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051: start LeaderState
datanode_4_1  | 2020-08-31 09:12:24,892 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-08-31 09:12:24,933 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-LeaderElection2] INFO impl.RaftServerImpl: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799: set configuration 0: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null at 0
datanode_4_1  | 2020-08-31 09:12:25,323 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799/current/log_inprogress_0
datanode_4_1  | 2020-08-31 09:12:25,330 [1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-923D69527124-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a40e8651-2594-4500-a3cd-923d69527124/current/log_inprogress_0
datanode_4_1  | 2020-08-31 09:12:44,089 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_4_1  | java.lang.InterruptedException: sleep interrupted
datanode_4_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-08-31 09:13:16,646 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_4_1  | java.lang.InterruptedException: sleep interrupted
datanode_4_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-08-31 09:14:03,818 [grpc-default-executor-1] WARN server.GrpcLogAppender: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode_4_1  | 2020-08-31 09:14:03,822 [grpc-default-executor-1] INFO impl.FollowerInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b: nextIndex: updateUnconditionally 194 -> 193
datanode_4_1  | 2020-08-31 09:14:34,435 [grpc-default-executor-0] WARN server.GrpcLogAppender: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_4_1  | 2020-08-31 09:14:37,437 [grpc-default-executor-0] WARN grpc.GrpcUtil: Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=26, target=10.5.0.6:9858}}. 
datanode_4_1  | 2020-08-31 09:14:37,440 [grpc-default-executor-0] INFO impl.FollowerInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b: nextIndex: updateUnconditionally 194 -> 193
datanode_4_1  | 2020-08-31 09:14:47,747 [grpc-default-executor-0] WARN server.GrpcLogAppender: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_4_1  | 2020-08-31 09:14:48,771 [grpc-default-executor-0] INFO impl.FollowerInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b: nextIndex: updateUnconditionally 194 -> 193
datanode_4_1  | 2020-08-31 09:14:49,952 [grpc-default-executor-1] WARN server.GrpcLogAppender: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_4_1  | 2020-08-31 09:14:49,954 [grpc-default-executor-1] INFO impl.FollowerInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b: nextIndex: updateUnconditionally 194 -> 193
datanode_4_1  | 2020-08-31 09:14:52,457 [grpc-default-executor-3] WARN server.GrpcLogAppender: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_4_1  | 2020-08-31 09:14:52,459 [grpc-default-executor-3] INFO impl.FollowerInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b: nextIndex: updateUnconditionally 194 -> 193
datanode_4_1  | 2020-08-31 09:14:54,955 [grpc-default-executor-1] WARN server.GrpcLogAppender: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_4_1  | 2020-08-31 09:14:54,956 [grpc-default-executor-1] INFO impl.FollowerInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b: nextIndex: updateUnconditionally 194 -> 193
datanode_4_1  | 2020-08-31 09:14:57,467 [grpc-default-executor-3] WARN server.GrpcLogAppender: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_4_1  | 2020-08-31 09:14:57,468 [grpc-default-executor-3] INFO impl.FollowerInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b: nextIndex: updateUnconditionally 194 -> 193
datanode_4_1  | 2020-08-31 09:15:00,005 [grpc-default-executor-1] WARN server.GrpcLogAppender: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_4_1  | 2020-08-31 09:15:00,049 [grpc-default-executor-1] INFO impl.FollowerInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b: nextIndex: updateUnconditionally 194 -> 193
datanode_4_1  | 2020-08-31 09:15:02,480 [grpc-default-executor-3] WARN server.GrpcLogAppender: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_4_1  | 2020-08-31 09:15:02,481 [grpc-default-executor-3] INFO impl.FollowerInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b: nextIndex: updateUnconditionally 194 -> 193
datanode_4_1  | 2020-08-31 09:15:04,983 [grpc-default-executor-1] WARN server.GrpcLogAppender: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_4_1  | 2020-08-31 09:15:04,984 [grpc-default-executor-1] INFO impl.FollowerInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b: nextIndex: updateUnconditionally 194 -> 193
datanode_4_1  | 2020-08-31 09:15:07,491 [grpc-default-executor-3] WARN server.GrpcLogAppender: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_4_1  | 2020-08-31 09:15:07,498 [grpc-default-executor-3] INFO impl.FollowerInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b: nextIndex: updateUnconditionally 194 -> 193
datanode_4_1  | 2020-08-31 09:15:09,988 [grpc-default-executor-3] WARN server.GrpcLogAppender: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_4_1  | 2020-08-31 09:15:09,990 [grpc-default-executor-3] INFO impl.FollowerInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b: nextIndex: updateUnconditionally 194 -> 193
datanode_4_1  | 2020-08-31 09:15:13,686 [grpc-default-executor-3] INFO impl.FollowerInfo: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051@group-C67C4A012799->fb769711-6072-404d-8d33-36b40dabaa1b: nextIndex: updateUnconditionally 194 -> 194
datanode_4_1  | 2020-08-31 09:15:15,528 [SIGTERM handler] ERROR ozone.HddsDatanodeService: RECEIVED SIGNAL 15: SIGTERM
datanode_4_1  | 2020-08-31 09:15:15,609 [shutdown-hook-0] INFO ozone.HddsDatanodeService: SHUTDOWN_MSG: 
datanode_4_1  | /************************************************************
datanode_4_1  | SHUTDOWN_MSG: Shutting down HddsDatanodeService at f7156b6193a5/10.5.0.7
datanode_4_1  | ************************************************************/
datanode_3_1  | 2020-08-31 09:12:17,078 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7024b68f-1a89-45d9-8080-14ad5c02c389 has been successfully formatted.
datanode_3_1  | 2020-08-31 09:12:17,104 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_3_1  | java.lang.InterruptedException: sleep interrupted
datanode_3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | 2020-08-31 09:12:17,169 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-14AD5C02C389: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-08-31 09:12:17,171 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3_1  | 2020-08-31 09:12:17,175 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-08-31 09:12:17,285 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-08-31 09:12:17,357 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389
datanode_3_1  | 2020-08-31 09:12:17,451 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-08-31 09:12:17,472 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-08-31 09:12:17,652 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-08-31 09:12:17,695 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/7024b68f-1a89-45d9-8080-14ad5c02c389
datanode_3_1  | 2020-08-31 09:12:17,722 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-08-31 09:12:17,728 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-08-31 09:12:17,750 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-08-31 09:12:17,751 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-08-31 09:12:17,751 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-08-31 09:12:17,751 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-08-31 09:12:17,762 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-08-31 09:12:17,771 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-08-31 09:12:17,771 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-08-31 09:12:17,928 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-08-31 09:12:17,995 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-08-31 09:12:18,035 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-08-31 09:12:18,131 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-08-31 09:12:18,146 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-08-31 09:12:18,149 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-08-31 09:12:18,155 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-08-31 09:12:18,182 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-08-31 09:12:18,441 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389
datanode_3_1  | 2020-08-31 09:12:18,456 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389
datanode_3_1  | 2020-08-31 09:12:18,559 [pool-19-thread-1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389: start as a follower, conf=-1: [fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858], old=null
datanode_3_1  | 2020-08-31 09:12:18,563 [pool-19-thread-1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-08-31 09:12:18,574 [pool-19-thread-1] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: start FollowerState
datanode_3_1  | 2020-08-31 09:12:18,629 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-14AD5C02C389,id=fb769711-6072-404d-8d33-36b40dabaa1b
datanode_3_1  | 2020-08-31 09:12:18,634 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389
datanode_3_1  | 2020-08-31 09:12:18,748 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "7024b68f-1a89-45d9-8080-14ad5c02c389"
datanode_3_1  | uuid128 {
datanode_3_1  |   mostSigBits: 8080784357151294937
datanode_3_1  |   leastSigBits: -9187320505030229111
datanode_3_1  | }
datanode_3_1  | .
datanode_3_1  | 2020-08-31 09:12:18,757 [Command processor thread] INFO impl.RaftServerProxy: fb769711-6072-404d-8d33-36b40dabaa1b: addNew group-C67C4A012799:[1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858] returns group-C67C4A012799:java.util.concurrent.CompletableFuture@3a8c83e0[Not completed]
datanode_3_1  | 2020-08-31 09:12:18,768 [pool-19-thread-1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b: new RaftServerImpl for group-C67C4A012799:[1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-08-31 09:12:18,785 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-08-31 09:12:18,789 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-08-31 09:12:18,790 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-08-31 09:12:18,790 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-08-31 09:12:18,790 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-08-31 09:15:01,854 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-08-31 09:15:01,858 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-08-31 09:15:01,912 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/in_use.lock acquired by nodename 6@d58915730696
datanode_2_1  | 2020-08-31 09:15:02,464 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-691DB78430A7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-08-31 09:15:02,473 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2_1  | 2020-08-31 09:15:02,539 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-08-31 09:15:02,620 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-08-31 09:15:02,680 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7
datanode_2_1  | 2020-08-31 09:15:02,913 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-08-31 09:15:02,994 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-08-31 09:15:03,022 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2_1  | 2020-08-31 09:15:03,067 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-08-31 09:15:03,081 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7
datanode_2_1  | 2020-08-31 09:15:03,085 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-08-31 09:15:03,090 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-08-31 09:15:03,091 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-08-31 09:15:03,092 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-08-31 09:15:03,092 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-08-31 09:15:03,092 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-08-31 09:15:03,110 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-08-31 09:15:03,110 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-08-31 09:15:03,110 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-08-31 09:15:03,140 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2_1  | 2020-08-31 09:15:03,168 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-08-31 09:15:03,408 [main] INFO util.log: Logging initialized @16419ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2_1  | 2020-08-31 09:15:03,630 [pool-19-thread-1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: set configuration 0: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-08-31 09:15:03,846 [pool-19-thread-1] INFO segmented.LogSegment: Successfully read 299 entries from segment file /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/current/log_inprogress_0
datanode_2_1  | 2020-08-31 09:15:03,887 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 298
datanode_2_1  | 2020-08-31 09:15:03,888 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-08-31 09:15:04,108 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2_1  | 2020-08-31 09:15:04,138 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2_1  | 2020-08-31 09:15:04,180 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2_1  | 2020-08-31 09:15:04,199 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2_1  | 2020-08-31 09:15:04,205 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2_1  | 2020-08-31 09:15:04,205 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2_1  | 2020-08-31 09:15:04,560 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2_1  | 2020-08-31 09:15:04,662 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2_1  | 2020-08-31 09:15:04,666 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_2_1  | 2020-08-31 09:15:04,674 [pool-19-thread-1] INFO raftlog.RaftLog: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLog: commitIndex: updateToMax old=-1, new=296, updated? true
datanode_2_1  | 2020-08-31 09:15:04,726 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-08-31 09:15:04,756 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-08-31 09:15:04,773 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-08-31 09:15:04,788 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-08-31 09:15:04,789 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-08-31 09:15:05,122 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2_1  | 2020-08-31 09:15:05,122 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2_1  | 2020-08-31 09:15:05,151 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2_1  | 2020-08-31 09:15:05,165 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7
datanode_2_1  | 2020-08-31 09:15:05,213 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1bec1589{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2_1  | 2020-08-31 09:15:05,320 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7
datanode_3_1  | 2020-08-31 09:12:18,790 [pool-19-thread-1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799: ConfigurationManager, init=-1: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-08-31 09:12:18,791 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-08-31 09:12:18,791 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-08-31 09:12:18,792 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799 does not exist. Creating ...
datanode_3_1  | 2020-08-31 09:12:18,797 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799/in_use.lock acquired by nodename 6@0e7bdc6ca2ae
datanode_3_1  | 2020-08-31 09:12:18,813 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799 has been successfully formatted.
datanode_3_1  | 2020-08-31 09:12:18,814 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-C67C4A012799: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-08-31 09:12:18,815 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_3_1  | java.lang.InterruptedException: sleep interrupted
datanode_3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | 2020-08-31 09:12:18,815 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3_1  | 2020-08-31 09:12:18,829 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-08-31 09:12:18,829 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-08-31 09:12:18,830 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799
datanode_3_1  | 2020-08-31 09:12:18,833 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-08-31 09:12:18,840 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-08-31 09:12:18,848 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-08-31 09:12:18,853 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799
datanode_3_1  | 2020-08-31 09:12:18,871 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-08-31 09:12:18,872 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-08-31 09:12:18,877 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-08-31 09:12:18,877 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-08-31 09:12:18,878 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-08-31 09:12:18,878 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-08-31 09:12:18,878 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-08-31 09:12:18,879 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-08-31 09:12:18,879 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-08-31 09:12:18,890 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-08-31 09:12:18,893 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-08-31 09:12:18,894 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-08-31 09:12:18,923 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-08-31 09:12:18,924 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-08-31 09:12:18,933 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-08-31 09:12:18,933 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-08-31 09:12:18,933 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-08-31 09:12:18,934 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799
datanode_3_1  | 2020-08-31 09:12:18,934 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799
datanode_3_1  | 2020-08-31 09:12:18,935 [pool-19-thread-1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799: start as a follower, conf=-1: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null
datanode_3_1  | 2020-08-31 09:12:18,944 [pool-19-thread-1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-08-31 09:12:18,948 [pool-19-thread-1] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: start FollowerState
datanode_3_1  | 2020-08-31 09:12:18,965 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C67C4A012799,id=fb769711-6072-404d-8d33-36b40dabaa1b
datanode_3_1  | 2020-08-31 09:12:18,966 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799
datanode_3_1  | 2020-08-31 09:12:23,327 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "2f48de6e-e67a-4c1b-a8d1-c67c4a012799"
datanode_3_1  | uuid128 {
datanode_3_1  |   mostSigBits: 3407217686000323611
datanode_3_1  |   leastSigBits: -6282021768085297255
datanode_3_1  | }
datanode_3_1  | .
datanode_3_1  | 2020-08-31 09:12:23,634 [Thread-23] INFO impl.FollowerState: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-FollowerState: change to CANDIDATE, lastRpcTime:5060ms, electionTimeout:5027ms
datanode_3_1  | 2020-08-31 09:12:23,636 [Thread-23] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: shutdown FollowerState
datanode_2_1  | 2020-08-31 09:15:05,343 [pool-19-thread-1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: new RaftServerImpl for group-6B2584A28C31:[] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-08-31 09:15:05,343 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-08-31 09:15:05,343 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-08-31 09:15:05,343 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-08-31 09:15:05,343 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-08-31 09:15:05,343 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-08-31 09:15:05,343 [pool-19-thread-1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-08-31 09:15:05,343 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-08-31 09:15:05,344 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-08-31 09:15:05,351 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@f10d055{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2_1  | 2020-08-31 09:15:05,377 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/32735a0c-b4d9-4bc0-babf-6b2584a28c31/in_use.lock acquired by nodename 6@d58915730696
datanode_2_1  | 2020-08-31 09:15:05,379 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-6B2584A28C31: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-08-31 09:15:05,379 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2_1  | 2020-08-31 09:15:05,379 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-08-31 09:15:05,379 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-08-31 09:15:05,379 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31
datanode_2_1  | 2020-08-31 09:15:05,379 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-08-31 09:15:05,380 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-08-31 09:15:05,380 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-08-31 09:15:05,380 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/32735a0c-b4d9-4bc0-babf-6b2584a28c31
datanode_2_1  | 2020-08-31 09:15:05,380 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-08-31 09:15:05,380 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-08-31 09:15:05,380 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-08-31 09:15:05,380 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-08-31 09:15:05,380 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-08-31 09:15:05,380 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-08-31 09:15:05,381 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-08-31 09:15:05,421 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-08-31 09:15:05,421 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-08-31 09:15:05,422 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-08-31 09:15:05,423 [pool-19-thread-1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31: set configuration 0: [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-08-31 09:15:05,424 [pool-19-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/32735a0c-b4d9-4bc0-babf-6b2584a28c31/current/log_inprogress_0
datanode_2_1  | 2020-08-31 09:15:05,424 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
datanode_2_1  | 2020-08-31 09:15:05,424 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-08-31 09:15:05,434 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-08-31 09:15:05,434 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-08-31 09:15:05,435 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-08-31 09:15:05,435 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-08-31 09:15:05,435 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-08-31 09:15:05,435 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31
datanode_2_1  | 2020-08-31 09:15:05,436 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31
datanode_2_1  | 2020-08-31 09:15:05,821 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3cb04dd{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-7306286538279393474.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2_1  | 2020-08-31 09:15:05,858 [main] INFO server.AbstractConnector: Started ServerConnector@100eeedc{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2_1  | 2020-08-31 09:15:05,860 [main] INFO server.Server: Started @18871ms
datanode_2_1  | 2020-08-31 09:15:05,865 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2_1  | 2020-08-31 09:15:05,865 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2_1  | 2020-08-31 09:15:05,871 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2_1  | 2020-08-31 09:15:05,968 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@83a6a53] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2_1  | 2020-08-31 09:15:08,458 [Datanode State Machine Task Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2_1  | 2020-08-31 09:15:08,464 [Datanode State Machine Task Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_6_1  | 2020-08-31 09:12:18,944 [pool-19-thread-1] INFO impl.RoleInfo: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca: start FollowerState
datanode_6_1  | 2020-08-31 09:12:18,993 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C67C4A012799,id=1ea02341-7f4f-4c0b-8dce-ac3c127598ca
datanode_6_1  | 2020-08-31 09:12:18,993 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799
datanode_6_1  | 2020-08-31 09:12:23,296 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "2f48de6e-e67a-4c1b-a8d1-c67c4a012799"
datanode_6_1  | uuid128 {
datanode_6_1  |   mostSigBits: 3407217686000323611
datanode_6_1  |   leastSigBits: -6282021768085297255
datanode_6_1  | }
datanode_6_1  | .
datanode_6_1  | 2020-08-31 09:12:23,710 [Thread-23] INFO impl.FollowerState: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-FollowerState: change to CANDIDATE, lastRpcTime:5071ms, electionTimeout:5048ms
datanode_6_1  | 2020-08-31 09:12:23,711 [Thread-23] INFO impl.RoleInfo: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca: shutdown FollowerState
datanode_1_1  | 2020-08-31 09:12:23,115 [Thread-23] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: start LeaderElection
datanode_1_1  | 2020-08-31 09:12:23,159 [grpc-default-executor-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:2eef5031-1d72-43cd-9aec-f2fe042a3f3c
datanode_1_1  | 2020-08-31 09:12:23,165 [grpc-default-executor-1] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: shutdown FollowerState
datanode_1_1  | 2020-08-31 09:12:23,174 [grpc-default-executor-1] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: start FollowerState
datanode_1_1  | 2020-08-31 09:12:23,177 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO impl.LeaderElection: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1: begin an election at term 1 for -1: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858], old=null
datanode_1_1  | 2020-08-31 09:12:23,180 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: shutdown LeaderElection
datanode_1_1  | 2020-08-31 09:12:23,174 [Thread-25] INFO impl.FollowerState: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1_1  | 2020-08-31 09:12:23,204 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1_1  | 2020-08-31 09:12:23,214 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-3ED01864ACBE with new leaderId: d42a3350-8147-4d70-91a8-098b29431c2d
datanode_1_1  | 2020-08-31 09:12:23,221 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE: change Leader from null to d42a3350-8147-4d70-91a8-098b29431c2d at term 1 for becomeLeader, leader elected after 7499ms
datanode_1_1  | 2020-08-31 09:12:23,221 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_1_1  | java.lang.InterruptedException: sleep interrupted
datanode_1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 2020-08-31 09:12:23,248 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1_1  | 2020-08-31 09:12:23,269 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1_1  | 2020-08-31 09:12:23,303 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE
datanode_1_1  | 2020-08-31 09:12:23,329 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1_1  | 2020-08-31 09:12:23,330 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1_1  | 2020-08-31 09:12:23,403 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "15c51e9f-babe-4940-b6ca-691db78430a7"
datanode_1_1  | uuid128 {
datanode_1_1  |   mostSigBits: 1568693716590152000
datanode_1_1  |   leastSigBits: -5275288437157252953
datanode_1_1  | }
datanode_1_1  | .
datanode_1_1  | 2020-08-31 09:12:23,408 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1_1  | 2020-08-31 09:12:23,422 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1_1  | 2020-08-31 09:12:23,426 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1_1  | 2020-08-31 09:12:23,472 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: start LeaderState
datanode_1_1  | 2020-08-31 09:12:23,559 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-08-31 09:12:23,645 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE: set configuration 0: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858], old=null at 0
datanode_1_1  | 2020-08-31 09:12:24,173 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6f9997fb-d6dd-4645-9521-3ed01864acbe/current/log_inprogress_0
datanode_1_1  | 2020-08-31 09:12:24,344 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-691DB78430A7 with new leaderId: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c
datanode_1_1  | 2020-08-31 09:12:24,344 [grpc-default-executor-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: change Leader from null to 2eef5031-1d72-43cd-9aec-f2fe042a3f3c at term 1 for appendEntries, leader elected after 6070ms
datanode_1_1  | 2020-08-31 09:12:24,463 [grpc-default-executor-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: set configuration 0: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null at 0
datanode_1_1  | 2020-08-31 09:12:24,489 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-08-31 09:12:24,494 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/current/log_inprogress_0
datanode_1_1  | 2020-08-31 09:12:41,617 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_1_1  | java.lang.InterruptedException: sleep interrupted
datanode_1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 2020-08-31 09:13:58,461 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_1_1  | java.lang.InterruptedException: sleep interrupted
datanode_1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 2020-08-31 09:14:03,300 [SIGTERM handler] ERROR ozone.HddsDatanodeService: RECEIVED SIGNAL 15: SIGTERM
datanode_6_1  | 2020-08-31 09:12:23,712 [Thread-23] INFO impl.RaftServerImpl: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_6_1  | 2020-08-31 09:12:23,714 [Thread-23] INFO impl.RoleInfo: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca: start LeaderElection
datanode_6_1  | 2020-08-31 09:12:23,743 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO impl.LeaderElection: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1: begin an election at term 1 for -1: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858], old=null
datanode_6_1  | 2020-08-31 09:12:23,744 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO impl.RoleInfo: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca: shutdown LeaderElection
datanode_6_1  | 2020-08-31 09:12:23,744 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO impl.RaftServerImpl: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_6_1  | 2020-08-31 09:12:23,745 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-E82389A92A2D with new leaderId: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca
datanode_6_1  | 2020-08-31 09:12:23,746 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO impl.RaftServerImpl: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D: change Leader from null to 1ea02341-7f4f-4c0b-8dce-ac3c127598ca at term 1 for becomeLeader, leader elected after 7009ms
datanode_6_1  | 2020-08-31 09:12:23,746 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_6_1  | java.lang.InterruptedException: sleep interrupted
datanode_6_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-08-31 09:12:23,783 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_6_1  | 2020-08-31 09:12:23,786 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_6_1  | 2020-08-31 09:12:23,795 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D
datanode_6_1  | 2020-08-31 09:12:23,836 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_6_1  | 2020-08-31 09:12:23,859 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_6_1  | 2020-08-31 09:12:23,892 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_6_1  | 2020-08-31 09:12:23,913 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_6_1  | 2020-08-31 09:12:23,921 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_6_1  | 2020-08-31 09:12:23,972 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO impl.RoleInfo: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca: start LeaderState
datanode_6_1  | 2020-08-31 09:12:24,054 [grpc-default-executor-0] INFO impl.RaftServerImpl: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051
datanode_6_1  | 2020-08-31 09:12:24,099 [grpc-default-executor-0] INFO impl.RoleInfo: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca: shutdown FollowerState
datanode_6_1  | 2020-08-31 09:12:24,100 [grpc-default-executor-0] INFO impl.RoleInfo: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca: start FollowerState
datanode_6_1  | 2020-08-31 09:12:24,217 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-08-31 09:12:24,563 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-LeaderElection1] INFO impl.RaftServerImpl: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D: set configuration 0: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858], old=null at 0
datanode_6_1  | 2020-08-31 09:12:24,965 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-E82389A92A2D-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/db19c46a-fcf4-4a0e-b4ad-e82389a92a2d/current/log_inprogress_0
datanode_6_1  | 2020-08-31 09:12:25,038 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C67C4A012799 with new leaderId: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051
datanode_6_1  | 2020-08-31 09:12:25,040 [grpc-default-executor-0] INFO impl.RaftServerImpl: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799: change Leader from null to 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051 at term 1 for appendEntries, leader elected after 6181ms
datanode_6_1  | 2020-08-31 09:12:25,175 [grpc-default-executor-0] INFO impl.RaftServerImpl: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799: set configuration 0: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null at 0
datanode_6_1  | 2020-08-31 09:12:25,176 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-08-31 09:12:25,180 [1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca@group-C67C4A012799-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799/current/log_inprogress_0
datanode_6_1  | 2020-08-31 09:12:44,514 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_6_1  | java.lang.InterruptedException: sleep interrupted
datanode_6_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-08-31 09:13:16,634 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_6_1  | java.lang.InterruptedException: sleep interrupted
datanode_6_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-08-31 09:15:15,554 [SIGTERM handler] ERROR ozone.HddsDatanodeService: RECEIVED SIGNAL 15: SIGTERM
datanode_6_1  | 2020-08-31 09:15:15,641 [shutdown-hook-0] INFO ozone.HddsDatanodeService: SHUTDOWN_MSG: 
datanode_5_1  | 2020-08-31 09:12:17,511 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-08-31 09:12:17,511 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7 does not exist. Creating ...
datanode_5_1  | 2020-08-31 09:12:17,549 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/in_use.lock acquired by nodename 6@8bb706c33d66
datanode_5_1  | 2020-08-31 09:12:17,556 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7 has been successfully formatted.
datanode_5_1  | 2020-08-31 09:12:17,557 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_5_1  | java.lang.InterruptedException: sleep interrupted
datanode_5_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-08-31 09:12:17,558 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-691DB78430A7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-08-31 09:12:17,563 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_5_1  | 2020-08-31 09:12:17,573 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-08-31 09:12:17,577 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-08-31 09:12:17,577 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7
datanode_5_1  | 2020-08-31 09:12:17,578 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-08-31 09:12:17,578 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-08-31 09:12:17,578 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-08-31 09:12:17,598 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7
datanode_5_1  | 2020-08-31 09:12:17,601 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-08-31 09:12:17,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-08-31 09:12:17,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-08-31 09:12:17,606 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-08-31 09:12:17,606 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-08-31 09:12:17,606 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-08-31 09:12:17,606 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-08-31 09:12:17,607 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-08-31 09:12:17,607 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-08-31 09:12:17,614 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-08-31 09:12:17,626 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-08-31 09:12:17,637 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-08-31 09:12:17,684 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-08-31 09:12:17,685 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-08-31 09:12:17,685 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-08-31 09:12:17,685 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-08-31 09:12:17,686 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-08-31 09:12:17,686 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7
datanode_5_1  | 2020-08-31 09:12:17,689 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7
datanode_5_1  | 2020-08-31 09:12:17,690 [pool-19-thread-1] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7: start as a follower, conf=-1: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null
datanode_5_1  | 2020-08-31 09:12:17,696 [pool-19-thread-1] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-08-31 09:12:17,697 [pool-19-thread-1] INFO impl.RoleInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: start FollowerState
datanode_5_1  | 2020-08-31 09:12:17,707 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-691DB78430A7,id=2eef5031-1d72-43cd-9aec-f2fe042a3f3c
datanode_5_1  | 2020-08-31 09:12:17,710 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7
datanode_5_1  | 2020-08-31 09:12:22,366 [Thread-23] INFO impl.FollowerState: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-FollowerState: change to CANDIDATE, lastRpcTime:5195ms, electionTimeout:5150ms
datanode_5_1  | 2020-08-31 09:12:22,414 [Thread-23] INFO impl.RoleInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: shutdown FollowerState
datanode_5_1  | 2020-08-31 09:12:22,418 [Thread-23] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-08-31 09:12:22,456 [Thread-23] INFO impl.RoleInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: start LeaderElection
datanode_5_1  | 2020-08-31 09:12:22,533 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO impl.LeaderElection: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1: begin an election at term 1 for -1: [2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858], old=null
datanode_5_1  | 2020-08-31 09:12:22,554 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO impl.RoleInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: shutdown LeaderElection
datanode_5_1  | 2020-08-31 09:12:22,560 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-08-31 09:12:22,587 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-AB0BCD82E761 with new leaderId: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c
datanode_5_1  | 2020-08-31 09:12:22,595 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_5_1  | java.lang.InterruptedException: sleep interrupted
datanode_5_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-08-31 09:12:22,596 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761: change Leader from null to 2eef5031-1d72-43cd-9aec-f2fe042a3f3c at term 1 for becomeLeader, leader elected after 7081ms
datanode_5_1  | 2020-08-31 09:12:22,655 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | 2020-08-31 09:12:22,657 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5_1  | 2020-08-31 09:12:22,678 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761
datanode_5_1  | 2020-08-31 09:12:22,688 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5_1  | 2020-08-31 09:12:22,737 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_5_1  | 2020-08-31 09:12:22,802 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5_1  | 2020-08-31 09:12:22,805 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5_1  | 2020-08-31 09:12:22,810 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5_1  | 2020-08-31 09:12:22,853 [Thread-25] INFO impl.FollowerState: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-FollowerState: change to CANDIDATE, lastRpcTime:5155ms, electionTimeout:5134ms
datanode_5_1  | 2020-08-31 09:12:22,866 [Thread-25] INFO impl.RoleInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: shutdown FollowerState
datanode_5_1  | 2020-08-31 09:12:22,866 [Thread-25] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1_1  | 2020-08-31 09:14:03,364 [shutdown-hook-0] INFO ozone.HddsDatanodeService: SHUTDOWN_MSG: 
datanode_1_1  | /************************************************************
datanode_1_1  | SHUTDOWN_MSG: Shutting down HddsDatanodeService at e2f9588ed766/10.5.0.4
datanode_1_1  | ************************************************************/
datanode_1_1  | Enabled profiling in kernel
datanode_1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1_1  | 2020-08-31 09:14:52,063 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1_1  | /************************************************************
datanode_1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1_1  | STARTUP_MSG:   host = e2f9588ed766/10.5.0.4
datanode_1_1  | STARTUP_MSG:   args = []
datanode_1_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_1_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/0ec1a8a011043711372c3f3a48ee4035beed641f ; compiled by 'runner' on 2020-08-31T08:37Z
datanode_1_1  | STARTUP_MSG:   java = 11.0.7
datanode_1_1  | ************************************************************/
datanode_1_1  | 2020-08-31 09:14:52,121 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1_1  | 2020-08-31 09:14:53,018 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1_1  | 2020-08-31 09:14:53,483 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1_1  | 2020-08-31 09:14:54,465 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1_1  | 2020-08-31 09:14:54,465 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1_1  | 2020-08-31 09:14:54,984 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:e2f9588ed766 ip:10.5.0.4
datanode_1_1  | 2020-08-31 09:14:55,549 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 8192 at 2020-08-31T09:14:03.359Z
datanode_1_1  | 2020-08-31 09:14:55,573 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1_1  | 2020-08-31 09:14:55,705 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1_1  | 2020-08-31 09:14:55,748 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1_1  | 2020-08-31 09:14:56,051 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1_1  | 2020-08-31 09:14:56,289 [Thread-5] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_1_1  | 2020-08-31 09:14:57,210 [Thread-5] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_1_1  | 2020-08-31 09:14:57,211 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_1_1  | 2020-08-31 09:15:01,578 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1_1  | 2020-08-31 09:15:02,050 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1_1  | 2020-08-31 09:15:02,725 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1_1  | 2020-08-31 09:15:02,741 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1_1  | 2020-08-31 09:15:02,748 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-08-31 09:15:02,759 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1_1  | 2020-08-31 09:15:02,763 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-08-31 09:15:03,602 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-08-31 09:15:03,610 [main] INFO impl.RaftServerProxy: d42a3350-8147-4d70-91a8-098b29431c2d: found a subdirectory /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7
datanode_1_1  | 2020-08-31 09:15:03,636 [main] INFO impl.RaftServerProxy: d42a3350-8147-4d70-91a8-098b29431c2d: addNew group-691DB78430A7:[] returns group-691DB78430A7:java.util.concurrent.CompletableFuture@4ce25e47[Not completed]
datanode_1_1  | 2020-08-31 09:15:03,637 [main] INFO impl.RaftServerProxy: d42a3350-8147-4d70-91a8-098b29431c2d: found a subdirectory /data/metadata/ratis/6f9997fb-d6dd-4645-9521-3ed01864acbe
datanode_1_1  | 2020-08-31 09:15:03,638 [main] INFO impl.RaftServerProxy: d42a3350-8147-4d70-91a8-098b29431c2d: addNew group-3ED01864ACBE:[] returns group-3ED01864ACBE:java.util.concurrent.CompletableFuture@6380e9e9[Not completed]
datanode_1_1  | 2020-08-31 09:15:03,638 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1_1  | 2020-08-31 09:15:04,005 [pool-19-thread-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d: new RaftServerImpl for group-691DB78430A7:[] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-08-31 09:15:04,017 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-08-31 09:15:04,028 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-08-31 09:15:04,028 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-08-31 09:15:04,029 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-08-31 09:15:04,029 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-08-31 09:15:04,052 [pool-19-thread-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-08-31 09:15:04,074 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-08-31 09:15:04,093 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-08-31 09:15:04,140 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/in_use.lock acquired by nodename 7@e2f9588ed766
datanode_1_1  | 2020-08-31 09:15:04,471 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-691DB78430A7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-08-31 09:15:04,486 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1_1  | 2020-08-31 09:15:04,519 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-08-31 09:15:04,582 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-08-31 09:15:04,660 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7
datanode_1_1  | 2020-08-31 09:15:04,860 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-08-31 09:15:04,900 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-08-31 09:15:05,009 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-08-31 09:15:05,018 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1_1  | 2020-08-31 09:15:05,109 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7
datanode_1_1  | 2020-08-31 09:15:05,253 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-08-31 09:15:05,254 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-08-31 09:15:05,255 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-08-31 09:15:05,255 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-08-31 09:15:05,256 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-08-31 09:15:05,256 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-08-31 09:15:05,270 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-08-31 09:15:05,270 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-08-31 09:15:05,270 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-08-31 09:15:05,281 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1_1  | 2020-08-31 09:15:05,437 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-08-31 09:15:05,509 [main] INFO util.log: Logging initialized @18160ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1_1  | 2020-08-31 09:15:05,665 [pool-19-thread-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: set configuration 0: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null at 0
datanode_1_1  | 2020-08-31 09:15:05,780 [pool-19-thread-1] INFO segmented.LogSegment: Successfully read 299 entries from segment file /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/current/log_inprogress_0
datanode_1_1  | 2020-08-31 09:15:05,810 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 298
datanode_1_1  | 2020-08-31 09:15:05,811 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-08-31 09:15:06,194 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1_1  | 2020-08-31 09:15:06,204 [pool-19-thread-1] INFO raftlog.RaftLog: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLog: commitIndex: updateToMax old=-1, new=296, updated? true
datanode_1_1  | 2020-08-31 09:15:06,217 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-08-31 09:15:06,227 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-08-31 09:15:06,229 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-08-31 09:15:06,233 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-08-31 09:15:06,235 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-08-31 09:15:06,237 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1_1  | 2020-08-31 09:15:06,274 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1_1  | 2020-08-31 09:15:06,291 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1_1  | 2020-08-31 09:15:06,291 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1_1  | 2020-08-31 09:15:06,291 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1_1  | 2020-08-31 09:15:06,314 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7
datanode_1_1  | 2020-08-31 09:15:06,330 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7
datanode_1_1  | 2020-08-31 09:15:06,385 [pool-19-thread-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d: new RaftServerImpl for group-3ED01864ACBE:[] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-08-31 09:15:06,387 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-08-31 09:15:06,393 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-08-31 09:15:06,393 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-08-31 09:15:06,393 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-08-31 09:15:06,393 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-08-31 09:15:06,393 [pool-19-thread-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-08-31 09:15:06,394 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-08-31 09:15:06,395 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-08-31 09:15:06,402 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6f9997fb-d6dd-4645-9521-3ed01864acbe/in_use.lock acquired by nodename 7@e2f9588ed766
datanode_2_1  | 2020-08-31 09:15:08,466 [Datanode State Machine Task Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa at port 9858
datanode_2_1  | 2020-08-31 09:15:08,538 [Datanode State Machine Task Thread - 1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31: start as a follower, conf=0: [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null
datanode_2_1  | 2020-08-31 09:15:08,539 [Datanode State Machine Task Thread - 1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31: changes role from      null to FOLLOWER at term 1 for startAsFollower
datanode_2_1  | 2020-08-31 09:15:08,540 [Datanode State Machine Task Thread - 1] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: start FollowerState
datanode_2_1  | 2020-08-31 09:15:08,551 [Datanode State Machine Task Thread - 1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6B2584A28C31,id=9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa
datanode_2_1  | 2020-08-31 09:15:08,552 [Datanode State Machine Task Thread - 1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31
datanode_2_1  | 2020-08-31 09:15:08,563 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: start as a follower, conf=0: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null
datanode_2_1  | 2020-08-31 09:15:08,563 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: changes role from      null to FOLLOWER at term 1 for startAsFollower
datanode_2_1  | 2020-08-31 09:15:08,563 [ForkJoinPool.commonPool-worker-3] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: start FollowerState
datanode_2_1  | 2020-08-31 09:15:08,586 [ForkJoinPool.commonPool-worker-3] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-691DB78430A7,id=9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa
datanode_2_1  | 2020-08-31 09:15:08,597 [ForkJoinPool.commonPool-worker-3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7
datanode_2_1  | 2020-08-31 09:15:08,608 [Datanode State Machine Task Thread - 1] INFO impl.RaftServerProxy: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: start RPC server
datanode_2_1  | 2020-08-31 09:15:08,819 [Datanode State Machine Task Thread - 1] INFO server.GrpcService: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2_1  | 2020-08-31 09:15:10,227 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-691DB78430A7 with new leaderId: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c
datanode_2_1  | 2020-08-31 09:15:10,232 [grpc-default-executor-0] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: change Leader from null to 2eef5031-1d72-43cd-9aec-f2fe042a3f3c at term 1 for appendEntries, leader elected after 7754ms
datanode_2_1  | 2020-08-31 09:15:10,285 [grpc-default-executor-0] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: Failed appendEntries: the first entry (index 298) is already committed (commit index: 298)
datanode_2_1  | 2020-08-31 09:15:10,285 [grpc-default-executor-0] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: inconsistency entries. Reply:2eef5031-1d72-43cd-9aec-f2fe042a3f3c<-9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa#366:FAIL,INCONSISTENCY,nextIndex:299,term:1,followerCommit:298
datanode_2_1  | 2020-08-31 09:15:13,595 [Thread-20] INFO impl.FollowerState: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-FollowerState: change to CANDIDATE, lastRpcTime:5054ms, electionTimeout:5032ms
datanode_2_1  | 2020-08-31 09:15:13,595 [Thread-20] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: shutdown FollowerState
datanode_2_1  | 2020-08-31 09:15:13,595 [Thread-20] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_2_1  | 2020-08-31 09:15:13,598 [Thread-20] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: start LeaderElection
datanode_2_1  | 2020-08-31 09:15:13,709 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO impl.LeaderElection: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1: begin an election at term 2 for 0: [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null
datanode_2_1  | 2020-08-31 09:15:13,710 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: shutdown LeaderElection
datanode_2_1  | 2020-08-31 09:15:13,711 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode_2_1  | 2020-08-31 09:15:13,711 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6B2584A28C31 with new leaderId: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa
datanode_2_1  | 2020-08-31 09:15:13,712 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_2_1  | java.lang.InterruptedException: sleep interrupted
datanode_2_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | 2020-08-31 09:15:13,724 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31: change Leader from null to 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa at term 2 for becomeLeader, leader elected after 8332ms
datanode_2_1  | 2020-08-31 09:15:13,766 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2_1  | 2020-08-31 09:15:13,767 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2_1  | 2020-08-31 09:15:13,776 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31
datanode_2_1  | 2020-08-31 09:15:13,779 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2_1  | 2020-08-31 09:15:13,804 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2_1  | 2020-08-31 09:15:13,854 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2_1  | 2020-08-31 09:15:13,856 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2_1  | 2020-08-31 09:15:13,867 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2_1  | 2020-08-31 09:15:13,924 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: start LeaderState
datanode_2_1  | 2020-08-31 09:15:13,963 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
datanode_2_1  | 2020-08-31 09:15:14,026 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/32735a0c-b4d9-4bc0-babf-6b2584a28c31/current/log_inprogress_0 to /data/metadata/ratis/32735a0c-b4d9-4bc0-babf-6b2584a28c31/current/log_0-0
datanode_2_1  | 2020-08-31 09:15:14,042 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/32735a0c-b4d9-4bc0-babf-6b2584a28c31/current/log_inprogress_1
datanode_2_1  | 2020-08-31 09:15:14,070 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31-LeaderElection1] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-6B2584A28C31: set configuration 1: [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null at 1
datanode_2_1  | 2020-08-31 09:15:16,131 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: installSnapshot onError, lastRequest: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa#366-t1, previous=(t:1, i:297), leaderCommit=298, initializing? false, entries: size=1, first=(t:1, i:298), METADATAENTRY(c:296): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_2_1  | 2020-08-31 09:15:20,950 [grpc-default-executor-0] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: change Leader from 2eef5031-1d72-43cd-9aec-f2fe042a3f3c to null at term 2 for updateCurrentTerm
datanode_2_1  | 2020-08-31 09:15:20,950 [grpc-default-executor-0] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:d42a3350-8147-4d70-91a8-098b29431c2d
datanode_2_1  | 2020-08-31 09:15:20,950 [grpc-default-executor-0] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: shutdown FollowerState
datanode_2_1  | 2020-08-31 09:15:20,950 [grpc-default-executor-0] INFO impl.RoleInfo: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: start FollowerState
datanode_2_1  | 2020-08-31 09:15:20,950 [Thread-21] INFO impl.FollowerState: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2_1  | 2020-08-31 09:15:21,139 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-691DB78430A7 with new leaderId: d42a3350-8147-4d70-91a8-098b29431c2d
datanode_2_1  | 2020-08-31 09:15:21,139 [grpc-default-executor-0] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: change Leader from null to d42a3350-8147-4d70-91a8-098b29431c2d at term 2 for appendEntries, leader elected after 189ms
datanode_2_1  | 2020-08-31 09:15:21,174 [grpc-default-executor-0] INFO impl.RaftServerImpl: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7: set configuration 299: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null at 299
datanode_2_1  | 2020-08-31 09:15:21,175 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLogWorker: Rolling segment log-0_298 to index:298
datanode_2_1  | 2020-08-31 09:15:21,176 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/current/log_inprogress_0 to /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/current/log_0-298
datanode_2_1  | 2020-08-31 09:15:21,179 [9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa@group-691DB78430A7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/current/log_inprogress_299
datanode_5_1  | 2020-08-31 09:12:22,867 [Thread-25] INFO impl.RoleInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: start LeaderElection
datanode_5_1  | 2020-08-31 09:12:22,944 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO impl.LeaderElection: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2: begin an election at term 1 for -1: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null
datanode_5_1  | 2020-08-31 09:12:22,951 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO impl.RoleInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: start LeaderState
datanode_5_1  | 2020-08-31 09:12:23,162 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-08-31 09:12:23,275 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-LeaderElection1] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761: set configuration 0: [2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858], old=null at 0
datanode_5_1  | 2020-08-31 09:12:23,305 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO impl.LeaderElection: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2: Election PASSED; received 1 response(s) [2eef5031-1d72-43cd-9aec-f2fe042a3f3c<-d42a3350-8147-4d70-91a8-098b29431c2d#0:OK-t1] and 0 exception(s); 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7:t1, leader=null, voted=2eef5031-1d72-43cd-9aec-f2fe042a3f3c, raftlog=2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null
datanode_5_1  | 2020-08-31 09:12:23,314 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO impl.RoleInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: shutdown LeaderElection
datanode_5_1  | 2020-08-31 09:12:23,331 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-08-31 09:12:23,333 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-691DB78430A7 with new leaderId: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c
datanode_5_1  | 2020-08-31 09:12:23,337 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7: change Leader from null to 2eef5031-1d72-43cd-9aec-f2fe042a3f3c at term 1 for becomeLeader, leader elected after 5772ms
datanode_5_1  | 2020-08-31 09:12:23,337 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | 2020-08-31 09:12:23,341 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5_1  | 2020-08-31 09:12:23,343 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7
datanode_5_1  | 2020-08-31 09:12:23,344 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5_1  | 2020-08-31 09:12:23,337 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_5_1  | java.lang.InterruptedException: sleep interrupted
datanode_5_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-08-31 09:12:23,356 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_6_1  | /************************************************************
datanode_6_1  | SHUTDOWN_MSG: Shutting down HddsDatanodeService at 4a45e335c821/10.5.0.9
datanode_6_1  | ************************************************************/
datanode_3_1  | 2020-08-31 09:12:23,637 [Thread-23] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3_1  | 2020-08-31 09:12:23,639 [Thread-23] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: start LeaderElection
datanode_3_1  | 2020-08-31 09:12:23,658 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO impl.LeaderElection: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1: begin an election at term 1 for -1: [fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858], old=null
datanode_3_1  | 2020-08-31 09:12:23,659 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: shutdown LeaderElection
datanode_3_1  | 2020-08-31 09:12:23,660 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3_1  | 2020-08-31 09:12:23,660 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-14AD5C02C389 with new leaderId: fb769711-6072-404d-8d33-36b40dabaa1b
datanode_3_1  | 2020-08-31 09:12:23,661 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389: change Leader from null to fb769711-6072-404d-8d33-36b40dabaa1b at term 1 for becomeLeader, leader elected after 6490ms
datanode_3_1  | 2020-08-31 09:12:23,661 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_3_1  | java.lang.InterruptedException: sleep interrupted
datanode_3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | 2020-08-31 09:12:23,687 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-08-31 09:12:23,688 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 2020-08-31 09:12:23,705 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389
datanode_3_1  | 2020-08-31 09:12:23,722 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-08-31 09:12:23,728 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-08-31 09:12:23,784 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3_1  | 2020-08-31 09:12:23,789 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-08-31 09:12:23,799 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-08-31 09:12:23,846 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: start LeaderState
datanode_3_1  | 2020-08-31 09:12:23,918 [grpc-default-executor-0] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051
datanode_3_1  | 2020-08-31 09:12:23,925 [grpc-default-executor-0] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: shutdown FollowerState
datanode_3_1  | 2020-08-31 09:12:23,929 [Thread-25] INFO impl.FollowerState: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_3_1  | 2020-08-31 09:12:23,930 [grpc-default-executor-0] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: start FollowerState
datanode_3_1  | 2020-08-31 09:12:24,115 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-08-31 09:12:24,365 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389: set configuration 0: [fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858], old=null at 0
datanode_3_1  | 2020-08-31 09:12:24,719 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7024b68f-1a89-45d9-8080-14ad5c02c389/current/log_inprogress_0
datanode_3_1  | 2020-08-31 09:12:25,084 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C67C4A012799 with new leaderId: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051
datanode_3_1  | 2020-08-31 09:12:25,097 [grpc-default-executor-0] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799: change Leader from null to 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051 at term 1 for appendEntries, leader elected after 6269ms
datanode_3_1  | 2020-08-31 09:12:25,223 [grpc-default-executor-0] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799: set configuration 0: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null at 0
datanode_3_1  | 2020-08-31 09:12:25,223 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-08-31 09:12:25,226 [fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799/current/log_inprogress_0
datanode_3_1  | 2020-08-31 09:12:44,710 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_3_1  | java.lang.InterruptedException: sleep interrupted
datanode_3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | 2020-08-31 09:13:16,643 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_3_1  | java.lang.InterruptedException: sleep interrupted
datanode_3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 2020-08-31 09:15:06,403 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-3ED01864ACBE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-08-31 09:15:06,403 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1_1  | 2020-08-31 09:15:06,404 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-08-31 09:15:06,404 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-08-31 09:15:06,406 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE
datanode_1_1  | 2020-08-31 09:15:06,407 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-08-31 09:15:06,408 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-08-31 09:15:06,413 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-08-31 09:14:03,306 [SIGTERM handler] ERROR ozone.HddsDatanodeService: RECEIVED SIGNAL 15: SIGTERM
datanode_3_1  | 2020-08-31 09:14:03,339 [shutdown-hook-0] INFO ozone.HddsDatanodeService: SHUTDOWN_MSG: 
datanode_3_1  | /************************************************************
datanode_3_1  | SHUTDOWN_MSG: Shutting down HddsDatanodeService at 0e7bdc6ca2ae/10.5.0.6
datanode_3_1  | ************************************************************/
datanode_3_1  | Enabled profiling in kernel
datanode_3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3_1  | 2020-08-31 09:14:53,654 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3_1  | /************************************************************
datanode_3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3_1  | STARTUP_MSG:   host = 0e7bdc6ca2ae/10.5.0.6
datanode_3_1  | STARTUP_MSG:   args = []
datanode_3_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_5_1  | 2020-08-31 09:12:23,365 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5_1  | 2020-08-31 09:12:23,371 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5_1  | 2020-08-31 09:12:23,375 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5_1  | 2020-08-31 09:12:23,416 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_5_1  | 2020-08-31 09:12:23,427 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-08-31 09:12:23,431 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_5_1  | 2020-08-31 09:12:23,466 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_5_1  | 2020-08-31 09:12:23,467 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-08-31 09:12:23,494 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "15c51e9f-babe-4940-b6ca-691db78430a7"
datanode_5_1  | uuid128 {
datanode_5_1  |   mostSigBits: 1568693716590152000
datanode_5_1  |   leastSigBits: -5275288437157252953
datanode_5_1  | }
datanode_5_1  | .
datanode_5_1  | 2020-08-31 09:12:23,545 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-08-31 09:12:23,574 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7
datanode_5_1  | 2020-08-31 09:12:23,603 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_5_1  | 2020-08-31 09:12:23,621 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-08-31 09:12:23,629 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_5_1  | 2020-08-31 09:12:23,631 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_5_1  | 2020-08-31 09:12:23,635 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-08-31 09:12:23,637 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-08-31 09:12:23,643 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO impl.RoleInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c: start LeaderState
datanode_5_1  | 2020-08-31 09:12:23,685 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-08-31 09:12:23,724 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-LeaderElection2] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7: set configuration 0: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null at 0
datanode_5_1  | 2020-08-31 09:12:23,869 [grpc-default-executor-0] INFO impl.RaftServerImpl: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-   LEADER: Withhold vote from candidate 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa with term 1. State: leader=2eef5031-1d72-43cd-9aec-f2fe042a3f3c, term=1, lastRpcElapsed=null
datanode_5_1  | 2020-08-31 09:12:24,494 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/current/log_inprogress_0
datanode_5_1  | 2020-08-31 09:12:24,555 [2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-AB0BCD82E761-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c16aa0e5-9758-42e0-b015-ab0bcd82e761/current/log_inprogress_0
datanode_5_1  | 2020-08-31 09:12:41,391 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_5_1  | java.lang.InterruptedException: sleep interrupted
datanode_5_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-08-31 09:13:58,472 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_5_1  | java.lang.InterruptedException: sleep interrupted
datanode_5_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-08-31 09:14:03,863 [grpc-default-executor-2] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode_5_1  | 2020-08-31 09:14:03,866 [grpc-default-executor-2] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:14:03,897 [grpc-default-executor-0] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: Network closed for unknown reason
datanode_5_1  | 2020-08-31 09:14:03,897 [grpc-default-executor-0] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:14:36,049 [grpc-default-executor-2] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_3_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/0ec1a8a011043711372c3f3a48ee4035beed641f ; compiled by 'runner' on 2020-08-31T08:37Z
datanode_3_1  | STARTUP_MSG:   java = 11.0.7
datanode_3_1  | ************************************************************/
datanode_3_1  | 2020-08-31 09:14:53,738 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3_1  | 2020-08-31 09:14:54,715 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3_1  | 2020-08-31 09:14:55,057 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3_1  | 2020-08-31 09:14:55,733 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3_1  | 2020-08-31 09:14:55,733 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3_1  | 2020-08-31 09:14:56,586 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:0e7bdc6ca2ae ip:10.5.0.6
datanode_3_1  | 2020-08-31 09:14:57,036 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 8192 at 2020-08-31T09:14:03.338Z
datanode_3_1  | 2020-08-31 09:14:57,041 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3_1  | 2020-08-31 09:14:57,067 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3_1  | 2020-08-31 09:14:57,084 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3_1  | 2020-08-31 09:14:57,253 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3_1  | 2020-08-31 09:14:57,418 [Thread-5] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_3_1  | 2020-08-31 09:14:58,658 [Thread-5] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_3_1  | 2020-08-31 09:14:58,659 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 1s
datanode_3_1  | 2020-08-31 09:15:02,794 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3_1  | 2020-08-31 09:15:03,400 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3_1  | 2020-08-31 09:15:03,627 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3_1  | 2020-08-31 09:15:03,628 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3_1  | 2020-08-31 09:15:03,633 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-08-31 09:15:03,637 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3_1  | 2020-08-31 09:15:03,645 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-08-31 09:15:04,246 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-08-31 09:15:04,254 [main] INFO impl.RaftServerProxy: fb769711-6072-404d-8d33-36b40dabaa1b: found a subdirectory /data/metadata/ratis/7024b68f-1a89-45d9-8080-14ad5c02c389
datanode_3_1  | 2020-08-31 09:15:04,285 [main] INFO impl.RaftServerProxy: fb769711-6072-404d-8d33-36b40dabaa1b: addNew group-14AD5C02C389:[] returns group-14AD5C02C389:java.util.concurrent.CompletableFuture@367d34c0[Not completed]
datanode_3_1  | 2020-08-31 09:15:04,286 [main] INFO impl.RaftServerProxy: fb769711-6072-404d-8d33-36b40dabaa1b: found a subdirectory /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799
datanode_3_1  | 2020-08-31 09:15:04,286 [main] INFO impl.RaftServerProxy: fb769711-6072-404d-8d33-36b40dabaa1b: addNew group-C67C4A012799:[] returns group-C67C4A012799:java.util.concurrent.CompletableFuture@4ce25e47[Not completed]
datanode_3_1  | 2020-08-31 09:15:04,288 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3_1  | 2020-08-31 09:15:04,785 [pool-19-thread-1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b: new RaftServerImpl for group-14AD5C02C389:[] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-08-31 09:15:04,788 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-08-31 09:15:04,812 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-08-31 09:15:04,829 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-08-31 09:15:04,830 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-08-31 09:15:04,840 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-08-31 09:15:04,896 [pool-19-thread-1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-08-31 09:15:04,931 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-08-31 09:15:04,954 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-08-31 09:15:05,088 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7024b68f-1a89-45d9-8080-14ad5c02c389/in_use.lock acquired by nodename 6@0e7bdc6ca2ae
datanode_3_1  | 2020-08-31 09:15:05,589 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-14AD5C02C389: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-08-31 09:15:05,590 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3_1  | 2020-08-31 09:15:05,616 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-08-31 09:15:05,652 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-08-31 09:15:05,679 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389
datanode_3_1  | 2020-08-31 09:15:05,716 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3_1  | 2020-08-31 09:15:05,725 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-08-31 09:15:05,743 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-08-31 09:15:05,854 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-08-31 09:15:05,881 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/7024b68f-1a89-45d9-8080-14ad5c02c389
datanode_3_1  | 2020-08-31 09:15:05,897 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-08-31 09:14:36,056 [grpc-default-executor-0] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_5_1  | 2020-08-31 09:14:39,050 [grpc-default-executor-2] WARN grpc.GrpcUtil: Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=28, target=10.5.0.4:9858}}. 
datanode_5_1  | 2020-08-31 09:14:39,052 [grpc-default-executor-2] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:14:39,056 [grpc-default-executor-0] WARN grpc.GrpcUtil: Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=32, target=10.5.0.5:9858}}. 
datanode_5_1  | 2020-08-31 09:14:39,057 [grpc-default-executor-0] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:14:54,402 [grpc-default-executor-2] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_5_1  | 2020-08-31 09:14:54,403 [grpc-default-executor-2] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:14:54,404 [grpc-default-executor-0] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_5_1  | 2020-08-31 09:14:54,406 [grpc-default-executor-0] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:14:56,564 [grpc-default-executor-3] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_5_1  | 2020-08-31 09:14:56,565 [grpc-default-executor-3] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:14:56,581 [grpc-default-executor-3] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_5_1  | 2020-08-31 09:14:56,584 [grpc-default-executor-3] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:14:59,081 [grpc-default-executor-2] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_5_1  | 2020-08-31 09:14:59,081 [grpc-default-executor-0] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_5_1  | 2020-08-31 09:14:59,092 [grpc-default-executor-2] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:14:59,095 [grpc-default-executor-0] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:15:01,574 [grpc-default-executor-3] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_5_1  | 2020-08-31 09:15:01,574 [grpc-default-executor-0] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_5_1  | 2020-08-31 09:15:01,575 [grpc-default-executor-3] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:15:01,576 [grpc-default-executor-0] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:15:04,070 [grpc-default-executor-0] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_5_1  | 2020-08-31 09:15:04,074 [grpc-default-executor-2] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_5_1  | 2020-08-31 09:15:04,080 [grpc-default-executor-0] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:15:04,080 [grpc-default-executor-2] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:15:06,579 [grpc-default-executor-3] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_5_1  | 2020-08-31 09:15:06,580 [grpc-default-executor-3] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:15:06,597 [grpc-default-executor-3] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_5_1  | 2020-08-31 09:15:06,626 [grpc-default-executor-3] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:15:09,081 [grpc-default-executor-3] WARN server.GrpcLogAppender: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_3_1  | 2020-08-31 09:15:05,897 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-08-31 09:15:05,900 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-08-31 09:15:05,910 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-08-31 09:15:05,913 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-08-31 09:15:05,925 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-08-31 09:15:05,928 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-08-31 09:15:05,930 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-08-31 09:15:05,931 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-08-31 09:15:05,933 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3_1  | 2020-08-31 09:15:05,989 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-08-31 09:15:06,083 [main] INFO util.log: Logging initialized @17242ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3_1  | 2020-08-31 09:15:06,178 [pool-19-thread-1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389: set configuration 0: [fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858], old=null at 0
datanode_3_1  | 2020-08-31 09:15:06,190 [pool-19-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/7024b68f-1a89-45d9-8080-14ad5c02c389/current/log_inprogress_0
datanode_3_1  | 2020-08-31 09:15:06,215 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
datanode_3_1  | 2020-08-31 09:15:06,216 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-08-31 09:15:06,790 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3_1  | 2020-08-31 09:15:06,830 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3_1  | 2020-08-31 09:15:06,839 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-08-31 09:15:06,849 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-08-31 09:15:06,849 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-08-31 09:15:06,869 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-08-31 09:15:06,854 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3_1  | 2020-08-31 09:15:06,871 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-08-31 09:15:06,873 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3_1  | 2020-08-31 09:15:06,892 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3_1  | 2020-08-31 09:15:06,892 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3_1  | 2020-08-31 09:15:07,100 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389
datanode_3_1  | 2020-08-31 09:15:07,131 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389
datanode_3_1  | 2020-08-31 09:15:07,229 [pool-19-thread-1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b: new RaftServerImpl for group-C67C4A012799:[] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-08-31 09:15:07,229 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-08-31 09:15:07,230 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-08-31 09:15:07,247 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-08-31 09:15:07,247 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-08-31 09:15:07,248 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-08-31 09:15:07,248 [pool-19-thread-1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-08-31 09:15:07,248 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-08-31 09:15:07,249 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-08-31 09:15:07,258 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799/in_use.lock acquired by nodename 6@0e7bdc6ca2ae
datanode_3_1  | 2020-08-31 09:15:07,259 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-C67C4A012799: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-08-31 09:15:07,259 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3_1  | 2020-08-31 09:15:07,260 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-08-31 09:15:07,262 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-08-31 09:15:07,262 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799
datanode_3_1  | 2020-08-31 09:15:07,263 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-08-31 09:15:07,263 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-08-31 09:15:07,264 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-08-31 09:15:07,265 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799
datanode_3_1  | 2020-08-31 09:15:07,277 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-08-31 09:15:07,277 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-08-31 09:15:07,281 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-08-31 09:15:07,281 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-08-31 09:15:07,281 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-08-31 09:15:07,281 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-08-31 09:15:07,282 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-08-31 09:15:07,287 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-08-31 09:15:07,288 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-08-31 09:15:07,289 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-08-31 09:15:07,300 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_3_1  | 2020-08-31 09:15:07,308 [pool-19-thread-1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799: set configuration 0: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null at 0
datanode_3_1  | 2020-08-31 09:15:07,360 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3_1  | 2020-08-31 09:15:07,394 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_3_1  | 2020-08-31 09:15:07,528 [pool-19-thread-1] INFO segmented.LogSegment: Successfully read 194 entries from segment file /data/metadata/ratis/2f48de6e-e67a-4c1b-a8d1-c67c4a012799/current/log_inprogress_0
datanode_3_1  | 2020-08-31 09:15:07,539 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 193
datanode_3_1  | 2020-08-31 09:15:07,539 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-08-31 09:15:07,603 [pool-19-thread-1] INFO raftlog.RaftLog: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-SegmentedRaftLog: commitIndex: updateToMax old=-1, new=191, updated? true
datanode_3_1  | 2020-08-31 09:15:07,603 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-08-31 09:15:07,603 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-08-31 09:15:07,603 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-08-31 09:15:07,603 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-08-31 09:15:07,604 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-08-31 09:15:07,604 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799
datanode_3_1  | 2020-08-31 09:15:07,604 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799
datanode_3_1  | 2020-08-31 09:15:07,676 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3_1  | 2020-08-31 09:15:07,676 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3_1  | 2020-08-31 09:15:07,685 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_3_1  | 2020-08-31 09:15:07,738 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@280ecc33{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3_1  | 2020-08-31 09:15:07,746 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1dca62c2{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3_1  | 2020-08-31 09:15:08,138 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c4059a{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-7661174901015738068.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3_1  | 2020-08-31 09:15:08,163 [main] INFO server.AbstractConnector: Started ServerConnector@4df0d9f8{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3_1  | 2020-08-31 09:15:08,165 [main] INFO server.Server: Started @19325ms
datanode_3_1  | 2020-08-31 09:15:08,178 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3_1  | 2020-08-31 09:15:08,178 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3_1  | 2020-08-31 09:15:08,190 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3_1  | 2020-08-31 09:15:08,280 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@b99735c] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3_1  | 2020-08-31 09:15:10,679 [Datanode State Machine Task Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3_1  | 2020-08-31 09:15:10,684 [Datanode State Machine Task Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3_1  | 2020-08-31 09:15:10,685 [Datanode State Machine Task Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis fb769711-6072-404d-8d33-36b40dabaa1b at port 9858
datanode_3_1  | 2020-08-31 09:15:10,754 [Datanode State Machine Task Thread - 1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389: start as a follower, conf=0: [fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858], old=null
datanode_3_1  | 2020-08-31 09:15:10,755 [Datanode State Machine Task Thread - 1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389: changes role from      null to FOLLOWER at term 1 for startAsFollower
datanode_3_1  | 2020-08-31 09:15:10,756 [Datanode State Machine Task Thread - 1] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: start FollowerState
datanode_3_1  | 2020-08-31 09:15:10,769 [Datanode State Machine Task Thread - 1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-14AD5C02C389,id=fb769711-6072-404d-8d33-36b40dabaa1b
datanode_3_1  | 2020-08-31 09:15:10,777 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799: start as a follower, conf=0: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null
datanode_3_1  | 2020-08-31 09:15:10,778 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799: changes role from      null to FOLLOWER at term 1 for startAsFollower
datanode_3_1  | 2020-08-31 09:15:10,778 [Datanode State Machine Task Thread - 1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389
datanode_3_1  | 2020-08-31 09:15:10,779 [ForkJoinPool.commonPool-worker-3] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: start FollowerState
datanode_3_1  | 2020-08-31 09:15:10,789 [ForkJoinPool.commonPool-worker-3] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C67C4A012799,id=fb769711-6072-404d-8d33-36b40dabaa1b
datanode_5_1  | 2020-08-31 09:15:09,086 [grpc-default-executor-3] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d: nextIndex: updateUnconditionally 299 -> 298
datanode_5_1  | 2020-08-31 09:15:10,314 [grpc-default-executor-3] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa: nextIndex: updateUnconditionally 299 -> 299
datanode_5_1  | 2020-08-31 09:15:13,244 [grpc-default-executor-3] INFO impl.FollowerInfo: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c@group-691DB78430A7->d42a3350-8147-4d70-91a8-098b29431c2d: nextIndex: updateUnconditionally 299 -> 299
datanode_5_1  | 2020-08-31 09:15:15,529 [SIGTERM handler] ERROR ozone.HddsDatanodeService: RECEIVED SIGNAL 15: SIGTERM
datanode_5_1  | 2020-08-31 09:15:15,547 [shutdown-hook-0] INFO ozone.HddsDatanodeService: SHUTDOWN_MSG: 
datanode_5_1  | /************************************************************
datanode_5_1  | SHUTDOWN_MSG: Shutting down HddsDatanodeService at 8bb706c33d66/10.5.0.8
datanode_5_1  | ************************************************************/
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-08-31 09:11:47,711 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = ebe3fdc40a91/10.5.0.71
scm_1         | STARTUP_MSG:   args = [--init]
scm_1         | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_3_1  | 2020-08-31 09:15:10,796 [ForkJoinPool.commonPool-worker-3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799
datanode_3_1  | 2020-08-31 09:15:10,802 [Datanode State Machine Task Thread - 1] INFO impl.RaftServerProxy: fb769711-6072-404d-8d33-36b40dabaa1b: start RPC server
datanode_3_1  | 2020-08-31 09:15:11,034 [Datanode State Machine Task Thread - 1] INFO server.GrpcService: fb769711-6072-404d-8d33-36b40dabaa1b: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3_1  | 2020-08-31 09:15:13,540 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C67C4A012799 with new leaderId: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051
datanode_3_1  | 2020-08-31 09:15:13,542 [grpc-default-executor-0] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799: change Leader from null to 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051 at term 1 for appendEntries, leader elected after 6281ms
datanode_3_1  | 2020-08-31 09:15:13,588 [grpc-default-executor-0] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799: Failed appendEntries: the first entry (index 193) is already committed (commit index: 193)
datanode_3_1  | 2020-08-31 09:15:13,589 [grpc-default-executor-0] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799: inconsistency entries. Reply:1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051<-fb769711-6072-404d-8d33-36b40dabaa1b#267:FAIL,INCONSISTENCY,nextIndex:194,term:1,followerCommit:191
datanode_3_1  | 2020-08-31 09:15:15,946 [Thread-20] INFO impl.FollowerState: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-FollowerState: change to CANDIDATE, lastRpcTime:5189ms, electionTimeout:5182ms
datanode_3_1  | 2020-08-31 09:15:15,946 [Thread-20] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: shutdown FollowerState
datanode_3_1  | 2020-08-31 09:15:15,947 [Thread-20] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_3_1  | 2020-08-31 09:15:15,950 [Thread-20] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: start LeaderElection
datanode_3_1  | 2020-08-31 09:15:16,041 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO impl.LeaderElection: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1: begin an election at term 2 for 0: [fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858], old=null
datanode_3_1  | 2020-08-31 09:15:16,045 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: shutdown LeaderElection
datanode_3_1  | 2020-08-31 09:15:16,046 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode_3_1  | 2020-08-31 09:15:16,053 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-14AD5C02C389 with new leaderId: fb769711-6072-404d-8d33-36b40dabaa1b
datanode_3_1  | 2020-08-31 09:15:16,085 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_3_1  | java.lang.InterruptedException: sleep interrupted
datanode_3_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | 2020-08-31 09:15:16,205 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389: change Leader from null to fb769711-6072-404d-8d33-36b40dabaa1b at term 2 for becomeLeader, leader elected after 10463ms
datanode_3_1  | 2020-08-31 09:15:16,212 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: fb769711-6072-404d-8d33-36b40dabaa1b: installSnapshot onError, lastRequest: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051->fb769711-6072-404d-8d33-36b40dabaa1b#267-t1, previous=(t:1, i:192), leaderCommit=193, initializing? false, entries: size=1, first=(t:1, i:193), METADATAENTRY(c:191): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_3_1  | 2020-08-31 09:15:16,216 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-08-31 09:15:16,216 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 2020-08-31 09:15:16,258 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389
datanode_3_1  | 2020-08-31 09:15:16,276 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-08-31 09:15:16,295 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-08-31 09:15:16,317 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3_1  | 2020-08-31 09:15:16,332 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-08-31 09:15:16,333 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-08-31 09:15:16,370 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: start LeaderState
datanode_3_1  | 2020-08-31 09:15:16,441 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
datanode_3_1  | 2020-08-31 09:15:17,167 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-LeaderElection1] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389: set configuration 1: [fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858], old=null at 1
datanode_3_1  | 2020-08-31 09:15:17,172 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/7024b68f-1a89-45d9-8080-14ad5c02c389/current/log_inprogress_0 to /data/metadata/ratis/7024b68f-1a89-45d9-8080-14ad5c02c389/current/log_0-0
datanode_3_1  | 2020-08-31 09:15:17,217 [fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: fb769711-6072-404d-8d33-36b40dabaa1b@group-14AD5C02C389-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7024b68f-1a89-45d9-8080-14ad5c02c389/current/log_inprogress_1
datanode_3_1  | 2020-08-31 09:15:21,076 [Thread-21] INFO impl.FollowerState: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-FollowerState: change to CANDIDATE, lastRpcTime:7486ms, electionTimeout:5183ms
datanode_3_1  | 2020-08-31 09:15:21,077 [Thread-21] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: shutdown FollowerState
datanode_3_1  | 2020-08-31 09:15:21,077 [Thread-21] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_3_1  | 2020-08-31 09:15:21,077 [Thread-21] INFO impl.RoleInfo: fb769711-6072-404d-8d33-36b40dabaa1b: start LeaderElection
datanode_3_1  | 2020-08-31 09:15:21,079 [fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-LeaderElection2] INFO impl.RaftServerImpl: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799: change Leader from 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051 to null at term 1 for initElection
datanode_3_1  | 2020-08-31 09:15:21,080 [fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-LeaderElection2] INFO impl.LeaderElection: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-LeaderElection2: begin an election at term 2 for 0: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null
datanode_3_1  | 2020-08-31 09:15:24,586 [fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-LeaderElection2] INFO impl.LeaderElection: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-LeaderElection2 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_3_1  | 2020-08-31 09:15:26,170 [fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-LeaderElection2] INFO impl.LeaderElection: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-LeaderElection2: Election TIMEOUT; received 0 response(s) [] and 1 exception(s); fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799:t2, leader=null, voted=fb769711-6072-404d-8d33-36b40dabaa1b, raftlog=fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-SegmentedRaftLog:OPENED:c193,f193,i193, conf=0: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null
datanode_3_1  | 2020-08-31 09:15:26,170 [fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-LeaderElection2] INFO impl.LeaderElection:   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_3_1  | 2020-08-31 09:15:26,174 [fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-LeaderElection2] INFO impl.LeaderElection: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-LeaderElection2: begin an election at term 3 for 0: [1ea02341-7f4f-4c0b-8dce-ac3c127598ca:10.5.0.9:9858, fb769711-6072-404d-8d33-36b40dabaa1b:10.5.0.6:9858, 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051:10.5.0.7:9858], old=null
datanode_3_1  | 2020-08-31 09:15:27,651 [fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-LeaderElection2] INFO impl.LeaderElection: fb769711-6072-404d-8d33-36b40dabaa1b@group-C67C4A012799-LeaderElection2 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
datanode_1_1  | 2020-08-31 09:15:06,416 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/6f9997fb-d6dd-4645-9521-3ed01864acbe
datanode_1_1  | 2020-08-31 09:15:06,417 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-08-31 09:15:06,417 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-08-31 09:15:06,418 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-08-31 09:15:06,418 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-08-31 09:15:06,418 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-08-31 09:15:06,418 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-08-31 09:15:06,419 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-08-31 09:15:06,419 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-08-31 09:15:06,425 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-08-31 09:15:06,434 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-08-31 09:15:06,450 [pool-19-thread-1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE: set configuration 0: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858], old=null at 0
datanode_1_1  | 2020-08-31 09:15:06,458 [pool-19-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/6f9997fb-d6dd-4645-9521-3ed01864acbe/current/log_inprogress_0
datanode_1_1  | 2020-08-31 09:15:06,459 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
datanode_1_1  | 2020-08-31 09:15:06,459 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-08-31 09:15:06,473 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-08-31 09:15:06,473 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-08-31 09:15:06,473 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-08-31 09:15:06,474 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-08-31 09:15:06,481 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-08-31 09:15:06,481 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE
datanode_1_1  | 2020-08-31 09:15:06,482 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE
datanode_1_1  | 2020-08-31 09:15:06,602 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1_1  | 2020-08-31 09:15:06,682 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1_1  | 2020-08-31 09:15:06,684 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
datanode_1_1  | 2020-08-31 09:15:06,910 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1_1  | 2020-08-31 09:15:06,928 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1_1  | 2020-08-31 09:15:06,930 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1_1  | 2020-08-31 09:15:07,003 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57b1ec84{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1_1  | 2020-08-31 09:15:07,020 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@52657d5f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1_1  | 2020-08-31 09:15:07,613 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4b336cc8{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-16178484455229132574.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1_1  | 2020-08-31 09:15:07,651 [main] INFO server.AbstractConnector: Started ServerConnector@35e75f7a{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1_1  | 2020-08-31 09:15:07,652 [main] INFO server.Server: Started @20302ms
datanode_1_1  | 2020-08-31 09:15:07,659 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1_1  | 2020-08-31 09:15:07,660 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1_1  | 2020-08-31 09:15:07,679 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1_1  | 2020-08-31 09:15:07,745 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6cb11a69] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1_1  | 2020-08-31 09:15:10,378 [Datanode State Machine Task Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1_1  | 2020-08-31 09:15:10,396 [Datanode State Machine Task Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1_1  | 2020-08-31 09:15:10,399 [Datanode State Machine Task Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis d42a3350-8147-4d70-91a8-098b29431c2d at port 9858
datanode_1_1  | 2020-08-31 09:15:10,422 [Datanode State Machine Task Thread - 1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE: start as a follower, conf=0: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858], old=null
datanode_1_1  | 2020-08-31 09:15:10,424 [Datanode State Machine Task Thread - 1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE: changes role from      null to FOLLOWER at term 1 for startAsFollower
datanode_1_1  | 2020-08-31 09:15:10,425 [Datanode State Machine Task Thread - 1] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: start FollowerState
datanode_1_1  | 2020-08-31 09:15:10,434 [Datanode State Machine Task Thread - 1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3ED01864ACBE,id=d42a3350-8147-4d70-91a8-098b29431c2d
datanode_1_1  | 2020-08-31 09:15:10,436 [Datanode State Machine Task Thread - 1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE
datanode_1_1  | 2020-08-31 09:15:10,446 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: start as a follower, conf=0: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null
datanode_1_1  | 2020-08-31 09:15:10,447 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: changes role from      null to FOLLOWER at term 1 for startAsFollower
datanode_1_1  | 2020-08-31 09:15:10,447 [ForkJoinPool.commonPool-worker-3] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: start FollowerState
datanode_1_1  | 2020-08-31 09:15:10,456 [ForkJoinPool.commonPool-worker-3] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-691DB78430A7,id=d42a3350-8147-4d70-91a8-098b29431c2d
datanode_1_1  | 2020-08-31 09:15:10,461 [ForkJoinPool.commonPool-worker-3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7
datanode_1_1  | 2020-08-31 09:15:10,462 [Datanode State Machine Task Thread - 1] INFO impl.RaftServerProxy: d42a3350-8147-4d70-91a8-098b29431c2d: start RPC server
datanode_1_1  | 2020-08-31 09:15:10,682 [Datanode State Machine Task Thread - 1] INFO server.GrpcService: d42a3350-8147-4d70-91a8-098b29431c2d: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1_1  | 2020-08-31 09:15:13,112 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-691DB78430A7 with new leaderId: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c
datanode_1_1  | 2020-08-31 09:15:13,121 [grpc-default-executor-0] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: change Leader from null to 2eef5031-1d72-43cd-9aec-f2fe042a3f3c at term 1 for appendEntries, leader elected after 8640ms
datanode_1_1  | 2020-08-31 09:15:13,208 [grpc-default-executor-0] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: Failed appendEntries: the first entry (index 298) is already committed (commit index: 298)
datanode_1_1  | 2020-08-31 09:15:13,213 [grpc-default-executor-0] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: inconsistency entries. Reply:2eef5031-1d72-43cd-9aec-f2fe042a3f3c<-d42a3350-8147-4d70-91a8-098b29431c2d#368:FAIL,INCONSISTENCY,nextIndex:299,term:1,followerCommit:298
datanode_1_1  | 2020-08-31 09:15:15,573 [Thread-20] INFO impl.FollowerState: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-FollowerState: change to CANDIDATE, lastRpcTime:5148ms, electionTimeout:5112ms
datanode_1_1  | 2020-08-31 09:15:15,573 [Thread-20] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: shutdown FollowerState
datanode_1_1  | 2020-08-31 09:15:15,574 [Thread-20] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_1_1  | 2020-08-31 09:15:15,576 [Thread-20] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: start LeaderElection
datanode_1_1  | 2020-08-31 09:15:15,653 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO impl.LeaderElection: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1: begin an election at term 2 for 0: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858], old=null
datanode_1_1  | 2020-08-31 09:15:15,658 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: shutdown LeaderElection
datanode_1_1  | 2020-08-31 09:15:15,673 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode_1_1  | 2020-08-31 09:15:15,673 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-3ED01864ACBE with new leaderId: d42a3350-8147-4d70-91a8-098b29431c2d
datanode_1_1  | 2020-08-31 09:15:15,675 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_1_1  | java.lang.InterruptedException: sleep interrupted
datanode_1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 2020-08-31 09:15:15,708 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE: change Leader from null to d42a3350-8147-4d70-91a8-098b29431c2d at term 2 for becomeLeader, leader elected after 9270ms
datanode_1_1  | 2020-08-31 09:15:15,729 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1_1  | 2020-08-31 09:15:15,732 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1_1  | 2020-08-31 09:15:15,753 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE
datanode_1_1  | 2020-08-31 09:15:15,762 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1_1  | 2020-08-31 09:15:15,775 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1_1  | 2020-08-31 09:15:15,835 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1_1  | 2020-08-31 09:15:15,846 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1_1  | 2020-08-31 09:15:15,848 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1_1  | 2020-08-31 09:15:15,891 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: start LeaderState
datanode_1_1  | 2020-08-31 09:15:15,908 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
datanode_1_1  | 2020-08-31 09:15:15,937 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/6f9997fb-d6dd-4645-9521-3ed01864acbe/current/log_inprogress_0 to /data/metadata/ratis/6f9997fb-d6dd-4645-9521-3ed01864acbe/current/log_0-0
datanode_1_1  | 2020-08-31 09:15:15,940 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-LeaderElection1] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE: set configuration 1: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858], old=null at 1
datanode_1_1  | 2020-08-31 09:15:15,962 [d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-3ED01864ACBE-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6f9997fb-d6dd-4645-9521-3ed01864acbe/current/log_inprogress_1
datanode_1_1  | 2020-08-31 09:15:16,120 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: d42a3350-8147-4d70-91a8-098b29431c2d: installSnapshot onError, lastRequest: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c->d42a3350-8147-4d70-91a8-098b29431c2d#368-t1, previous=(t:1, i:297), leaderCommit=298, initializing? false, entries: size=1, first=(t:1, i:298), METADATAENTRY(c:296): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
datanode_1_1  | 2020-08-31 09:15:20,590 [Thread-21] INFO impl.FollowerState: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-FollowerState: change to CANDIDATE, lastRpcTime:7376ms, electionTimeout:5103ms
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/0ec1a8a011043711372c3f3a48ee4035beed641f ; compiled by 'runner' on 2020-08-31T08:37Z
scm_1         | STARTUP_MSG:   java = 11.0.7
scm_1         | ************************************************************/
scm_1         | 2020-08-31 09:11:47,944 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-08-31 09:11:49,639 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-08-31 09:11:50,397 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-e424131d-f9e4-4dcd-8e99-014ef902334f;layoutVersion=0
scm_1         | 2020-08-31 09:11:50,517 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1         | /************************************************************
scm_1         | SHUTDOWN_MSG: Shutting down StorageContainerManager at ebe3fdc40a91/10.5.0.71
scm_1         | ************************************************************/
scm_1         | Enabled profiling in kernel
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-08-31 09:12:05,548 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = ebe3fdc40a91/10.5.0.71
scm_1         | STARTUP_MSG:   args = []
scm_1         | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/0ec1a8a011043711372c3f3a48ee4035beed641f ; compiled by 'runner' on 2020-08-31T08:37Z
scm_1         | STARTUP_MSG:   java = 11.0.7
scm_1         | ************************************************************/
scm_1         | 2020-08-31 09:12:05,566 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-08-31 09:12:05,773 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-08-31 09:12:06,022 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-08-31 09:12:06,197 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@30c31dd7
scm_1         | 2020-08-31 09:12:06,198 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1         | 2020-08-31 09:12:06,346 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1         | 2020-08-31 09:12:06,495 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
scm_1         | 2020-08-31 09:12:06,549 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1         | 2020-08-31 09:12:06,585 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm_1         | 2020-08-31 09:12:06,644 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1         | 2020-08-31 09:12:06,646 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1         | 2020-08-31 09:12:07,377 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-08-31 09:12:07,408 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1         | 2020-08-31 09:12:07,451 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-08-31 09:12:07,505 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1         | 2020-08-31 09:12:07,550 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-08-31 09:12:07,562 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1         | 2020-08-31 09:12:07,624 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1         | 2020-08-31 09:12:07,624 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1         | 2020-08-31 09:12:07,671 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @14524ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1         | 2020-08-31 09:12:07,855 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | 2020-08-31 09:12:07,884 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1         | 2020-08-31 09:12:07,900 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1         | 2020-08-31 09:12:07,905 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1         | 2020-08-31 09:12:07,908 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1         | 2020-08-31 09:12:07,908 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1         | 2020-08-31 09:12:07,977 [Listener at 0.0.0.0/9860] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
scm_1         | 2020-08-31 09:12:08,011 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1         | 2020-08-31 09:12:08,132 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1         | 2020-08-31 09:12:08,222 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1         | 2020-08-31 09:12:08,222 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1         | 2020-08-31 09:12:08,545 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1         | 2020-08-31 09:12:08,545 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-08-31 09:12:08,546 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1         | 2020-08-31 09:12:08,718 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1         | 2020-08-31 09:12:08,721 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1         | 2020-08-31 09:12:08,726 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-08-31 09:12:08,726 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1         | 2020-08-31 09:12:08,832 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1         | 2020-08-31 09:12:08,842 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1         | 2020-08-31 09:12:08,848 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-08-31 09:12:08,851 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
datanode_1_1  | 2020-08-31 09:15:20,591 [Thread-21] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: shutdown FollowerState
datanode_1_1  | 2020-08-31 09:15:20,591 [Thread-21] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_1_1  | 2020-08-31 09:15:20,591 [Thread-21] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: start LeaderElection
datanode_1_1  | 2020-08-31 09:15:20,593 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: change Leader from 2eef5031-1d72-43cd-9aec-f2fe042a3f3c to null at term 1 for initElection
datanode_1_1  | 2020-08-31 09:15:20,596 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO impl.LeaderElection: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2: begin an election at term 2 for 0: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null
datanode_1_1  | 2020-08-31 09:15:20,982 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO impl.LeaderElection: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2: Election PASSED; received 1 response(s) [d42a3350-8147-4d70-91a8-098b29431c2d<-9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa#0:OK-t2] and 0 exception(s); d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7:t2, leader=null, voted=d42a3350-8147-4d70-91a8-098b29431c2d, raftlog=d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLog:OPENED:c298,f298,i298, conf=0: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null
datanode_1_1  | 2020-08-31 09:15:20,985 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: shutdown LeaderElection
datanode_1_1  | 2020-08-31 09:15:20,986 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
datanode_1_1  | 2020-08-31 09:15:20,986 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-691DB78430A7 with new leaderId: d42a3350-8147-4d70-91a8-098b29431c2d
datanode_1_1  | 2020-08-31 09:15:20,987 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: change Leader from null to d42a3350-8147-4d70-91a8-098b29431c2d at term 2 for becomeLeader, leader elected after 393ms
datanode_1_1  | 2020-08-31 09:15:20,987 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1_1  | 2020-08-31 09:15:20,987 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1_1  | 2020-08-31 09:15:20,987 [Datanode State Machine Thread - 0] WARN statemachine.DatanodeStateMachine: Interrupt the execution.
datanode_1_1  | java.lang.InterruptedException: sleep interrupted
datanode_1_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:243)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:405)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | 2020-08-31 09:15:20,992 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7
datanode_1_1  | 2020-08-31 09:15:20,994 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1_1  | 2020-08-31 09:15:20,994 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1_1  | 2020-08-31 09:15:20,994 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1_1  | 2020-08-31 09:15:20,994 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1_1  | 2020-08-31 09:15:20,995 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1_1  | 2020-08-31 09:15:21,009 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1_1  | 2020-08-31 09:15:21,009 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-08-31 09:15:21,010 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1_1  | 2020-08-31 09:15:21,021 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1_1  | 2020-08-31 09:15:21,023 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-08-31 09:15:21,023 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-08-31 09:15:21,028 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7
datanode_1_1  | 2020-08-31 09:15:21,043 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1_1  | 2020-08-31 09:15:21,043 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-08-31 09:15:21,043 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1_1  | 2020-08-31 09:15:21,043 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1_1  | 2020-08-31 09:15:21,049 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-08-31 09:15:21,049 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-08-31 09:15:21,063 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO impl.RoleInfo: d42a3350-8147-4d70-91a8-098b29431c2d: start LeaderState
datanode_1_1  | 2020-08-31 09:15:21,067 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLogWorker: Rolling segment log-0_298 to index:298
datanode_1_1  | 2020-08-31 09:15:21,070 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/current/log_inprogress_0 to /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/current/log_0-298
datanode_1_1  | 2020-08-31 09:15:21,075 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/15c51e9f-babe-4940-b6ca-691db78430a7/current/log_inprogress_299
datanode_1_1  | 2020-08-31 09:15:21,089 [d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7-LeaderElection2] INFO impl.RaftServerImpl: d42a3350-8147-4d70-91a8-098b29431c2d@group-691DB78430A7: set configuration 299: [d42a3350-8147-4d70-91a8-098b29431c2d:10.5.0.4:9858, 2eef5031-1d72-43cd-9aec-f2fe042a3f3c:10.5.0.8:9858, 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa:10.5.0.5:9858], old=null at 299
scm_1         | 2020-08-31 09:12:08,966 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1         | 2020-08-31 09:12:08,976 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.7+10-LTS
scm_1         | 2020-08-31 09:12:09,146 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1         | 2020-08-31 09:12:09,154 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1         | 2020-08-31 09:12:09,177 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1         | 2020-08-31 09:12:09,222 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@48567727{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1         | 2020-08-31 09:12:09,223 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@70091872{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1         | 2020-08-31 09:12:09,444 [IPC Server handler 4 on default port 9861] WARN ipc.Server: IPC Server handler 4 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.9:33464: output error
scm_1         | 2020-08-31 09:12:09,452 [IPC Server handler 6 on default port 9861] WARN ipc.Server: IPC Server handler 6 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.6:41970: output error
scm_1         | 2020-08-31 09:12:09,453 [IPC Server handler 9 on default port 9861] WARN ipc.Server: IPC Server handler 9 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.5:57074: output error
scm_1         | 2020-08-31 09:12:09,457 [IPC Server handler 5 on default port 9861] WARN ipc.Server: IPC Server handler 5 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.7:51910: output error
scm_1         | 2020-08-31 09:12:09,458 [IPC Server handler 0 on default port 9861] WARN ipc.Server: IPC Server handler 0 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.8:44470: output error
scm_1         | 2020-08-31 09:12:09,465 [IPC Server handler 2 on default port 9861] WARN ipc.Server: IPC Server handler 2 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.4:35534: output error
scm_1         | 2020-08-31 09:12:09,527 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-08-31 09:12:09,538 [IPC Server handler 6 on default port 9861] INFO ipc.Server: IPC Server handler 6 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-08-31 09:12:09,539 [IPC Server handler 5 on default port 9861] INFO ipc.Server: IPC Server handler 5 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-08-31 09:12:09,553 [IPC Server handler 9 on default port 9861] INFO ipc.Server: IPC Server handler 9 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-08-31 09:12:09,553 [IPC Server handler 2 on default port 9861] INFO ipc.Server: IPC Server handler 2 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-08-31 09:12:09,556 [IPC Server handler 4 on default port 9861] INFO ipc.Server: IPC Server handler 4 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-08-31 09:12:10,474 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@386e9fd8{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-1_1_0-SNAPSHOT_jar-_-any-15893617363067185446.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar!/webapps/scm}
scm_1         | 2020-08-31 09:12:10,605 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@7661e474{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1         | 2020-08-31 09:12:10,633 [Listener at 0.0.0.0/9860] INFO server.Server: Started @17486ms
scm_1         | 2020-08-31 09:12:10,657 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1         | 2020-08-31 09:12:10,657 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1         | 2020-08-31 09:12:10,670 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1         | 2020-08-31 09:12:10,764 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7858d31d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1         | 2020-08-31 09:12:12,011 [IPC Server handler 46 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/2eef5031-1d72-43cd-9aec-f2fe042a3f3c
scm_1         | 2020-08-31 09:12:12,062 [IPC Server handler 46 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 2eef5031-1d72-43cd-9aec-f2fe042a3f3c{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-08-31 09:12:12,106 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 4 required.
scm_1         | 2020-08-31 09:12:12,084 [IPC Server handler 13 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/d42a3350-8147-4d70-91a8-098b29431c2d
scm_1         | 2020-08-31 09:12:12,237 [IPC Server handler 13 on default port 9861] INFO node.SCMNodeManager: Registered Data node : d42a3350-8147-4d70-91a8-098b29431c2d{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-08-31 09:12:12,239 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 4 required.
scm_1         | 2020-08-31 09:12:12,107 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-08-31 09:12:12,239 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-08-31 09:12:12,322 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c16aa0e5-9758-42e0-b015-ab0bcd82e761 to datanode:2eef5031-1d72-43cd-9aec-f2fe042a3f3c
scm_1         | 2020-08-31 09:12:12,404 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa
scm_1         | 2020-08-31 09:12:12,404 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-08-31 09:12:12,422 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 4 required.
scm_1         | 2020-08-31 09:12:12,422 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-08-31 09:12:12,564 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: c16aa0e5-9758-42e0-b015-ab0bcd82e761, Nodes: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-08-31T09:12:12.317987Z]
scm_1         | 2020-08-31 09:12:12,630 [IPC Server handler 7 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/1ea02341-7f4f-4c0b-8dce-ac3c127598ca
scm_1         | 2020-08-31 09:12:12,630 [IPC Server handler 7 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 1ea02341-7f4f-4c0b-8dce-ac3c127598ca{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-08-31 09:12:12,642 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 4 required.
scm_1         | 2020-08-31 09:12:12,642 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-08-31 09:12:12,655 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=6f9997fb-d6dd-4645-9521-3ed01864acbe to datanode:d42a3350-8147-4d70-91a8-098b29431c2d
scm_1         | 2020-08-31 09:12:12,663 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 6f9997fb-d6dd-4645-9521-3ed01864acbe, Nodes: d42a3350-8147-4d70-91a8-098b29431c2d{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-08-31T09:12:12.655429Z]
scm_1         | 2020-08-31 09:12:12,664 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=db19c46a-fcf4-4a0e-b4ad-e82389a92a2d to datanode:1ea02341-7f4f-4c0b-8dce-ac3c127598ca
scm_1         | 2020-08-31 09:12:12,664 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: db19c46a-fcf4-4a0e-b4ad-e82389a92a2d, Nodes: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-08-31T09:12:12.664336Z]
scm_1         | 2020-08-31 09:12:12,676 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-08-31 09:12:12,676 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1         | 2020-08-31 09:12:12,698 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=32735a0c-b4d9-4bc0-babf-6b2584a28c31 to datanode:9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa
scm_1         | 2020-08-31 09:12:12,699 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 32735a0c-b4d9-4bc0-babf-6b2584a28c31, Nodes: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-08-31T09:12:12.698459Z]
scm_1         | 2020-08-31 09:12:12,854 [IPC Server handler 14 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051
scm_1         | 2020-08-31 09:12:12,854 [IPC Server handler 14 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-08-31 09:12:12,885 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-08-31 09:12:12,885 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-08-31 09:12:12,886 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a40e8651-2594-4500-a3cd-923d69527124 to datanode:1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051
scm_1         | 2020-08-31 09:12:12,886 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: a40e8651-2594-4500-a3cd-923d69527124, Nodes: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-08-31T09:12:12.886254Z]
scm_1         | 2020-08-31 09:12:12,942 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=15c51e9f-babe-4940-b6ca-691db78430a7 to datanode:d42a3350-8147-4d70-91a8-098b29431c2d
scm_1         | 2020-08-31 09:12:12,942 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=15c51e9f-babe-4940-b6ca-691db78430a7 to datanode:2eef5031-1d72-43cd-9aec-f2fe042a3f3c
scm_1         | 2020-08-31 09:12:12,943 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=15c51e9f-babe-4940-b6ca-691db78430a7 to datanode:9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa
scm_1         | 2020-08-31 09:12:12,943 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 15c51e9f-babe-4940-b6ca-691db78430a7, Nodes: d42a3350-8147-4d70-91a8-098b29431c2d{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}2eef5031-1d72-43cd-9aec-f2fe042a3f3c{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-08-31T09:12:12.942621Z]
scm_1         | 2020-08-31 09:12:12,961 [IPC Server handler 47 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/fb769711-6072-404d-8d33-36b40dabaa1b
scm_1         | 2020-08-31 09:12:12,961 [IPC Server handler 47 on default port 9861] INFO node.SCMNodeManager: Registered Data node : fb769711-6072-404d-8d33-36b40dabaa1b{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-08-31 09:12:12,963 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-08-31 09:12:13,000 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-08-31 09:12:12,985 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7024b68f-1a89-45d9-8080-14ad5c02c389 to datanode:fb769711-6072-404d-8d33-36b40dabaa1b
scm_1         | 2020-08-31 09:12:13,023 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 7024b68f-1a89-45d9-8080-14ad5c02c389, Nodes: fb769711-6072-404d-8d33-36b40dabaa1b{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-08-31T09:12:12.985720Z]
scm_1         | 2020-08-31 09:12:13,058 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2f48de6e-e67a-4c1b-a8d1-c67c4a012799 to datanode:1ea02341-7f4f-4c0b-8dce-ac3c127598ca
scm_1         | 2020-08-31 09:12:13,065 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2f48de6e-e67a-4c1b-a8d1-c67c4a012799 to datanode:fb769711-6072-404d-8d33-36b40dabaa1b
scm_1         | 2020-08-31 09:12:13,078 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2f48de6e-e67a-4c1b-a8d1-c67c4a012799 to datanode:1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051
scm_1         | 2020-08-31 09:12:13,090 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 2f48de6e-e67a-4c1b-a8d1-c67c4a012799, Nodes: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}fb769711-6072-404d-8d33-36b40dabaa1b{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-08-31T09:12:13.058193Z]
scm_1         | 2020-08-31 09:12:17,165 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: c16aa0e5-9758-42e0-b015-ab0bcd82e761, Nodes: 2eef5031-1d72-43cd-9aec-f2fe042a3f3c{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:2eef5031-1d72-43cd-9aec-f2fe042a3f3c, CreationTimestamp2020-08-31T09:12:12.317987Z] moved to OPEN state
scm_1         | 2020-08-31 09:12:17,209 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-08-31 09:12:17,255 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-08-31 09:12:17,802 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 32735a0c-b4d9-4bc0-babf-6b2584a28c31, Nodes: 9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa, CreationTimestamp2020-08-31T09:12:12.698459Z] moved to OPEN state
scm_1         | 2020-08-31 09:12:17,813 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-08-31 09:12:17,825 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-08-31 09:12:17,843 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 6f9997fb-d6dd-4645-9521-3ed01864acbe, Nodes: d42a3350-8147-4d70-91a8-098b29431c2d{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:d42a3350-8147-4d70-91a8-098b29431c2d, CreationTimestamp2020-08-31T09:12:12.655429Z] moved to OPEN state
scm_1         | 2020-08-31 09:12:17,843 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-08-31 09:12:17,843 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-08-31 09:12:18,077 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: a40e8651-2594-4500-a3cd-923d69527124, Nodes: 1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051, CreationTimestamp2020-08-31T09:12:12.886254Z] moved to OPEN state
scm_1         | 2020-08-31 09:12:18,077 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-08-31 09:12:18,078 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-08-31 09:12:18,304 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 7024b68f-1a89-45d9-8080-14ad5c02c389, Nodes: fb769711-6072-404d-8d33-36b40dabaa1b{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:fb769711-6072-404d-8d33-36b40dabaa1b, CreationTimestamp2020-08-31T09:12:12.985720Z] moved to OPEN state
scm_1         | 2020-08-31 09:12:18,305 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-08-31 09:12:18,305 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-08-31 09:12:18,642 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: db19c46a-fcf4-4a0e-b4ad-e82389a92a2d, Nodes: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:1ea02341-7f4f-4c0b-8dce-ac3c127598ca, CreationTimestamp2020-08-31T09:12:12.664336Z] moved to OPEN state
scm_1         | 2020-08-31 09:12:18,657 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-08-31 09:12:18,657 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-08-31 09:12:23,361 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 15c51e9f-babe-4940-b6ca-691db78430a7, Nodes: d42a3350-8147-4d70-91a8-098b29431c2d{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}2eef5031-1d72-43cd-9aec-f2fe042a3f3c{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}9ddfcaa0-9e51-4885-9d6d-687c9d0d28aa{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:2eef5031-1d72-43cd-9aec-f2fe042a3f3c, CreationTimestamp2020-08-31T09:12:12.942621Z] moved to OPEN state
scm_1         | 2020-08-31 09:12:23,362 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-08-31 09:12:23,369 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1         | 2020-08-31 09:12:23,373 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1         | 2020-08-31 09:12:23,373 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1         | 2020-08-31 09:12:23,373 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1         | 2020-08-31 09:12:24,391 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 2f48de6e-e67a-4c1b-a8d1-c67c4a012799, Nodes: 1ea02341-7f4f-4c0b-8dce-ac3c127598ca{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}fb769711-6072-404d-8d33-36b40dabaa1b{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:1d09f4f6-f7c4-4b7c-9e91-c9b3699e1051, CreationTimestamp2020-08-31T09:12:13.058193Z] moved to OPEN state
scm_1         | 2020-08-31 09:12:43,024 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:45,081 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:45,409 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:45,520 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:45,682 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:45,814 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:45,927 [IPC Server handler 69 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:46,048 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:46,162 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:46,305 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:46,449 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:46,527 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:46,682 [IPC Server handler 25 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:46,800 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:46,915 [IPC Server handler 64 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:47,027 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:47,136 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:47,251 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:47,346 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:47,492 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:47,578 [IPC Server handler 24 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:47,697 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:47,765 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:47,860 [IPC Server handler 41 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:47,969 [IPC Server handler 88 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:48,080 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:50,654 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:50,763 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:50,846 [IPC Server handler 49 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:50,934 [IPC Server handler 69 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:51,045 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:51,163 [IPC Server handler 10 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:51,275 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:53,854 [IPC Server handler 30 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:53,954 [IPC Server handler 79 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:54,047 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:56,627 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:56,721 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:56,814 [IPC Server handler 52 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:56,928 [IPC Server handler 69 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:57,013 [IPC Server handler 97 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:57,109 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:57,201 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:57,285 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:57,394 [IPC Server handler 25 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:57,466 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:57,546 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:57,650 [IPC Server handler 57 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:57,761 [IPC Server handler 15 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:57,874 [IPC Server handler 39 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:12:58,026 [IPC Server handler 98 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:00,584 [IPC Server handler 57 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:00,672 [IPC Server handler 15 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:00,791 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:00,887 [IPC Server handler 48 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:00,985 [IPC Server handler 95 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:01,143 [IPC Server handler 10 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:01,260 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:01,355 [IPC Server handler 24 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:01,438 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:01,542 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:01,629 [IPC Server handler 15 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:01,698 [IPC Server handler 0 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:01,781 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:01,884 [IPC Server handler 31 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:01,961 [IPC Server handler 79 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:02,034 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:04,618 [IPC Server handler 14 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:04,701 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:07,269 [IPC Server handler 25 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:07,346 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:07,419 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:07,499 [IPC Server handler 52 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:07,594 [IPC Server handler 14 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:07,685 [IPC Server handler 0 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:10,258 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:10,349 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:10,440 [IPC Server handler 57 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:10,523 [IPC Server handler 14 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:10,595 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:10,669 [IPC Server handler 28 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:10,760 [IPC Server handler 20 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:10,849 [IPC Server handler 22 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:10,928 [IPC Server handler 69 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:11,009 [IPC Server handler 96 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:13,614 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:13,684 [IPC Server handler 19 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:13,805 [IPC Server handler 49 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:16,384 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:16,489 [IPC Server handler 14 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:16,580 [IPC Server handler 0 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:16,701 [IPC Server handler 49 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:16,784 [IPC Server handler 7 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:16,866 [IPC Server handler 30 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:19,439 [IPC Server handler 57 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:19,521 [IPC Server handler 0 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:19,620 [IPC Server handler 28 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:19,696 [IPC Server handler 22 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:19,769 [IPC Server handler 29 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:22,334 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:22,421 [IPC Server handler 57 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:22,513 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:22,595 [IPC Server handler 28 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:22,668 [IPC Server handler 20 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:22,745 [IPC Server handler 29 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:22,853 [IPC Server handler 30 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:22,963 [IPC Server handler 79 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:23,084 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:23,196 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:23,285 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:23,366 [IPC Server handler 26 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:23,455 [IPC Server handler 14 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:23,553 [IPC Server handler 28 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:23,620 [IPC Server handler 19 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:23,680 [IPC Server handler 49 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:23,737 [IPC Server handler 29 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:23,820 [IPC Server handler 30 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:23,908 [IPC Server handler 54 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:24,007 [IPC Server handler 97 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:24,101 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:24,156 [IPC Server handler 10 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:24,211 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:24,269 [IPC Server handler 25 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:24,341 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:13:24,389 [IPC Server handler 52 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:14:10,007 [IPC Server handler 95 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-08-31 09:15:23,578 [IPC Server handler 0 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
