Attaching to ozone-topology_datanode_5_1, ozone-topology_scm_1, ozone-topology_datanode_1_1, ozone-topology_om_1, ozone-topology_datanode_3_1, ozone-topology_datanode_4_1, ozone-topology_datanode_6_1, ozone-topology_datanode_2_1
datanode_1_1  | Enabled profiling in kernel
datanode_1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1_1  | 2020-06-30 05:35:29,377 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1_1  | /************************************************************
datanode_1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1_1  | STARTUP_MSG:   host = 3490d681d880/10.5.0.4
datanode_1_1  | STARTUP_MSG:   args = []
datanode_1_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/bf23dcb95194fc844485de860846edb45b7aeb63 ; compiled by 'runner' on 2020-06-30T05:10Z
datanode_1_1  | STARTUP_MSG:   java = 11.0.6
datanode_1_1  | ************************************************************/
datanode_1_1  | 2020-06-30 05:35:29,482 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1_1  | 2020-06-30 05:35:31,360 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1_1  | 2020-06-30 05:35:32,207 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1_1  | 2020-06-30 05:35:33,537 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1_1  | 2020-06-30 05:35:33,539 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1_1  | 2020-06-30 05:35:34,163 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:3490d681d880 ip:10.5.0.4
datanode_1_1  | 2020-06-30 05:35:35,265 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1_1  | 2020-06-30 05:35:35,377 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1_1  | 2020-06-30 05:35:35,380 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1_1  | 2020-06-30 05:35:35,471 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1_1  | 2020-06-30 05:35:35,754 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1_1  | 2020-06-30 05:35:42,997 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1_1  | 2020-06-30 05:35:43,595 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1_1  | 2020-06-30 05:35:44,820 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1_1  | 2020-06-30 05:35:44,839 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1_1  | 2020-06-30 05:35:44,840 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-06-30 05:35:44,840 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1_1  | 2020-06-30 05:35:44,844 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-06-30 05:35:46,172 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-06-30 05:35:47,923 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1_1  | 2020-06-30 05:35:48,073 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1_1  | 2020-06-30 05:35:48,242 [main] INFO util.log: Logging initialized @26154ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1_1  | 2020-06-30 05:35:48,905 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1_1  | 2020-06-30 05:35:48,944 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1_1  | 2020-06-30 05:35:49,006 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1_1  | 2020-06-30 05:35:49,010 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1_1  | 2020-06-30 05:35:49,013 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1_1  | 2020-06-30 05:35:49,013 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1_1  | 2020-06-30 05:35:49,202 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1_1  | 2020-06-30 05:35:49,270 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1_1  | 2020-06-30 05:35:49,278 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1_1  | 2020-06-30 05:35:49,492 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1_1  | 2020-06-30 05:35:49,517 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1_1  | 2020-06-30 05:35:49,519 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1_1  | 2020-06-30 05:35:49,604 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d64a960{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1_1  | 2020-06-30 05:35:49,617 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@53ba1175{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1_1  | 2020-06-30 05:35:50,042 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@14590fe2{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-16368529364925640590.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1_1  | 2020-06-30 05:35:50,096 [main] INFO server.AbstractConnector: Started ServerConnector@2ab8589a{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1_1  | 2020-06-30 05:35:50,097 [main] INFO server.Server: Started @28009ms
datanode_1_1  | 2020-06-30 05:35:50,122 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1_1  | 2020-06-30 05:35:50,122 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1_1  | 2020-06-30 05:35:50,138 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1_1  | 2020-06-30 05:35:50,328 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7d2cc443] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1_1  | 2020-06-30 05:35:51,454 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1_1  | 2020-06-30 05:35:53,782 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-06-30 05:35:54,782 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-06-30 05:35:55,783 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-06-30 05:35:56,784 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-06-30 05:35:58,169 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2_1  | Enabled profiling in kernel
datanode_2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2_1  | 2020-06-30 05:35:32,013 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2_1  | /************************************************************
datanode_2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2_1  | STARTUP_MSG:   host = 347479a8e2bd/10.5.0.5
datanode_2_1  | STARTUP_MSG:   args = []
datanode_2_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/bf23dcb95194fc844485de860846edb45b7aeb63 ; compiled by 'runner' on 2020-06-30T05:10Z
datanode_2_1  | STARTUP_MSG:   java = 11.0.6
datanode_2_1  | ************************************************************/
datanode_2_1  | 2020-06-30 05:35:32,075 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2_1  | 2020-06-30 05:35:34,039 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2_1  | 2020-06-30 05:35:34,869 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2_1  | 2020-06-30 05:35:36,297 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2_1  | 2020-06-30 05:35:36,297 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2_1  | 2020-06-30 05:35:36,987 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:347479a8e2bd ip:10.5.0.5
datanode_2_1  | 2020-06-30 05:35:38,068 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2_1  | 2020-06-30 05:35:38,126 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2_1  | 2020-06-30 05:35:38,135 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2_1  | 2020-06-30 05:35:38,182 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2_1  | 2020-06-30 05:35:38,615 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2_1  | 2020-06-30 05:35:45,542 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2_1  | 2020-06-30 05:35:45,867 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2_1  | 2020-06-30 05:35:46,840 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2_1  | 2020-06-30 05:35:46,850 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2_1  | 2020-06-30 05:35:46,854 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-30 05:35:46,858 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2_1  | 2020-06-30 05:35:46,866 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-06-30 05:35:48,062 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-06-30 05:35:49,437 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2_1  | 2020-06-30 05:35:49,581 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2_1  | 2020-06-30 05:35:49,774 [main] INFO util.log: Logging initialized @25543ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2_1  | 2020-06-30 05:35:50,396 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2_1  | 2020-06-30 05:35:50,449 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2_1  | 2020-06-30 05:35:50,460 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2_1  | 2020-06-30 05:35:50,480 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2_1  | 2020-06-30 05:35:50,488 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2_1  | 2020-06-30 05:35:50,488 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2_1  | 2020-06-30 05:35:50,694 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2_1  | 2020-06-30 05:35:50,752 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2_1  | 2020-06-30 05:35:50,765 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2_1  | 2020-06-30 05:35:51,005 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2_1  | 2020-06-30 05:35:51,005 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2_1  | 2020-06-30 05:35:51,017 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_2_1  | 2020-06-30 05:35:51,121 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3ad847f8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2_1  | 2020-06-30 05:35:51,122 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@ec5f944{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2_1  | 2020-06-30 05:35:51,671 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@72f3f14c{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-9815554512727910080.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2_1  | 2020-06-30 05:35:51,718 [main] INFO server.AbstractConnector: Started ServerConnector@52909a97{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2_1  | 2020-06-30 05:35:51,721 [main] INFO server.Server: Started @27487ms
datanode_2_1  | 2020-06-30 05:35:51,741 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2_1  | 2020-06-30 05:35:51,741 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2_1  | 2020-06-30 05:35:51,753 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2_1  | 2020-06-30 05:35:51,878 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6e823a9d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2_1  | 2020-06-30 05:35:53,011 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2_1  | 2020-06-30 05:35:55,146 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-06-30 05:35:56,147 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-06-30 05:35:57,167 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2_1  | java.net.SocketTimeoutException: Call From 347479a8e2bd/10.5.0.5 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:34550 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_2_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:34550 remote=scm/10.5.0.71:9861]
datanode_2_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_2_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_2_1  | 2020-06-30 05:35:58,136 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2_1  | 2020-06-30 05:35:58,139 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2_1  | 2020-06-30 05:35:58,146 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis b33eb83e-f955-480a-aaae-270c6d5e999a at port 9858
datanode_2_1  | 2020-06-30 05:35:58,268 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: b33eb83e-f955-480a-aaae-270c6d5e999a: start RPC server
datanode_2_1  | 2020-06-30 05:35:58,806 [Datanode State Machine Thread - 1] INFO server.GrpcService: b33eb83e-f955-480a-aaae-270c6d5e999a: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2_1  | 2020-06-30 05:36:03,129 [Command processor thread] INFO impl.RaftServerProxy: b33eb83e-f955-480a-aaae-270c6d5e999a: addNew group-28251FCAA17B:[b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858] returns group-28251FCAA17B:java.util.concurrent.CompletableFuture@2321704d[Not completed]
datanode_2_1  | 2020-06-30 05:36:03,267 [pool-19-thread-1] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a: new RaftServerImpl for group-28251FCAA17B:[b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-06-30 05:36:03,279 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-06-30 05:36:03,285 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-06-30 05:36:03,289 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-06-30 05:36:03,294 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-06-30 05:36:03,297 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-06-30 05:36:03,346 [pool-19-thread-1] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B: ConfigurationManager, init=-1: [b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-06-30 05:36:03,349 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-06-30 05:36:03,362 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-06-30 05:36:03,379 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c981a611-0363-4e47-ae03-28251fcaa17b does not exist. Creating ...
datanode_2_1  | 2020-06-30 05:36:03,401 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c981a611-0363-4e47-ae03-28251fcaa17b/in_use.lock acquired by nodename 6@347479a8e2bd
datanode_2_1  | 2020-06-30 05:36:03,414 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c981a611-0363-4e47-ae03-28251fcaa17b has been successfully formatted.
datanode_2_1  | 2020-06-30 05:36:03,458 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-28251FCAA17B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-06-30 05:36:03,501 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-06-30 05:36:03,504 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-06-30 05:36:03,586 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-06-30 05:36:03,606 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-30 05:36:03,708 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-30 05:36:03,751 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B
datanode_2_1  | 2020-06-30 05:36:03,989 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | Enabled profiling in kernel
datanode_3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3_1  | 2020-06-30 05:35:31,645 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3_1  | /************************************************************
datanode_3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3_1  | STARTUP_MSG:   host = 4e1a56669dc5/10.5.0.6
datanode_3_1  | STARTUP_MSG:   args = []
datanode_3_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/bf23dcb95194fc844485de860846edb45b7aeb63 ; compiled by 'runner' on 2020-06-30T05:10Z
datanode_3_1  | STARTUP_MSG:   java = 11.0.6
datanode_3_1  | ************************************************************/
datanode_3_1  | 2020-06-30 05:35:31,728 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3_1  | 2020-06-30 05:35:33,791 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3_1  | 2020-06-30 05:35:34,747 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3_1  | 2020-06-30 05:35:36,274 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3_1  | 2020-06-30 05:35:36,274 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3_1  | 2020-06-30 05:35:37,052 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:4e1a56669dc5 ip:10.5.0.6
datanode_3_1  | 2020-06-30 05:35:38,049 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3_1  | 2020-06-30 05:35:38,102 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3_1  | 2020-06-30 05:35:38,129 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3_1  | 2020-06-30 05:35:38,165 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3_1  | 2020-06-30 05:35:38,552 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3_1  | 2020-06-30 05:35:45,073 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3_1  | 2020-06-30 05:35:45,452 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3_1  | 2020-06-30 05:35:46,428 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3_1  | 2020-06-30 05:35:46,470 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3_1  | 2020-06-30 05:35:46,471 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-30 05:35:46,471 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3_1  | 2020-06-30 05:35:46,473 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-06-30 05:35:47,406 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-06-30 05:35:49,058 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3_1  | 2020-06-30 05:35:49,193 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3_1  | 2020-06-30 05:35:49,346 [main] INFO util.log: Logging initialized @25157ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3_1  | 2020-06-30 05:35:49,995 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3_1  | 2020-06-30 05:35:50,024 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3_1  | 2020-06-30 05:35:50,084 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3_1  | 2020-06-30 05:35:50,095 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3_1  | 2020-06-30 05:35:50,109 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3_1  | 2020-06-30 05:35:50,110 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3_1  | 2020-06-30 05:35:50,294 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_3_1  | 2020-06-30 05:35:50,357 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3_1  | 2020-06-30 05:35:50,358 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3_1  | 2020-06-30 05:35:50,557 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3_1  | 2020-06-30 05:35:50,557 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3_1  | 2020-06-30 05:35:50,558 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_3_1  | 2020-06-30 05:35:50,655 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b4954b2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3_1  | 2020-06-30 05:35:50,664 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57416e49{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3_1  | 2020-06-30 05:35:51,165 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c27f72{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-7175222756229633334.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3_1  | 2020-06-30 05:35:51,258 [main] INFO server.AbstractConnector: Started ServerConnector@25cde5bb{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3_1  | 2020-06-30 05:35:51,261 [main] INFO server.Server: Started @27072ms
datanode_3_1  | 2020-06-30 05:35:51,274 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3_1  | 2020-06-30 05:35:51,280 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3_1  | 2020-06-30 05:35:51,298 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3_1  | 2020-06-30 05:35:51,459 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3fc56d1d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3_1  | 2020-06-30 05:35:52,374 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3_1  | 2020-06-30 05:35:54,624 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-06-30 05:35:55,625 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-06-30 05:35:56,626 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-06-30 05:35:57,684 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2_1  | 2020-06-30 05:36:04,032 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/c981a611-0363-4e47-ae03-28251fcaa17b
datanode_2_1  | 2020-06-30 05:36:04,090 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-06-30 05:36:04,093 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-06-30 05:36:04,103 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-30 05:36:04,125 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-06-30 05:36:04,133 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-06-30 05:36:04,137 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-06-30 05:36:04,146 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-06-30 05:36:04,172 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-06-30 05:36:04,176 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-06-30 05:36:04,411 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-06-30 05:36:04,500 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-30 05:36:04,501 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-30 05:36:04,540 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-06-30 05:36:04,546 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-06-30 05:36:04,549 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-06-30 05:36:04,551 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-06-30 05:36:04,556 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-06-30 05:36:04,760 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B
datanode_2_1  | 2020-06-30 05:36:04,787 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B
datanode_2_1  | 2020-06-30 05:36:04,832 [pool-19-thread-1] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B: start as a follower, conf=-1: [b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null
datanode_2_1  | 2020-06-30 05:36:04,841 [pool-19-thread-1] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-06-30 05:36:04,864 [pool-19-thread-1] INFO impl.RoleInfo: b33eb83e-f955-480a-aaae-270c6d5e999a: start FollowerState
datanode_2_1  | 2020-06-30 05:36:04,904 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-28251FCAA17B,id=b33eb83e-f955-480a-aaae-270c6d5e999a
datanode_2_1  | 2020-06-30 05:36:04,918 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B
datanode_2_1  | 2020-06-30 05:36:05,002 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "c981a611-0363-4e47-ae03-28251fcaa17b"
datanode_2_1  | .
datanode_2_1  | 2020-06-30 05:36:05,007 [Command processor thread] INFO impl.RaftServerProxy: b33eb83e-f955-480a-aaae-270c6d5e999a: addNew group-A47B89AB861D:[e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858] returns group-A47B89AB861D:java.util.concurrent.CompletableFuture@4d2fcc57[Not completed]
datanode_2_1  | 2020-06-30 05:36:05,023 [pool-19-thread-1] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a: new RaftServerImpl for group-A47B89AB861D:[e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-06-30 05:36:05,037 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-06-30 05:36:05,094 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-06-30 05:36:05,095 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-06-30 05:36:05,095 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-06-30 05:36:05,095 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-06-30 05:36:05,095 [pool-19-thread-1] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D: ConfigurationManager, init=-1: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-06-30 05:36:05,095 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-06-30 05:36:05,096 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-06-30 05:36:05,096 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7a2acb68-f280-4577-9a67-a47b89ab861d does not exist. Creating ...
datanode_2_1  | 2020-06-30 05:36:05,098 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7a2acb68-f280-4577-9a67-a47b89ab861d/in_use.lock acquired by nodename 6@347479a8e2bd
datanode_2_1  | 2020-06-30 05:36:05,099 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7a2acb68-f280-4577-9a67-a47b89ab861d has been successfully formatted.
datanode_2_1  | 2020-06-30 05:36:05,104 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-A47B89AB861D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-06-30 05:36:05,107 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-06-30 05:36:05,107 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-06-30 05:36:05,109 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-06-30 05:36:05,109 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-30 05:36:05,109 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-30 05:36:05,109 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D
datanode_2_1  | 2020-06-30 05:36:05,113 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-06-30 05:36:05,113 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/7a2acb68-f280-4577-9a67-a47b89ab861d
datanode_2_1  | 2020-06-30 05:36:05,113 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-06-30 05:36:05,115 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-06-30 05:36:05,117 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-30 05:36:05,117 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-06-30 05:36:05,121 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-06-30 05:36:05,124 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-06-30 05:36:05,124 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-06-30 05:36:05,125 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-06-30 05:36:05,126 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-06-30 05:36:05,206 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-06-30 05:36:05,207 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-30 05:36:05,207 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-30 05:36:05,207 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-06-30 05:36:05,207 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-06-30 05:35:58,174 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1_1  | 2020-06-30 05:35:58,177 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis e0f2b5b7-e5e0-4691-810d-9d57d7b98662 at port 9858
datanode_1_1  | 2020-06-30 05:35:58,307 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: start RPC server
datanode_1_1  | 2020-06-30 05:35:58,754 [Datanode State Machine Thread - 0] INFO server.GrpcService: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1_1  | 2020-06-30 05:36:03,856 [Command processor thread] INFO impl.RaftServerProxy: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: addNew group-05E3BA85F36B:[e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858] returns group-05E3BA85F36B:java.util.concurrent.CompletableFuture@3eaaab31[Not completed]
datanode_1_1  | 2020-06-30 05:36:04,156 [pool-19-thread-1] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: new RaftServerImpl for group-05E3BA85F36B:[e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-06-30 05:36:04,269 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-06-30 05:36:04,278 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-06-30 05:36:04,279 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-06-30 05:36:04,285 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-06-30 05:36:04,291 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-06-30 05:36:04,379 [pool-19-thread-1] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B: ConfigurationManager, init=-1: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-06-30 05:36:04,380 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-06-30 05:36:04,420 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-06-30 05:36:04,435 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/9e7b3f67-33a4-47d0-bd3b-05e3ba85f36b does not exist. Creating ...
datanode_1_1  | 2020-06-30 05:36:04,482 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/9e7b3f67-33a4-47d0-bd3b-05e3ba85f36b/in_use.lock acquired by nodename 6@3490d681d880
datanode_1_1  | 2020-06-30 05:36:04,502 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/9e7b3f67-33a4-47d0-bd3b-05e3ba85f36b has been successfully formatted.
datanode_1_1  | 2020-06-30 05:36:04,543 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-05E3BA85F36B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-06-30 05:36:04,554 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-06-30 05:36:04,569 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-06-30 05:36:04,614 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-06-30 05:36:04,614 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-06-30 05:36:04,618 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-06-30 05:36:04,671 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B
datanode_1_1  | 2020-06-30 05:36:04,778 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-06-30 05:36:04,810 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/9e7b3f67-33a4-47d0-bd3b-05e3ba85f36b
datanode_1_1  | 2020-06-30 05:36:04,813 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-06-30 05:36:04,817 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-06-30 05:36:04,822 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-06-30 05:36:04,827 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-06-30 05:36:04,829 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-06-30 05:36:04,832 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-06-30 05:36:04,837 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-06-30 05:36:04,855 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-06-30 05:36:04,860 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-06-30 05:36:04,965 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-06-30 05:36:05,015 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-06-30 05:36:05,023 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-06-30 05:36:05,045 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-06-30 05:36:05,071 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-06-30 05:36:05,074 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-06-30 05:36:05,076 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-06-30 05:36:05,083 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-06-30 05:36:05,218 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B
datanode_1_1  | 2020-06-30 05:36:05,242 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B
datanode_1_1  | 2020-06-30 05:36:05,354 [pool-19-thread-1] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B: start as a follower, conf=-1: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858], old=null
datanode_1_1  | 2020-06-30 05:36:05,355 [pool-19-thread-1] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-06-30 05:36:05,360 [pool-19-thread-1] INFO impl.RoleInfo: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: start FollowerState
datanode_1_1  | 2020-06-30 05:36:05,439 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-05E3BA85F36B,id=e0f2b5b7-e5e0-4691-810d-9d57d7b98662
datanode_1_1  | 2020-06-30 05:36:05,441 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B
datanode_1_1  | 2020-06-30 05:36:05,540 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "9e7b3f67-33a4-47d0-bd3b-05e3ba85f36b"
datanode_1_1  | .
datanode_1_1  | 2020-06-30 05:36:05,549 [Command processor thread] INFO impl.RaftServerProxy: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: addNew group-A47B89AB861D:[e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858] returns group-A47B89AB861D:java.util.concurrent.CompletableFuture@3e29d79f[Not completed]
datanode_1_1  | 2020-06-30 05:36:05,580 [pool-19-thread-1] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: new RaftServerImpl for group-A47B89AB861D:[e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-06-30 05:36:05,602 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-06-30 05:36:05,602 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-06-30 05:36:05,603 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-06-30 05:36:05,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-06-30 05:36:05,608 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-06-30 05:36:05,609 [pool-19-thread-1] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D: ConfigurationManager, init=-1: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-06-30 05:36:05,615 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-06-30 05:36:05,615 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-06-30 05:36:05,625 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7a2acb68-f280-4577-9a67-a47b89ab861d does not exist. Creating ...
datanode_1_1  | 2020-06-30 05:36:05,639 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7a2acb68-f280-4577-9a67-a47b89ab861d/in_use.lock acquired by nodename 6@3490d681d880
datanode_1_1  | 2020-06-30 05:36:05,641 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7a2acb68-f280-4577-9a67-a47b89ab861d has been successfully formatted.
datanode_1_1  | 2020-06-30 05:36:05,647 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-A47B89AB861D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-06-30 05:36:05,651 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-06-30 05:36:05,653 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-06-30 05:36:05,653 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-06-30 05:36:05,653 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-06-30 05:36:05,653 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-06-30 05:36:05,654 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D
datanode_1_1  | 2020-06-30 05:36:05,654 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-06-30 05:36:05,657 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/7a2acb68-f280-4577-9a67-a47b89ab861d
datanode_1_1  | 2020-06-30 05:36:05,662 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-06-30 05:36:05,665 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-06-30 05:36:05,666 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-06-30 05:36:05,666 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-06-30 05:36:05,669 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-06-30 05:36:05,672 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-06-30 05:36:05,672 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-06-30 05:36:05,672 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-06-30 05:36:05,677 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-06-30 05:36:05,678 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-06-30 05:36:05,689 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-06-30 05:36:05,697 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-06-30 05:36:05,719 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-06-30 05:36:05,719 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-06-30 05:36:05,720 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-06-30 05:36:05,721 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-06-30 05:36:05,725 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-06-30 05:36:05,725 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D
datanode_1_1  | 2020-06-30 05:36:05,726 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D
datanode_1_1  | 2020-06-30 05:36:05,728 [pool-19-thread-1] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D: start as a follower, conf=-1: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null
datanode_1_1  | 2020-06-30 05:36:05,740 [pool-19-thread-1] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-06-30 05:36:05,744 [pool-19-thread-1] INFO impl.RoleInfo: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: start FollowerState
datanode_1_1  | 2020-06-30 05:36:05,745 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A47B89AB861D,id=e0f2b5b7-e5e0-4691-810d-9d57d7b98662
datanode_1_1  | 2020-06-30 05:36:05,745 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D
datanode_1_1  | 2020-06-30 05:36:10,009 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "7a2acb68-f280-4577-9a67-a47b89ab861d"
datanode_1_1  | .
datanode_1_1  | 2020-06-30 05:36:10,558 [Thread-22] INFO impl.FollowerState: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-FollowerState: change to CANDIDATE, lastRpcTime:5198ms, electionTimeout:5141ms
datanode_1_1  | 2020-06-30 05:36:10,560 [Thread-22] INFO impl.RoleInfo: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: shutdown FollowerState
datanode_1_1  | 2020-06-30 05:36:10,560 [Thread-22] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1_1  | 2020-06-30 05:36:10,562 [Thread-22] INFO impl.RoleInfo: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: start LeaderElection
datanode_1_1  | 2020-06-30 05:36:10,620 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO impl.LeaderElection: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1: begin an election at term 1 for -1: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858], old=null
datanode_1_1  | 2020-06-30 05:36:10,621 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO impl.RoleInfo: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: shutdown LeaderElection
datanode_1_1  | 2020-06-30 05:36:10,622 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1_1  | 2020-06-30 05:36:10,622 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-05E3BA85F36B with new leaderId: e0f2b5b7-e5e0-4691-810d-9d57d7b98662
datanode_1_1  | 2020-06-30 05:36:10,626 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B: change Leader from null to e0f2b5b7-e5e0-4691-810d-9d57d7b98662 at term 1 for becomeLeader, leader elected after 6068ms
datanode_1_1  | 2020-06-30 05:36:10,665 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1_1  | 2020-06-30 05:36:10,668 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1_1  | 2020-06-30 05:36:10,727 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B
datanode_1_1  | 2020-06-30 05:36:10,758 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1_1  | 2020-06-30 05:36:10,766 [Thread-24] INFO impl.FollowerState: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D-FollowerState: change to CANDIDATE, lastRpcTime:5021ms, electionTimeout:5020ms
datanode_1_1  | 2020-06-30 05:36:10,777 [Thread-24] INFO impl.RoleInfo: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: shutdown FollowerState
datanode_1_1  | 2020-06-30 05:36:10,777 [Thread-24] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1_1  | 2020-06-30 05:36:10,777 [Thread-24] INFO impl.RoleInfo: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: start LeaderElection
datanode_1_1  | 2020-06-30 05:36:10,778 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1_1  | 2020-06-30 05:36:10,820 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D-LeaderElection2] INFO impl.LeaderElection: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D-LeaderElection2: begin an election at term 1 for -1: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null
datanode_1_1  | 2020-06-30 05:36:10,852 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1_1  | 2020-06-30 05:36:11,028 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1_1  | 2020-06-30 05:36:11,030 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1_1  | 2020-06-30 05:36:11,115 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO impl.RoleInfo: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: start LeaderState
datanode_1_1  | 2020-06-30 05:36:11,313 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-06-30 05:36:11,434 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-LeaderElection1] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B: set configuration 0: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858], old=null at 0
datanode_1_1  | 2020-06-30 05:36:11,480 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D-LeaderElection2] INFO impl.LeaderElection: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D-LeaderElection2: Election REJECTED; received 2 response(s) [e0f2b5b7-e5e0-4691-810d-9d57d7b98662<-ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7#0:FAIL-t1, e0f2b5b7-e5e0-4691-810d-9d57d7b98662<-b33eb83e-f955-480a-aaae-270c6d5e999a#0:FAIL-t1] and 0 exception(s); e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D:t1, leader=null, voted=e0f2b5b7-e5e0-4691-810d-9d57d7b98662, raftlog=e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null
datanode_1_1  | 2020-06-30 05:36:11,481 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D-LeaderElection2] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
datanode_1_1  | 2020-06-30 05:36:11,481 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D-LeaderElection2] INFO impl.RoleInfo: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: shutdown LeaderElection
datanode_1_1  | 2020-06-30 05:36:11,482 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D-LeaderElection2] INFO impl.RoleInfo: e0f2b5b7-e5e0-4691-810d-9d57d7b98662: start FollowerState
datanode_1_1  | 2020-06-30 05:36:11,760 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A47B89AB861D with new leaderId: b33eb83e-f955-480a-aaae-270c6d5e999a
datanode_1_1  | 2020-06-30 05:36:11,763 [grpc-default-executor-1] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D: change Leader from null to b33eb83e-f955-480a-aaae-270c6d5e999a at term 1 for appendEntries, leader elected after 6108ms
datanode_1_1  | 2020-06-30 05:36:11,903 [grpc-default-executor-1] INFO impl.RaftServerImpl: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D: set configuration 0: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null at 0
datanode_1_1  | 2020-06-30 05:36:11,927 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-06-30 05:36:11,977 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-A47B89AB861D-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7a2acb68-f280-4577-9a67-a47b89ab861d/current/log_inprogress_0
datanode_1_1  | 2020-06-30 05:36:11,984 [e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e0f2b5b7-e5e0-4691-810d-9d57d7b98662@group-05E3BA85F36B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/9e7b3f67-33a4-47d0-bd3b-05e3ba85f36b/current/log_inprogress_0
datanode_4_1  | Enabled profiling in kernel
datanode_4_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_4_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_4_1  | 2020-06-30 05:35:30,021 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_4_1  | /************************************************************
datanode_4_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_4_1  | STARTUP_MSG:   host = c7383f102dc5/10.5.0.7
datanode_4_1  | STARTUP_MSG:   args = []
datanode_4_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2_1  | 2020-06-30 05:36:05,208 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-06-30 05:36:05,208 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-06-30 05:36:05,208 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-06-30 05:36:05,226 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D
datanode_2_1  | 2020-06-30 05:36:05,233 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D
datanode_2_1  | 2020-06-30 05:36:05,237 [pool-19-thread-1] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D: start as a follower, conf=-1: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null
datanode_2_1  | 2020-06-30 05:36:05,238 [pool-19-thread-1] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-06-30 05:36:05,253 [pool-19-thread-1] INFO impl.RoleInfo: b33eb83e-f955-480a-aaae-270c6d5e999a: start FollowerState
datanode_2_1  | 2020-06-30 05:36:05,254 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A47B89AB861D,id=b33eb83e-f955-480a-aaae-270c6d5e999a
datanode_2_1  | 2020-06-30 05:36:05,254 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D
datanode_2_1  | 2020-06-30 05:36:09,654 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "7a2acb68-f280-4577-9a67-a47b89ab861d"
datanode_2_1  | .
datanode_2_1  | 2020-06-30 05:36:09,997 [Thread-23] INFO impl.FollowerState: b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-FollowerState: change to CANDIDATE, lastRpcTime:5141ms, electionTimeout:5128ms
datanode_2_1  | 2020-06-30 05:36:10,014 [Thread-23] INFO impl.RoleInfo: b33eb83e-f955-480a-aaae-270c6d5e999a: shutdown FollowerState
datanode_2_1  | 2020-06-30 05:36:10,017 [Thread-23] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2_1  | 2020-06-30 05:36:10,031 [Thread-23] INFO impl.RoleInfo: b33eb83e-f955-480a-aaae-270c6d5e999a: start LeaderElection
datanode_2_1  | 2020-06-30 05:36:10,036 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO impl.LeaderElection: b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1: begin an election at term 1 for -1: [b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null
datanode_2_1  | 2020-06-30 05:36:10,039 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO impl.RoleInfo: b33eb83e-f955-480a-aaae-270c6d5e999a: shutdown LeaderElection
datanode_2_1  | 2020-06-30 05:36:10,051 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2_1  | 2020-06-30 05:36:10,089 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-28251FCAA17B with new leaderId: b33eb83e-f955-480a-aaae-270c6d5e999a
datanode_2_1  | 2020-06-30 05:36:10,111 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B: change Leader from null to b33eb83e-f955-480a-aaae-270c6d5e999a at term 1 for becomeLeader, leader elected after 6629ms
datanode_2_1  | 2020-06-30 05:36:10,138 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2_1  | 2020-06-30 05:36:10,153 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2_1  | 2020-06-30 05:36:10,163 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B
datanode_2_1  | 2020-06-30 05:36:10,192 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2_1  | 2020-06-30 05:36:10,197 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2_1  | 2020-06-30 05:36:10,228 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2_1  | 2020-06-30 05:36:10,237 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2_1  | 2020-06-30 05:36:10,245 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2_1  | 2020-06-30 05:36:10,298 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO impl.RoleInfo: b33eb83e-f955-480a-aaae-270c6d5e999a: start LeaderState
datanode_2_1  | 2020-06-30 05:36:10,378 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-06-30 05:36:10,384 [Thread-25] INFO impl.FollowerState: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-FollowerState: change to CANDIDATE, lastRpcTime:5131ms, electionTimeout:5129ms
datanode_2_1  | 2020-06-30 05:36:10,388 [Thread-25] INFO impl.RoleInfo: b33eb83e-f955-480a-aaae-270c6d5e999a: shutdown FollowerState
datanode_2_1  | 2020-06-30 05:36:10,389 [Thread-25] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2_1  | 2020-06-30 05:36:10,392 [Thread-25] INFO impl.RoleInfo: b33eb83e-f955-480a-aaae-270c6d5e999a: start LeaderElection
datanode_2_1  | 2020-06-30 05:36:10,501 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO impl.LeaderElection: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2: begin an election at term 1 for -1: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null
datanode_2_1  | 2020-06-30 05:36:10,617 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-LeaderElection1] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B: set configuration 0: [b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-06-30 05:36:11,276 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO impl.LeaderElection: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2: Election PASSED; received 2 response(s) [b33eb83e-f955-480a-aaae-270c6d5e999a<-e0f2b5b7-e5e0-4691-810d-9d57d7b98662#0:FAIL-t1, b33eb83e-f955-480a-aaae-270c6d5e999a<-ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7#0:OK-t1] and 0 exception(s); b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D:t1, leader=null, voted=b33eb83e-f955-480a-aaae-270c6d5e999a, raftlog=b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null
datanode_2_1  | 2020-06-30 05:36:11,277 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO impl.RoleInfo: b33eb83e-f955-480a-aaae-270c6d5e999a: shutdown LeaderElection
datanode_2_1  | 2020-06-30 05:36:11,277 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2_1  | 2020-06-30 05:36:11,294 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A47B89AB861D with new leaderId: b33eb83e-f955-480a-aaae-270c6d5e999a
datanode_2_1  | 2020-06-30 05:36:11,295 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D: change Leader from null to b33eb83e-f955-480a-aaae-270c6d5e999a at term 1 for becomeLeader, leader elected after 6187ms
datanode_2_1  | 2020-06-30 05:36:11,295 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2_1  | 2020-06-30 05:36:11,305 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2_1  | 2020-06-30 05:36:11,335 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D
datanode_2_1  | 2020-06-30 05:36:11,336 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2_1  | 2020-06-30 05:36:11,338 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2_1  | 2020-06-30 05:36:11,358 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2_1  | 2020-06-30 05:36:11,359 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2_1  | 2020-06-30 05:36:11,359 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2_1  | 2020-06-30 05:36:11,388 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2_1  | 2020-06-30 05:36:11,388 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-30 05:36:11,407 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2_1  | 2020-06-30 05:36:11,424 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2_1  | 2020-06-30 05:36:11,448 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-06-30 05:36:11,448 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-06-30 05:36:11,449 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D
datanode_2_1  | 2020-06-30 05:36:11,486 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2_1  | 2020-06-30 05:36:11,495 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-30 05:36:11,495 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2_1  | 2020-06-30 05:36:11,495 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2_1  | 2020-06-30 05:36:11,500 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | java.net.SocketTimeoutException: Call From 4e1a56669dc5/10.5.0.6 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:45222 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_3_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:45222 remote=scm/10.5.0.71:9861]
datanode_3_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_3_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_3_1  | 2020-06-30 05:35:58,179 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3_1  | 2020-06-30 05:35:58,189 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3_1  | 2020-06-30 05:35:58,189 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis c7810c94-92e8-4071-bf24-3fb5d1be0ccd at port 9858
datanode_3_1  | 2020-06-30 05:35:58,299 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: start RPC server
datanode_3_1  | 2020-06-30 05:35:58,814 [Datanode State Machine Thread - 1] INFO server.GrpcService: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3_1  | 2020-06-30 05:36:02,645 [Command processor thread] INFO impl.RaftServerProxy: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: addNew group-8B8645B1098A:[c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858] returns group-8B8645B1098A:java.util.concurrent.CompletableFuture@7197803[Not completed]
datanode_3_1  | 2020-06-30 05:36:02,760 [pool-19-thread-1] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: new RaftServerImpl for group-8B8645B1098A:[c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-06-30 05:36:02,774 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-06-30 05:36:02,777 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-06-30 05:36:02,777 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-06-30 05:36:02,787 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-06-30 05:36:02,787 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-06-30 05:36:02,842 [pool-19-thread-1] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A: ConfigurationManager, init=-1: [c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-06-30 05:36:02,842 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-06-30 05:36:02,851 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-06-30 05:36:02,868 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/54c09bb2-982d-403b-8ee3-8b8645b1098a does not exist. Creating ...
datanode_3_1  | 2020-06-30 05:36:02,913 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/54c09bb2-982d-403b-8ee3-8b8645b1098a/in_use.lock acquired by nodename 7@4e1a56669dc5
datanode_3_1  | 2020-06-30 05:36:02,929 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/54c09bb2-982d-403b-8ee3-8b8645b1098a has been successfully formatted.
datanode_3_1  | 2020-06-30 05:36:02,955 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-8B8645B1098A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-06-30 05:36:02,985 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-06-30 05:36:02,988 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-06-30 05:36:03,039 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-06-30 05:36:03,073 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-30 05:36:03,075 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-30 05:36:11,500 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-06-30 05:36:11,502 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO impl.RoleInfo: b33eb83e-f955-480a-aaae-270c6d5e999a: start LeaderState
datanode_2_1  | 2020-06-30 05:36:11,518 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-06-30 05:36:11,513 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: b33eb83e-f955-480a-aaae-270c6d5e999a@group-28251FCAA17B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c981a611-0363-4e47-ae03-28251fcaa17b/current/log_inprogress_0
datanode_2_1  | 2020-06-30 05:36:11,523 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7a2acb68-f280-4577-9a67-a47b89ab861d/current/log_inprogress_0
datanode_2_1  | 2020-06-30 05:36:11,565 [b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D-LeaderElection2] INFO impl.RaftServerImpl: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D: set configuration 0: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-06-30 05:37:11,759 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1,entriesCount=1,lastEntry=(t:1, i:0)
datanode_2_1  | 2020-06-30 05:37:24,326 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6,entriesCount=1,lastEntry=(t:1, i:1)
datanode_2_1  | 2020-06-30 05:37:24,518 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=7,entriesCount=1,lastEntry=(t:1, i:2)
datanode_2_1  | 2020-06-30 05:37:25,779 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=8,entriesCount=1,lastEntry=(t:1, i:3)
datanode_2_1  | 2020-06-30 05:37:25,793 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=9,entriesCount=1,lastEntry=(t:1, i:4)
datanode_2_1  | 2020-06-30 05:37:35,622 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=13,entriesCount=1,lastEntry=(t:1, i:5)
datanode_2_1  | 2020-06-30 05:37:35,630 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=14,entriesCount=1,lastEntry=(t:1, i:6)
datanode_2_1  | 2020-06-30 05:37:35,649 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=15,entriesCount=1,lastEntry=(t:1, i:7)
datanode_2_1  | 2020-06-30 05:37:35,657 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=16,entriesCount=1,lastEntry=(t:1, i:8)
datanode_2_1  | 2020-06-30 05:37:40,811 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=19,entriesCount=1,lastEntry=(t:1, i:9)
datanode_2_1  | 2020-06-30 05:37:40,819 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=20,entriesCount=1,lastEntry=(t:1, i:10)
datanode_2_1  | 2020-06-30 05:37:40,824 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=21,entriesCount=1,lastEntry=(t:1, i:11)
datanode_2_1  | 2020-06-30 05:37:40,837 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=22,entriesCount=1,lastEntry=(t:1, i:12)
datanode_2_1  | 2020-06-30 05:37:43,393 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=24,entriesCount=1,lastEntry=(t:1, i:13)
datanode_2_1  | 2020-06-30 05:37:43,397 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=25,entriesCount=1,lastEntry=(t:1, i:14)
datanode_2_1  | 2020-06-30 05:37:43,414 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=26,entriesCount=1,lastEntry=(t:1, i:15)
datanode_2_1  | 2020-06-30 05:38:04,073 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=35,entriesCount=1,lastEntry=(t:1, i:16)
datanode_2_1  | 2020-06-30 05:38:04,083 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=36,entriesCount=1,lastEntry=(t:1, i:17)
datanode_4_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_4_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/bf23dcb95194fc844485de860846edb45b7aeb63 ; compiled by 'runner' on 2020-06-30T05:10Z
datanode_4_1  | STARTUP_MSG:   java = 11.0.6
datanode_4_1  | ************************************************************/
datanode_4_1  | 2020-06-30 05:35:30,092 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_4_1  | 2020-06-30 05:35:31,856 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_4_1  | 2020-06-30 05:35:32,728 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_4_1  | 2020-06-30 05:35:33,818 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_4_1  | 2020-06-30 05:35:33,818 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_4_1  | 2020-06-30 05:35:34,530 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:c7383f102dc5 ip:10.5.0.7
datanode_4_1  | 2020-06-30 05:35:35,515 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_4_1  | 2020-06-30 05:35:35,597 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_4_1  | 2020-06-30 05:35:35,632 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_4_1  | 2020-06-30 05:35:35,723 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_4_1  | 2020-06-30 05:35:36,100 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_4_1  | 2020-06-30 05:35:42,961 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4_1  | 2020-06-30 05:35:43,330 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_4_1  | 2020-06-30 05:35:44,241 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_4_1  | 2020-06-30 05:35:44,242 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_4_1  | 2020-06-30 05:35:44,242 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-06-30 05:35:44,243 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_4_1  | 2020-06-30 05:35:44,244 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 2020-06-30 05:35:46,050 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-06-30 05:35:47,468 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_4_1  | 2020-06-30 05:35:47,582 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_4_1  | 2020-06-30 05:35:47,806 [main] INFO util.log: Logging initialized @25229ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_4_1  | 2020-06-30 05:35:48,692 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_4_1  | 2020-06-30 05:35:48,714 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_4_1  | 2020-06-30 05:35:48,753 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_4_1  | 2020-06-30 05:35:48,773 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_4_1  | 2020-06-30 05:35:48,774 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_4_1  | 2020-06-30 05:35:48,774 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_4_1  | 2020-06-30 05:35:49,002 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_4_1  | 2020-06-30 05:35:49,060 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_4_1  | 2020-06-30 05:35:49,075 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_4_1  | 2020-06-30 05:35:49,456 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_4_1  | 2020-06-30 05:35:49,459 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_4_1  | 2020-06-30 05:35:49,460 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_4_1  | 2020-06-30 05:35:49,509 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b4954b2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_4_1  | 2020-06-30 05:35:49,520 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57416e49{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_4_1  | 2020-06-30 05:35:50,044 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c27f72{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-5692117879522198302.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_4_1  | 2020-06-30 05:35:50,100 [main] INFO server.AbstractConnector: Started ServerConnector@25cde5bb{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_4_1  | 2020-06-30 05:35:50,105 [main] INFO server.Server: Started @27528ms
datanode_4_1  | 2020-06-30 05:35:50,126 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_4_1  | 2020-06-30 05:35:50,134 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_4_1  | 2020-06-30 05:35:50,138 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_4_1  | 2020-06-30 05:35:50,275 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1f272c4d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_4_1  | 2020-06-30 05:35:51,608 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_4_1  | 2020-06-30 05:35:53,760 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-06-30 05:35:54,761 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-06-30 05:35:55,762 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-06-30 05:35:56,763 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-06-30 05:38:04,084 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=37,entriesCount=1,lastEntry=(t:1, i:18)
datanode_2_1  | 2020-06-30 05:38:04,102 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=38,entriesCount=1,lastEntry=(t:1, i:19)
datanode_2_1  | 2020-06-30 05:38:06,649 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=40,entriesCount=1,lastEntry=(t:1, i:20)
datanode_2_1  | 2020-06-30 05:38:06,659 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=41,entriesCount=1,lastEntry=(t:1, i:21)
datanode_2_1  | 2020-06-30 05:38:06,670 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=42,entriesCount=1,lastEntry=(t:1, i:22)
datanode_2_1  | 2020-06-30 05:38:06,687 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=43,entriesCount=1,lastEntry=(t:1, i:23)
datanode_2_1  | 2020-06-30 05:38:09,218 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=45,entriesCount=1,lastEntry=(t:1, i:24)
datanode_2_1  | 2020-06-30 05:38:09,230 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=46,entriesCount=1,lastEntry=(t:1, i:25)
datanode_2_1  | 2020-06-30 05:38:09,247 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=47,entriesCount=1,lastEntry=(t:1, i:26)
datanode_2_1  | 2020-06-30 05:38:09,264 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=48,entriesCount=1,lastEntry=(t:1, i:27)
datanode_2_1  | 2020-06-30 05:38:14,395 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=51,entriesCount=1,lastEntry=(t:1, i:28)
datanode_2_1  | 2020-06-30 05:38:14,411 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=52,entriesCount=1,lastEntry=(t:1, i:29)
datanode_2_1  | 2020-06-30 05:38:14,429 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=53,entriesCount=1,lastEntry=(t:1, i:30)
datanode_2_1  | 2020-06-30 05:38:14,458 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=54,entriesCount=1,lastEntry=(t:1, i:31)
datanode_2_1  | 2020-06-30 05:38:19,589 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=57,entriesCount=1,lastEntry=(t:1, i:32)
datanode_2_1  | 2020-06-30 05:38:19,594 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=58,entriesCount=1,lastEntry=(t:1, i:33)
datanode_2_1  | 2020-06-30 05:38:19,602 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=59,entriesCount=1,lastEntry=(t:1, i:34)
datanode_2_1  | 2020-06-30 05:38:19,610 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=60,entriesCount=1,lastEntry=(t:1, i:35)
datanode_2_1  | 2020-06-30 05:38:27,335 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=64,entriesCount=1,lastEntry=(t:1, i:36)
datanode_2_1  | 2020-06-30 05:38:27,381 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=65,entriesCount=1,lastEntry=(t:1, i:37)
datanode_2_1  | 2020-06-30 05:38:27,382 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=66,entriesCount=1,lastEntry=(t:1, i:38)
datanode_2_1  | 2020-06-30 05:38:27,401 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=67,entriesCount=1,lastEntry=(t:1, i:39)
datanode_2_1  | 2020-06-30 05:38:29,933 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=69,entriesCount=1,lastEntry=(t:1, i:40)
datanode_3_1  | 2020-06-30 05:36:03,128 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A
datanode_3_1  | 2020-06-30 05:36:03,249 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-06-30 05:36:03,284 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/54c09bb2-982d-403b-8ee3-8b8645b1098a
datanode_3_1  | 2020-06-30 05:36:03,293 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-06-30 05:36:03,296 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-30 05:36:03,317 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-06-30 05:36:03,318 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-06-30 05:36:03,321 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-06-30 05:36:03,325 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-06-30 05:36:03,340 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-06-30 05:36:03,342 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-06-30 05:36:03,345 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-06-30 05:36:03,465 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-06-30 05:36:03,558 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-30 05:36:03,558 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-30 05:36:03,594 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-06-30 05:36:03,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-06-30 05:36:03,625 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-06-30 05:36:03,646 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-06-30 05:36:03,648 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-06-30 05:36:04,045 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A
datanode_3_1  | 2020-06-30 05:36:04,072 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A
datanode_3_1  | 2020-06-30 05:36:04,099 [pool-19-thread-1] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A: start as a follower, conf=-1: [c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858], old=null
datanode_3_1  | 2020-06-30 05:36:04,147 [pool-19-thread-1] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-06-30 05:36:04,162 [pool-19-thread-1] INFO impl.RoleInfo: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: start FollowerState
datanode_3_1  | 2020-06-30 05:36:04,270 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8B8645B1098A,id=c7810c94-92e8-4071-bf24-3fb5d1be0ccd
datanode_3_1  | 2020-06-30 05:36:04,272 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A
datanode_3_1  | 2020-06-30 05:36:04,481 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "54c09bb2-982d-403b-8ee3-8b8645b1098a"
datanode_3_1  | .
datanode_3_1  | 2020-06-30 05:36:04,482 [Command processor thread] INFO impl.RaftServerProxy: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: addNew group-2E18FCD31541:[d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858] returns group-2E18FCD31541:java.util.concurrent.CompletableFuture@36e12e1d[Not completed]
datanode_3_1  | 2020-06-30 05:36:04,493 [pool-19-thread-1] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: new RaftServerImpl for group-2E18FCD31541:[d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-06-30 05:36:04,563 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-06-30 05:36:04,565 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-06-30 05:36:04,565 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-06-30 05:36:04,565 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-06-30 05:36:04,565 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-06-30 05:36:04,565 [pool-19-thread-1] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541: ConfigurationManager, init=-1: [d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-06-30 05:36:04,565 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-06-30 05:36:04,566 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-06-30 05:36:04,566 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/0f942154-9669-46a8-b1d1-2e18fcd31541 does not exist. Creating ...
datanode_3_1  | 2020-06-30 05:36:04,589 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/0f942154-9669-46a8-b1d1-2e18fcd31541/in_use.lock acquired by nodename 7@4e1a56669dc5
datanode_3_1  | 2020-06-30 05:36:04,593 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/0f942154-9669-46a8-b1d1-2e18fcd31541 has been successfully formatted.
datanode_3_1  | 2020-06-30 05:36:04,594 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-2E18FCD31541: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-06-30 05:36:04,594 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-06-30 05:36:04,594 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-06-30 05:36:04,594 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-06-30 05:36:04,594 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-30 05:38:29,943 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=70,entriesCount=1,lastEntry=(t:1, i:41)
datanode_2_1  | 2020-06-30 05:38:29,954 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=71,entriesCount=1,lastEntry=(t:1, i:42)
datanode_2_1  | 2020-06-30 05:38:29,974 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=72,entriesCount=1,lastEntry=(t:1, i:43)
datanode_2_1  | 2020-06-30 05:38:32,517 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=74,entriesCount=1,lastEntry=(t:1, i:44)
datanode_2_1  | 2020-06-30 05:38:32,524 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=75,entriesCount=1,lastEntry=(t:1, i:45)
datanode_2_1  | 2020-06-30 05:38:32,533 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=76,entriesCount=1,lastEntry=(t:1, i:46)
datanode_2_1  | 2020-06-30 05:38:32,544 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=77,entriesCount=1,lastEntry=(t:1, i:47)
datanode_2_1  | 2020-06-30 05:38:35,076 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=79,entriesCount=1,lastEntry=(t:1, i:48)
datanode_2_1  | 2020-06-30 05:38:35,080 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=80,entriesCount=1,lastEntry=(t:1, i:49)
datanode_2_1  | 2020-06-30 05:38:35,094 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=81,entriesCount=1,lastEntry=(t:1, i:50)
datanode_2_1  | 2020-06-30 05:38:35,108 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=82,entriesCount=1,lastEntry=(t:1, i:51)
datanode_2_1  | 2020-06-30 05:38:37,666 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=84,entriesCount=1,lastEntry=(t:1, i:52)
datanode_2_1  | 2020-06-30 05:38:37,667 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=85,entriesCount=1,lastEntry=(t:1, i:53)
datanode_2_1  | 2020-06-30 05:38:37,688 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=86,entriesCount=1,lastEntry=(t:1, i:54)
datanode_2_1  | 2020-06-30 05:38:37,701 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=87,entriesCount=1,lastEntry=(t:1, i:55)
datanode_2_1  | 2020-06-30 05:38:40,238 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=89,entriesCount=1,lastEntry=(t:1, i:56)
datanode_2_1  | 2020-06-30 05:38:40,246 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=90,entriesCount=1,lastEntry=(t:1, i:57)
datanode_2_1  | 2020-06-30 05:38:40,252 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=91,entriesCount=1,lastEntry=(t:1, i:58)
datanode_2_1  | 2020-06-30 05:38:40,262 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=92,entriesCount=1,lastEntry=(t:1, i:59)
datanode_2_1  | 2020-06-30 05:38:42,802 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=94,entriesCount=1,lastEntry=(t:1, i:60)
datanode_2_1  | 2020-06-30 05:38:42,808 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=95,entriesCount=1,lastEntry=(t:1, i:61)
datanode_2_1  | 2020-06-30 05:38:42,813 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=96,entriesCount=1,lastEntry=(t:1, i:62)
datanode_2_1  | 2020-06-30 05:38:42,828 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=97,entriesCount=1,lastEntry=(t:1, i:63)
datanode_2_1  | 2020-06-30 05:38:45,374 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=99,entriesCount=1,lastEntry=(t:1, i:64)
datanode_2_1  | 2020-06-30 05:38:45,377 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=100,entriesCount=1,lastEntry=(t:1, i:65)
datanode_2_1  | 2020-06-30 05:38:45,386 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=101,entriesCount=1,lastEntry=(t:1, i:66)
datanode_2_1  | 2020-06-30 05:38:45,394 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=102,entriesCount=1,lastEntry=(t:1, i:67)
datanode_2_1  | 2020-06-30 05:38:53,158 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=106,entriesCount=1,lastEntry=(t:1, i:68)
datanode_2_1  | 2020-06-30 05:38:53,166 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=107,entriesCount=1,lastEntry=(t:1, i:69)
datanode_2_1  | 2020-06-30 05:38:53,167 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=108,entriesCount=1,lastEntry=(t:1, i:70)
datanode_2_1  | 2020-06-30 05:38:53,183 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=109,entriesCount=1,lastEntry=(t:1, i:71)
datanode_2_1  | 2020-06-30 05:38:55,720 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=111,entriesCount=1,lastEntry=(t:1, i:72)
datanode_2_1  | 2020-06-30 05:38:55,730 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=112,entriesCount=1,lastEntry=(t:1, i:73)
datanode_2_1  | 2020-06-30 05:38:55,743 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=113,entriesCount=1,lastEntry=(t:1, i:74)
datanode_2_1  | 2020-06-30 05:38:55,752 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=114,entriesCount=1,lastEntry=(t:1, i:75)
datanode_2_1  | 2020-06-30 05:39:06,028 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=119,entriesCount=1,lastEntry=(t:1, i:76)
datanode_2_1  | 2020-06-30 05:39:06,028 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=120,entriesCount=1,lastEntry=(t:1, i:77)
datanode_2_1  | 2020-06-30 05:39:06,069 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=121,entriesCount=1,lastEntry=(t:1, i:78)
datanode_2_1  | 2020-06-30 05:39:06,079 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=122,entriesCount=1,lastEntry=(t:1, i:79)
datanode_2_1  | 2020-06-30 05:39:08,617 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=124,entriesCount=1,lastEntry=(t:1, i:80)
datanode_2_1  | 2020-06-30 05:39:08,627 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=125,entriesCount=1,lastEntry=(t:1, i:81)
datanode_2_1  | 2020-06-30 05:39:08,633 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=126,entriesCount=1,lastEntry=(t:1, i:82)
datanode_2_1  | 2020-06-30 05:39:08,639 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=127,entriesCount=1,lastEntry=(t:1, i:83)
datanode_2_1  | 2020-06-30 05:39:16,313 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=131,entriesCount=1,lastEntry=(t:1, i:84)
datanode_2_1  | 2020-06-30 05:39:16,322 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=132,entriesCount=1,lastEntry=(t:1, i:85)
datanode_2_1  | 2020-06-30 05:39:16,336 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=133,entriesCount=1,lastEntry=(t:1, i:86)
datanode_2_1  | 2020-06-30 05:39:16,344 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=134,entriesCount=1,lastEntry=(t:1, i:87)
datanode_2_1  | 2020-06-30 05:39:21,449 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=137,entriesCount=1,lastEntry=(t:1, i:88)
datanode_2_1  | 2020-06-30 05:39:21,460 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=138,entriesCount=1,lastEntry=(t:1, i:89)
datanode_2_1  | 2020-06-30 05:39:21,461 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=139,entriesCount=1,lastEntry=(t:1, i:90)
datanode_2_1  | 2020-06-30 05:39:21,464 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=140,entriesCount=1,lastEntry=(t:1, i:91)
datanode_2_1  | 2020-06-30 05:39:29,129 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=144,entriesCount=1,lastEntry=(t:1, i:92)
datanode_2_1  | 2020-06-30 05:39:29,134 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=145,entriesCount=1,lastEntry=(t:1, i:93)
datanode_2_1  | 2020-06-30 05:39:29,136 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=146,entriesCount=1,lastEntry=(t:1, i:94)
datanode_2_1  | 2020-06-30 05:39:31,688 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=148,entriesCount=1,lastEntry=(t:1, i:95)
datanode_2_1  | 2020-06-30 05:39:31,696 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=149,entriesCount=1,lastEntry=(t:1, i:96)
datanode_2_1  | 2020-06-30 05:39:31,710 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=150,entriesCount=1,lastEntry=(t:1, i:97)
datanode_2_1  | 2020-06-30 05:39:31,712 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=151,entriesCount=1,lastEntry=(t:1, i:98)
datanode_2_1  | 2020-06-30 05:39:36,836 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=154,entriesCount=1,lastEntry=(t:1, i:99)
datanode_2_1  | 2020-06-30 05:39:36,840 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=155,entriesCount=1,lastEntry=(t:1, i:100)
datanode_2_1  | 2020-06-30 05:39:36,853 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=156,entriesCount=1,lastEntry=(t:1, i:101)
datanode_2_1  | 2020-06-30 05:39:36,855 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=157,entriesCount=1,lastEntry=(t:1, i:102)
datanode_2_1  | 2020-06-30 05:39:41,958 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=160,entriesCount=1,lastEntry=(t:1, i:103)
datanode_2_1  | 2020-06-30 05:39:41,963 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=161,entriesCount=1,lastEntry=(t:1, i:104)
datanode_2_1  | 2020-06-30 05:39:41,985 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=162,entriesCount=1,lastEntry=(t:1, i:105)
datanode_2_1  | 2020-06-30 05:39:41,991 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=163,entriesCount=1,lastEntry=(t:1, i:106)
datanode_2_1  | 2020-06-30 05:39:49,670 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=167,entriesCount=1,lastEntry=(t:1, i:107)
datanode_2_1  | 2020-06-30 05:39:49,670 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=168,entriesCount=1,lastEntry=(t:1, i:108)
datanode_2_1  | 2020-06-30 05:39:49,683 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=169,entriesCount=1,lastEntry=(t:1, i:109)
datanode_2_1  | 2020-06-30 05:39:52,220 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=171,entriesCount=1,lastEntry=(t:1, i:110)
datanode_2_1  | 2020-06-30 05:39:52,226 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=172,entriesCount=1,lastEntry=(t:1, i:111)
datanode_2_1  | 2020-06-30 05:39:52,230 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=173,entriesCount=1,lastEntry=(t:1, i:112)
datanode_2_1  | 2020-06-30 05:39:52,232 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=174,entriesCount=1,lastEntry=(t:1, i:113)
datanode_2_1  | 2020-06-30 05:39:54,756 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=176,entriesCount=1,lastEntry=(t:1, i:114)
datanode_2_1  | 2020-06-30 05:39:54,760 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=177,entriesCount=1,lastEntry=(t:1, i:115)
datanode_2_1  | 2020-06-30 05:39:54,767 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=178,entriesCount=1,lastEntry=(t:1, i:116)
datanode_2_1  | 2020-06-30 05:39:54,784 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=179,entriesCount=1,lastEntry=(t:1, i:117)
datanode_2_1  | 2020-06-30 05:40:07,704 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=185,entriesCount=1,lastEntry=(t:1, i:118)
datanode_2_1  | 2020-06-30 05:40:07,705 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=186,entriesCount=1,lastEntry=(t:1, i:119)
datanode_2_1  | 2020-06-30 05:40:07,768 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=187,entriesCount=1,lastEntry=(t:1, i:120)
datanode_2_1  | 2020-06-30 05:40:20,436 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=193,entriesCount=1,lastEntry=(t:1, i:121)
datanode_2_1  | 2020-06-30 05:40:20,442 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=194,entriesCount=1,lastEntry=(t:1, i:122)
datanode_2_1  | 2020-06-30 05:40:20,471 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=195,entriesCount=1,lastEntry=(t:1, i:123)
datanode_2_1  | 2020-06-30 05:40:20,480 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=196,entriesCount=1,lastEntry=(t:1, i:124)
datanode_2_1  | 2020-06-30 05:41:05,771 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=215,entriesCount=1,lastEntry=(t:1, i:125)
datanode_2_1  | 2020-06-30 05:41:05,772 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=216,entriesCount=1,lastEntry=(t:1, i:126)
datanode_2_1  | 2020-06-30 05:41:05,823 [java.util.concurrent.ThreadPoolExecutor$Worker@6df1c776[State = -1, empty queue]] WARN server.GrpcLogAppender: b33eb83e-f955-480a-aaae-270c6d5e999a@group-A47B89AB861D->ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=217,entriesCount=1,lastEntry=(t:1, i:127)
datanode_4_1  | 2020-06-30 05:35:58,096 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_4_1  | 2020-06-30 05:35:58,097 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_4_1  | 2020-06-30 05:35:58,099 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7 at port 9858
datanode_4_1  | 2020-06-30 05:35:58,319 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7: start RPC server
datanode_4_1  | 2020-06-30 05:35:58,876 [Datanode State Machine Thread - 0] INFO server.GrpcService: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_4_1  | 2020-06-30 05:36:03,572 [Command processor thread] INFO impl.RaftServerProxy: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7: addNew group-4F157D79C1E5:[ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858] returns group-4F157D79C1E5:java.util.concurrent.CompletableFuture@7197803[Not completed]
datanode_4_1  | 2020-06-30 05:36:03,739 [pool-19-thread-1] INFO impl.RaftServerImpl: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7: new RaftServerImpl for group-4F157D79C1E5:[ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-06-30 05:36:03,747 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-06-30 05:36:03,748 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-06-30 05:36:03,748 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-06-30 05:36:03,748 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-06-30 05:36:03,772 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-06-30 05:36:03,859 [pool-19-thread-1] INFO impl.RaftServerImpl: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5: ConfigurationManager, init=-1: [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-06-30 05:36:03,905 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-06-30 05:36:04,004 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-06-30 05:36:04,019 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ce990fde-9ce0-4be0-83bf-4f157d79c1e5 does not exist. Creating ...
datanode_4_1  | 2020-06-30 05:36:04,110 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ce990fde-9ce0-4be0-83bf-4f157d79c1e5/in_use.lock acquired by nodename 6@c7383f102dc5
datanode_4_1  | 2020-06-30 05:36:04,134 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ce990fde-9ce0-4be0-83bf-4f157d79c1e5 has been successfully formatted.
datanode_4_1  | 2020-06-30 05:36:04,213 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-4F157D79C1E5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-06-30 05:36:04,214 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-06-30 05:36:04,309 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-06-30 05:36:04,369 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-06-30 05:36:04,374 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-06-30 05:36:04,409 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-06-30 05:36:04,489 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5
datanode_4_1  | 2020-06-30 05:36:04,658 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-06-30 05:36:04,750 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/ce990fde-9ce0-4be0-83bf-4f157d79c1e5
datanode_4_1  | 2020-06-30 05:36:04,753 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-06-30 05:36:04,754 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-06-30 05:36:04,759 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-06-30 05:36:04,777 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-06-30 05:36:04,779 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-06-30 05:36:04,785 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-06-30 05:36:04,789 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-06-30 05:36:04,790 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-06-30 05:36:04,825 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-06-30 05:36:05,007 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-06-30 05:36:05,012 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-06-30 05:36:05,012 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-06-30 05:36:05,075 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-06-30 05:36:05,098 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-06-30 05:36:05,101 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-06-30 05:36:05,110 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-06-30 05:36:05,114 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-06-30 05:36:05,310 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5
datanode_4_1  | 2020-06-30 05:36:05,322 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5
datanode_4_1  | 2020-06-30 05:36:05,387 [pool-19-thread-1] INFO impl.RaftServerImpl: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5: start as a follower, conf=-1: [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858], old=null
datanode_4_1  | 2020-06-30 05:36:05,404 [pool-19-thread-1] INFO impl.RaftServerImpl: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-06-30 05:36:04,594 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-06-30 05:36:04,594 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541
datanode_3_1  | 2020-06-30 05:36:04,594 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-06-30 05:36:04,594 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/0f942154-9669-46a8-b1d1-2e18fcd31541
datanode_3_1  | 2020-06-30 05:36:04,595 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-06-30 05:36:04,595 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-30 05:36:04,595 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-06-30 05:36:04,595 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-06-30 05:36:04,595 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-06-30 05:36:04,595 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-06-30 05:36:04,595 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-06-30 05:36:04,595 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-06-30 05:36:04,633 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-06-30 05:36:04,634 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-06-30 05:36:04,635 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-30 05:36:04,635 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-30 05:36:04,664 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-06-30 05:36:04,664 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-06-30 05:36:04,665 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-06-30 05:36:04,665 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-06-30 05:36:04,665 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-06-30 05:36:04,669 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541
datanode_3_1  | 2020-06-30 05:36:04,669 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541
datanode_3_1  | 2020-06-30 05:36:04,670 [pool-19-thread-1] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541: start as a follower, conf=-1: [d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858], old=null
datanode_3_1  | 2020-06-30 05:36:04,673 [pool-19-thread-1] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-06-30 05:36:04,676 [pool-19-thread-1] INFO impl.RoleInfo: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: start FollowerState
datanode_3_1  | 2020-06-30 05:36:04,701 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2E18FCD31541,id=c7810c94-92e8-4071-bf24-3fb5d1be0ccd
datanode_3_1  | 2020-06-30 05:36:04,701 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541
datanode_3_1  | 2020-06-30 05:36:09,068 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for d92e4c01-a037-4da8-acd1-3a6f4234f2d6{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
datanode_3_1  | org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 1.698038406s. [buffered_nanos=1298059177, remote_addr=/10.5.0.9:9858]
datanode_3_1  | 	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
datanode_3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:86)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:187)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:156)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:95)
datanode_3_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:337)
datanode_3_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:249)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:102)
datanode_3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode_3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode_3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654)
datanode_3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode_3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode_3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode_3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode_3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode_3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:99)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:465)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 1.698038406s. [buffered_nanos=1298059177, remote_addr=/10.5.0.9:9858]
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
datanode_5_1  | Enabled profiling in kernel
datanode_5_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_5_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_5_1  | 2020-06-30 05:35:29,723 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_5_1  | /************************************************************
datanode_5_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_5_1  | STARTUP_MSG:   host = 62ebcea04efd/10.5.0.8
datanode_5_1  | STARTUP_MSG:   args = []
datanode_5_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_6_1  | Enabled profiling in kernel
datanode_6_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_6_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_6_1  | 2020-06-30 05:35:31,374 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_6_1  | /************************************************************
datanode_6_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_6_1  | STARTUP_MSG:   host = 70f903e69d72/10.5.0.9
datanode_6_1  | STARTUP_MSG:   args = []
datanode_6_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_5_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_5_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/bf23dcb95194fc844485de860846edb45b7aeb63 ; compiled by 'runner' on 2020-06-30T05:10Z
datanode_5_1  | STARTUP_MSG:   java = 11.0.6
datanode_5_1  | ************************************************************/
datanode_5_1  | 2020-06-30 05:35:29,764 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_5_1  | 2020-06-30 05:35:31,703 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_5_1  | 2020-06-30 05:35:32,323 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_5_1  | 2020-06-30 05:35:33,605 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_5_1  | 2020-06-30 05:35:33,606 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_5_1  | 2020-06-30 05:35:34,572 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:62ebcea04efd ip:10.5.0.8
datanode_5_1  | 2020-06-30 05:35:35,671 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_5_1  | 2020-06-30 05:35:35,777 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_5_1  | 2020-06-30 05:35:35,806 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_5_1  | 2020-06-30 05:35:35,933 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_5_1  | 2020-06-30 05:35:36,352 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_5_1  | 2020-06-30 05:35:43,455 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5_1  | 2020-06-30 05:35:44,067 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_5_1  | 2020-06-30 05:35:44,628 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_5_1  | 2020-06-30 05:35:44,662 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_5_1  | 2020-06-30 05:35:44,662 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-06-30 05:35:44,663 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_5_1  | 2020-06-30 05:35:44,692 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-06-30 05:35:46,617 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-06-30 05:35:48,294 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_5_1  | 2020-06-30 05:35:48,436 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_5_1  | 2020-06-30 05:35:48,652 [main] INFO util.log: Logging initialized @26182ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_5_1  | 2020-06-30 05:35:49,311 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_5_1  | 2020-06-30 05:35:49,389 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_5_1  | 2020-06-30 05:35:49,436 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_5_1  | 2020-06-30 05:35:49,442 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_5_1  | 2020-06-30 05:35:49,449 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_5_1  | 2020-06-30 05:35:49,449 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_5_1  | 2020-06-30 05:35:49,671 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_5_1  | 2020-06-30 05:35:49,722 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_5_1  | 2020-06-30 05:35:49,734 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_5_1  | 2020-06-30 05:35:49,933 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_5_1  | 2020-06-30 05:35:49,933 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_5_1  | 2020-06-30 05:35:49,939 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_5_1  | 2020-06-30 05:35:49,993 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b4954b2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_5_1  | 2020-06-30 05:35:50,018 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57416e49{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_5_1  | 2020-06-30 05:35:50,478 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c27f72{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-5200621200963145609.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_5_1  | 2020-06-30 05:35:50,573 [main] INFO server.AbstractConnector: Started ServerConnector@25cde5bb{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_5_1  | 2020-06-30 05:35:50,574 [main] INFO server.Server: Started @28104ms
datanode_5_1  | 2020-06-30 05:35:50,593 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_5_1  | 2020-06-30 05:35:50,593 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_5_1  | 2020-06-30 05:35:50,602 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_5_1  | 2020-06-30 05:35:50,842 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@16bb7222] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_5_1  | 2020-06-30 05:35:52,049 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_5_1  | 2020-06-30 05:35:54,192 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-06-30 05:35:55,193 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-06-30 05:35:56,194 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-06-30 05:35:57,211 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_5_1  | java.net.SocketTimeoutException: Call From 62ebcea04efd/10.5.0.8 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.8:39522 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_5_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_5_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_5_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_5_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_5_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_5_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_5_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_5_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_5_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_5_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_5_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_5_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4_1  | 2020-06-30 05:36:05,411 [pool-19-thread-1] INFO impl.RoleInfo: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7: start FollowerState
datanode_4_1  | 2020-06-30 05:36:05,450 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4F157D79C1E5,id=ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7
datanode_4_1  | 2020-06-30 05:36:05,452 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5
datanode_4_1  | 2020-06-30 05:36:05,556 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "ce990fde-9ce0-4be0-83bf-4f157d79c1e5"
datanode_4_1  | .
datanode_4_1  | 2020-06-30 05:36:05,561 [Command processor thread] INFO impl.RaftServerProxy: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7: addNew group-A47B89AB861D:[e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858] returns group-A47B89AB861D:java.util.concurrent.CompletableFuture@36e12e1d[Not completed]
datanode_4_1  | 2020-06-30 05:36:05,582 [pool-19-thread-1] INFO impl.RaftServerImpl: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7: new RaftServerImpl for group-A47B89AB861D:[e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-06-30 05:36:05,585 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-06-30 05:36:05,585 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-06-30 05:36:05,586 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-06-30 05:36:05,587 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-06-30 05:36:05,587 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-06-30 05:36:05,587 [pool-19-thread-1] INFO impl.RaftServerImpl: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D: ConfigurationManager, init=-1: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-06-30 05:36:05,588 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-06-30 05:36:05,589 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-06-30 05:36:05,591 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7a2acb68-f280-4577-9a67-a47b89ab861d does not exist. Creating ...
datanode_4_1  | 2020-06-30 05:36:05,609 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7a2acb68-f280-4577-9a67-a47b89ab861d/in_use.lock acquired by nodename 6@c7383f102dc5
datanode_4_1  | 2020-06-30 05:36:05,633 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7a2acb68-f280-4577-9a67-a47b89ab861d has been successfully formatted.
datanode_4_1  | 2020-06-30 05:36:05,637 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-A47B89AB861D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-06-30 05:36:05,639 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-06-30 05:36:05,641 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-06-30 05:36:05,641 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-06-30 05:36:05,645 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-06-30 05:36:05,645 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-06-30 05:36:05,645 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D
datanode_4_1  | 2020-06-30 05:36:05,646 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-06-30 05:36:05,646 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/7a2acb68-f280-4577-9a67-a47b89ab861d
datanode_4_1  | 2020-06-30 05:36:05,646 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-06-30 05:36:05,646 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-06-30 05:36:05,646 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-06-30 05:36:05,647 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-06-30 05:36:05,648 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-06-30 05:36:05,648 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-06-30 05:36:05,648 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-06-30 05:36:05,648 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-06-30 05:36:05,648 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-06-30 05:36:05,655 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-06-30 05:36:05,657 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-06-30 05:36:05,665 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-06-30 05:36:05,679 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-06-30 05:36:05,679 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-06-30 05:36:05,679 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-06-30 05:36:05,681 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-06-30 05:36:05,681 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-06-30 05:36:05,681 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D
datanode_4_1  | 2020-06-30 05:36:05,683 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D
datanode_3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:284)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:158)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:185)
datanode_3_1  | 	... 18 more
datanode_3_1  | 2020-06-30 05:36:09,360 [Thread-23] INFO impl.FollowerState: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-FollowerState: change to CANDIDATE, lastRpcTime:5198ms, electionTimeout:5178ms
datanode_3_1  | 2020-06-30 05:36:09,362 [Thread-23] INFO impl.RoleInfo: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: shutdown FollowerState
datanode_3_1  | 2020-06-30 05:36:09,362 [Thread-23] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3_1  | 2020-06-30 05:36:09,365 [Thread-23] INFO impl.RoleInfo: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: start LeaderElection
datanode_3_1  | 2020-06-30 05:36:09,394 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO impl.LeaderElection: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1: begin an election at term 1 for -1: [c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858], old=null
datanode_3_1  | 2020-06-30 05:36:09,408 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO impl.RoleInfo: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: shutdown LeaderElection
datanode_3_1  | 2020-06-30 05:36:09,435 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3_1  | 2020-06-30 05:36:09,436 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8B8645B1098A with new leaderId: c7810c94-92e8-4071-bf24-3fb5d1be0ccd
datanode_3_1  | 2020-06-30 05:36:09,437 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A: change Leader from null to c7810c94-92e8-4071-bf24-3fb5d1be0ccd at term 1 for becomeLeader, leader elected after 6458ms
datanode_3_1  | 2020-06-30 05:36:09,450 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-06-30 05:36:09,468 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 2020-06-30 05:36:09,494 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A
datanode_3_1  | 2020-06-30 05:36:09,511 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-30 05:36:09,512 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-06-30 05:36:09,602 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3_1  | 2020-06-30 05:36:09,603 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-06-30 05:36:09,604 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-06-30 05:36:09,657 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO impl.RoleInfo: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: start LeaderState
datanode_3_1  | 2020-06-30 05:36:09,745 [Thread-25] INFO impl.FollowerState: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-FollowerState: change to CANDIDATE, lastRpcTime:5068ms, electionTimeout:5007ms
datanode_3_1  | 2020-06-30 05:36:09,745 [Thread-25] INFO impl.RoleInfo: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: shutdown FollowerState
datanode_3_1  | 2020-06-30 05:36:09,746 [Thread-25] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3_1  | 2020-06-30 05:36:09,746 [Thread-25] INFO impl.RoleInfo: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: start LeaderElection
datanode_3_1  | 2020-06-30 05:36:09,776 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO impl.LeaderElection: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2: begin an election at term 1 for -1: [d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858], old=null
datanode_3_1  | 2020-06-30 05:36:09,798 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-06-30 05:36:09,955 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-LeaderElection1] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A: set configuration 0: [c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858], old=null at 0
datanode_3_1  | 2020-06-30 05:36:10,168 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO impl.LeaderElection: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2: Election PASSED; received 1 response(s) [c7810c94-92e8-4071-bf24-3fb5d1be0ccd<-d92e4c01-a037-4da8-acd1-3a6f4234f2d6#0:OK-t1] and 0 exception(s); c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541:t1, leader=null, voted=c7810c94-92e8-4071-bf24-3fb5d1be0ccd, raftlog=c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858], old=null
datanode_3_1  | 2020-06-30 05:36:10,170 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO impl.RoleInfo: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: shutdown LeaderElection
datanode_3_1  | 2020-06-30 05:36:10,197 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3_1  | 2020-06-30 05:36:10,197 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-2E18FCD31541 with new leaderId: c7810c94-92e8-4071-bf24-3fb5d1be0ccd
datanode_3_1  | 2020-06-30 05:36:10,198 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541: change Leader from null to c7810c94-92e8-4071-bf24-3fb5d1be0ccd at term 1 for becomeLeader, leader elected after 5603ms
datanode_3_1  | 2020-06-30 05:36:10,199 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-06-30 05:36:10,199 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_6_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_6_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/bf23dcb95194fc844485de860846edb45b7aeb63 ; compiled by 'runner' on 2020-06-30T05:10Z
datanode_6_1  | STARTUP_MSG:   java = 11.0.6
datanode_6_1  | ************************************************************/
datanode_6_1  | 2020-06-30 05:35:31,454 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_6_1  | 2020-06-30 05:35:33,303 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_6_1  | 2020-06-30 05:35:34,167 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_6_1  | 2020-06-30 05:35:35,837 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_6_1  | 2020-06-30 05:35:35,837 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_6_1  | 2020-06-30 05:35:36,471 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:70f903e69d72 ip:10.5.0.9
datanode_6_1  | 2020-06-30 05:35:37,452 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_6_1  | 2020-06-30 05:35:37,494 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_6_1  | 2020-06-30 05:35:37,537 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_6_1  | 2020-06-30 05:35:37,603 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_6_1  | 2020-06-30 05:35:38,030 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_6_1  | 2020-06-30 05:35:45,510 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_6_1  | 2020-06-30 05:35:45,910 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_6_1  | 2020-06-30 05:35:47,057 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_6_1  | 2020-06-30 05:35:47,059 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_6_1  | 2020-06-30 05:35:47,067 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-06-30 05:35:47,068 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_6_1  | 2020-06-30 05:35:47,072 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 2020-06-30 05:35:49,035 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-06-30 05:35:50,669 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_6_1  | 2020-06-30 05:35:50,794 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_6_1  | 2020-06-30 05:35:50,991 [main] INFO util.log: Logging initialized @27272ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_6_1  | 2020-06-30 05:35:51,566 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_6_1  | 2020-06-30 05:35:51,582 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_6_1  | 2020-06-30 05:35:51,626 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_6_1  | 2020-06-30 05:35:51,648 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_6_1  | 2020-06-30 05:35:51,648 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_6_1  | 2020-06-30 05:35:51,656 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_6_1  | 2020-06-30 05:35:51,827 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_6_1  | 2020-06-30 05:35:51,900 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_6_1  | 2020-06-30 05:35:51,904 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_6_1  | 2020-06-30 05:35:52,054 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_6_1  | 2020-06-30 05:35:52,054 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_6_1  | 2020-06-30 05:35:52,055 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_6_1  | 2020-06-30 05:35:52,120 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b4954b2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_6_1  | 2020-06-30 05:35:52,121 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57416e49{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_6_1  | 2020-06-30 05:35:52,593 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c27f72{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-17325207241166377311.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_6_1  | 2020-06-30 05:35:52,630 [main] INFO server.AbstractConnector: Started ServerConnector@25cde5bb{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_6_1  | 2020-06-30 05:35:52,632 [main] INFO server.Server: Started @28914ms
datanode_6_1  | 2020-06-30 05:35:52,656 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_6_1  | 2020-06-30 05:35:52,656 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_6_1  | 2020-06-30 05:35:52,668 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_6_1  | 2020-06-30 05:35:52,791 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d4fc3c4] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_6_1  | 2020-06-30 05:35:53,578 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_6_1  | 2020-06-30 05:35:55,887 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-06-30 05:35:56,888 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-06-30 05:35:58,265 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_6_1  | 2020-06-30 05:35:58,272 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_6_1  | 2020-06-30 05:35:58,289 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis d92e4c01-a037-4da8-acd1-3a6f4234f2d6 at port 9858
datanode_6_1  | 2020-06-30 05:35:58,412 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: d92e4c01-a037-4da8-acd1-3a6f4234f2d6: start RPC server
datanode_6_1  | 2020-06-30 05:35:59,015 [Datanode State Machine Thread - 0] INFO server.GrpcService: d92e4c01-a037-4da8-acd1-3a6f4234f2d6: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_6_1  | 2020-06-30 05:36:04,352 [Command processor thread] INFO impl.RaftServerProxy: d92e4c01-a037-4da8-acd1-3a6f4234f2d6: addNew group-E896E9793CA3:[d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858] returns group-E896E9793CA3:java.util.concurrent.CompletableFuture@35fe7ae0[Not completed]
datanode_6_1  | 2020-06-30 05:36:04,549 [pool-19-thread-1] INFO impl.RaftServerImpl: d92e4c01-a037-4da8-acd1-3a6f4234f2d6: new RaftServerImpl for group-E896E9793CA3:[d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-06-30 05:36:04,552 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-06-30 05:36:04,558 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-06-30 05:36:04,560 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-06-30 05:36:04,562 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-06-30 05:36:04,564 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-06-30 05:36:04,613 [pool-19-thread-1] INFO impl.RaftServerImpl: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3: ConfigurationManager, init=-1: [d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-06-30 05:36:04,616 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-06-30 05:36:04,628 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.8:39522 remote=scm/10.5.0.71:9861]
datanode_5_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_5_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_5_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_5_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_5_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_5_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_5_1  | 2020-06-30 05:35:58,206 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_5_1  | 2020-06-30 05:35:58,210 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_5_1  | 2020-06-30 05:35:58,217 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 7982fe8b-3966-40b2-9c7b-13327725473f at port 9858
datanode_5_1  | 2020-06-30 05:35:58,413 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 7982fe8b-3966-40b2-9c7b-13327725473f: start RPC server
datanode_5_1  | 2020-06-30 05:35:58,878 [Datanode State Machine Thread - 1] INFO server.GrpcService: 7982fe8b-3966-40b2-9c7b-13327725473f: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_5_1  | 2020-06-30 05:36:01,978 [Command processor thread] INFO impl.RaftServerProxy: 7982fe8b-3966-40b2-9c7b-13327725473f: addNew group-4B0B774E891A:[7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858] returns group-4B0B774E891A:java.util.concurrent.CompletableFuture@112d77f0[Not completed]
datanode_5_1  | 2020-06-30 05:36:02,051 [pool-19-thread-1] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f: new RaftServerImpl for group-4B0B774E891A:[7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-06-30 05:36:02,065 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-06-30 05:36:02,066 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-06-30 05:36:02,066 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-06-30 05:36:02,067 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-06-30 05:36:02,067 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-06-30 05:36:02,120 [pool-19-thread-1] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A: ConfigurationManager, init=-1: [7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-06-30 05:36:02,121 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-06-30 05:36:02,125 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-06-30 05:36:02,126 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/5d6d0aa2-df03-41f8-b757-4b0b774e891a does not exist. Creating ...
datanode_5_1  | 2020-06-30 05:36:02,144 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/5d6d0aa2-df03-41f8-b757-4b0b774e891a/in_use.lock acquired by nodename 6@62ebcea04efd
datanode_5_1  | 2020-06-30 05:36:02,161 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/5d6d0aa2-df03-41f8-b757-4b0b774e891a has been successfully formatted.
datanode_5_1  | 2020-06-30 05:36:02,193 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-4B0B774E891A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-06-30 05:36:02,197 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-06-30 05:36:02,199 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-06-30 05:36:02,215 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-06-30 05:36:02,220 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-06-30 05:36:02,222 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-06-30 05:36:10,199 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541
datanode_3_1  | 2020-06-30 05:36:10,199 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-30 05:36:10,199 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-06-30 05:36:10,200 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3_1  | 2020-06-30 05:36:10,226 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-06-30 05:36:10,228 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-06-30 05:36:10,265 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3_1  | 2020-06-30 05:36:10,265 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-30 05:36:10,266 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3_1  | 2020-06-30 05:36:10,285 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3_1  | 2020-06-30 05:36:10,297 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-06-30 05:36:10,297 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-06-30 05:36:10,297 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541
datanode_3_1  | 2020-06-30 05:36:10,320 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3_1  | 2020-06-30 05:36:10,325 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-30 05:36:10,325 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3_1  | 2020-06-30 05:36:10,325 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3_1  | 2020-06-30 05:36:10,327 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-06-30 05:36:10,327 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-06-30 05:36:10,333 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO impl.RoleInfo: c7810c94-92e8-4071-bf24-3fb5d1be0ccd: start LeaderState
datanode_3_1  | 2020-06-30 05:36:10,343 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-06-30 05:36:10,382 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-LeaderElection2] INFO impl.RaftServerImpl: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541: set configuration 0: [d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858], old=null at 0
datanode_3_1  | 2020-06-30 05:36:10,909 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0f942154-9669-46a8-b1d1-2e18fcd31541/current/log_inprogress_0
datanode_3_1  | 2020-06-30 05:36:11,013 [c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-8B8645B1098A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/54c09bb2-982d-403b-8ee3-8b8645b1098a/current/log_inprogress_0
datanode_3_1  | 2020-06-30 05:36:11,222 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "0f942154-9669-46a8-b1d1-2e18fcd31541"
datanode_3_1  | .
datanode_3_1  | 2020-06-30 05:36:13,030 [grpc-default-executor-1] INFO impl.FollowerInfo: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f: nextIndex: updateUnconditionally 1 -> 0
datanode_3_1  | 2020-06-30 05:37:13,031 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3,entriesCount=1,lastEntry=(t:1, i:0)
datanode_3_1  | 2020-06-30 05:37:29,023 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=10,entriesCount=1,lastEntry=(t:1, i:1)
datanode_3_1  | 2020-06-30 05:37:29,130 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=11,entriesCount=1,lastEntry=(t:1, i:2)
datanode_3_1  | 2020-06-30 05:37:30,423 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=12,entriesCount=1,lastEntry=(t:1, i:3)
datanode_3_1  | 2020-06-30 05:37:30,423 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=13,entriesCount=1,lastEntry=(t:1, i:4)
datanode_3_1  | 2020-06-30 05:37:32,965 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=15,entriesCount=1,lastEntry=(t:1, i:5)
datanode_3_1  | 2020-06-30 05:37:32,971 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=16,entriesCount=1,lastEntry=(t:1, i:6)
datanode_3_1  | 2020-06-30 05:37:32,996 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=17,entriesCount=1,lastEntry=(t:1, i:7)
datanode_3_1  | 2020-06-30 05:37:33,003 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=18,entriesCount=1,lastEntry=(t:1, i:8)
datanode_3_1  | 2020-06-30 05:37:38,203 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=21,entriesCount=1,lastEntry=(t:1, i:9)
datanode_3_1  | 2020-06-30 05:37:38,215 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=22,entriesCount=1,lastEntry=(t:1, i:10)
datanode_3_1  | 2020-06-30 05:37:38,243 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=23,entriesCount=1,lastEntry=(t:1, i:11)
datanode_3_1  | 2020-06-30 05:37:38,252 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=24,entriesCount=1,lastEntry=(t:1, i:12)
datanode_3_1  | 2020-06-30 05:37:45,956 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=28,entriesCount=1,lastEntry=(t:1, i:13)
datanode_3_1  | 2020-06-30 05:37:45,966 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=29,entriesCount=1,lastEntry=(t:1, i:14)
datanode_3_1  | 2020-06-30 05:37:45,966 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=30,entriesCount=1,lastEntry=(t:1, i:15)
datanode_3_1  | 2020-06-30 05:37:45,993 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=31,entriesCount=1,lastEntry=(t:1, i:16)
datanode_3_1  | 2020-06-30 05:37:48,541 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=33,entriesCount=1,lastEntry=(t:1, i:17)
datanode_3_1  | 2020-06-30 05:37:48,546 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=34,entriesCount=1,lastEntry=(t:1, i:18)
datanode_3_1  | 2020-06-30 05:37:48,559 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=35,entriesCount=1,lastEntry=(t:1, i:19)
datanode_3_1  | 2020-06-30 05:37:48,573 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=36,entriesCount=1,lastEntry=(t:1, i:20)
datanode_3_1  | 2020-06-30 05:37:51,125 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=38,entriesCount=1,lastEntry=(t:1, i:21)
datanode_3_1  | 2020-06-30 05:37:51,135 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=39,entriesCount=1,lastEntry=(t:1, i:22)
datanode_3_1  | 2020-06-30 05:37:51,144 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=40,entriesCount=1,lastEntry=(t:1, i:23)
datanode_3_1  | 2020-06-30 05:37:51,163 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=41,entriesCount=1,lastEntry=(t:1, i:24)
datanode_3_1  | 2020-06-30 05:37:53,704 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=43,entriesCount=1,lastEntry=(t:1, i:25)
datanode_3_1  | 2020-06-30 05:37:53,723 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=44,entriesCount=1,lastEntry=(t:1, i:26)
datanode_3_1  | 2020-06-30 05:37:53,725 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=45,entriesCount=1,lastEntry=(t:1, i:27)
datanode_3_1  | 2020-06-30 05:37:53,741 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=46,entriesCount=1,lastEntry=(t:1, i:28)
datanode_4_1  | 2020-06-30 05:36:05,684 [pool-19-thread-1] INFO impl.RaftServerImpl: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D: start as a follower, conf=-1: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null
datanode_4_1  | 2020-06-30 05:36:05,689 [pool-19-thread-1] INFO impl.RaftServerImpl: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-06-30 05:36:05,693 [pool-19-thread-1] INFO impl.RoleInfo: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7: start FollowerState
datanode_4_1  | 2020-06-30 05:36:05,709 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A47B89AB861D,id=ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7
datanode_4_1  | 2020-06-30 05:36:05,715 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D
datanode_4_1  | 2020-06-30 05:36:09,998 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "7a2acb68-f280-4577-9a67-a47b89ab861d"
datanode_4_1  | .
datanode_4_1  | 2020-06-30 05:36:10,528 [Thread-22] INFO impl.FollowerState: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-FollowerState: change to CANDIDATE, lastRpcTime:5116ms, electionTimeout:5078ms
datanode_4_1  | 2020-06-30 05:36:10,542 [Thread-22] INFO impl.RoleInfo: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7: shutdown FollowerState
datanode_4_1  | 2020-06-30 05:36:10,542 [Thread-22] INFO impl.RaftServerImpl: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4_1  | 2020-06-30 05:36:10,544 [Thread-22] INFO impl.RoleInfo: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7: start LeaderElection
datanode_4_1  | 2020-06-30 05:36:10,555 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO impl.LeaderElection: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1: begin an election at term 1 for -1: [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858], old=null
datanode_4_1  | 2020-06-30 05:36:10,581 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO impl.RoleInfo: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7: shutdown LeaderElection
datanode_4_1  | 2020-06-30 05:36:10,594 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO impl.RaftServerImpl: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_4_1  | 2020-06-30 05:36:10,597 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4F157D79C1E5 with new leaderId: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7
datanode_4_1  | 2020-06-30 05:36:10,620 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO impl.RaftServerImpl: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5: change Leader from null to ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7 at term 1 for becomeLeader, leader elected after 6383ms
datanode_4_1  | 2020-06-30 05:36:10,671 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4_1  | 2020-06-30 05:36:10,680 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4_1  | 2020-06-30 05:36:10,720 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5
datanode_4_1  | 2020-06-30 05:36:10,847 [grpc-default-executor-0] INFO impl.RaftServerImpl: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:b33eb83e-f955-480a-aaae-270c6d5e999a
datanode_4_1  | 2020-06-30 05:36:10,853 [grpc-default-executor-0] INFO impl.RoleInfo: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7: shutdown FollowerState
datanode_4_1  | 2020-06-30 05:36:10,854 [grpc-default-executor-0] INFO impl.RoleInfo: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7: start FollowerState
datanode_4_1  | 2020-06-30 05:36:10,854 [Thread-24] INFO impl.FollowerState: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_4_1  | 2020-06-30 05:36:10,882 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4_1  | 2020-06-30 05:36:10,884 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_4_1  | 2020-06-30 05:36:11,251 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4_1  | 2020-06-30 05:36:11,269 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4_1  | 2020-06-30 05:36:11,270 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4_1  | 2020-06-30 05:36:11,386 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO impl.RoleInfo: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7: start LeaderState
datanode_4_1  | 2020-06-30 05:36:11,484 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-06-30 05:36:11,567 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-LeaderElection1] INFO impl.RaftServerImpl: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5: set configuration 0: [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858], old=null at 0
datanode_4_1  | 2020-06-30 05:36:11,849 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A47B89AB861D with new leaderId: b33eb83e-f955-480a-aaae-270c6d5e999a
datanode_4_1  | 2020-06-30 05:36:11,852 [grpc-default-executor-1] INFO impl.RaftServerImpl: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D: change Leader from null to b33eb83e-f955-480a-aaae-270c6d5e999a at term 1 for appendEntries, leader elected after 6210ms
datanode_4_1  | 2020-06-30 05:36:11,856 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-4F157D79C1E5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ce990fde-9ce0-4be0-83bf-4f157d79c1e5/current/log_inprogress_0
datanode_4_1  | 2020-06-30 05:36:11,893 [grpc-default-executor-1] INFO impl.RaftServerImpl: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D: set configuration 0: [e0f2b5b7-e5e0-4691-810d-9d57d7b98662:10.5.0.4:9858, ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7:10.5.0.7:9858, b33eb83e-f955-480a-aaae-270c6d5e999a:10.5.0.5:9858], old=null at 0
datanode_4_1  | 2020-06-30 05:36:11,899 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-06-30 05:36:11,915 [ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7@group-A47B89AB861D-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7a2acb68-f280-4577-9a67-a47b89ab861d/current/log_inprogress_0
datanode_6_1  | 2020-06-30 05:36:04,640 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/435cd0da-b619-4126-8475-e896e9793ca3 does not exist. Creating ...
datanode_6_1  | 2020-06-30 05:36:04,693 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/435cd0da-b619-4126-8475-e896e9793ca3/in_use.lock acquired by nodename 6@70f903e69d72
datanode_6_1  | 2020-06-30 05:36:04,726 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/435cd0da-b619-4126-8475-e896e9793ca3 has been successfully formatted.
datanode_6_1  | 2020-06-30 05:36:04,763 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-E896E9793CA3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-06-30 05:36:04,797 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_6_1  | 2020-06-30 05:36:04,799 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-06-30 05:36:04,861 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-06-30 05:36:04,867 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-06-30 05:36:04,888 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-06-30 05:36:04,946 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3
datanode_6_1  | 2020-06-30 05:36:05,083 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-06-30 05:36:05,165 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/435cd0da-b619-4126-8475-e896e9793ca3
datanode_6_1  | 2020-06-30 05:36:05,193 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-06-30 05:36:05,197 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-06-30 05:36:05,198 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-06-30 05:36:05,207 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-06-30 05:36:05,207 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-06-30 05:36:05,208 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-06-30 05:36:05,230 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-06-30 05:36:05,238 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-06-30 05:36:05,238 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-06-30 05:36:05,420 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-06-30 05:36:05,511 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-30 05:36:05,525 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-30 05:36:05,591 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-06-30 05:36:05,628 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-06-30 05:36:05,632 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-06-30 05:36:05,651 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-06-30 05:36:05,658 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-06-30 05:36:05,980 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3
datanode_6_1  | 2020-06-30 05:36:06,035 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3
datanode_6_1  | 2020-06-30 05:36:06,068 [pool-19-thread-1] INFO impl.RaftServerImpl: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3: start as a follower, conf=-1: [d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858], old=null
datanode_6_1  | 2020-06-30 05:36:06,074 [pool-19-thread-1] INFO impl.RaftServerImpl: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-06-30 05:36:06,080 [pool-19-thread-1] INFO impl.RoleInfo: d92e4c01-a037-4da8-acd1-3a6f4234f2d6: start FollowerState
datanode_6_1  | 2020-06-30 05:36:06,117 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E896E9793CA3,id=d92e4c01-a037-4da8-acd1-3a6f4234f2d6
datanode_6_1  | 2020-06-30 05:36:06,120 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-06-30 05:35:31,441 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 83cf7863961d/10.5.0.70
om_1          | STARTUP_MSG:   args = [--init]
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_6_1  | 2020-06-30 05:36:06,307 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "435cd0da-b619-4126-8475-e896e9793ca3"
datanode_6_1  | .
datanode_6_1  | 2020-06-30 05:36:06,311 [Command processor thread] INFO impl.RaftServerProxy: d92e4c01-a037-4da8-acd1-3a6f4234f2d6: addNew group-2E18FCD31541:[d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858] returns group-2E18FCD31541:java.util.concurrent.CompletableFuture@9b84d7f[Not completed]
datanode_6_1  | 2020-06-30 05:36:06,343 [pool-19-thread-1] INFO impl.RaftServerImpl: d92e4c01-a037-4da8-acd1-3a6f4234f2d6: new RaftServerImpl for group-2E18FCD31541:[d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-06-30 05:36:06,345 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-06-30 05:36:06,345 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-06-30 05:36:06,347 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-06-30 05:36:06,350 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-06-30 05:36:06,350 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-06-30 05:36:06,350 [pool-19-thread-1] INFO impl.RaftServerImpl: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541: ConfigurationManager, init=-1: [d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-06-30 05:36:06,351 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-06-30 05:36:06,351 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-06-30 05:36:06,359 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/0f942154-9669-46a8-b1d1-2e18fcd31541 does not exist. Creating ...
datanode_6_1  | 2020-06-30 05:36:06,364 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/0f942154-9669-46a8-b1d1-2e18fcd31541/in_use.lock acquired by nodename 6@70f903e69d72
datanode_6_1  | 2020-06-30 05:36:06,376 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/0f942154-9669-46a8-b1d1-2e18fcd31541 has been successfully formatted.
datanode_6_1  | 2020-06-30 05:36:06,376 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-2E18FCD31541: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-06-30 05:36:06,394 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_6_1  | 2020-06-30 05:36:06,397 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-06-30 05:36:06,403 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-06-30 05:36:06,403 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-06-30 05:36:06,404 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-06-30 05:36:06,404 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541
datanode_6_1  | 2020-06-30 05:36:06,414 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-06-30 05:36:06,419 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/0f942154-9669-46a8-b1d1-2e18fcd31541
datanode_6_1  | 2020-06-30 05:36:06,420 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-06-30 05:36:06,420 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-06-30 05:36:06,420 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-06-30 05:36:06,421 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-06-30 05:36:06,424 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-06-30 05:36:06,426 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-06-30 05:36:06,429 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-06-30 05:36:06,429 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-06-30 05:36:06,429 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-06-30 05:36:06,431 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-06-30 05:36:06,439 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-30 05:36:06,448 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-30 05:36:06,449 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-06-30 05:36:06,453 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-06-30 05:36:06,453 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-06-30 05:36:06,453 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-06-30 05:36:06,457 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-06-30 05:36:06,457 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541
datanode_6_1  | 2020-06-30 05:36:06,458 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541
datanode_6_1  | 2020-06-30 05:36:06,470 [pool-19-thread-1] INFO impl.RaftServerImpl: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541: start as a follower, conf=-1: [d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858], old=null
datanode_6_1  | 2020-06-30 05:36:06,475 [pool-19-thread-1] INFO impl.RaftServerImpl: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-06-30 05:36:06,478 [pool-19-thread-1] INFO impl.RoleInfo: d92e4c01-a037-4da8-acd1-3a6f4234f2d6: start FollowerState
datanode_3_1  | 2020-06-30 05:37:56,279 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=48,entriesCount=1,lastEntry=(t:1, i:29)
datanode_3_1  | 2020-06-30 05:37:56,301 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=49,entriesCount=1,lastEntry=(t:1, i:30)
datanode_3_1  | 2020-06-30 05:37:56,328 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=50,entriesCount=1,lastEntry=(t:1, i:31)
datanode_3_1  | 2020-06-30 05:37:56,343 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=51,entriesCount=1,lastEntry=(t:1, i:32)
datanode_3_1  | 2020-06-30 05:37:58,891 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=53,entriesCount=1,lastEntry=(t:1, i:33)
datanode_3_1  | 2020-06-30 05:37:58,897 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=54,entriesCount=1,lastEntry=(t:1, i:34)
datanode_3_1  | 2020-06-30 05:37:58,905 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=55,entriesCount=1,lastEntry=(t:1, i:35)
datanode_3_1  | 2020-06-30 05:37:58,917 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=56,entriesCount=1,lastEntry=(t:1, i:36)
datanode_3_1  | 2020-06-30 05:38:01,451 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=58,entriesCount=1,lastEntry=(t:1, i:37)
datanode_3_1  | 2020-06-30 05:38:01,463 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=59,entriesCount=1,lastEntry=(t:1, i:38)
datanode_3_1  | 2020-06-30 05:38:01,471 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=60,entriesCount=1,lastEntry=(t:1, i:39)
datanode_3_1  | 2020-06-30 05:38:01,496 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=61,entriesCount=1,lastEntry=(t:1, i:40)
datanode_3_1  | 2020-06-30 05:38:11,832 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=66,entriesCount=1,lastEntry=(t:1, i:41)
datanode_3_1  | 2020-06-30 05:38:11,841 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=67,entriesCount=1,lastEntry=(t:1, i:42)
datanode_3_1  | 2020-06-30 05:38:11,850 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=68,entriesCount=1,lastEntry=(t:1, i:43)
datanode_3_1  | 2020-06-30 05:38:11,863 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=69,entriesCount=1,lastEntry=(t:1, i:44)
datanode_3_1  | 2020-06-30 05:38:16,998 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=72,entriesCount=1,lastEntry=(t:1, i:45)
datanode_3_1  | 2020-06-30 05:38:17,002 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=73,entriesCount=1,lastEntry=(t:1, i:46)
datanode_3_1  | 2020-06-30 05:38:17,013 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=74,entriesCount=1,lastEntry=(t:1, i:47)
datanode_3_1  | 2020-06-30 05:38:17,034 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=75,entriesCount=1,lastEntry=(t:1, i:48)
datanode_3_1  | 2020-06-30 05:38:22,146 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=78,entriesCount=1,lastEntry=(t:1, i:49)
datanode_3_1  | 2020-06-30 05:38:22,159 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=79,entriesCount=1,lastEntry=(t:1, i:50)
datanode_3_1  | 2020-06-30 05:38:22,184 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=80,entriesCount=1,lastEntry=(t:1, i:51)
datanode_6_1  | 2020-06-30 05:36:06,479 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2E18FCD31541,id=d92e4c01-a037-4da8-acd1-3a6f4234f2d6
datanode_6_1  | 2020-06-30 05:36:06,479 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541
datanode_6_1  | 2020-06-30 05:36:10,030 [grpc-default-executor-0] INFO impl.RaftServerImpl: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:c7810c94-92e8-4071-bf24-3fb5d1be0ccd
datanode_6_1  | 2020-06-30 05:36:10,033 [grpc-default-executor-0] INFO impl.RoleInfo: d92e4c01-a037-4da8-acd1-3a6f4234f2d6: shutdown FollowerState
datanode_6_1  | 2020-06-30 05:36:10,061 [Thread-24] INFO impl.FollowerState: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_6_1  | 2020-06-30 05:36:10,061 [grpc-default-executor-0] INFO impl.RoleInfo: d92e4c01-a037-4da8-acd1-3a6f4234f2d6: start FollowerState
datanode_6_1  | 2020-06-30 05:36:10,672 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-2E18FCD31541 with new leaderId: c7810c94-92e8-4071-bf24-3fb5d1be0ccd
datanode_6_1  | 2020-06-30 05:36:10,685 [grpc-default-executor-0] INFO impl.RaftServerImpl: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541: change Leader from null to c7810c94-92e8-4071-bf24-3fb5d1be0ccd at term 1 for appendEntries, leader elected after 4294ms
datanode_6_1  | 2020-06-30 05:36:10,835 [grpc-default-executor-0] INFO impl.RaftServerImpl: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541: set configuration 0: [d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858], old=null at 0
datanode_6_1  | 2020-06-30 05:36:10,903 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-06-30 05:36:11,031 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "0f942154-9669-46a8-b1d1-2e18fcd31541"
datanode_6_1  | .
datanode_6_1  | 2020-06-30 05:36:11,161 [Thread-22] INFO impl.FollowerState: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-FollowerState: change to CANDIDATE, lastRpcTime:5081ms, electionTimeout:5070ms
datanode_6_1  | 2020-06-30 05:36:11,166 [Thread-22] INFO impl.RoleInfo: d92e4c01-a037-4da8-acd1-3a6f4234f2d6: shutdown FollowerState
datanode_6_1  | 2020-06-30 05:36:11,168 [Thread-22] INFO impl.RaftServerImpl: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_6_1  | 2020-06-30 05:36:11,185 [Thread-22] INFO impl.RoleInfo: d92e4c01-a037-4da8-acd1-3a6f4234f2d6: start LeaderElection
datanode_6_1  | 2020-06-30 05:36:11,319 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO impl.LeaderElection: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1: begin an election at term 1 for -1: [d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858], old=null
datanode_6_1  | 2020-06-30 05:36:11,320 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO impl.RoleInfo: d92e4c01-a037-4da8-acd1-3a6f4234f2d6: shutdown LeaderElection
datanode_6_1  | 2020-06-30 05:36:11,325 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO impl.RaftServerImpl: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_6_1  | 2020-06-30 05:36:11,327 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-E896E9793CA3 with new leaderId: d92e4c01-a037-4da8-acd1-3a6f4234f2d6
datanode_6_1  | 2020-06-30 05:36:11,328 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO impl.RaftServerImpl: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3: change Leader from null to d92e4c01-a037-4da8-acd1-3a6f4234f2d6 at term 1 for becomeLeader, leader elected after 6563ms
datanode_6_1  | 2020-06-30 05:36:11,368 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_6_1  | 2020-06-30 05:36:11,370 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_6_1  | 2020-06-30 05:36:11,373 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3
datanode_6_1  | 2020-06-30 05:36:11,420 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_6_1  | 2020-06-30 05:36:11,421 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_6_1  | 2020-06-30 05:36:11,484 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_6_1  | 2020-06-30 05:36:11,487 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_6_1  | 2020-06-30 05:36:11,492 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_6_1  | 2020-06-30 05:36:11,573 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO impl.RoleInfo: d92e4c01-a037-4da8-acd1-3a6f4234f2d6: start LeaderState
datanode_6_1  | 2020-06-30 05:36:11,639 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-06-30 05:36:11,666 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-LeaderElection1] INFO impl.RaftServerImpl: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3: set configuration 0: [d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858], old=null at 0
datanode_6_1  | 2020-06-30 05:36:11,783 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-E896E9793CA3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/435cd0da-b619-4126-8475-e896e9793ca3/current/log_inprogress_0
datanode_6_1  | 2020-06-30 05:36:11,806 [d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d92e4c01-a037-4da8-acd1-3a6f4234f2d6@group-2E18FCD31541-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0f942154-9669-46a8-b1d1-2e18fcd31541/current/log_inprogress_0
datanode_5_1  | 2020-06-30 05:36:02,229 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A
datanode_5_1  | 2020-06-30 05:36:02,244 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-06-30 05:36:02,249 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/5d6d0aa2-df03-41f8-b757-4b0b774e891a
datanode_5_1  | 2020-06-30 05:36:02,250 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-06-30 05:36:02,250 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-06-30 05:36:02,251 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-06-30 05:36:02,252 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-06-30 05:36:02,252 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-06-30 05:36:02,253 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-06-30 05:36:02,254 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-06-30 05:36:02,254 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-06-30 05:36:02,255 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-06-30 05:36:02,301 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-06-30 05:36:02,316 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-30 05:36:02,321 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-30 05:36:02,332 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-06-30 05:36:02,341 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-06-30 05:36:02,342 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-06-30 05:36:02,343 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-06-30 05:36:02,344 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-06-30 05:36:02,402 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A
datanode_5_1  | 2020-06-30 05:36:02,405 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A
datanode_5_1  | 2020-06-30 05:36:02,425 [pool-19-thread-1] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A: start as a follower, conf=-1: [7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858], old=null
datanode_5_1  | 2020-06-30 05:36:02,427 [pool-19-thread-1] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-06-30 05:36:02,434 [pool-19-thread-1] INFO impl.RoleInfo: 7982fe8b-3966-40b2-9c7b-13327725473f: start FollowerState
datanode_5_1  | 2020-06-30 05:36:02,520 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4B0B774E891A,id=7982fe8b-3966-40b2-9c7b-13327725473f
datanode_5_1  | 2020-06-30 05:36:02,529 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A
datanode_5_1  | 2020-06-30 05:36:02,684 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "5d6d0aa2-df03-41f8-b757-4b0b774e891a"
datanode_5_1  | .
datanode_5_1  | 2020-06-30 05:36:07,665 [Thread-23] INFO impl.FollowerState: 7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-FollowerState: change to CANDIDATE, lastRpcTime:5231ms, electionTimeout:5186ms
datanode_5_1  | 2020-06-30 05:36:07,667 [Thread-23] INFO impl.RoleInfo: 7982fe8b-3966-40b2-9c7b-13327725473f: shutdown FollowerState
datanode_5_1  | 2020-06-30 05:36:07,667 [Thread-23] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-06-30 05:36:07,670 [Thread-23] INFO impl.RoleInfo: 7982fe8b-3966-40b2-9c7b-13327725473f: start LeaderElection
datanode_5_1  | 2020-06-30 05:36:07,695 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO impl.LeaderElection: 7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1: begin an election at term 1 for -1: [7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858], old=null
datanode_5_1  | 2020-06-30 05:36:07,697 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO impl.RoleInfo: 7982fe8b-3966-40b2-9c7b-13327725473f: shutdown LeaderElection
datanode_5_1  | 2020-06-30 05:36:07,697 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-06-30 05:36:07,698 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4B0B774E891A with new leaderId: 7982fe8b-3966-40b2-9c7b-13327725473f
datanode_5_1  | 2020-06-30 05:36:07,698 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A: change Leader from null to 7982fe8b-3966-40b2-9c7b-13327725473f at term 1 for becomeLeader, leader elected after 5500ms
datanode_5_1  | 2020-06-30 05:36:07,713 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | 2020-06-30 05:36:07,717 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5_1  | 2020-06-30 05:36:07,719 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A
datanode_5_1  | 2020-06-30 05:36:07,730 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5_1  | 2020-06-30 05:36:07,731 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_5_1  | 2020-06-30 05:36:07,794 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5_1  | 2020-06-30 05:36:07,801 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/bf23dcb95194fc844485de860846edb45b7aeb63 ; compiled by 'runner' on 2020-06-30T05:10Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-06-30 05:35:31,498 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-06-30 05:35:37,920 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-06-30 05:35:38,857 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-06-30 05:35:38,857 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-06-30 05:35:39,002 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-30 05:35:42,327 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 05:35:43,336 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 05:35:44,337 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 05:35:45,338 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 05:35:46,339 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 05:35:47,339 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 05:35:48,340 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 05:35:49,341 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 05:35:50,342 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 05:35:51,343 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 05:35:51,345 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1          | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-ac953157-4f58-41d4-9a53-2cd164004bf1
om_1          | 2020-06-30 05:35:57,607 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1          | /************************************************************
om_1          | SHUTDOWN_MSG: Shutting down OzoneManager at 83cf7863961d/10.5.0.70
om_1          | ************************************************************/
om_1          | Enabled profiling in kernel
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-06-30 05:36:03,543 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 83cf7863961d/10.5.0.70
om_1          | STARTUP_MSG:   args = []
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_5_1  | 2020-06-30 05:36:07,802 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5_1  | 2020-06-30 05:36:07,830 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO impl.RoleInfo: 7982fe8b-3966-40b2-9c7b-13327725473f: start LeaderState
datanode_5_1  | 2020-06-30 05:36:07,925 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-06-30 05:36:08,073 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-LeaderElection1] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A: set configuration 0: [7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858], old=null at 0
datanode_5_1  | 2020-06-30 05:36:08,265 [7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 7982fe8b-3966-40b2-9c7b-13327725473f@group-4B0B774E891A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/5d6d0aa2-df03-41f8-b757-4b0b774e891a/current/log_inprogress_0
datanode_5_1  | 2020-06-30 05:36:10,610 [grpc-default-executor-2] WARN server.GrpcServerProtocolService: 7982fe8b-3966-40b2-9c7b-13327725473f: Failed requestVote c7810c94-92e8-4071-bf24-3fb5d1be0ccd->7982fe8b-3966-40b2-9c7b-13327725473f#0
datanode_5_1  | org.apache.ratis.protocol.GroupMismatchException: 7982fe8b-3966-40b2-9c7b-13327725473f: group-2E18FCD31541 not found.
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:127)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:274)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:283)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:278)
datanode_5_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:455)
datanode_5_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:170)
datanode_5_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:325)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:817)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | 2020-06-30 05:36:10,619 [pool-19-thread-1] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f: new RaftServerImpl for group-2E18FCD31541:[d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-06-30 05:36:10,641 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-06-30 05:36:10,641 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-06-30 05:36:10,641 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-06-30 05:36:10,642 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-06-30 05:36:10,613 [grpc-default-executor-0] INFO impl.RaftServerProxy: 7982fe8b-3966-40b2-9c7b-13327725473f: addNew group-2E18FCD31541:[d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858] returns group-2E18FCD31541:java.util.concurrent.CompletableFuture@16b5c292[Not completed]
datanode_5_1  | 2020-06-30 05:36:10,645 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-06-30 05:36:10,646 [pool-19-thread-1] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541: ConfigurationManager, init=-1: [d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-06-30 05:36:10,647 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-06-30 05:36:10,647 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-06-30 05:36:10,647 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/0f942154-9669-46a8-b1d1-2e18fcd31541 does not exist. Creating ...
datanode_5_1  | 2020-06-30 05:36:10,653 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/0f942154-9669-46a8-b1d1-2e18fcd31541/in_use.lock acquired by nodename 6@62ebcea04efd
datanode_5_1  | 2020-06-30 05:36:10,677 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/0f942154-9669-46a8-b1d1-2e18fcd31541 has been successfully formatted.
datanode_5_1  | 2020-06-30 05:36:10,678 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-2E18FCD31541: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-06-30 05:36:10,680 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-06-30 05:36:10,680 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-06-30 05:36:10,682 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-06-30 05:36:10,689 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-06-30 05:36:10,701 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-06-30 05:36:10,701 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541
datanode_5_1  | 2020-06-30 05:36:10,701 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-06-30 05:36:10,701 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/0f942154-9669-46a8-b1d1-2e18fcd31541
datanode_5_1  | 2020-06-30 05:36:10,722 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-06-30 05:36:10,722 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-06-30 05:36:10,723 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-06-30 05:36:10,745 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/bf23dcb95194fc844485de860846edb45b7aeb63 ; compiled by 'runner' on 2020-06-30T05:10Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-06-30 05:36:03,698 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-06-30 05:36:09,895 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-06-30 05:36:10,327 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-06-30 05:36:10,327 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-06-30 05:36:10,371 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-30 05:36:10,487 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-30 05:36:14,055 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-30 05:36:15,197 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1          | 2020-06-30 05:36:15,224 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1          | 2020-06-30 05:36:15,488 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1          | 2020-06-30 05:36:15,647 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1          | 2020-06-30 05:36:15,648 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1          | 2020-06-30 05:36:15,728 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/10.5.0.70:9862
om_1          | 2020-06-30 05:36:15,765 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1          | 2020-06-30 05:36:15,757 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1          | 2020-06-30 05:36:16,166 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1          | 2020-06-30 05:36:16,166 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1          | 2020-06-30 05:36:16,214 [Listener at om/9862] INFO util.log: Logging initialized @18282ms to org.eclipse.jetty.util.log.Slf4jLog
om_1          | 2020-06-30 05:36:16,500 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1          | 2020-06-30 05:36:16,512 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
datanode_5_1  | 2020-06-30 05:36:10,748 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-06-30 05:36:10,749 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-06-30 05:36:10,756 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-06-30 05:36:10,759 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-06-30 05:36:10,759 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-06-30 05:36:10,770 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-06-30 05:36:10,784 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-30 05:36:10,817 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-30 05:36:10,824 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-06-30 05:36:10,824 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-06-30 05:36:10,824 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-06-30 05:36:10,824 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-06-30 05:36:10,825 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-06-30 05:36:10,833 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541
datanode_5_1  | 2020-06-30 05:36:10,833 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541
datanode_5_1  | 2020-06-30 05:36:10,871 [pool-19-thread-1] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541: start as a follower, conf=-1: [d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858], old=null
datanode_5_1  | 2020-06-30 05:36:10,886 [pool-19-thread-1] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-06-30 05:36:10,893 [pool-19-thread-1] INFO impl.RoleInfo: 7982fe8b-3966-40b2-9c7b-13327725473f: start FollowerState
datanode_5_1  | 2020-06-30 05:36:10,934 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2E18FCD31541,id=7982fe8b-3966-40b2-9c7b-13327725473f
datanode_5_1  | 2020-06-30 05:36:10,934 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541
datanode_5_1  | 2020-06-30 05:36:13,010 [grpc-default-executor-2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-2E18FCD31541 with new leaderId: c7810c94-92e8-4071-bf24-3fb5d1be0ccd
datanode_5_1  | 2020-06-30 05:36:13,013 [grpc-default-executor-2] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541: change Leader from null to c7810c94-92e8-4071-bf24-3fb5d1be0ccd at term 1 for appendEntries, leader elected after 2329ms
datanode_5_1  | 2020-06-30 05:36:13,015 [grpc-default-executor-2] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode_5_1  | 2020-06-30 05:36:13,021 [grpc-default-executor-2] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541: inconsistency entries. Reply:c7810c94-92e8-4071-bf24-3fb5d1be0ccd<-7982fe8b-3966-40b2-9c7b-13327725473f#2:FAIL,INCONSISTENCY,nextIndex:0,term:0,followerCommit:-1
datanode_5_1  | 2020-06-30 05:36:13,041 [grpc-default-executor-2] INFO impl.RaftServerImpl: 7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541: set configuration 0: [d92e4c01-a037-4da8-acd1-3a6f4234f2d6:10.5.0.9:9858, 7982fe8b-3966-40b2-9c7b-13327725473f:10.5.0.8:9858, c7810c94-92e8-4071-bf24-3fb5d1be0ccd:10.5.0.6:9858], old=null at 0
datanode_5_1  | 2020-06-30 05:36:13,042 [grpc-default-executor-2] INFO segmented.SegmentedRaftLogWorker: 7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-06-30 05:36:13,043 [7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 7982fe8b-3966-40b2-9c7b-13327725473f@group-2E18FCD31541-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0f942154-9669-46a8-b1d1-2e18fcd31541/current/log_inprogress_0
datanode_3_1  | 2020-06-30 05:38:22,193 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=81,entriesCount=1,lastEntry=(t:1, i:52)
datanode_3_1  | 2020-06-30 05:38:24,753 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=83,entriesCount=1,lastEntry=(t:1, i:53)
datanode_3_1  | 2020-06-30 05:38:24,762 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=84,entriesCount=1,lastEntry=(t:1, i:54)
datanode_3_1  | 2020-06-30 05:38:24,804 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=85,entriesCount=1,lastEntry=(t:1, i:55)
datanode_3_1  | 2020-06-30 05:38:24,807 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=86,entriesCount=1,lastEntry=(t:1, i:56)
datanode_3_1  | 2020-06-30 05:38:47,964 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=96,entriesCount=1,lastEntry=(t:1, i:57)
datanode_3_1  | 2020-06-30 05:38:47,976 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=97,entriesCount=1,lastEntry=(t:1, i:58)
datanode_3_1  | 2020-06-30 05:38:48,033 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=98,entriesCount=1,lastEntry=(t:1, i:59)
datanode_3_1  | 2020-06-30 05:38:48,037 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=99,entriesCount=1,lastEntry=(t:1, i:60)
datanode_3_1  | 2020-06-30 05:38:50,581 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=101,entriesCount=1,lastEntry=(t:1, i:61)
datanode_3_1  | 2020-06-30 05:38:50,590 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=102,entriesCount=1,lastEntry=(t:1, i:62)
datanode_3_1  | 2020-06-30 05:38:50,595 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=103,entriesCount=1,lastEntry=(t:1, i:63)
datanode_3_1  | 2020-06-30 05:38:50,617 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=104,entriesCount=1,lastEntry=(t:1, i:64)
datanode_3_1  | 2020-06-30 05:38:58,290 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=108,entriesCount=1,lastEntry=(t:1, i:65)
datanode_3_1  | 2020-06-30 05:38:58,300 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=109,entriesCount=1,lastEntry=(t:1, i:66)
datanode_3_1  | 2020-06-30 05:38:58,314 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=110,entriesCount=1,lastEntry=(t:1, i:67)
datanode_3_1  | 2020-06-30 05:38:58,322 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=111,entriesCount=1,lastEntry=(t:1, i:68)
datanode_3_1  | 2020-06-30 05:39:00,865 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=113,entriesCount=1,lastEntry=(t:1, i:69)
datanode_3_1  | 2020-06-30 05:39:00,871 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=114,entriesCount=1,lastEntry=(t:1, i:70)
datanode_3_1  | 2020-06-30 05:39:00,877 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=115,entriesCount=1,lastEntry=(t:1, i:71)
datanode_3_1  | 2020-06-30 05:39:00,890 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=116,entriesCount=1,lastEntry=(t:1, i:72)
datanode_3_1  | 2020-06-30 05:39:03,420 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=118,entriesCount=1,lastEntry=(t:1, i:73)
datanode_3_1  | 2020-06-30 05:39:03,427 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=119,entriesCount=1,lastEntry=(t:1, i:74)
datanode_3_1  | 2020-06-30 05:39:03,445 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=120,entriesCount=1,lastEntry=(t:1, i:75)
datanode_3_1  | 2020-06-30 05:39:03,453 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=121,entriesCount=1,lastEntry=(t:1, i:76)
datanode_3_1  | 2020-06-30 05:39:11,179 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=125,entriesCount=1,lastEntry=(t:1, i:77)
datanode_3_1  | 2020-06-30 05:39:11,188 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=126,entriesCount=1,lastEntry=(t:1, i:78)
datanode_3_1  | 2020-06-30 05:39:11,194 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=127,entriesCount=1,lastEntry=(t:1, i:79)
datanode_3_1  | 2020-06-30 05:39:11,204 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=128,entriesCount=1,lastEntry=(t:1, i:80)
datanode_3_1  | 2020-06-30 05:39:13,749 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=130,entriesCount=1,lastEntry=(t:1, i:81)
datanode_3_1  | 2020-06-30 05:39:13,759 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=131,entriesCount=1,lastEntry=(t:1, i:82)
datanode_3_1  | 2020-06-30 05:39:13,766 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=132,entriesCount=1,lastEntry=(t:1, i:83)
datanode_3_1  | 2020-06-30 05:39:13,776 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=133,entriesCount=1,lastEntry=(t:1, i:84)
datanode_3_1  | 2020-06-30 05:39:18,878 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=136,entriesCount=1,lastEntry=(t:1, i:85)
datanode_3_1  | 2020-06-30 05:39:18,890 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=137,entriesCount=1,lastEntry=(t:1, i:86)
datanode_3_1  | 2020-06-30 05:39:18,915 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=138,entriesCount=1,lastEntry=(t:1, i:87)
datanode_3_1  | 2020-06-30 05:39:18,921 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=139,entriesCount=1,lastEntry=(t:1, i:88)
datanode_3_1  | 2020-06-30 05:39:23,999 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=142,entriesCount=1,lastEntry=(t:1, i:89)
datanode_3_1  | 2020-06-30 05:39:24,012 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=143,entriesCount=1,lastEntry=(t:1, i:90)
datanode_3_1  | 2020-06-30 05:39:24,012 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=144,entriesCount=1,lastEntry=(t:1, i:91)
datanode_3_1  | 2020-06-30 05:39:24,029 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=145,entriesCount=1,lastEntry=(t:1, i:92)
datanode_3_1  | 2020-06-30 05:39:26,563 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=147,entriesCount=1,lastEntry=(t:1, i:93)
datanode_3_1  | 2020-06-30 05:39:26,567 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=148,entriesCount=1,lastEntry=(t:1, i:94)
datanode_3_1  | 2020-06-30 05:39:26,576 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=149,entriesCount=1,lastEntry=(t:1, i:95)
datanode_3_1  | 2020-06-30 05:39:26,590 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=150,entriesCount=1,lastEntry=(t:1, i:96)
datanode_3_1  | 2020-06-30 05:39:34,253 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=154,entriesCount=1,lastEntry=(t:1, i:97)
datanode_3_1  | 2020-06-30 05:39:34,265 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=155,entriesCount=1,lastEntry=(t:1, i:98)
datanode_3_1  | 2020-06-30 05:39:34,270 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=156,entriesCount=1,lastEntry=(t:1, i:99)
datanode_3_1  | 2020-06-30 05:39:34,283 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=157,entriesCount=1,lastEntry=(t:1, i:100)
datanode_3_1  | 2020-06-30 05:39:39,389 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=160,entriesCount=1,lastEntry=(t:1, i:101)
datanode_3_1  | 2020-06-30 05:39:39,396 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=161,entriesCount=1,lastEntry=(t:1, i:102)
datanode_3_1  | 2020-06-30 05:39:39,416 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=162,entriesCount=1,lastEntry=(t:1, i:103)
datanode_3_1  | 2020-06-30 05:39:39,424 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=163,entriesCount=1,lastEntry=(t:1, i:104)
datanode_3_1  | 2020-06-30 05:39:44,520 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=166,entriesCount=1,lastEntry=(t:1, i:105)
datanode_3_1  | 2020-06-30 05:39:44,529 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=167,entriesCount=1,lastEntry=(t:1, i:106)
datanode_3_1  | 2020-06-30 05:39:44,538 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=168,entriesCount=1,lastEntry=(t:1, i:107)
datanode_3_1  | 2020-06-30 05:39:44,553 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=169,entriesCount=1,lastEntry=(t:1, i:108)
datanode_3_1  | 2020-06-30 05:39:47,111 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=171,entriesCount=1,lastEntry=(t:1, i:109)
datanode_3_1  | 2020-06-30 05:39:47,124 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=172,entriesCount=1,lastEntry=(t:1, i:110)
datanode_3_1  | 2020-06-30 05:39:47,125 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=173,entriesCount=1,lastEntry=(t:1, i:111)
datanode_3_1  | 2020-06-30 05:39:47,144 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=174,entriesCount=1,lastEntry=(t:1, i:112)
datanode_3_1  | 2020-06-30 05:39:57,346 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=179,entriesCount=1,lastEntry=(t:1, i:113)
datanode_3_1  | 2020-06-30 05:39:57,354 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=180,entriesCount=1,lastEntry=(t:1, i:114)
datanode_3_1  | 2020-06-30 05:39:57,406 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=181,entriesCount=1,lastEntry=(t:1, i:115)
datanode_3_1  | 2020-06-30 05:39:57,419 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=182,entriesCount=1,lastEntry=(t:1, i:116)
datanode_3_1  | 2020-06-30 05:39:59,955 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=184,entriesCount=1,lastEntry=(t:1, i:117)
datanode_3_1  | 2020-06-30 05:39:59,961 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=185,entriesCount=1,lastEntry=(t:1, i:118)
datanode_3_1  | 2020-06-30 05:39:59,962 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=186,entriesCount=1,lastEntry=(t:1, i:119)
om_1          | 2020-06-30 05:36:16,520 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1          | 2020-06-30 05:36:16,523 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1          | 2020-06-30 05:36:16,523 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1          | 2020-06-30 05:36:16,523 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1          | 2020-06-30 05:36:16,577 [Listener at om/9862] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1          | 2020-06-30 05:36:16,583 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1          | 2020-06-30 05:36:16,584 [Listener at om/9862] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1          | 2020-06-30 05:36:16,679 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1          | 2020-06-30 05:36:16,684 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1          | 2020-06-30 05:36:16,689 [Listener at om/9862] INFO server.session: node0 Scavenging every 660000ms
om_1          | 2020-06-30 05:36:16,722 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@424a152f{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1          | 2020-06-30 05:36:16,723 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6fa7ce4{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1          | 2020-06-30 05:36:16,875 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1cee3e05{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-376776219406957362.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1          | 2020-06-30 05:36:16,895 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@633a11eb{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1          | 2020-06-30 05:36:16,895 [Listener at om/9862] INFO server.Server: Started @18964ms
om_1          | 2020-06-30 05:36:16,904 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1          | 2020-06-30 05:36:16,904 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1          | 2020-06-30 05:36:16,909 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1          | 2020-06-30 05:36:16,921 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36453773] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1          | 2020-06-30 05:36:21,696 [IPC Server handler 1 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-76623 for user:hadoop
om_1          | 2020-06-30 05:36:21,746 [IPC Server handler 3 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-38861 for user:hadoop
om_1          | 2020-06-30 05:36:21,768 [IPC Server handler 5 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-44363 for user:hadoop
om_1          | 2020-06-30 05:36:21,784 [IPC Server handler 7 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-90109 for user:hadoop
om_1          | 2020-06-30 05:36:21,790 [IPC Server handler 10 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-48883 for user:hadoop
datanode_3_1  | 2020-06-30 05:39:59,966 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=187,entriesCount=1,lastEntry=(t:1, i:120)
datanode_3_1  | 2020-06-30 05:40:02,493 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=189,entriesCount=1,lastEntry=(t:1, i:121)
datanode_3_1  | 2020-06-30 05:40:02,494 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=190,entriesCount=1,lastEntry=(t:1, i:122)
datanode_3_1  | 2020-06-30 05:40:02,510 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=191,entriesCount=1,lastEntry=(t:1, i:123)
datanode_3_1  | 2020-06-30 05:40:05,064 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=193,entriesCount=1,lastEntry=(t:1, i:124)
datanode_3_1  | 2020-06-30 05:40:05,072 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=194,entriesCount=1,lastEntry=(t:1, i:125)
datanode_3_1  | 2020-06-30 05:40:05,085 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=195,entriesCount=1,lastEntry=(t:1, i:126)
datanode_3_1  | 2020-06-30 05:40:05,086 [java.util.concurrent.ThreadPoolExecutor$Worker@17a9784a[State = -1, empty queue]] WARN server.GrpcLogAppender: c7810c94-92e8-4071-bf24-3fb5d1be0ccd@group-2E18FCD31541->7982fe8b-3966-40b2-9c7b-13327725473f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=196,entriesCount=1,lastEntry=(t:1, i:127)
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-06-30 05:35:35,023 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = 109141527b63/10.5.0.71
scm_1         | STARTUP_MSG:   args = [--init]
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/bf23dcb95194fc844485de860846edb45b7aeb63 ; compiled by 'runner' on 2020-06-30T05:10Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-06-30 05:35:35,255 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-06-30 05:35:36,273 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-06-30 05:35:36,563 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-ac953157-4f58-41d4-9a53-2cd164004bf1
scm_1         | 2020-06-30 05:35:36,658 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1         | /************************************************************
scm_1         | SHUTDOWN_MSG: Shutting down StorageContainerManager at 109141527b63/10.5.0.71
scm_1         | ************************************************************/
scm_1         | Enabled profiling in kernel
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-06-30 05:35:52,925 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = 109141527b63/10.5.0.71
scm_1         | STARTUP_MSG:   args = []
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/bf23dcb95194fc844485de860846edb45b7aeb63 ; compiled by 'runner' on 2020-06-30T05:10Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-06-30 05:35:53,016 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-06-30 05:35:53,730 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-06-30 05:35:54,472 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-06-30 05:35:54,788 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@7555b920
scm_1         | 2020-06-30 05:35:54,790 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1         | 2020-06-30 05:35:54,965 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1         | 2020-06-30 05:35:55,124 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
scm_1         | 2020-06-30 05:35:55,173 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1         | 2020-06-30 05:35:55,259 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1         | 2020-06-30 05:35:55,262 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1         | 2020-06-30 05:35:55,309 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1         | 2020-06-30 05:35:55,936 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-06-30 05:35:55,960 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1         | 2020-06-30 05:35:56,013 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-06-30 05:35:56,013 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1         | 2020-06-30 05:35:56,041 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-06-30 05:35:56,041 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1         | 2020-06-30 05:35:56,070 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1         | 2020-06-30 05:35:56,071 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1         | 2020-06-30 05:35:56,094 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @17117ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1         | 2020-06-30 05:35:56,213 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | 2020-06-30 05:35:56,235 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1         | 2020-06-30 05:35:56,243 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1         | 2020-06-30 05:35:56,245 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1         | 2020-06-30 05:35:56,245 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1         | 2020-06-30 05:35:56,245 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1         | 2020-06-30 05:35:56,282 [Listener at 0.0.0.0/9860] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
scm_1         | 2020-06-30 05:35:56,439 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1         | 2020-06-30 05:35:56,541 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1         | 2020-06-30 05:35:56,594 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1         | 2020-06-30 05:35:56,595 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1         | 2020-06-30 05:35:56,887 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1         | 2020-06-30 05:35:56,902 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-06-30 05:35:56,904 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1         | 2020-06-30 05:35:57,041 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1         | 2020-06-30 05:35:57,054 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1         | 2020-06-30 05:35:57,060 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-06-30 05:35:57,060 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1         | 2020-06-30 05:35:57,296 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1         | 2020-06-30 05:35:57,297 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1         | 2020-06-30 05:35:57,305 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-06-30 05:35:57,305 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1         | 2020-06-30 05:35:57,427 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1         | 2020-06-30 05:35:57,436 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1         | 2020-06-30 05:35:57,468 [IPC Server handler 6 on default port 9861] INFO ipc.Server: IPC Server handler 6 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.8:39522
scm_1         | 2020-06-30 05:35:57,584 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1         | 2020-06-30 05:35:57,584 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1         | 2020-06-30 05:35:57,596 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm_1         | 2020-06-30 05:35:57,650 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@15d236fd{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1         | 2020-06-30 05:35:57,653 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2aea717c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1         | 2020-06-30 05:35:57,740 [IPC Server handler 0 on default port 9861] WARN ipc.Server: IPC Server handler 0 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.5:34550: output error
scm_1         | 2020-06-30 05:35:57,744 [IPC Server handler 4 on default port 9861] WARN ipc.Server: IPC Server handler 4 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.6:45222: output error
scm_1         | 2020-06-30 05:35:57,837 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-30 05:35:57,839 [IPC Server handler 4 on default port 9861] INFO ipc.Server: IPC Server handler 4 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-30 05:35:59,432 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@15f2a43f{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-14777536711798733710.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
scm_1         | 2020-06-30 05:35:59,443 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/7982fe8b-3966-40b2-9c7b-13327725473f
scm_1         | 2020-06-30 05:35:59,443 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 7982fe8b-3966-40b2-9c7b-13327725473f{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-06-30 05:35:59,588 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 4 required.
scm_1         | 2020-06-30 05:35:59,619 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 05:35:59,767 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@22a4ca4a{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1         | 2020-06-30 05:35:59,768 [Listener at 0.0.0.0/9860] INFO server.Server: Started @20790ms
scm_1         | 2020-06-30 05:35:59,780 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1         | 2020-06-30 05:35:59,780 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1         | 2020-06-30 05:35:59,756 [IPC Server handler 99 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/c7810c94-92e8-4071-bf24-3fb5d1be0ccd
scm_1         | 2020-06-30 05:35:59,848 [IPC Server handler 99 on default port 9861] INFO node.SCMNodeManager: Registered Data node : c7810c94-92e8-4071-bf24-3fb5d1be0ccd{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-06-30 05:35:59,849 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 4 required.
scm_1         | 2020-06-30 05:35:59,849 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 05:35:59,876 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1         | 2020-06-30 05:36:00,009 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6dcf7b6a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1         | 2020-06-30 05:36:00,038 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=5d6d0aa2-df03-41f8-b757-4b0b774e891a to datanode:7982fe8b-3966-40b2-9c7b-13327725473f
scm_1         | 2020-06-30 05:36:00,253 [IPC Server handler 10 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/b33eb83e-f955-480a-aaae-270c6d5e999a
scm_1         | 2020-06-30 05:36:00,309 [IPC Server handler 10 on default port 9861] INFO node.SCMNodeManager: Registered Data node : b33eb83e-f955-480a-aaae-270c6d5e999a{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-06-30 05:36:00,313 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 4 required.
scm_1         | 2020-06-30 05:36:00,313 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 05:36:00,341 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 5d6d0aa2-df03-41f8-b757-4b0b774e891a, Nodes: 7982fe8b-3966-40b2-9c7b-13327725473f{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T05:36:00.018011Z]
scm_1         | 2020-06-30 05:36:00,481 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c981a611-0363-4e47-ae03-28251fcaa17b to datanode:b33eb83e-f955-480a-aaae-270c6d5e999a
scm_1         | 2020-06-30 05:36:00,488 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: c981a611-0363-4e47-ae03-28251fcaa17b, Nodes: b33eb83e-f955-480a-aaae-270c6d5e999a{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T05:36:00.481739Z]
scm_1         | 2020-06-30 05:36:00,529 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=54c09bb2-982d-403b-8ee3-8b8645b1098a to datanode:c7810c94-92e8-4071-bf24-3fb5d1be0ccd
scm_1         | 2020-06-30 05:36:00,530 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 54c09bb2-982d-403b-8ee3-8b8645b1098a, Nodes: c7810c94-92e8-4071-bf24-3fb5d1be0ccd{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T05:36:00.529599Z]
scm_1         | 2020-06-30 05:36:00,541 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1         | 2020-06-30 05:36:00,697 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/e0f2b5b7-e5e0-4691-810d-9d57d7b98662
scm_1         | 2020-06-30 05:36:00,698 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e0f2b5b7-e5e0-4691-810d-9d57d7b98662{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-06-30 05:36:00,698 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 4 required.
scm_1         | 2020-06-30 05:36:00,698 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 05:36:00,700 [IPC Server handler 3 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7
scm_1         | 2020-06-30 05:36:00,700 [IPC Server handler 3 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-06-30 05:36:00,711 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9e7b3f67-33a4-47d0-bd3b-05e3ba85f36b to datanode:e0f2b5b7-e5e0-4691-810d-9d57d7b98662
scm_1         | 2020-06-30 05:36:00,717 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 9e7b3f67-33a4-47d0-bd3b-05e3ba85f36b, Nodes: e0f2b5b7-e5e0-4691-810d-9d57d7b98662{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T05:36:00.711333Z]
scm_1         | 2020-06-30 05:36:00,721 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ce990fde-9ce0-4be0-83bf-4f157d79c1e5 to datanode:ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7
scm_1         | 2020-06-30 05:36:00,725 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: ce990fde-9ce0-4be0-83bf-4f157d79c1e5, Nodes: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T05:36:00.721418Z]
scm_1         | 2020-06-30 05:36:00,713 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 05:36:00,728 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 05:36:00,728 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1         | 2020-06-30 05:36:00,728 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 05:36:00,737 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 5 nodes. Healthy nodes 5
scm_1         | 2020-06-30 05:36:00,781 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7a2acb68-f280-4577-9a67-a47b89ab861d to datanode:e0f2b5b7-e5e0-4691-810d-9d57d7b98662
scm_1         | 2020-06-30 05:36:00,787 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7a2acb68-f280-4577-9a67-a47b89ab861d to datanode:ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7
scm_1         | 2020-06-30 05:36:00,787 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7a2acb68-f280-4577-9a67-a47b89ab861d to datanode:b33eb83e-f955-480a-aaae-270c6d5e999a
scm_1         | 2020-06-30 05:36:00,804 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 7a2acb68-f280-4577-9a67-a47b89ab861d, Nodes: e0f2b5b7-e5e0-4691-810d-9d57d7b98662{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}b33eb83e-f955-480a-aaae-270c6d5e999a{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T05:36:00.781399Z]
scm_1         | 2020-06-30 05:36:00,807 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 2
scm_1         | 2020-06-30 05:36:01,102 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/d92e4c01-a037-4da8-acd1-3a6f4234f2d6
scm_1         | 2020-06-30 05:36:01,154 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered Data node : d92e4c01-a037-4da8-acd1-3a6f4234f2d6{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-06-30 05:36:01,155 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 05:36:01,155 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=435cd0da-b619-4126-8475-e896e9793ca3 to datanode:d92e4c01-a037-4da8-acd1-3a6f4234f2d6
scm_1         | 2020-06-30 05:36:01,166 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 435cd0da-b619-4126-8475-e896e9793ca3, Nodes: d92e4c01-a037-4da8-acd1-3a6f4234f2d6{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T05:36:01.155005Z]
scm_1         | 2020-06-30 05:36:01,166 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-06-30 05:36:01,167 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=0f942154-9669-46a8-b1d1-2e18fcd31541 to datanode:d92e4c01-a037-4da8-acd1-3a6f4234f2d6
scm_1         | 2020-06-30 05:36:01,167 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=0f942154-9669-46a8-b1d1-2e18fcd31541 to datanode:c7810c94-92e8-4071-bf24-3fb5d1be0ccd
scm_1         | 2020-06-30 05:36:01,167 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=0f942154-9669-46a8-b1d1-2e18fcd31541 to datanode:7982fe8b-3966-40b2-9c7b-13327725473f
scm_1         | 2020-06-30 05:36:01,174 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 05:36:01,174 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 0f942154-9669-46a8-b1d1-2e18fcd31541, Nodes: d92e4c01-a037-4da8-acd1-3a6f4234f2d6{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}c7810c94-92e8-4071-bf24-3fb5d1be0ccd{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}7982fe8b-3966-40b2-9c7b-13327725473f{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T05:36:01.167104Z]
scm_1         | 2020-06-30 05:36:01,175 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-06-30 05:36:02,693 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 5d6d0aa2-df03-41f8-b757-4b0b774e891a, Nodes: 7982fe8b-3966-40b2-9c7b-13327725473f{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:7982fe8b-3966-40b2-9c7b-13327725473f, CreationTimestamp2020-06-30T05:36:00.018011Z] moved to OPEN state
scm_1         | 2020-06-30 05:36:02,725 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-30 05:36:02,745 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-30 05:36:04,107 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 54c09bb2-982d-403b-8ee3-8b8645b1098a, Nodes: c7810c94-92e8-4071-bf24-3fb5d1be0ccd{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:c7810c94-92e8-4071-bf24-3fb5d1be0ccd, CreationTimestamp2020-06-30T05:36:00.529599Z] moved to OPEN state
scm_1         | 2020-06-30 05:36:04,107 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-30 05:36:04,107 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-30 05:36:04,835 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: c981a611-0363-4e47-ae03-28251fcaa17b, Nodes: b33eb83e-f955-480a-aaae-270c6d5e999a{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:b33eb83e-f955-480a-aaae-270c6d5e999a, CreationTimestamp2020-06-30T05:36:00.481739Z] moved to OPEN state
scm_1         | 2020-06-30 05:36:04,835 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-30 05:36:04,835 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-30 05:36:05,382 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: ce990fde-9ce0-4be0-83bf-4f157d79c1e5, Nodes: ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7, CreationTimestamp2020-06-30T05:36:00.721418Z] moved to OPEN state
scm_1         | 2020-06-30 05:36:05,382 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-30 05:36:05,382 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-30 05:36:05,838 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 9e7b3f67-33a4-47d0-bd3b-05e3ba85f36b, Nodes: e0f2b5b7-e5e0-4691-810d-9d57d7b98662{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:e0f2b5b7-e5e0-4691-810d-9d57d7b98662, CreationTimestamp2020-06-30T05:36:00.711333Z] moved to OPEN state
scm_1         | 2020-06-30 05:36:05,838 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-30 05:36:05,838 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-30 05:36:05,948 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 435cd0da-b619-4126-8475-e896e9793ca3, Nodes: d92e4c01-a037-4da8-acd1-3a6f4234f2d6{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:d92e4c01-a037-4da8-acd1-3a6f4234f2d6, CreationTimestamp2020-06-30T05:36:01.155005Z] moved to OPEN state
scm_1         | 2020-06-30 05:36:05,949 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-30 05:36:05,949 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-30 05:36:10,726 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 0f942154-9669-46a8-b1d1-2e18fcd31541, Nodes: d92e4c01-a037-4da8-acd1-3a6f4234f2d6{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}c7810c94-92e8-4071-bf24-3fb5d1be0ccd{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}7982fe8b-3966-40b2-9c7b-13327725473f{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:c7810c94-92e8-4071-bf24-3fb5d1be0ccd, CreationTimestamp2020-06-30T05:36:01.167104Z] moved to OPEN state
scm_1         | 2020-06-30 05:36:10,746 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-30 05:36:10,747 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1         | 2020-06-30 05:36:10,755 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 05:36:10,755 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1         | 2020-06-30 05:36:10,755 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1         | 2020-06-30 05:36:11,339 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 7a2acb68-f280-4577-9a67-a47b89ab861d, Nodes: e0f2b5b7-e5e0-4691-810d-9d57d7b98662{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}ce3fc5ad-f2d7-4499-8d70-0b8f12e3e5c7{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}b33eb83e-f955-480a-aaae-270c6d5e999a{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:b33eb83e-f955-480a-aaae-270c6d5e999a, CreationTimestamp2020-06-30T05:36:00.781399Z] moved to OPEN state
scm_1         | 2020-06-30 05:36:28,842 [IPC Server handler 26 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:36:32,951 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:36:35,529 [IPC Server handler 26 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:36:38,192 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:36:40,784 [IPC Server handler 45 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:36:43,368 [IPC Server handler 98 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:36:45,939 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:36:48,521 [IPC Server handler 26 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:36:51,105 [IPC Server handler 70 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:36:53,695 [IPC Server handler 45 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:36:56,270 [IPC Server handler 86 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:36:58,870 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:01,445 [IPC Server handler 0 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:04,018 [IPC Server handler 70 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:06,633 [IPC Server handler 45 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:09,212 [IPC Server handler 86 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:11,784 [IPC Server handler 20 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:14,391 [IPC Server handler 0 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:16,979 [IPC Server handler 74 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:19,558 [IPC Server handler 45 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:22,133 [IPC Server handler 86 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:24,740 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:27,323 [IPC Server handler 43 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:29,927 [IPC Server handler 70 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:32,498 [IPC Server handler 45 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:35,064 [IPC Server handler 86 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:37,635 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:40,226 [IPC Server handler 93 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:42,788 [IPC Server handler 70 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:45,353 [IPC Server handler 62 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:47,923 [IPC Server handler 53 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:50,554 [IPC Server handler 20 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:53,137 [IPC Server handler 40 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:55,315 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-06-30 05:37:55,315 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-06-30 05:37:55,705 [IPC Server handler 74 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:37:58,279 [IPC Server handler 54 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:00,849 [IPC Server handler 53 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:03,416 [IPC Server handler 45 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:05,978 [IPC Server handler 93 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:08,612 [IPC Server handler 74 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:11,165 [IPC Server handler 54 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:13,730 [IPC Server handler 53 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:16,306 [IPC Server handler 60 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:18,871 [IPC Server handler 40 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:21,437 [IPC Server handler 20 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:23,979 [IPC Server handler 38 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:26,550 [IPC Server handler 74 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:29,110 [IPC Server handler 60 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:31,663 [IPC Server handler 53 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:34,233 [IPC Server handler 44 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:36,814 [IPC Server handler 40 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:39,401 [IPC Server handler 98 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:41,951 [IPC Server handler 54 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:44,509 [IPC Server handler 74 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:47,081 [IPC Server handler 60 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:49,681 [IPC Server handler 93 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:52,212 [IPC Server handler 44 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:54,750 [IPC Server handler 38 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:57,315 [IPC Server handler 66 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:38:59,947 [IPC Server handler 25 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:39:02,481 [IPC Server handler 74 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:39:05,033 [IPC Server handler 49 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:39:07,625 [IPC Server handler 86 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:39:10,296 [IPC Server handler 66 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:39:20,405 [IPC Server handler 0 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:39:25,460 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:39:35,573 [IPC Server handler 86 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:39:50,650 [IPC Server handler 93 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:39:55,316 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-06-30 05:39:55,317 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-06-30 05:40:05,743 [IPC Server handler 38 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:40:10,810 [IPC Server handler 25 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:40:20,842 [IPC Server handler 60 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:40:35,938 [IPC Server handler 61 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:40:51,036 [IPC Server handler 56 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:41:06,157 [IPC Server handler 84 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 05:41:10,795 [EventQueue-Delayed safe mode statusForReplicationManager] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1         | 2020-06-30 05:41:10,814 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #5
scm_1         | 2020-06-30 05:41:10,819 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #6
scm_1         | 2020-06-30 05:41:10,816 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 19 milliseconds for processing 9 containers.
scm_1         | 2020-06-30 05:41:10,830 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #7
scm_1         | 2020-06-30 05:41:10,832 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #8
scm_1         | 2020-06-30 05:41:10,832 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #9
scm_1         | 2020-06-30 05:41:10,833 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1
scm_1         | 2020-06-30 05:41:10,834 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2
scm_1         | 2020-06-30 05:41:10,835 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #3
scm_1         | 2020-06-30 05:41:10,835 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #4
scm_1         | 2020-06-30 05:41:21,330 [IPC Server handler 80 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
