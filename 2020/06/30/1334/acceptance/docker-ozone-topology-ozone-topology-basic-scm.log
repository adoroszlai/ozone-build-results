Attaching to ozone-topology_datanode_3_1, ozone-topology_datanode_4_1, ozone-topology_datanode_2_1, ozone-topology_om_1, ozone-topology_scm_1, ozone-topology_datanode_5_1, ozone-topology_datanode_6_1, ozone-topology_datanode_1_1
datanode_2_1  | Enabled profiling in kernel
datanode_2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2_1  | 2020-06-30 12:25:37,209 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2_1  | /************************************************************
datanode_2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2_1  | STARTUP_MSG:   host = 5a0ef71b81e1/10.5.0.5
datanode_2_1  | STARTUP_MSG:   args = []
datanode_2_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2fb4a402fb97acb0b0294bc7a2ae17c6f5397edd ; compiled by 'runner' on 2020-06-30T11:59Z
datanode_2_1  | STARTUP_MSG:   java = 11.0.6
datanode_2_1  | ************************************************************/
datanode_2_1  | 2020-06-30 12:25:37,238 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2_1  | 2020-06-30 12:25:39,490 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2_1  | 2020-06-30 12:25:41,240 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2_1  | 2020-06-30 12:25:42,715 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2_1  | 2020-06-30 12:25:42,715 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2_1  | 2020-06-30 12:25:43,533 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:5a0ef71b81e1 ip:10.5.0.5
datanode_2_1  | 2020-06-30 12:25:44,485 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2_1  | 2020-06-30 12:25:44,571 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2_1  | 2020-06-30 12:25:44,592 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2_1  | 2020-06-30 12:25:44,685 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2_1  | 2020-06-30 12:25:45,142 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2_1  | 2020-06-30 12:25:53,839 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2_1  | 2020-06-30 12:25:54,365 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2_1  | 2020-06-30 12:25:55,659 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2_1  | 2020-06-30 12:25:55,680 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2_1  | 2020-06-30 12:25:55,680 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-30 12:25:55,718 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2_1  | 2020-06-30 12:25:55,723 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-06-30 12:25:57,888 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-06-30 12:25:59,601 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2_1  | 2020-06-30 12:25:59,752 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2_1  | 2020-06-30 12:25:59,948 [main] INFO util.log: Logging initialized @30333ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2_1  | 2020-06-30 12:26:00,674 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2_1  | 2020-06-30 12:26:00,715 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2_1  | 2020-06-30 12:26:00,766 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2_1  | 2020-06-30 12:26:00,793 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2_1  | 2020-06-30 12:26:00,800 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2_1  | 2020-06-30 12:26:00,805 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2_1  | 2020-06-30 12:26:01,083 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2_1  | 2020-06-30 12:26:01,139 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2_1  | 2020-06-30 12:26:01,146 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2_1  | 2020-06-30 12:26:01,536 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2_1  | 2020-06-30 12:26:01,536 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2_1  | 2020-06-30 12:26:01,538 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2_1  | 2020-06-30 12:26:01,635 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@74eec640{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2_1  | 2020-06-30 12:26:01,636 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2e7bb00e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2_1  | 2020-06-30 12:26:02,153 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5cbe95b1{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-13252219019540513363.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2_1  | 2020-06-30 12:26:02,276 [main] INFO server.AbstractConnector: Started ServerConnector@38a96593{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2_1  | 2020-06-30 12:26:02,947 [main] INFO server.Server: Started @33332ms
datanode_2_1  | 2020-06-30 12:26:04,023 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2_1  | 2020-06-30 12:26:04,023 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2_1  | 2020-06-30 12:26:04,027 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2_1  | 2020-06-30 12:26:04,498 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6dd4173d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2_1  | 2020-06-30 12:26:05,184 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2_1  | 2020-06-30 12:26:07,727 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-06-30 12:26:08,728 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-06-30 12:26:09,728 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-06-30 12:26:10,764 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2_1  | java.net.SocketTimeoutException: Call From 5a0ef71b81e1/10.5.0.5 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:56636 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_2_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:56636 remote=scm/10.5.0.71:9861]
datanode_2_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_2_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_2_1  | 2020-06-30 12:26:11,323 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2_1  | 2020-06-30 12:26:11,334 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2_1  | 2020-06-30 12:26:11,339 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis c7c89d62-1bd1-4840-8dc0-c863fd86ce3b at port 9858
datanode_2_1  | 2020-06-30 12:26:11,457 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b: start RPC server
datanode_2_1  | 2020-06-30 12:26:11,989 [Datanode State Machine Thread - 1] INFO server.GrpcService: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2_1  | 2020-06-30 12:26:20,986 [grpc-default-executor-0] INFO impl.RaftServerProxy: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b: addNew group-417987BD28FF:[e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858] returns group-417987BD28FF:java.util.concurrent.CompletableFuture@9ba58a2[Not completed]
datanode_2_1  | 2020-06-30 12:26:21,168 [pool-19-thread-1] INFO impl.RaftServerImpl: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b: new RaftServerImpl for group-417987BD28FF:[e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-06-30 12:26:21,210 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-06-30 12:26:21,219 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-06-30 12:26:21,223 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-06-30 12:26:21,224 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-06-30 12:26:21,232 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-06-30 12:26:21,278 [pool-19-thread-1] INFO impl.RaftServerImpl: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF: ConfigurationManager, init=-1: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-06-30 12:26:21,285 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-06-30 12:26:21,351 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-06-30 12:26:21,352 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/8f9e6e0b-51d1-41f9-968d-417987bd28ff does not exist. Creating ...
datanode_2_1  | 2020-06-30 12:26:21,420 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/8f9e6e0b-51d1-41f9-968d-417987bd28ff/in_use.lock acquired by nodename 6@5a0ef71b81e1
datanode_2_1  | 2020-06-30 12:26:21,439 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/8f9e6e0b-51d1-41f9-968d-417987bd28ff has been successfully formatted.
datanode_2_1  | 2020-06-30 12:26:21,495 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-417987BD28FF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-06-30 12:26:21,531 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-06-30 12:26:21,534 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-06-30 12:26:21,558 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-06-30 12:26:21,575 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | Enabled profiling in kernel
datanode_1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1_1  | 2020-06-30 12:25:36,108 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1_1  | /************************************************************
datanode_1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1_1  | STARTUP_MSG:   host = d130c5830294/10.5.0.4
datanode_1_1  | STARTUP_MSG:   args = []
datanode_1_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2fb4a402fb97acb0b0294bc7a2ae17c6f5397edd ; compiled by 'runner' on 2020-06-30T11:59Z
datanode_1_1  | STARTUP_MSG:   java = 11.0.6
datanode_1_1  | ************************************************************/
datanode_1_1  | 2020-06-30 12:25:36,195 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1_1  | 2020-06-30 12:25:37,984 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1_1  | 2020-06-30 12:25:39,032 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1_1  | 2020-06-30 12:25:41,631 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1_1  | 2020-06-30 12:25:41,652 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1_1  | 2020-06-30 12:25:42,218 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:d130c5830294 ip:10.5.0.4
datanode_1_1  | 2020-06-30 12:25:43,131 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1_1  | 2020-06-30 12:25:43,149 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1_1  | 2020-06-30 12:25:43,155 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1_1  | 2020-06-30 12:25:43,222 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1_1  | 2020-06-30 12:25:43,606 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1_1  | 2020-06-30 12:25:52,076 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1_1  | 2020-06-30 12:25:52,470 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1_1  | 2020-06-30 12:25:53,389 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1_1  | 2020-06-30 12:25:53,431 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1_1  | 2020-06-30 12:25:53,443 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-06-30 12:25:53,507 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1_1  | 2020-06-30 12:25:53,515 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-06-30 12:25:55,165 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-06-30 12:25:56,845 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1_1  | 2020-06-30 12:25:57,078 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1_1  | 2020-06-30 12:25:57,298 [main] INFO util.log: Logging initialized @28135ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1_1  | 2020-06-30 12:25:58,167 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1_1  | 2020-06-30 12:25:58,196 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1_1  | 2020-06-30 12:25:58,227 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1_1  | 2020-06-30 12:25:58,259 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1_1  | 2020-06-30 12:25:58,259 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1_1  | 2020-06-30 12:25:58,260 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1_1  | 2020-06-30 12:25:58,579 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1_1  | 2020-06-30 12:25:58,703 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1_1  | 2020-06-30 12:25:58,714 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1_1  | 2020-06-30 12:25:59,006 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1_1  | 2020-06-30 12:25:59,006 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1_1  | 2020-06-30 12:25:59,014 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_1_1  | 2020-06-30 12:25:59,080 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b4954b2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1_1  | 2020-06-30 12:25:59,080 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57416e49{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1_1  | 2020-06-30 12:25:59,533 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c27f72{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-3112687164720558980.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1_1  | 2020-06-30 12:25:59,628 [main] INFO server.AbstractConnector: Started ServerConnector@25cde5bb{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1_1  | 2020-06-30 12:25:59,628 [main] INFO server.Server: Started @30481ms
datanode_1_1  | 2020-06-30 12:25:59,646 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1_1  | 2020-06-30 12:25:59,648 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1_1  | 2020-06-30 12:25:59,719 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1_1  | 2020-06-30 12:25:59,955 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@736bb7ec] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1_1  | 2020-06-30 12:26:01,357 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1_1  | 2020-06-30 12:26:05,171 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-06-30 12:26:06,172 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-06-30 12:26:07,173 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-06-30 12:26:08,173 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-06-30 12:26:09,174 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-06-30 12:26:10,191 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_1_1  | java.net.SocketTimeoutException: Call From d130c5830294/10.5.0.4 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.4:43830 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_1_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_1_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.4:43830 remote=scm/10.5.0.71:9861]
datanode_1_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_1_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_1_1  | 2020-06-30 12:26:11,323 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1_1  | 2020-06-30 12:26:11,325 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1_1  | 2020-06-30 12:26:11,339 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 5d636ad6-6c45-4d25-921b-ebdea2d03333 at port 9858
datanode_1_1  | 2020-06-30 12:26:11,455 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 5d636ad6-6c45-4d25-921b-ebdea2d03333: start RPC server
datanode_1_1  | 2020-06-30 12:26:12,049 [Datanode State Machine Thread - 1] INFO server.GrpcService: 5d636ad6-6c45-4d25-921b-ebdea2d03333: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1_1  | 2020-06-30 12:26:15,278 [Datanode State Machine Thread - 1] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_1_1  | java.net.SocketTimeoutException: Call From d130c5830294/10.5.0.4 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.4:43846 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_1_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_1_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:148)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:145)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:76)
datanode_1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | 2020-06-30 12:26:21,587 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-30 12:26:21,642 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF
datanode_2_1  | 2020-06-30 12:26:21,778 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-06-30 12:26:21,814 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/8f9e6e0b-51d1-41f9-968d-417987bd28ff
datanode_2_1  | 2020-06-30 12:26:21,834 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-06-30 12:26:21,845 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-06-30 12:26:21,846 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-30 12:26:21,862 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-06-30 12:26:21,875 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-06-30 12:26:21,876 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-06-30 12:26:21,879 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-06-30 12:26:21,883 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-06-30 12:26:21,883 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-06-30 12:26:22,030 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-06-30 12:26:22,177 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-30 12:26:22,215 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-30 12:26:22,238 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-06-30 12:26:22,258 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-06-30 12:26:22,263 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-06-30 12:26:22,272 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-06-30 12:26:22,275 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-06-30 12:26:22,522 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF
datanode_2_1  | 2020-06-30 12:26:22,536 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF
datanode_2_1  | 2020-06-30 12:26:22,570 [pool-19-thread-1] INFO impl.RaftServerImpl: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF: start as a follower, conf=-1: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null
datanode_2_1  | 2020-06-30 12:26:22,574 [pool-19-thread-1] INFO impl.RaftServerImpl: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-06-30 12:26:22,583 [pool-19-thread-1] INFO impl.RoleInfo: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b: start FollowerState
datanode_2_1  | 2020-06-30 12:26:22,610 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-417987BD28FF,id=c7c89d62-1bd1-4840-8dc0-c863fd86ce3b
datanode_2_1  | 2020-06-30 12:26:22,614 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF
datanode_2_1  | 2020-06-30 12:26:23,848 [grpc-default-executor-0] INFO impl.RaftServerImpl: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f
datanode_2_1  | 2020-06-30 12:26:23,848 [grpc-default-executor-0] INFO impl.RoleInfo: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b: shutdown FollowerState
datanode_2_1  | 2020-06-30 12:26:23,848 [Thread-24] INFO impl.FollowerState: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2_1  | 2020-06-30 12:26:23,849 [grpc-default-executor-0] INFO impl.RoleInfo: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b: start FollowerState
datanode_2_1  | 2020-06-30 12:26:24,711 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-417987BD28FF with new leaderId: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f
datanode_2_1  | 2020-06-30 12:26:24,825 [grpc-default-executor-0] INFO impl.RaftServerImpl: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF: change Leader from null to e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f at term 1 for appendEntries, leader elected after 3180ms
datanode_2_1  | 2020-06-30 12:26:26,212 [grpc-default-executor-0] INFO impl.RaftServerImpl: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF: set configuration 0: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-06-30 12:26:26,224 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-06-30 12:26:26,482 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-417987BD28FF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8f9e6e0b-51d1-41f9-968d-417987bd28ff/current/log_inprogress_0
datanode_2_1  | 2020-06-30 12:26:45,583 [Command processor thread] INFO impl.RaftServerProxy: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b: addNew group-FE97191506E8:[c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858] returns group-FE97191506E8:java.util.concurrent.CompletableFuture@15267d2[Not completed]
datanode_2_1  | 2020-06-30 12:26:45,585 [pool-19-thread-1] INFO impl.RaftServerImpl: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b: new RaftServerImpl for group-FE97191506E8:[c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-06-30 12:26:45,586 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-06-30 12:26:45,586 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-06-30 12:26:45,586 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-06-30 12:26:45,586 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-06-30 12:26:45,586 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.4:43846 remote=scm/10.5.0.71:9861]
datanode_1_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_1_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_1_1  | 2020-06-30 12:26:20,204 [grpc-default-executor-0] INFO impl.RaftServerProxy: 5d636ad6-6c45-4d25-921b-ebdea2d03333: addNew group-A2D077235929:[af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858] returns group-A2D077235929:java.util.concurrent.CompletableFuture@21a83cd6[Not completed]
datanode_1_1  | 2020-06-30 12:26:20,342 [pool-19-thread-1] INFO impl.RaftServerImpl: 5d636ad6-6c45-4d25-921b-ebdea2d03333: new RaftServerImpl for group-A2D077235929:[af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-06-30 12:26:20,360 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-06-30 12:26:20,363 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-06-30 12:26:20,364 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-06-30 12:26:20,375 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-06-30 12:26:20,378 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-06-30 12:26:20,409 [pool-19-thread-1] INFO impl.RaftServerImpl: 5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929: ConfigurationManager, init=-1: [af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-06-30 12:26:20,417 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-06-30 12:26:20,432 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-06-30 12:26:20,438 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/997168be-72df-4784-bd0d-a2d077235929 does not exist. Creating ...
datanode_1_1  | 2020-06-30 12:26:20,466 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/997168be-72df-4784-bd0d-a2d077235929/in_use.lock acquired by nodename 6@d130c5830294
datanode_1_1  | 2020-06-30 12:26:20,481 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/997168be-72df-4784-bd0d-a2d077235929 has been successfully formatted.
datanode_1_1  | 2020-06-30 12:26:20,602 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-A2D077235929: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-06-30 12:26:20,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-06-30 12:26:20,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-06-30 12:26:20,641 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-06-30 12:26:20,656 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-06-30 12:26:20,684 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-06-30 12:26:20,703 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929
datanode_1_1  | 2020-06-30 12:26:20,795 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-06-30 12:26:20,871 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/997168be-72df-4784-bd0d-a2d077235929
datanode_1_1  | 2020-06-30 12:26:20,875 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-06-30 12:26:20,875 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-06-30 12:26:20,877 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-06-30 12:26:20,895 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-06-30 12:26:20,896 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-06-30 12:26:20,897 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-06-30 12:26:20,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-06-30 12:26:20,925 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-06-30 12:26:20,926 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-06-30 12:26:21,025 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-06-30 12:26:21,105 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-06-30 12:26:21,114 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-06-30 12:26:21,123 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-06-30 12:26:21,132 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-06-30 12:26:21,133 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-06-30 12:26:21,134 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-06-30 12:26:21,134 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-06-30 12:26:21,335 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929
datanode_1_1  | 2020-06-30 12:26:21,350 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929
datanode_1_1  | 2020-06-30 12:26:21,373 [pool-19-thread-1] INFO impl.RaftServerImpl: 5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929: start as a follower, conf=-1: [af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858], old=null
datanode_1_1  | 2020-06-30 12:26:21,388 [pool-19-thread-1] INFO impl.RaftServerImpl: 5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-06-30 12:26:21,414 [pool-19-thread-1] INFO impl.RoleInfo: 5d636ad6-6c45-4d25-921b-ebdea2d03333: start FollowerState
datanode_1_1  | 2020-06-30 12:26:21,475 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A2D077235929,id=5d636ad6-6c45-4d25-921b-ebdea2d03333
datanode_1_1  | 2020-06-30 12:26:21,496 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929
datanode_1_1  | 2020-06-30 12:26:22,694 [grpc-default-executor-1] INFO impl.RaftServerImpl: 5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:af137417-7801-4a96-9b21-1b6e75d3578d
datanode_1_1  | 2020-06-30 12:26:22,710 [grpc-default-executor-1] INFO impl.RoleInfo: 5d636ad6-6c45-4d25-921b-ebdea2d03333: shutdown FollowerState
datanode_1_1  | 2020-06-30 12:26:22,714 [Thread-24] INFO impl.FollowerState: 5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1_1  | 2020-06-30 12:26:22,714 [grpc-default-executor-1] INFO impl.RoleInfo: 5d636ad6-6c45-4d25-921b-ebdea2d03333: start FollowerState
datanode_1_1  | 2020-06-30 12:26:23,168 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A2D077235929 with new leaderId: af137417-7801-4a96-9b21-1b6e75d3578d
datanode_1_1  | 2020-06-30 12:26:23,174 [grpc-default-executor-1] INFO impl.RaftServerImpl: 5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929: change Leader from null to af137417-7801-4a96-9b21-1b6e75d3578d at term 1 for appendEntries, leader elected after 2564ms
datanode_1_1  | 2020-06-30 12:26:23,342 [grpc-default-executor-1] INFO impl.RaftServerImpl: 5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929: set configuration 0: [af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858], old=null at 0
datanode_1_1  | 2020-06-30 12:26:23,391 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-06-30 12:26:23,914 [5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 5d636ad6-6c45-4d25-921b-ebdea2d03333@group-A2D077235929-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/997168be-72df-4784-bd0d-a2d077235929/current/log_inprogress_0
datanode_2_1  | 2020-06-30 12:26:45,587 [pool-19-thread-1] INFO impl.RaftServerImpl: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8: ConfigurationManager, init=-1: [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-06-30 12:26:45,587 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-06-30 12:26:45,587 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-06-30 12:26:45,588 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/59d287fa-f96a-4cf2-b879-fe97191506e8 does not exist. Creating ...
datanode_2_1  | 2020-06-30 12:26:45,590 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/59d287fa-f96a-4cf2-b879-fe97191506e8/in_use.lock acquired by nodename 6@5a0ef71b81e1
datanode_2_1  | 2020-06-30 12:26:45,591 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/59d287fa-f96a-4cf2-b879-fe97191506e8 has been successfully formatted.
datanode_2_1  | 2020-06-30 12:26:45,592 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-FE97191506E8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-06-30 12:26:45,592 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-06-30 12:26:45,597 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-06-30 12:26:45,597 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-06-30 12:26:45,597 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-30 12:26:45,597 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-30 12:26:45,598 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8
datanode_2_1  | 2020-06-30 12:26:45,598 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-06-30 12:26:45,598 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/59d287fa-f96a-4cf2-b879-fe97191506e8
datanode_2_1  | 2020-06-30 12:26:45,598 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-06-30 12:26:45,599 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-06-30 12:26:45,599 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-30 12:26:45,599 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-06-30 12:26:45,599 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-06-30 12:26:45,599 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-06-30 12:26:45,600 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-06-30 12:26:45,600 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-06-30 12:26:45,601 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-06-30 12:26:45,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-06-30 12:26:45,605 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-30 12:26:45,606 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-30 12:26:45,612 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-06-30 12:26:45,612 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-06-30 12:26:45,612 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-06-30 12:26:45,613 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-06-30 12:26:45,613 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-06-30 12:26:45,613 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8
datanode_2_1  | 2020-06-30 12:26:45,614 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8
datanode_2_1  | 2020-06-30 12:26:45,615 [pool-19-thread-1] INFO impl.RaftServerImpl: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8: start as a follower, conf=-1: [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null
datanode_2_1  | 2020-06-30 12:26:45,616 [pool-19-thread-1] INFO impl.RaftServerImpl: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-06-30 12:26:45,616 [pool-19-thread-1] INFO impl.RoleInfo: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b: start FollowerState
datanode_2_1  | 2020-06-30 12:26:45,616 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FE97191506E8,id=c7c89d62-1bd1-4840-8dc0-c863fd86ce3b
datanode_2_1  | 2020-06-30 12:26:45,617 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8
datanode_2_1  | 2020-06-30 12:26:45,620 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "59d287fa-f96a-4cf2-b879-fe97191506e8"
datanode_2_1  | .
datanode_2_1  | 2020-06-30 12:26:50,925 [Thread-46] INFO impl.FollowerState: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-FollowerState: change to CANDIDATE, lastRpcTime:5308ms, electionTimeout:5134ms
datanode_2_1  | 2020-06-30 12:26:50,928 [Thread-46] INFO impl.RoleInfo: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b: shutdown FollowerState
datanode_2_1  | 2020-06-30 12:26:50,929 [Thread-46] INFO impl.RaftServerImpl: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2_1  | 2020-06-30 12:26:50,932 [Thread-46] INFO impl.RoleInfo: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b: start LeaderElection
datanode_2_1  | 2020-06-30 12:26:50,939 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO impl.LeaderElection: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1: begin an election at term 1 for -1: [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null
datanode_2_1  | 2020-06-30 12:26:50,940 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO impl.RoleInfo: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b: shutdown LeaderElection
datanode_3_1  | Enabled profiling in kernel
datanode_3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3_1  | 2020-06-30 12:25:42,156 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3_1  | /************************************************************
datanode_3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3_1  | STARTUP_MSG:   host = 73407aaf1fd9/10.5.0.6
datanode_3_1  | STARTUP_MSG:   args = []
datanode_3_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2_1  | 2020-06-30 12:26:50,940 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO impl.RaftServerImpl: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2_1  | 2020-06-30 12:26:50,940 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-FE97191506E8 with new leaderId: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b
datanode_2_1  | 2020-06-30 12:26:50,941 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO impl.RaftServerImpl: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8: change Leader from null to c7c89d62-1bd1-4840-8dc0-c863fd86ce3b at term 1 for becomeLeader, leader elected after 5348ms
datanode_2_1  | 2020-06-30 12:26:50,950 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2_1  | 2020-06-30 12:26:50,951 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2_1  | 2020-06-30 12:26:50,954 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8
datanode_2_1  | 2020-06-30 12:26:50,956 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2_1  | 2020-06-30 12:26:50,956 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2_1  | 2020-06-30 12:26:50,962 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2_1  | 2020-06-30 12:26:50,962 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2_1  | 2020-06-30 12:26:50,965 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2_1  | 2020-06-30 12:26:50,971 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO impl.RoleInfo: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b: start LeaderState
datanode_2_1  | 2020-06-30 12:26:50,974 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-06-30 12:26:50,976 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-LeaderElection1] INFO impl.RaftServerImpl: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8: set configuration 0: [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-06-30 12:26:50,976 [c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b@group-FE97191506E8-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/59d287fa-f96a-4cf2-b879-fe97191506e8/current/log_inprogress_0
datanode_3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2fb4a402fb97acb0b0294bc7a2ae17c6f5397edd ; compiled by 'runner' on 2020-06-30T11:59Z
datanode_3_1  | STARTUP_MSG:   java = 11.0.6
datanode_3_1  | ************************************************************/
datanode_3_1  | 2020-06-30 12:25:42,247 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3_1  | 2020-06-30 12:25:44,296 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3_1  | 2020-06-30 12:25:45,354 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3_1  | 2020-06-30 12:25:46,783 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3_1  | 2020-06-30 12:25:46,791 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3_1  | 2020-06-30 12:25:47,644 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:73407aaf1fd9 ip:10.5.0.6
datanode_3_1  | 2020-06-30 12:25:48,553 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3_1  | 2020-06-30 12:25:48,587 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3_1  | 2020-06-30 12:25:48,606 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3_1  | 2020-06-30 12:25:48,778 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3_1  | 2020-06-30 12:25:49,201 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3_1  | 2020-06-30 12:25:57,473 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3_1  | 2020-06-30 12:25:57,869 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3_1  | 2020-06-30 12:25:59,118 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3_1  | 2020-06-30 12:25:59,124 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3_1  | 2020-06-30 12:25:59,124 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-30 12:25:59,125 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3_1  | 2020-06-30 12:25:59,136 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-06-30 12:26:00,479 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-06-30 12:26:02,220 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3_1  | 2020-06-30 12:26:02,869 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3_1  | 2020-06-30 12:26:03,799 [main] INFO util.log: Logging initialized @30910ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3_1  | 2020-06-30 12:26:04,361 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3_1  | 2020-06-30 12:26:04,371 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3_1  | 2020-06-30 12:26:04,463 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3_1  | 2020-06-30 12:26:04,491 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3_1  | 2020-06-30 12:26:04,491 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3_1  | 2020-06-30 12:26:04,491 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3_1  | 2020-06-30 12:26:04,660 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_3_1  | 2020-06-30 12:26:04,721 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3_1  | 2020-06-30 12:26:04,726 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3_1  | 2020-06-30 12:26:04,876 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3_1  | 2020-06-30 12:26:04,883 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3_1  | 2020-06-30 12:26:04,885 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_3_1  | 2020-06-30 12:26:05,059 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b4954b2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3_1  | 2020-06-30 12:26:05,061 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57416e49{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3_1  | 2020-06-30 12:26:05,340 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c27f72{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-7352553790639374051.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3_1  | 2020-06-30 12:26:05,376 [main] INFO server.AbstractConnector: Started ServerConnector@25cde5bb{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3_1  | 2020-06-30 12:26:05,378 [main] INFO server.Server: Started @32488ms
datanode_3_1  | 2020-06-30 12:26:05,383 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3_1  | 2020-06-30 12:26:05,383 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3_1  | 2020-06-30 12:26:05,391 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3_1  | 2020-06-30 12:26:05,447 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@411f68b4] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3_1  | 2020-06-30 12:26:05,979 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3_1  | 2020-06-30 12:26:08,715 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-06-30 12:26:09,716 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-06-30 12:26:10,749 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_3_1  | java.net.SocketTimeoutException: Call From 73407aaf1fd9/10.5.0.6 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:45134 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_3_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:45134 remote=scm/10.5.0.71:9861]
datanode_3_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_3_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_4_1  | Enabled profiling in kernel
datanode_4_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_4_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_4_1  | 2020-06-30 12:25:36,333 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_4_1  | /************************************************************
datanode_4_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_4_1  | STARTUP_MSG:   host = 449b60852d9a/10.5.0.7
datanode_4_1  | STARTUP_MSG:   args = []
datanode_4_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_4_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_4_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2fb4a402fb97acb0b0294bc7a2ae17c6f5397edd ; compiled by 'runner' on 2020-06-30T11:59Z
datanode_4_1  | STARTUP_MSG:   java = 11.0.6
datanode_4_1  | ************************************************************/
datanode_4_1  | 2020-06-30 12:25:36,407 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_4_1  | 2020-06-30 12:25:38,370 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_4_1  | 2020-06-30 12:25:40,885 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_4_1  | 2020-06-30 12:25:42,455 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_4_1  | 2020-06-30 12:25:42,455 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_4_1  | 2020-06-30 12:25:43,172 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:449b60852d9a ip:10.5.0.7
datanode_4_1  | 2020-06-30 12:25:44,304 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_4_1  | 2020-06-30 12:25:44,355 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_4_1  | 2020-06-30 12:25:44,358 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_4_1  | 2020-06-30 12:25:44,444 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_4_1  | 2020-06-30 12:25:44,903 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_4_1  | 2020-06-30 12:25:53,721 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4_1  | 2020-06-30 12:25:54,094 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_4_1  | 2020-06-30 12:25:55,304 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_4_1  | 2020-06-30 12:25:55,324 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_4_1  | 2020-06-30 12:25:55,325 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-06-30 12:25:55,325 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_4_1  | 2020-06-30 12:25:55,342 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 2020-06-30 12:25:57,708 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-06-30 12:25:59,404 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_4_1  | 2020-06-30 12:25:59,576 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_4_1  | 2020-06-30 12:25:59,781 [main] INFO util.log: Logging initialized @30506ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_4_1  | 2020-06-30 12:26:00,474 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_4_1  | 2020-06-30 12:26:00,516 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_4_1  | 2020-06-30 12:26:00,573 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_4_1  | 2020-06-30 12:26:00,597 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_4_1  | 2020-06-30 12:26:00,609 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_4_1  | 2020-06-30 12:26:00,609 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_4_1  | 2020-06-30 12:26:00,871 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_4_1  | 2020-06-30 12:26:00,934 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_4_1  | 2020-06-30 12:26:00,959 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_4_1  | 2020-06-30 12:26:01,207 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_4_1  | 2020-06-30 12:26:01,209 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_4_1  | 2020-06-30 12:26:01,239 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_4_1  | 2020-06-30 12:26:01,385 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b4954b2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_4_1  | 2020-06-30 12:26:01,402 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57416e49{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_4_1  | 2020-06-30 12:26:01,918 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c27f72{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-4732001134645880714.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_4_1  | 2020-06-30 12:26:01,982 [main] INFO server.AbstractConnector: Started ServerConnector@25cde5bb{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_4_1  | 2020-06-30 12:26:01,987 [main] INFO server.Server: Started @32712ms
datanode_4_1  | 2020-06-30 12:26:02,001 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_4_1  | 2020-06-30 12:26:02,001 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_4_1  | 2020-06-30 12:26:02,005 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_4_1  | 2020-06-30 12:26:02,108 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@f417870] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_4_1  | 2020-06-30 12:26:04,177 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine: Unable to finish the execution.
datanode_4_1  | java.util.concurrent.TimeoutException
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.InitDatanodeState.await(InitDatanodeState.java:185)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.InitDatanodeState.await(InitDatanodeState.java:49)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:419)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:208)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:379)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-06-30 12:26:04,223 [Datanode State Machine Thread - 1] WARN statemachine.SCMConnectionManager: Trying to add an existing SCM Machine to Machines group. Ignoring the request.
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_3_1  | 2020-06-30 12:26:11,227 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3_1  | 2020-06-30 12:26:11,235 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3_1  | 2020-06-30 12:26:11,249 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f at port 9858
datanode_3_1  | 2020-06-30 12:26:11,381 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: start RPC server
datanode_3_1  | 2020-06-30 12:26:11,938 [Datanode State Machine Thread - 1] INFO server.GrpcService: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3_1  | 2020-06-30 12:26:16,564 [Command processor thread] INFO impl.RaftServerProxy: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: addNew group-2F8DC1CFEFE5:[e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858] returns group-2F8DC1CFEFE5:java.util.concurrent.CompletableFuture@46e9aa55[Not completed]
datanode_3_1  | 2020-06-30 12:26:16,672 [pool-19-thread-1] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: new RaftServerImpl for group-2F8DC1CFEFE5:[e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-06-30 12:26:16,687 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-06-30 12:26:16,693 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-06-30 12:26:16,693 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-06-30 12:26:16,694 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-06-30 12:26:16,695 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-06-30 12:26:16,740 [pool-19-thread-1] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5: ConfigurationManager, init=-1: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-06-30 12:26:16,746 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-06-30 12:26:16,760 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-06-30 12:26:16,776 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/88c1ea85-78cc-4aad-8b60-2f8dc1cfefe5 does not exist. Creating ...
datanode_3_1  | 2020-06-30 12:26:16,812 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/88c1ea85-78cc-4aad-8b60-2f8dc1cfefe5/in_use.lock acquired by nodename 7@73407aaf1fd9
datanode_3_1  | 2020-06-30 12:26:16,833 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/88c1ea85-78cc-4aad-8b60-2f8dc1cfefe5 has been successfully formatted.
datanode_3_1  | 2020-06-30 12:26:16,873 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-2F8DC1CFEFE5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-06-30 12:26:16,915 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-06-30 12:26:16,924 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-06-30 12:26:16,962 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-06-30 12:26:16,963 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-30 12:26:16,967 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-06-30 12:26:17,019 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5
datanode_3_1  | 2020-06-30 12:26:17,128 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-06-30 12:26:17,211 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/88c1ea85-78cc-4aad-8b60-2f8dc1cfefe5
datanode_3_1  | 2020-06-30 12:26:17,216 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-06-30 12:26:17,227 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-30 12:26:17,234 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-06-30 12:26:17,235 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-06-30 12:26:17,243 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-06-30 12:26:17,243 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-06-30 12:26:17,247 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-06-30 12:26:17,297 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-06-30 12:26:17,302 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-06-30 12:26:17,504 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-06-30 12:26:17,514 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-30 12:26:17,536 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-30 12:26:17,632 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-06-30 12:26:17,665 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-06-30 12:26:17,665 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-06-30 12:26:17,666 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-06-30 12:26:17,679 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-06-30 12:26:17,967 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5
datanode_3_1  | 2020-06-30 12:26:17,994 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5
datanode_3_1  | 2020-06-30 12:26:18,029 [pool-19-thread-1] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5: start as a follower, conf=-1: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858], old=null
datanode_3_1  | 2020-06-30 12:26:18,038 [pool-19-thread-1] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-06-30 12:26:18,048 [pool-19-thread-1] INFO impl.RoleInfo: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: start FollowerState
datanode_3_1  | 2020-06-30 12:26:18,103 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2F8DC1CFEFE5,id=e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f
datanode_3_1  | 2020-06-30 12:26:18,108 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5
datanode_3_1  | 2020-06-30 12:26:18,307 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "88c1ea85-78cc-4aad-8b60-2f8dc1cfefe5"
datanode_3_1  | .
datanode_3_1  | 2020-06-30 12:26:18,312 [Command processor thread] INFO impl.RaftServerProxy: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: addNew group-417987BD28FF:[e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858] returns group-417987BD28FF:java.util.concurrent.CompletableFuture@1fd71a39[Not completed]
datanode_3_1  | 2020-06-30 12:26:18,314 [pool-19-thread-1] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: new RaftServerImpl for group-417987BD28FF:[e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-06-30 12:26:18,318 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-06-30 12:26:18,319 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-06-30 12:26:18,320 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-06-30 12:26:18,323 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-06-30 12:26:18,324 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-06-30 12:26:18,324 [pool-19-thread-1] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF: ConfigurationManager, init=-1: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-06-30 12:26:18,324 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-06-30 12:26:18,325 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-06-30 12:26:18,326 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/8f9e6e0b-51d1-41f9-968d-417987bd28ff does not exist. Creating ...
datanode_3_1  | 2020-06-30 12:26:18,330 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/8f9e6e0b-51d1-41f9-968d-417987bd28ff/in_use.lock acquired by nodename 7@73407aaf1fd9
datanode_3_1  | 2020-06-30 12:26:18,339 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/8f9e6e0b-51d1-41f9-968d-417987bd28ff has been successfully formatted.
datanode_3_1  | 2020-06-30 12:26:18,340 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-417987BD28FF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-06-30 12:26:18,340 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-06-30 12:26:18,340 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-06-30 12:26:18,341 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-06-30 12:26:18,341 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-30 12:26:18,342 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-06-30 12:26:18,343 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF
datanode_3_1  | 2020-06-30 12:26:18,343 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-06-30 12:26:18,343 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/8f9e6e0b-51d1-41f9-968d-417987bd28ff
datanode_3_1  | 2020-06-30 12:26:18,344 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-06-30 12:26:18,346 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-30 12:26:18,348 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-06-30 12:26:18,348 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-06-30 12:26:18,348 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-06-30 12:26:18,353 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-06-30 12:26:18,353 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-06-30 12:26:18,353 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-06-30 12:26:18,354 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-06-30 12:26:18,357 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-06-30 12:26:18,357 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-30 12:26:18,358 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-30 12:26:18,361 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-06-30 12:26:18,362 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-06-30 12:26:18,364 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-06-30 12:26:18,365 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-06-30 12:26:18,366 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-06-30 12:26:18,366 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF
datanode_3_1  | 2020-06-30 12:26:18,367 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF
datanode_3_1  | 2020-06-30 12:26:18,369 [pool-19-thread-1] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF: start as a follower, conf=-1: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null
datanode_3_1  | 2020-06-30 12:26:18,370 [pool-19-thread-1] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-06-30 12:26:18,370 [pool-19-thread-1] INFO impl.RoleInfo: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: start FollowerState
datanode_3_1  | 2020-06-30 12:26:18,382 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-417987BD28FF,id=e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f
datanode_3_1  | 2020-06-30 12:26:18,382 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF
datanode_3_1  | 2020-06-30 12:26:21,928 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "8f9e6e0b-51d1-41f9-968d-417987bd28ff"
datanode_3_1  | .
datanode_3_1  | 2020-06-30 12:26:23,221 [Thread-23] INFO impl.FollowerState: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-FollowerState: change to CANDIDATE, lastRpcTime:5173ms, electionTimeout:5157ms
datanode_3_1  | 2020-06-30 12:26:23,222 [Thread-23] INFO impl.RoleInfo: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: shutdown FollowerState
datanode_3_1  | 2020-06-30 12:26:23,223 [Thread-23] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3_1  | 2020-06-30 12:26:23,225 [Thread-23] INFO impl.RoleInfo: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: start LeaderElection
datanode_3_1  | 2020-06-30 12:26:23,232 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO impl.LeaderElection: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1: begin an election at term 1 for -1: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858], old=null
datanode_3_1  | 2020-06-30 12:26:23,233 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO impl.RoleInfo: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: shutdown LeaderElection
datanode_3_1  | 2020-06-30 12:26:23,234 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3_1  | 2020-06-30 12:26:23,234 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-2F8DC1CFEFE5 with new leaderId: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f
datanode_3_1  | 2020-06-30 12:26:23,235 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5: change Leader from null to e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f at term 1 for becomeLeader, leader elected after 6353ms
datanode_3_1  | 2020-06-30 12:26:23,276 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-06-30 12:26:23,297 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 2020-06-30 12:26:23,316 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5
datanode_3_1  | 2020-06-30 12:26:23,341 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-30 12:26:23,341 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-06-30 12:26:23,397 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3_1  | 2020-06-30 12:26:23,397 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-06-30 12:26:23,398 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-06-30 12:26:23,464 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO impl.RoleInfo: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: start LeaderState
datanode_3_1  | 2020-06-30 12:26:23,569 [Thread-25] INFO impl.FollowerState: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-FollowerState: change to CANDIDATE, lastRpcTime:5198ms, electionTimeout:5183ms
datanode_3_1  | 2020-06-30 12:26:23,569 [Thread-25] INFO impl.RoleInfo: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: shutdown FollowerState
datanode_3_1  | 2020-06-30 12:26:23,569 [Thread-25] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3_1  | 2020-06-30 12:26:23,569 [Thread-25] INFO impl.RoleInfo: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: start LeaderElection
datanode_3_1  | 2020-06-30 12:26:23,554 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-06-30 12:26:04,592 [Datanode State Machine Thread - 1] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_4_1  | 2020-06-30 12:26:04,599 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_4_1  | 2020-06-30 12:26:07,568 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-06-30 12:26:08,569 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-06-30 12:26:09,570 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-06-30 12:26:10,587 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_4_1  | java.net.SocketTimeoutException: Call From 449b60852d9a/10.5.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:52612 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_4_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_4_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_4_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:52612 remote=scm/10.5.0.71:9861]
datanode_4_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_4_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-06-30 12:25:42,779 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 8b6abfea5c3b/10.5.0.70
om_1          | STARTUP_MSG:   args = [--init]
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2fb4a402fb97acb0b0294bc7a2ae17c6f5397edd ; compiled by 'runner' on 2020-06-30T11:59Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-06-30 12:25:42,872 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-06-30 12:25:48,806 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-06-30 12:25:49,155 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-06-30 12:25:49,155 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-06-30 12:25:49,482 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-30 12:25:53,311 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 12:25:54,311 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 12:25:55,315 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 12:25:56,316 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 12:25:57,317 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 12:25:58,318 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 12:25:59,319 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 12:26:00,320 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 12:26:01,321 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 12:26:02,331 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 12:26:02,333 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1          | 2020-06-30 12:26:08,335 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-30 12:26:09,336 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-542db014-c84e-4a7f-adbf-6bf1626e2271
om_1          | 2020-06-30 12:26:11,177 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1          | /************************************************************
om_1          | SHUTDOWN_MSG: Shutting down OzoneManager at 8b6abfea5c3b/10.5.0.70
om_1          | ************************************************************/
om_1          | Enabled profiling in kernel
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-06-30 12:26:17,031 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 8b6abfea5c3b/10.5.0.70
om_1          | STARTUP_MSG:   args = []
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2fb4a402fb97acb0b0294bc7a2ae17c6f5397edd ; compiled by 'runner' on 2020-06-30T11:59Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-06-30 12:26:17,071 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-06-30 12:26:22,070 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-06-30 12:26:22,847 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-06-30 12:26:22,853 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-06-30 12:26:22,971 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-30 12:26:23,069 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-30 12:26:27,865 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-30 12:26:28,853 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1          | 2020-06-30 12:26:28,917 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1          | 2020-06-30 12:26:29,236 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1          | 2020-06-30 12:26:29,431 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1          | 2020-06-30 12:26:29,432 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1          | 2020-06-30 12:26:29,542 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/10.5.0.70:9862
om_1          | 2020-06-30 12:26:29,596 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1          | 2020-06-30 12:26:29,607 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1          | 2020-06-30 12:26:29,833 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1          | 2020-06-30 12:26:29,833 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3_1  | 2020-06-30 12:26:23,645 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO impl.LeaderElection: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2: begin an election at term 1 for -1: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null
datanode_3_1  | 2020-06-30 12:26:23,813 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-LeaderElection1] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5: set configuration 0: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858], old=null at 0
datanode_3_1  | 2020-06-30 12:26:23,930 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO impl.LeaderElection: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2: Election PASSED; received 1 response(s) [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f<-c7c89d62-1bd1-4840-8dc0-c863fd86ce3b#0:OK-t1] and 0 exception(s); e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF:t1, leader=null, voted=e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f, raftlog=e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null
datanode_3_1  | 2020-06-30 12:26:23,931 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO impl.RoleInfo: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: shutdown LeaderElection
datanode_3_1  | 2020-06-30 12:26:23,931 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3_1  | 2020-06-30 12:26:23,931 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-417987BD28FF with new leaderId: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f
datanode_3_1  | 2020-06-30 12:26:23,931 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF: change Leader from null to e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f at term 1 for becomeLeader, leader elected after 5591ms
datanode_3_1  | 2020-06-30 12:26:23,931 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-06-30 12:26:23,931 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 2020-06-30 12:26:23,931 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF
datanode_3_1  | 2020-06-30 12:26:23,931 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-30 12:26:23,932 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-06-30 12:26:23,932 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3_1  | 2020-06-30 12:26:23,932 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-06-30 12:26:23,945 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-06-30 12:26:23,954 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3_1  | 2020-06-30 12:26:23,957 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-30 12:26:23,961 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3_1  | 2020-06-30 12:26:24,005 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3_1  | 2020-06-30 12:26:24,051 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-06-30 12:26:24,053 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-06-30 12:26:24,053 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF
datanode_3_1  | 2020-06-30 12:26:24,069 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3_1  | 2020-06-30 12:26:24,135 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-30 12:26:24,135 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3_1  | 2020-06-30 12:26:24,137 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3_1  | 2020-06-30 12:26:24,139 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-06-30 12:26:24,139 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_4_1  | 2020-06-30 12:26:11,315 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_4_1  | 2020-06-30 12:26:11,316 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_4_1  | 2020-06-30 12:26:11,322 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis ae41103f-5e55-496f-aac5-65fab8cc3ad2 at port 9858
datanode_4_1  | 2020-06-30 12:26:11,433 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: ae41103f-5e55-496f-aac5-65fab8cc3ad2: start RPC server
datanode_4_1  | 2020-06-30 12:26:11,944 [Datanode State Machine Thread - 1] INFO server.GrpcService: ae41103f-5e55-496f-aac5-65fab8cc3ad2: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_4_1  | 2020-06-30 12:26:15,347 [Datanode State Machine Thread - 2] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_4_1  | java.net.SocketTimeoutException: Call From 449b60852d9a/10.5.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:52626 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_4_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_4_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_4_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:148)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:145)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:76)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:52626 remote=scm/10.5.0.71:9861]
datanode_4_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_4_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_4_1  | 2020-06-30 12:26:22,939 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: ae41103f-5e55-496f-aac5-65fab8cc3ad2: Failed requestVote af137417-7801-4a96-9b21-1b6e75d3578d->ae41103f-5e55-496f-aac5-65fab8cc3ad2#0
datanode_4_1  | org.apache.ratis.protocol.GroupMismatchException: ae41103f-5e55-496f-aac5-65fab8cc3ad2: group-A2D077235929 not found.
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:127)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:274)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:283)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:278)
datanode_4_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:455)
datanode_4_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:170)
datanode_4_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:325)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:817)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_4_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | 2020-06-30 12:26:23,208 [grpc-default-executor-0] INFO impl.RaftServerProxy: ae41103f-5e55-496f-aac5-65fab8cc3ad2: addNew group-A2D077235929:[af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858] returns group-A2D077235929:java.util.concurrent.CompletableFuture@2dd23753[Not completed]
datanode_4_1  | 2020-06-30 12:26:23,391 [pool-19-thread-1] INFO impl.RaftServerImpl: ae41103f-5e55-496f-aac5-65fab8cc3ad2: new RaftServerImpl for group-A2D077235929:[af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-06-30 12:26:23,396 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-06-30 12:26:23,397 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-06-30 12:26:23,398 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-06-30 12:26:23,399 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-06-30 12:26:23,403 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-06-30 12:26:23,421 [pool-19-thread-1] INFO impl.RaftServerImpl: ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929: ConfigurationManager, init=-1: [af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-06-30 12:26:23,447 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-06-30 12:26:23,468 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-06-30 12:26:23,471 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/997168be-72df-4784-bd0d-a2d077235929 does not exist. Creating ...
datanode_4_1  | 2020-06-30 12:26:23,508 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/997168be-72df-4784-bd0d-a2d077235929/in_use.lock acquired by nodename 6@449b60852d9a
datanode_4_1  | 2020-06-30 12:26:23,528 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/997168be-72df-4784-bd0d-a2d077235929 has been successfully formatted.
datanode_4_1  | 2020-06-30 12:26:23,614 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-A2D077235929: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-06-30 12:26:23,621 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-06-30 12:26:23,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-06-30 12:26:23,645 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-06-30 12:26:23,665 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-06-30 12:26:23,673 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-06-30 12:26:23,699 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929
datanode_6_1  | Enabled profiling in kernel
datanode_6_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_6_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_6_1  | 2020-06-30 12:25:40,576 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_6_1  | /************************************************************
datanode_6_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_6_1  | STARTUP_MSG:   host = b92d877f5c7e/10.5.0.9
datanode_6_1  | STARTUP_MSG:   args = []
datanode_6_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_6_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_6_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2fb4a402fb97acb0b0294bc7a2ae17c6f5397edd ; compiled by 'runner' on 2020-06-30T11:59Z
datanode_6_1  | STARTUP_MSG:   java = 11.0.6
datanode_6_1  | ************************************************************/
datanode_6_1  | 2020-06-30 12:25:40,657 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_6_1  | 2020-06-30 12:25:42,684 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_6_1  | 2020-06-30 12:25:43,594 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_6_1  | 2020-06-30 12:25:45,287 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_6_1  | 2020-06-30 12:25:45,287 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_6_1  | 2020-06-30 12:25:45,893 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:b92d877f5c7e ip:10.5.0.9
datanode_6_1  | 2020-06-30 12:25:46,823 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_6_1  | 2020-06-30 12:25:46,847 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_6_1  | 2020-06-30 12:25:46,876 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_6_1  | 2020-06-30 12:25:46,913 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_6_1  | 2020-06-30 12:25:47,442 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_6_1  | 2020-06-30 12:25:56,139 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_6_1  | 2020-06-30 12:25:56,506 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_6_1  | 2020-06-30 12:25:57,667 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_6_1  | 2020-06-30 12:25:57,668 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_6_1  | 2020-06-30 12:25:57,671 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-06-30 12:25:57,677 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_6_1  | 2020-06-30 12:25:57,684 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 2020-06-30 12:25:59,810 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-06-30 12:26:01,368 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_6_1  | 2020-06-30 12:26:01,539 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_6_1  | 2020-06-30 12:26:01,841 [main] INFO util.log: Logging initialized @30617ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_6_1  | 2020-06-30 12:26:03,004 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_6_1  | 2020-06-30 12:26:03,008 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_6_1  | 2020-06-30 12:26:03,961 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_6_1  | 2020-06-30 12:26:03,966 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_6_1  | 2020-06-30 12:26:03,974 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_6_1  | 2020-06-30 12:26:03,975 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_6_1  | 2020-06-30 12:26:04,143 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_6_1  | 2020-06-30 12:26:04,208 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_6_1  | 2020-06-30 12:26:04,215 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_6_1  | 2020-06-30 12:26:04,413 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_6_1  | 2020-06-30 12:26:04,443 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_6_1  | 2020-06-30 12:26:04,449 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_6_1  | 2020-06-30 12:26:04,495 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b4954b2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_6_1  | 2020-06-30 12:26:04,497 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57416e49{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_6_1  | 2020-06-30 12:26:04,912 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c27f72{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-9999336307198435195.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_6_1  | 2020-06-30 12:26:04,947 [main] INFO server.AbstractConnector: Started ServerConnector@25cde5bb{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_6_1  | 2020-06-30 12:26:04,947 [main] INFO server.Server: Started @33723ms
datanode_6_1  | 2020-06-30 12:26:04,963 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_6_1  | 2020-06-30 12:26:04,963 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_6_1  | 2020-06-30 12:26:04,971 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_6_1  | 2020-06-30 12:26:05,080 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3287997a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_6_1  | 2020-06-30 12:26:05,682 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_6_1  | 2020-06-30 12:26:08,238 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-06-30 12:26:09,239 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-06-30 12:26:10,301 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_6_1  | java.net.SocketTimeoutException: Call From b92d877f5c7e/10.5.0.9 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:43852 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_5_1  | Enabled profiling in kernel
datanode_5_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_5_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_5_1  | 2020-06-30 12:25:34,706 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_5_1  | /************************************************************
datanode_5_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_5_1  | STARTUP_MSG:   host = 75fefa6dac4f/10.5.0.8
datanode_5_1  | STARTUP_MSG:   args = []
datanode_5_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_5_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_5_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2fb4a402fb97acb0b0294bc7a2ae17c6f5397edd ; compiled by 'runner' on 2020-06-30T11:59Z
datanode_5_1  | STARTUP_MSG:   java = 11.0.6
datanode_5_1  | ************************************************************/
datanode_5_1  | 2020-06-30 12:25:34,790 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_5_1  | 2020-06-30 12:25:36,650 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_5_1  | 2020-06-30 12:25:37,554 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_5_1  | 2020-06-30 12:25:39,751 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_5_1  | 2020-06-30 12:25:39,754 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_5_1  | 2020-06-30 12:25:41,030 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:75fefa6dac4f ip:10.5.0.8
datanode_5_1  | 2020-06-30 12:25:42,028 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_5_1  | 2020-06-30 12:25:42,056 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_5_1  | 2020-06-30 12:25:42,077 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_5_1  | 2020-06-30 12:25:42,119 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_5_1  | 2020-06-30 12:25:42,547 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_5_1  | 2020-06-30 12:25:49,981 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5_1  | 2020-06-30 12:25:50,346 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_5_1  | 2020-06-30 12:25:53,056 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_5_1  | 2020-06-30 12:25:53,077 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_5_1  | 2020-06-30 12:25:53,081 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-06-30 12:25:53,090 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_5_1  | 2020-06-30 12:25:53,111 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-06-30 12:25:55,126 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-06-30 12:25:56,668 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_5_1  | 2020-06-30 12:25:56,840 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_5_1  | 2020-06-30 12:25:57,052 [main] INFO util.log: Logging initialized @29662ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_5_1  | 2020-06-30 12:25:57,748 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_5_1  | 2020-06-30 12:25:57,794 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_5_1  | 2020-06-30 12:25:57,821 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_5_1  | 2020-06-30 12:25:57,863 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_5_1  | 2020-06-30 12:25:57,866 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_5_1  | 2020-06-30 12:25:57,869 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_5_1  | 2020-06-30 12:25:58,172 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_5_1  | 2020-06-30 12:25:58,212 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_5_1  | 2020-06-30 12:25:58,218 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_5_1  | 2020-06-30 12:25:58,613 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_5_1  | 2020-06-30 12:25:58,613 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_5_1  | 2020-06-30 12:25:58,616 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_5_1  | 2020-06-30 12:25:58,788 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b4954b2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_5_1  | 2020-06-30 12:25:58,790 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57416e49{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_5_1  | 2020-06-30 12:25:59,260 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c27f72{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-94151461857469396.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_5_1  | 2020-06-30 12:25:59,316 [main] INFO server.AbstractConnector: Started ServerConnector@25cde5bb{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_5_1  | 2020-06-30 12:25:59,325 [main] INFO server.Server: Started @31935ms
datanode_5_1  | 2020-06-30 12:25:59,383 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_5_1  | 2020-06-30 12:25:59,384 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_5_1  | 2020-06-30 12:25:59,415 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_5_1  | 2020-06-30 12:25:59,641 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7d2cc443] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_5_1  | 2020-06-30 12:26:01,137 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_5_1  | 2020-06-30 12:26:03,913 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-06-30 12:26:04,914 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-06-30 12:26:05,914 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-06-30 12:26:06,915 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-06-30 12:26:07,916 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-06-30 12:26:08,917 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-06-30 12:26:09,918 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-06-30 12:26:11,227 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_5_1  | 2020-06-30 12:26:11,251 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_5_1  | 2020-06-30 12:26:11,265 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 93760607-1873-432f-a86f-159b2f1f3a3a at port 9858
datanode_5_1  | 2020-06-30 12:26:11,411 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 93760607-1873-432f-a86f-159b2f1f3a3a: start RPC server
datanode_5_1  | 2020-06-30 12:26:11,969 [Datanode State Machine Thread - 0] INFO server.GrpcService: 93760607-1873-432f-a86f-159b2f1f3a3a: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_5_1  | 2020-06-30 12:26:17,008 [Command processor thread] INFO impl.RaftServerProxy: 93760607-1873-432f-a86f-159b2f1f3a3a: addNew group-4304D4C7BE58:[93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858] returns group-4304D4C7BE58:java.util.concurrent.CompletableFuture@740ce019[Not completed]
datanode_5_1  | 2020-06-30 12:26:17,059 [pool-19-thread-1] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a: new RaftServerImpl for group-4304D4C7BE58:[93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-06-30 12:26:17,073 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-06-30 12:26:17,078 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-06-30 12:26:17,079 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-06-30 12:26:17,079 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-06-30 12:26:17,080 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-06-30 12:26:17,110 [pool-19-thread-1] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58: ConfigurationManager, init=-1: [93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-06-30 12:26:17,111 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-06-30 12:26:17,126 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-06-30 12:26:17,128 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/cb75f1f1-e95c-44f7-9fa1-4304d4c7be58 does not exist. Creating ...
datanode_5_1  | 2020-06-30 12:26:17,164 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cb75f1f1-e95c-44f7-9fa1-4304d4c7be58/in_use.lock acquired by nodename 6@75fefa6dac4f
datanode_5_1  | 2020-06-30 12:26:17,172 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/cb75f1f1-e95c-44f7-9fa1-4304d4c7be58 has been successfully formatted.
datanode_5_1  | 2020-06-30 12:26:17,210 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-4304D4C7BE58: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-06-30 12:26:17,210 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-06-30 12:26:17,215 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-06-30 12:26:17,222 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-06-30 12:26:17,246 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-06-30 12:26:17,251 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-06-30 12:26:17,269 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58
datanode_5_1  | 2020-06-30 12:26:17,366 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-06-30 12:26:17,419 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/cb75f1f1-e95c-44f7-9fa1-4304d4c7be58
datanode_5_1  | 2020-06-30 12:26:17,432 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-06-30 12:26:17,434 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-06-30 12:26:17,439 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-06-30 12:26:17,440 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-06-30 12:26:17,440 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-06-30 12:26:17,440 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-06-30 12:26:17,441 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-06-30 12:26:17,441 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-06-30 12:26:17,442 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-06-30 12:26:17,608 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-06-30 12:26:17,696 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-30 12:26:17,696 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-30 12:26:17,754 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-06-30 12:26:17,775 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-06-30 12:26:17,802 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-06-30 12:26:17,823 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-06-30 12:26:17,824 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-06-30 12:26:24,180 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO impl.RoleInfo: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f: start LeaderState
datanode_3_1  | 2020-06-30 12:26:24,189 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-06-30 12:26:24,207 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-LeaderElection2] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF: set configuration 0: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null at 0
datanode_3_1  | 2020-06-30 12:26:24,302 [grpc-default-executor-1] INFO impl.RaftServerImpl: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-   LEADER: Withhold vote from candidate 93760607-1873-432f-a86f-159b2f1f3a3a with term 1. State: leader=e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f, term=1, lastRpcElapsed=null
datanode_3_1  | 2020-06-30 12:26:26,301 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-2F8DC1CFEFE5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/88c1ea85-78cc-4aad-8b60-2f8dc1cfefe5/current/log_inprogress_0
datanode_3_1  | 2020-06-30 12:26:26,302 [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f@group-417987BD28FF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8f9e6e0b-51d1-41f9-968d-417987bd28ff/current/log_inprogress_0
om_1          | 2020-06-30 12:26:29,901 [Listener at om/9862] INFO util.log: Logging initialized @17947ms to org.eclipse.jetty.util.log.Slf4jLog
om_1          | 2020-06-30 12:26:30,097 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1          | 2020-06-30 12:26:30,105 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1          | 2020-06-30 12:26:30,122 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1          | 2020-06-30 12:26:30,124 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1          | 2020-06-30 12:26:30,125 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1          | 2020-06-30 12:26:30,125 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1          | 2020-06-30 12:26:30,189 [Listener at om/9862] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1          | 2020-06-30 12:26:30,198 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1          | 2020-06-30 12:26:30,203 [Listener at om/9862] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1          | 2020-06-30 12:26:30,347 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1          | 2020-06-30 12:26:30,347 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1          | 2020-06-30 12:26:30,354 [Listener at om/9862] INFO server.session: node0 Scavenging every 600000ms
om_1          | 2020-06-30 12:26:30,372 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4bb9f7d4{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1          | 2020-06-30 12:26:30,377 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@44106e25{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1          | 2020-06-30 12:26:30,561 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2d2133fd{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-7907652975373522254.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1          | 2020-06-30 12:26:30,576 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@45cb5307{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1          | 2020-06-30 12:26:30,576 [Listener at om/9862] INFO server.Server: Started @18622ms
om_1          | 2020-06-30 12:26:30,580 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1          | 2020-06-30 12:26:30,580 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1          | 2020-06-30 12:26:30,584 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1          | 2020-06-30 12:26:30,601 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5e3cb58e] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1          | 2020-06-30 12:26:36,029 [IPC Server handler 78 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-01550 for user:hadoop
om_1          | 2020-06-30 12:26:36,051 [IPC Server handler 1 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-26739 for user:hadoop
om_1          | 2020-06-30 12:26:36,061 [IPC Server handler 3 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-16678 for user:hadoop
om_1          | 2020-06-30 12:26:36,069 [IPC Server handler 5 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-62540 for user:hadoop
om_1          | 2020-06-30 12:26:36,076 [IPC Server handler 7 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-77037 for user:hadoop
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-06-30 12:25:47,234 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = a288739d67a7/10.5.0.71
scm_1         | STARTUP_MSG:   args = [--init]
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2fb4a402fb97acb0b0294bc7a2ae17c6f5397edd ; compiled by 'runner' on 2020-06-30T11:59Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-06-30 12:25:47,420 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-06-30 12:25:48,752 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-06-30 12:25:49,407 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-542db014-c84e-4a7f-adbf-6bf1626e2271
scm_1         | 2020-06-30 12:25:49,482 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1         | /************************************************************
scm_1         | SHUTDOWN_MSG: Shutting down StorageContainerManager at a288739d67a7/10.5.0.71
scm_1         | ************************************************************/
scm_1         | Enabled profiling in kernel
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-06-30 12:26:06,714 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = a288739d67a7/10.5.0.71
scm_1         | STARTUP_MSG:   args = []
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/2fb4a402fb97acb0b0294bc7a2ae17c6f5397edd ; compiled by 'runner' on 2020-06-30T11:59Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-06-30 12:26:06,768 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-06-30 12:26:07,146 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-06-30 12:26:07,738 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-06-30 12:26:07,944 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@7a11c4c7
scm_1         | 2020-06-30 12:26:07,945 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1         | 2020-06-30 12:26:08,096 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1         | 2020-06-30 12:26:08,263 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
scm_1         | 2020-06-30 12:26:08,310 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1         | 2020-06-30 12:26:08,400 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1         | 2020-06-30 12:26:08,403 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1         | 2020-06-30 12:26:08,442 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1         | 2020-06-30 12:26:08,955 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-06-30 12:26:08,989 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1         | 2020-06-30 12:26:09,046 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-06-30 12:26:09,051 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1         | 2020-06-30 12:26:09,088 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-06-30 12:26:09,089 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1         | 2020-06-30 12:26:09,115 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1         | 2020-06-30 12:26:09,116 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1         | 2020-06-30 12:26:09,141 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @15828ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1         | 2020-06-30 12:26:09,252 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | 2020-06-30 12:26:09,282 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1         | 2020-06-30 12:26:09,290 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1         | 2020-06-30 12:26:09,292 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1         | 2020-06-30 12:26:09,293 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1         | 2020-06-30 12:26:09,293 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1         | 2020-06-30 12:26:09,331 [Listener at 0.0.0.0/9860] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
scm_1         | 2020-06-30 12:26:09,439 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1         | 2020-06-30 12:26:09,524 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1         | 2020-06-30 12:26:09,572 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1         | 2020-06-30 12:26:09,572 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1         | 2020-06-30 12:26:09,877 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1         | 2020-06-30 12:26:09,877 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-06-30 12:26:09,884 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1         | 2020-06-30 12:26:10,046 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1         | 2020-06-30 12:26:10,048 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1         | 2020-06-30 12:26:10,055 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_4_1  | 2020-06-30 12:26:23,780 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-06-30 12:26:23,836 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/997168be-72df-4784-bd0d-a2d077235929
datanode_4_1  | 2020-06-30 12:26:23,865 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-06-30 12:26:23,869 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-06-30 12:26:23,871 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-06-30 12:26:23,881 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-06-30 12:26:23,884 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-06-30 12:26:23,885 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-06-30 12:26:23,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-06-30 12:26:23,899 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-06-30 12:26:23,899 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-06-30 12:26:24,010 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-06-30 12:26:24,064 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-06-30 12:26:24,066 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-06-30 12:26:24,096 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-06-30 12:26:24,117 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-06-30 12:26:24,148 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-06-30 12:26:24,151 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-06-30 12:26:24,163 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-06-30 12:26:25,880 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@f417870] INFO util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1108ms
datanode_4_1  | GC pool 'ParNew' had collection(s): count=1 time=1575ms
datanode_4_1  | 2020-06-30 12:26:25,902 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929
datanode_4_1  | 2020-06-30 12:26:25,980 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929
datanode_4_1  | 2020-06-30 12:26:26,059 [pool-19-thread-1] INFO impl.RaftServerImpl: ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929: start as a follower, conf=-1: [af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858], old=null
datanode_4_1  | 2020-06-30 12:26:26,065 [pool-19-thread-1] INFO impl.RaftServerImpl: ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-06-30 12:26:26,085 [pool-19-thread-1] INFO impl.RoleInfo: ae41103f-5e55-496f-aac5-65fab8cc3ad2: start FollowerState
datanode_4_1  | 2020-06-30 12:26:26,119 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A2D077235929,id=ae41103f-5e55-496f-aac5-65fab8cc3ad2
datanode_4_1  | 2020-06-30 12:26:26,131 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929
datanode_4_1  | 2020-06-30 12:26:28,294 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A2D077235929 with new leaderId: af137417-7801-4a96-9b21-1b6e75d3578d
datanode_4_1  | 2020-06-30 12:26:28,295 [grpc-default-executor-0] INFO impl.RaftServerImpl: ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929: change Leader from null to af137417-7801-4a96-9b21-1b6e75d3578d at term 1 for appendEntries, leader elected after 4673ms
datanode_4_1  | 2020-06-30 12:26:28,299 [grpc-default-executor-0] INFO impl.RaftServerImpl: ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode_4_1  | 2020-06-30 12:26:28,301 [grpc-default-executor-0] INFO impl.RaftServerImpl: ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929: inconsistency entries. Reply:af137417-7801-4a96-9b21-1b6e75d3578d<-ae41103f-5e55-496f-aac5-65fab8cc3ad2#3:FAIL,INCONSISTENCY,nextIndex:0,term:0,followerCommit:-1
datanode_4_1  | 2020-06-30 12:26:28,334 [grpc-default-executor-0] INFO impl.RaftServerImpl: ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929: set configuration 0: [af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858], old=null at 0
datanode_4_1  | 2020-06-30 12:26:28,355 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-06-30 12:26:28,495 [ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ae41103f-5e55-496f-aac5-65fab8cc3ad2@group-A2D077235929-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/997168be-72df-4784-bd0d-a2d077235929/current/log_inprogress_0
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_6_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_6_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_6_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_6_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:43852 remote=scm/10.5.0.71:9861]
datanode_6_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_6_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_6_1  | 2020-06-30 12:26:11,171 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_6_1  | 2020-06-30 12:26:11,194 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_6_1  | 2020-06-30 12:26:11,194 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis af137417-7801-4a96-9b21-1b6e75d3578d at port 9858
datanode_6_1  | 2020-06-30 12:26:11,298 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: af137417-7801-4a96-9b21-1b6e75d3578d: start RPC server
datanode_6_1  | 2020-06-30 12:26:11,801 [Datanode State Machine Thread - 1] INFO server.GrpcService: af137417-7801-4a96-9b21-1b6e75d3578d: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_6_1  | 2020-06-30 12:26:16,240 [Command processor thread] INFO impl.RaftServerProxy: af137417-7801-4a96-9b21-1b6e75d3578d: addNew group-CDDB1DAAA19E:[af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858] returns group-CDDB1DAAA19E:java.util.concurrent.CompletableFuture@35fe7ae0[Not completed]
datanode_6_1  | 2020-06-30 12:26:16,311 [pool-19-thread-1] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d: new RaftServerImpl for group-CDDB1DAAA19E:[af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-06-30 12:26:16,312 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-06-30 12:26:16,315 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-06-30 12:26:16,316 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-06-30 12:26:16,317 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-06-30 12:26:16,318 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-06-30 12:26:16,336 [pool-19-thread-1] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E: ConfigurationManager, init=-1: [af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-06-30 12:26:16,344 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-06-30 12:26:16,356 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-06-30 12:26:16,360 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b60e30b0-61e2-4092-828b-cddb1daaa19e does not exist. Creating ...
datanode_6_1  | 2020-06-30 12:26:16,383 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b60e30b0-61e2-4092-828b-cddb1daaa19e/in_use.lock acquired by nodename 6@b92d877f5c7e
datanode_6_1  | 2020-06-30 12:26:16,391 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b60e30b0-61e2-4092-828b-cddb1daaa19e has been successfully formatted.
datanode_6_1  | 2020-06-30 12:26:16,417 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-CDDB1DAAA19E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-06-30 12:26:16,420 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_6_1  | 2020-06-30 12:26:16,430 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-06-30 12:26:16,457 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-06-30 12:26:16,459 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-06-30 12:26:16,463 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-06-30 12:26:16,521 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E
datanode_6_1  | 2020-06-30 12:26:16,635 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-06-30 12:26:18,123 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58
datanode_5_1  | 2020-06-30 12:26:18,159 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58
datanode_5_1  | 2020-06-30 12:26:18,176 [pool-19-thread-1] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58: start as a follower, conf=-1: [93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858], old=null
datanode_5_1  | 2020-06-30 12:26:18,195 [pool-19-thread-1] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-06-30 12:26:18,196 [pool-19-thread-1] INFO impl.RoleInfo: 93760607-1873-432f-a86f-159b2f1f3a3a: start FollowerState
datanode_5_1  | 2020-06-30 12:26:18,222 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4304D4C7BE58,id=93760607-1873-432f-a86f-159b2f1f3a3a
datanode_5_1  | 2020-06-30 12:26:18,234 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58
datanode_5_1  | 2020-06-30 12:26:18,318 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "cb75f1f1-e95c-44f7-9fa1-4304d4c7be58"
datanode_5_1  | .
datanode_5_1  | 2020-06-30 12:26:18,324 [Command processor thread] INFO impl.RaftServerProxy: 93760607-1873-432f-a86f-159b2f1f3a3a: addNew group-417987BD28FF:[e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858] returns group-417987BD28FF:java.util.concurrent.CompletableFuture@14a0df71[Not completed]
datanode_5_1  | 2020-06-30 12:26:18,355 [pool-19-thread-1] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a: new RaftServerImpl for group-417987BD28FF:[e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-06-30 12:26:18,366 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-06-30 12:26:18,367 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-06-30 12:26:18,367 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-06-30 12:26:18,368 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-06-30 12:26:18,369 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-06-30 12:26:18,370 [pool-19-thread-1] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF: ConfigurationManager, init=-1: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-06-30 12:26:18,370 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-06-30 12:26:18,376 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-06-30 12:26:18,376 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/8f9e6e0b-51d1-41f9-968d-417987bd28ff does not exist. Creating ...
datanode_5_1  | 2020-06-30 12:26:18,379 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/8f9e6e0b-51d1-41f9-968d-417987bd28ff/in_use.lock acquired by nodename 6@75fefa6dac4f
datanode_5_1  | 2020-06-30 12:26:18,381 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/8f9e6e0b-51d1-41f9-968d-417987bd28ff has been successfully formatted.
datanode_5_1  | 2020-06-30 12:26:18,386 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-417987BD28FF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-06-30 12:26:18,388 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-06-30 12:26:18,391 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-06-30 12:26:18,391 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-06-30 12:26:18,391 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-06-30 12:26:18,392 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-06-30 12:26:18,392 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF
datanode_5_1  | 2020-06-30 12:26:18,392 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-06-30 12:26:18,392 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/8f9e6e0b-51d1-41f9-968d-417987bd28ff
datanode_5_1  | 2020-06-30 12:26:18,401 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-06-30 12:26:18,401 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-06-30 12:26:18,401 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-06-30 12:26:18,401 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-06-30 12:26:18,401 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-06-30 12:26:18,405 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-06-30 12:26:18,405 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-06-30 12:26:18,405 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-06-30 12:26:18,406 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-06-30 12:26:18,408 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-06-30 12:26:18,418 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-30 12:26:18,418 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-30 12:26:18,422 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-06-30 12:26:18,422 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-06-30 12:26:18,422 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1         | 2020-06-30 12:26:10,063 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1         | 2020-06-30 12:26:10,321 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1         | 2020-06-30 12:26:10,325 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1         | 2020-06-30 12:26:10,326 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-06-30 12:26:10,328 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1         | 2020-06-30 12:26:10,425 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1         | 2020-06-30 12:26:10,426 [IPC Server handler 2 on default port 9861] INFO ipc.Server: IPC Server handler 2 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.9:43852
scm_1         | 2020-06-30 12:26:10,427 [IPC Server handler 5 on default port 9861] INFO ipc.Server: IPC Server handler 5 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.4:43830
scm_1         | 2020-06-30 12:26:10,429 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1         | 2020-06-30 12:26:10,522 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1         | 2020-06-30 12:26:10,524 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1         | 2020-06-30 12:26:10,528 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm_1         | 2020-06-30 12:26:10,581 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5fdd97c1{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1         | 2020-06-30 12:26:10,584 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@224d86d2{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1         | 2020-06-30 12:26:10,799 [IPC Server handler 4 on default port 9861] WARN ipc.Server: IPC Server handler 4 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.6:45134: output error
scm_1         | 2020-06-30 12:26:10,815 [IPC Server handler 6 on default port 9861] WARN ipc.Server: IPC Server handler 6 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.5:56636: output error
scm_1         | 2020-06-30 12:26:10,805 [IPC Server handler 1 on default port 9861] WARN ipc.Server: IPC Server handler 1 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.7:52612: output error
scm_1         | 2020-06-30 12:26:10,869 [IPC Server handler 4 on default port 9861] INFO ipc.Server: IPC Server handler 4 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-30 12:26:10,882 [IPC Server handler 1 on default port 9861] INFO ipc.Server: IPC Server handler 1 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-30 12:26:10,882 [IPC Server handler 6 on default port 9861] INFO ipc.Server: IPC Server handler 6 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-30 12:26:11,590 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3d3930fe{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-12269681509957728260.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
datanode_5_1  | 2020-06-30 12:26:18,422 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-06-30 12:26:18,423 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-06-30 12:26:18,423 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF
datanode_5_1  | 2020-06-30 12:26:18,425 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF
datanode_5_1  | 2020-06-30 12:26:18,439 [pool-19-thread-1] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF: start as a follower, conf=-1: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null
datanode_5_1  | 2020-06-30 12:26:18,441 [pool-19-thread-1] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-06-30 12:26:18,441 [pool-19-thread-1] INFO impl.RoleInfo: 93760607-1873-432f-a86f-159b2f1f3a3a: start FollowerState
datanode_5_1  | 2020-06-30 12:26:18,442 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-417987BD28FF,id=93760607-1873-432f-a86f-159b2f1f3a3a
datanode_5_1  | 2020-06-30 12:26:18,442 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF
datanode_5_1  | 2020-06-30 12:26:22,071 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for c7c89d62-1bd1-4840-8dc0-c863fd86ce3b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
datanode_5_1  | org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2.896203108s. [buffered_nanos=1472555135, remote_addr=/10.5.0.5:9858]
datanode_5_1  | 	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
datanode_5_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:86)
datanode_5_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:187)
datanode_5_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:156)
datanode_5_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:95)
datanode_5_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:337)
datanode_5_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:249)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:102)
datanode_5_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode_5_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode_5_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654)
datanode_5_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode_5_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode_5_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode_5_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode_5_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode_5_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:99)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:465)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.896203108s. [buffered_nanos=1472555135, remote_addr=/10.5.0.5:9858]
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
datanode_5_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:284)
datanode_5_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:158)
datanode_5_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:185)
datanode_5_1  | 	... 18 more
datanode_5_1  | 2020-06-30 12:26:22,487 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "8f9e6e0b-51d1-41f9-968d-417987bd28ff"
datanode_5_1  | .
datanode_5_1  | 2020-06-30 12:26:23,211 [Thread-22] INFO impl.FollowerState: 93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-FollowerState: change to CANDIDATE, lastRpcTime:5015ms, electionTimeout:5004ms
datanode_5_1  | 2020-06-30 12:26:23,212 [Thread-22] INFO impl.RoleInfo: 93760607-1873-432f-a86f-159b2f1f3a3a: shutdown FollowerState
datanode_5_1  | 2020-06-30 12:26:23,213 [Thread-22] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-06-30 12:26:23,215 [Thread-22] INFO impl.RoleInfo: 93760607-1873-432f-a86f-159b2f1f3a3a: start LeaderElection
datanode_5_1  | 2020-06-30 12:26:23,233 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO impl.LeaderElection: 93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1: begin an election at term 1 for -1: [93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858], old=null
datanode_5_1  | 2020-06-30 12:26:23,257 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO impl.RoleInfo: 93760607-1873-432f-a86f-159b2f1f3a3a: shutdown LeaderElection
datanode_5_1  | 2020-06-30 12:26:23,259 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-06-30 12:26:23,261 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4304D4C7BE58 with new leaderId: 93760607-1873-432f-a86f-159b2f1f3a3a
datanode_5_1  | 2020-06-30 12:26:23,272 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58: change Leader from null to 93760607-1873-432f-a86f-159b2f1f3a3a at term 1 for becomeLeader, leader elected after 6051ms
datanode_5_1  | 2020-06-30 12:26:23,289 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | 2020-06-30 12:26:23,303 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_6_1  | 2020-06-30 12:26:16,648 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/b60e30b0-61e2-4092-828b-cddb1daaa19e
datanode_6_1  | 2020-06-30 12:26:16,649 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-06-30 12:26:16,649 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-06-30 12:26:16,650 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-06-30 12:26:16,650 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-06-30 12:26:16,650 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-06-30 12:26:16,661 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-06-30 12:26:16,662 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-06-30 12:26:16,662 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-06-30 12:26:16,672 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-06-30 12:26:16,761 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-06-30 12:26:16,783 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-30 12:26:16,783 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-30 12:26:16,801 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-06-30 12:26:16,812 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-06-30 12:26:16,827 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-06-30 12:26:16,828 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-06-30 12:26:16,828 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-06-30 12:26:16,937 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E
datanode_6_1  | 2020-06-30 12:26:16,951 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E
datanode_6_1  | 2020-06-30 12:26:16,977 [pool-19-thread-1] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E: start as a follower, conf=-1: [af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858], old=null
datanode_6_1  | 2020-06-30 12:26:16,978 [pool-19-thread-1] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-06-30 12:26:16,985 [pool-19-thread-1] INFO impl.RoleInfo: af137417-7801-4a96-9b21-1b6e75d3578d: start FollowerState
datanode_6_1  | 2020-06-30 12:26:17,000 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CDDB1DAAA19E,id=af137417-7801-4a96-9b21-1b6e75d3578d
datanode_6_1  | 2020-06-30 12:26:17,002 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E
datanode_6_1  | 2020-06-30 12:26:17,052 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "b60e30b0-61e2-4092-828b-cddb1daaa19e"
datanode_6_1  | .
datanode_6_1  | 2020-06-30 12:26:17,067 [Command processor thread] INFO impl.RaftServerProxy: af137417-7801-4a96-9b21-1b6e75d3578d: addNew group-A2D077235929:[af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858] returns group-A2D077235929:java.util.concurrent.CompletableFuture@9b84d7f[Not completed]
datanode_6_1  | 2020-06-30 12:26:17,076 [pool-19-thread-1] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d: new RaftServerImpl for group-A2D077235929:[af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-06-30 12:26:17,080 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-06-30 12:26:17,080 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-06-30 12:26:17,081 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-06-30 12:26:17,082 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-06-30 12:26:17,083 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-06-30 12:26:17,083 [pool-19-thread-1] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929: ConfigurationManager, init=-1: [af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-06-30 12:26:17,083 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-06-30 12:26:17,083 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-06-30 12:26:17,083 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/997168be-72df-4784-bd0d-a2d077235929 does not exist. Creating ...
datanode_6_1  | 2020-06-30 12:26:17,091 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/997168be-72df-4784-bd0d-a2d077235929/in_use.lock acquired by nodename 6@b92d877f5c7e
datanode_6_1  | 2020-06-30 12:26:17,093 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/997168be-72df-4784-bd0d-a2d077235929 has been successfully formatted.
datanode_6_1  | 2020-06-30 12:26:17,099 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-A2D077235929: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-06-30 12:26:17,103 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_6_1  | 2020-06-30 12:26:17,103 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-06-30 12:26:17,103 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-06-30 12:26:17,103 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-06-30 12:26:17,103 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1         | 2020-06-30 12:26:11,868 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@7f22687e{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1         | 2020-06-30 12:26:11,892 [Listener at 0.0.0.0/9860] INFO server.Server: Started @18573ms
scm_1         | 2020-06-30 12:26:11,945 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1         | 2020-06-30 12:26:11,945 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1         | 2020-06-30 12:26:11,956 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1         | 2020-06-30 12:26:12,098 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@184de357] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1         | 2020-06-30 12:26:12,666 [IPC Server handler 2 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/ae41103f-5e55-496f-aac5-65fab8cc3ad2
scm_1         | 2020-06-30 12:26:12,666 [IPC Server handler 2 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ae41103f-5e55-496f-aac5-65fab8cc3ad2{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-06-30 12:26:12,707 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 12:26:12,707 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 4 required.
scm_1         | 2020-06-30 12:26:12,853 [IPC Server handler 89 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/5d636ad6-6c45-4d25-921b-ebdea2d03333
scm_1         | 2020-06-30 12:26:12,868 [IPC Server handler 89 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 5d636ad6-6c45-4d25-921b-ebdea2d03333{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-06-30 12:26:12,886 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 12:26:12,886 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 4 required.
scm_1         | 2020-06-30 12:26:12,886 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/c7c89d62-1bd1-4840-8dc0-c863fd86ce3b
scm_1         | 2020-06-30 12:26:12,886 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered Data node : c7c89d62-1bd1-4840-8dc0-c863fd86ce3b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-06-30 12:26:12,886 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 12:26:12,887 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 4 required.
scm_1         | 2020-06-30 12:26:12,977 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=8e81e2a0-2660-4d15-b4ba-d758135d51fb to datanode:ae41103f-5e55-496f-aac5-65fab8cc3ad2
scm_1         | 2020-06-30 12:26:13,158 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 8e81e2a0-2660-4d15-b4ba-d758135d51fb, Nodes: ae41103f-5e55-496f-aac5-65fab8cc3ad2{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T12:26:12.962093Z]
scm_1         | 2020-06-30 12:26:13,230 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c8f254bd-d61d-49b9-a338-e2307ca34514 to datanode:5d636ad6-6c45-4d25-921b-ebdea2d03333
scm_1         | 2020-06-30 12:26:13,235 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: c8f254bd-d61d-49b9-a338-e2307ca34514, Nodes: 5d636ad6-6c45-4d25-921b-ebdea2d03333{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T12:26:13.230061Z]
scm_1         | 2020-06-30 12:26:13,249 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=59d287fa-f96a-4cf2-b879-fe97191506e8 to datanode:c7c89d62-1bd1-4840-8dc0-c863fd86ce3b
scm_1         | 2020-06-30 12:26:13,251 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 59d287fa-f96a-4cf2-b879-fe97191506e8, Nodes: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T12:26:13.249777Z]
scm_1         | 2020-06-30 12:26:13,253 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1         | 2020-06-30 12:26:13,324 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/af137417-7801-4a96-9b21-1b6e75d3578d
scm_1         | 2020-06-30 12:26:13,324 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered Data node : af137417-7801-4a96-9b21-1b6e75d3578d{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-06-30 12:26:13,325 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 12:26:13,328 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 4 required.
scm_1         | 2020-06-30 12:26:13,343 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 12:26:13,343 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1         | 2020-06-30 12:26:13,352 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b60e30b0-61e2-4092-828b-cddb1daaa19e to datanode:af137417-7801-4a96-9b21-1b6e75d3578d
scm_1         | 2020-06-30 12:26:13,353 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: b60e30b0-61e2-4092-828b-cddb1daaa19e, Nodes: af137417-7801-4a96-9b21-1b6e75d3578d{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T12:26:13.352887Z]
scm_1         | 2020-06-30 12:26:13,371 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 4 nodes. Healthy nodes 4
scm_1         | 2020-06-30 12:26:13,402 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=997168be-72df-4784-bd0d-a2d077235929 to datanode:af137417-7801-4a96-9b21-1b6e75d3578d
scm_1         | 2020-06-30 12:26:13,402 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=997168be-72df-4784-bd0d-a2d077235929 to datanode:5d636ad6-6c45-4d25-921b-ebdea2d03333
scm_1         | 2020-06-30 12:26:13,403 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=997168be-72df-4784-bd0d-a2d077235929 to datanode:ae41103f-5e55-496f-aac5-65fab8cc3ad2
scm_1         | 2020-06-30 12:26:13,404 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 997168be-72df-4784-bd0d-a2d077235929, Nodes: af137417-7801-4a96-9b21-1b6e75d3578d{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}5d636ad6-6c45-4d25-921b-ebdea2d03333{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}ae41103f-5e55-496f-aac5-65fab8cc3ad2{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T12:26:13.402419Z]
scm_1         | 2020-06-30 12:26:13,413 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 1
scm_1         | 2020-06-30 12:26:13,668 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f
scm_1         | 2020-06-30 12:26:13,670 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-06-30 12:26:13,671 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 12:26:13,671 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 12:26:13,669 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=88c1ea85-78cc-4aad-8b60-2f8dc1cfefe5 to datanode:e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f
scm_1         | 2020-06-30 12:26:13,683 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 88c1ea85-78cc-4aad-8b60-2f8dc1cfefe5, Nodes: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T12:26:13.669408Z]
scm_1         | 2020-06-30 12:26:13,684 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 5 nodes. Healthy nodes 5
scm_1         | 2020-06-30 12:26:13,684 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 2
scm_1         | 2020-06-30 12:26:14,859 [IPC Server handler 80 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/93760607-1873-432f-a86f-159b2f1f3a3a
scm_1         | 2020-06-30 12:26:14,860 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cb75f1f1-e95c-44f7-9fa1-4304d4c7be58 to datanode:93760607-1873-432f-a86f-159b2f1f3a3a
scm_1         | 2020-06-30 12:26:14,862 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: cb75f1f1-e95c-44f7-9fa1-4304d4c7be58, Nodes: 93760607-1873-432f-a86f-159b2f1f3a3a{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T12:26:14.860528Z]
scm_1         | 2020-06-30 12:26:14,863 [IPC Server handler 80 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 93760607-1873-432f-a86f-159b2f1f3a3a{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-06-30 12:26:14,863 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 12:26:14,866 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 12:26:14,868 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-06-30 12:26:14,873 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=8f9e6e0b-51d1-41f9-968d-417987bd28ff to datanode:c7c89d62-1bd1-4840-8dc0-c863fd86ce3b
scm_1         | 2020-06-30 12:26:14,878 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=8f9e6e0b-51d1-41f9-968d-417987bd28ff to datanode:93760607-1873-432f-a86f-159b2f1f3a3a
scm_1         | 2020-06-30 12:26:14,881 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=8f9e6e0b-51d1-41f9-968d-417987bd28ff to datanode:e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f
scm_1         | 2020-06-30 12:26:14,882 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 8f9e6e0b-51d1-41f9-968d-417987bd28ff, Nodes: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}93760607-1873-432f-a86f-159b2f1f3a3a{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-30T12:26:14.873487Z]
scm_1         | 2020-06-30 12:26:14,895 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-06-30 12:26:15,493 [IPC Server handler 80 on default port 9861] WARN ipc.Server: IPC Server handler 80 on default port 9861, call Call#3 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.7:52626: output error
scm_1         | 2020-06-30 12:26:15,526 [IPC Server handler 80 on default port 9861] INFO ipc.Server: IPC Server handler 80 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
datanode_5_1  | 2020-06-30 12:26:23,308 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58
datanode_5_1  | 2020-06-30 12:26:23,350 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5_1  | 2020-06-30 12:26:23,351 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_5_1  | 2020-06-30 12:26:23,365 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5_1  | 2020-06-30 12:26:23,367 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5_1  | 2020-06-30 12:26:23,368 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5_1  | 2020-06-30 12:26:23,422 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO impl.RoleInfo: 93760607-1873-432f-a86f-159b2f1f3a3a: start LeaderState
datanode_5_1  | 2020-06-30 12:26:23,562 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-06-30 12:26:23,597 [Thread-24] INFO impl.FollowerState: 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF-FollowerState: change to CANDIDATE, lastRpcTime:5155ms, electionTimeout:5148ms
datanode_5_1  | 2020-06-30 12:26:23,631 [Thread-24] INFO impl.RoleInfo: 93760607-1873-432f-a86f-159b2f1f3a3a: shutdown FollowerState
datanode_5_1  | 2020-06-30 12:26:23,632 [Thread-24] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-06-30 12:26:23,632 [Thread-24] INFO impl.RoleInfo: 93760607-1873-432f-a86f-159b2f1f3a3a: start LeaderElection
datanode_5_1  | 2020-06-30 12:26:23,725 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-LeaderElection1] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58: set configuration 0: [93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858], old=null at 0
datanode_5_1  | 2020-06-30 12:26:23,730 [93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF-LeaderElection2] INFO impl.LeaderElection: 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF-LeaderElection2: begin an election at term 1 for -1: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null
datanode_5_1  | 2020-06-30 12:26:25,229 [93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF-LeaderElection2] INFO impl.LeaderElection: 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF-LeaderElection2: Election REJECTED; received 2 response(s) [93760607-1873-432f-a86f-159b2f1f3a3a<-e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f#0:FAIL-t1, 93760607-1873-432f-a86f-159b2f1f3a3a<-c7c89d62-1bd1-4840-8dc0-c863fd86ce3b#0:FAIL-t1] and 0 exception(s); 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF:t1, leader=null, voted=93760607-1873-432f-a86f-159b2f1f3a3a, raftlog=93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null
datanode_5_1  | 2020-06-30 12:26:25,890 [grpc-default-executor-0] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF: changes role from CANDIDATE to FOLLOWER at term 1 for appendEntries
datanode_5_1  | 2020-06-30 12:26:25,892 [grpc-default-executor-0] INFO impl.RoleInfo: 93760607-1873-432f-a86f-159b2f1f3a3a: shutdown LeaderElection
datanode_5_1  | 2020-06-30 12:26:25,892 [grpc-default-executor-0] INFO impl.RoleInfo: 93760607-1873-432f-a86f-159b2f1f3a3a: start FollowerState
datanode_5_1  | 2020-06-30 12:26:25,892 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-417987BD28FF with new leaderId: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f
datanode_5_1  | 2020-06-30 12:26:25,893 [grpc-default-executor-0] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF: change Leader from null to e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f at term 1 for appendEntries, leader elected after 7506ms
datanode_5_1  | 2020-06-30 12:26:26,101 [93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 93760607-1873-432f-a86f-159b2f1f3a3a@group-4304D4C7BE58-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cb75f1f1-e95c-44f7-9fa1-4304d4c7be58/current/log_inprogress_0
datanode_5_1  | 2020-06-30 12:26:26,660 [grpc-default-executor-0] INFO impl.RaftServerImpl: 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF: set configuration 0: [e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f:10.5.0.6:9858, 93760607-1873-432f-a86f-159b2f1f3a3a:10.5.0.8:9858, c7c89d62-1bd1-4840-8dc0-c863fd86ce3b:10.5.0.5:9858], old=null at 0
datanode_5_1  | 2020-06-30 12:26:26,664 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-06-30 12:26:26,666 [93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 93760607-1873-432f-a86f-159b2f1f3a3a@group-417987BD28FF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8f9e6e0b-51d1-41f9-968d-417987bd28ff/current/log_inprogress_0
datanode_6_1  | 2020-06-30 12:26:17,104 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929
datanode_6_1  | 2020-06-30 12:26:17,104 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-06-30 12:26:17,104 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/997168be-72df-4784-bd0d-a2d077235929
datanode_6_1  | 2020-06-30 12:26:17,104 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-06-30 12:26:17,104 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-06-30 12:26:17,104 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-06-30 12:26:17,105 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-06-30 12:26:17,105 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-06-30 12:26:17,114 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-06-30 12:26:17,116 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-06-30 12:26:17,117 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-06-30 12:26:17,117 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-06-30 12:26:17,118 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-06-30 12:26:17,123 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-30 12:26:17,124 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-30 12:26:17,124 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-06-30 12:26:17,124 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-06-30 12:26:17,125 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-06-30 12:26:17,125 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-06-30 12:26:17,125 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-06-30 12:26:17,126 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929
datanode_6_1  | 2020-06-30 12:26:17,126 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929
datanode_6_1  | 2020-06-30 12:26:17,131 [pool-19-thread-1] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929: start as a follower, conf=-1: [af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858], old=null
datanode_6_1  | 2020-06-30 12:26:17,143 [pool-19-thread-1] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-06-30 12:26:17,144 [pool-19-thread-1] INFO impl.RoleInfo: af137417-7801-4a96-9b21-1b6e75d3578d: start FollowerState
datanode_6_1  | 2020-06-30 12:26:17,144 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A2D077235929,id=af137417-7801-4a96-9b21-1b6e75d3578d
datanode_6_1  | 2020-06-30 12:26:17,145 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929
datanode_6_1  | 2020-06-30 12:26:21,303 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 5d636ad6-6c45-4d25-921b-ebdea2d03333{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
datanode_6_1  | org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2.880167185s. [buffered_nanos=1360385287, remote_addr=/10.5.0.4:9858]
datanode_6_1  | 	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
datanode_6_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:86)
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:187)
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:156)
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:95)
datanode_6_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:337)
datanode_6_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:249)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:102)
datanode_6_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode_6_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode_6_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654)
datanode_6_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode_6_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode_6_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode_6_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode_6_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode_6_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:99)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:465)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.880167185s. [buffered_nanos=1360385287, remote_addr=/10.5.0.4:9858]
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
datanode_6_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:284)
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:158)
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:185)
datanode_6_1  | 	... 18 more
datanode_6_1  | 2020-06-30 12:26:22,090 [Thread-23] INFO impl.FollowerState: af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-FollowerState: change to CANDIDATE, lastRpcTime:5106ms, electionTimeout:5099ms
datanode_6_1  | 2020-06-30 12:26:22,092 [Thread-23] INFO impl.RoleInfo: af137417-7801-4a96-9b21-1b6e75d3578d: shutdown FollowerState
datanode_6_1  | 2020-06-30 12:26:22,092 [Thread-23] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_6_1  | 2020-06-30 12:26:22,094 [Thread-23] INFO impl.RoleInfo: af137417-7801-4a96-9b21-1b6e75d3578d: start LeaderElection
datanode_6_1  | 2020-06-30 12:26:22,111 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO impl.LeaderElection: af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1: begin an election at term 1 for -1: [af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858], old=null
datanode_6_1  | 2020-06-30 12:26:22,113 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO impl.RoleInfo: af137417-7801-4a96-9b21-1b6e75d3578d: shutdown LeaderElection
datanode_6_1  | 2020-06-30 12:26:22,113 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_6_1  | 2020-06-30 12:26:22,113 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CDDB1DAAA19E with new leaderId: af137417-7801-4a96-9b21-1b6e75d3578d
datanode_6_1  | 2020-06-30 12:26:22,114 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E: change Leader from null to af137417-7801-4a96-9b21-1b6e75d3578d at term 1 for becomeLeader, leader elected after 5694ms
datanode_6_1  | 2020-06-30 12:26:22,128 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_6_1  | 2020-06-30 12:26:22,131 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_6_1  | 2020-06-30 12:26:22,148 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E
datanode_6_1  | 2020-06-30 12:26:22,152 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_6_1  | 2020-06-30 12:26:22,153 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_6_1  | 2020-06-30 12:26:22,164 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_6_1  | 2020-06-30 12:26:22,165 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_6_1  | 2020-06-30 12:26:22,213 [Thread-25] INFO impl.FollowerState: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-FollowerState: change to CANDIDATE, lastRpcTime:5068ms, electionTimeout:5062ms
datanode_6_1  | 2020-06-30 12:26:22,225 [Thread-25] INFO impl.RoleInfo: af137417-7801-4a96-9b21-1b6e75d3578d: shutdown FollowerState
datanode_6_1  | 2020-06-30 12:26:22,225 [Thread-25] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_6_1  | 2020-06-30 12:26:22,226 [Thread-25] INFO impl.RoleInfo: af137417-7801-4a96-9b21-1b6e75d3578d: start LeaderElection
datanode_6_1  | 2020-06-30 12:26:22,236 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_6_1  | 2020-06-30 12:26:22,282 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO impl.RoleInfo: af137417-7801-4a96-9b21-1b6e75d3578d: start LeaderState
datanode_6_1  | 2020-06-30 12:26:22,283 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO impl.LeaderElection: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2: begin an election at term 1 for -1: [af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858], old=null
datanode_6_1  | 2020-06-30 12:26:22,547 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-06-30 12:26:22,692 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-LeaderElection1] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E: set configuration 0: [af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858], old=null at 0
datanode_6_1  | 2020-06-30 12:26:22,874 [af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: af137417-7801-4a96-9b21-1b6e75d3578d@group-CDDB1DAAA19E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b60e30b0-61e2-4092-828b-cddb1daaa19e/current/log_inprogress_0
datanode_6_1  | 2020-06-30 12:26:22,895 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO impl.LeaderElection: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2: Election PASSED; received 1 response(s) [af137417-7801-4a96-9b21-1b6e75d3578d<-5d636ad6-6c45-4d25-921b-ebdea2d03333#0:OK-t1] and 0 exception(s); af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929:t1, leader=null, voted=af137417-7801-4a96-9b21-1b6e75d3578d, raftlog=af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858], old=null
datanode_6_1  | 2020-06-30 12:26:22,895 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO impl.RoleInfo: af137417-7801-4a96-9b21-1b6e75d3578d: shutdown LeaderElection
datanode_6_1  | 2020-06-30 12:26:22,896 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_6_1  | 2020-06-30 12:26:22,901 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A2D077235929 with new leaderId: af137417-7801-4a96-9b21-1b6e75d3578d
datanode_6_1  | 2020-06-30 12:26:22,924 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929: change Leader from null to af137417-7801-4a96-9b21-1b6e75d3578d at term 1 for becomeLeader, leader elected after 5801ms
datanode_6_1  | 2020-06-30 12:26:22,944 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_6_1  | 2020-06-30 12:26:22,945 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-30 12:26:15,561 [IPC Server handler 7 on default port 9861] WARN ipc.Server: IPC Server handler 7 on default port 9861, call Call#3 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.4:43846: output error
scm_1         | 2020-06-30 12:26:15,561 [IPC Server handler 7 on default port 9861] INFO ipc.Server: IPC Server handler 7 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-30 12:26:16,977 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: b60e30b0-61e2-4092-828b-cddb1daaa19e, Nodes: af137417-7801-4a96-9b21-1b6e75d3578d{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:af137417-7801-4a96-9b21-1b6e75d3578d, CreationTimestamp2020-06-30T12:26:13.352887Z] moved to OPEN state
scm_1         | 2020-06-30 12:26:16,986 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-30 12:26:16,992 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-30 12:26:17,914 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 88c1ea85-78cc-4aad-8b60-2f8dc1cfefe5, Nodes: e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f, CreationTimestamp2020-06-30T12:26:13.669408Z] moved to OPEN state
scm_1         | 2020-06-30 12:26:17,927 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-30 12:26:17,927 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-30 12:26:18,166 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: cb75f1f1-e95c-44f7-9fa1-4304d4c7be58, Nodes: 93760607-1873-432f-a86f-159b2f1f3a3a{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:93760607-1873-432f-a86f-159b2f1f3a3a, CreationTimestamp2020-06-30T12:26:14.860528Z] moved to OPEN state
scm_1         | 2020-06-30 12:26:18,170 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-30 12:26:18,170 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-30 12:26:23,957 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 8f9e6e0b-51d1-41f9-968d-417987bd28ff, Nodes: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}93760607-1873-432f-a86f-159b2f1f3a3a{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:e2097891-5bc2-4f96-b1f2-fbe3cb4beb1f, CreationTimestamp2020-06-30T12:26:14.873487Z] moved to OPEN state
scm_1         | 2020-06-30 12:26:23,958 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1         | 2020-06-30 12:26:23,958 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-30 12:26:23,965 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1         | 2020-06-30 12:26:23,965 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1         | 2020-06-30 12:26:23,965 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1         | 2020-06-30 12:26:26,043 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 997168be-72df-4784-bd0d-a2d077235929, Nodes: af137417-7801-4a96-9b21-1b6e75d3578d{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}5d636ad6-6c45-4d25-921b-ebdea2d03333{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}ae41103f-5e55-496f-aac5-65fab8cc3ad2{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:af137417-7801-4a96-9b21-1b6e75d3578d, CreationTimestamp2020-06-30T12:26:13.402419Z] moved to OPEN state
scm_1         | 2020-06-30 12:26:42,520 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:26:43,322 [IPC Server handler 0 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 2020-06-30 12:26:22,945 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929
datanode_6_1  | 2020-06-30 12:26:22,945 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_6_1  | 2020-06-30 12:26:22,950 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_6_1  | 2020-06-30 12:26:22,951 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_6_1  | 2020-06-30 12:26:22,951 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_6_1  | 2020-06-30 12:26:22,951 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_6_1  | 2020-06-30 12:26:22,961 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_6_1  | 2020-06-30 12:26:22,967 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-06-30 12:26:22,968 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_6_1  | 2020-06-30 12:26:22,980 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_6_1  | 2020-06-30 12:26:22,993 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 2020-06-30 12:26:22,994 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-06-30 12:26:23,002 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929
datanode_6_1  | 2020-06-30 12:26:23,033 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_6_1  | 2020-06-30 12:26:23,034 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-06-30 12:26:23,035 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_6_1  | 2020-06-30 12:26:23,035 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_6_1  | 2020-06-30 12:26:23,035 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 2020-06-30 12:26:23,037 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-06-30 12:26:23,052 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO impl.RoleInfo: af137417-7801-4a96-9b21-1b6e75d3578d: start LeaderState
datanode_6_1  | 2020-06-30 12:26:23,058 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-06-30 12:26:23,066 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/997168be-72df-4784-bd0d-a2d077235929/current/log_inprogress_0
datanode_6_1  | 2020-06-30 12:26:23,091 [af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929-LeaderElection2] INFO impl.RaftServerImpl: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929: set configuration 0: [af137417-7801-4a96-9b21-1b6e75d3578d:10.5.0.9:9858, ae41103f-5e55-496f-aac5-65fab8cc3ad2:10.5.0.7:9858, 5d636ad6-6c45-4d25-921b-ebdea2d03333:10.5.0.4:9858], old=null at 0
datanode_6_1  | 2020-06-30 12:26:24,324 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for ae41103f-5e55-496f-aac5-65fab8cc3ad2{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
datanode_6_1  | org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2.961657408s. [buffered_nanos=1073336874, remote_addr=/10.5.0.7:9858]
datanode_6_1  | 	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
datanode_6_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:86)
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:187)
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:156)
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:95)
datanode_6_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:337)
datanode_6_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:249)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:102)
datanode_6_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode_6_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode_6_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654)
datanode_6_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode_6_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode_6_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode_6_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode_6_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode_6_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:99)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:465)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.961657408s. [buffered_nanos=1073336874, remote_addr=/10.5.0.7:9858]
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
scm_1         | 2020-06-30 12:26:45,594 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 59d287fa-f96a-4cf2-b879-fe97191506e8, Nodes: c7c89d62-1bd1-4840-8dc0-c863fd86ce3b{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:c7c89d62-1bd1-4840-8dc0-c863fd86ce3b, CreationTimestamp2020-06-30T12:26:13.249777Z] moved to OPEN state
scm_1         | 2020-06-30 12:26:46,852 [IPC Server handler 54 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:26:47,042 [IPC Server handler 93 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:26:49,658 [IPC Server handler 52 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:26:52,419 [IPC Server handler 39 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:26:55,025 [IPC Server handler 93 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:26:57,606 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:00,206 [IPC Server handler 70 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:00,378 [IPC Server handler 39 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:00,483 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:03,074 [IPC Server handler 42 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:03,174 [IPC Server handler 68 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:03,266 [IPC Server handler 49 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:03,360 [IPC Server handler 63 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:03,446 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:06,031 [IPC Server handler 53 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:06,123 [IPC Server handler 68 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:06,213 [IPC Server handler 49 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:08,792 [IPC Server handler 34 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:08,893 [IPC Server handler 54 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:08,975 [IPC Server handler 53 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:11,560 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:14,137 [IPC Server handler 49 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:14,230 [IPC Server handler 97 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:17,173 [IPC Server handler 97 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:19,741 [IPC Server handler 74 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:22,335 [IPC Server handler 83 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:22,430 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:25,222 [IPC Server handler 83 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:25,585 [IPC Server handler 21 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:25,683 [IPC Server handler 40 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:25,753 [IPC Server handler 66 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:28,329 [IPC Server handler 43 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:30,883 [IPC Server handler 57 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:30,957 [IPC Server handler 71 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:33,521 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:36,687 [IPC Server handler 29 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:39,265 [IPC Server handler 47 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:39,354 [IPC Server handler 41 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:41,919 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:42,047 [IPC Server handler 53 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:44,607 [IPC Server handler 21 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:44,695 [IPC Server handler 55 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:47,302 [IPC Server handler 41 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:47,656 [IPC Server handler 62 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:50,289 [IPC Server handler 97 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:52,865 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:55,460 [IPC Server handler 88 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:55,564 [IPC Server handler 79 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:27:58,136 [IPC Server handler 63 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:00,693 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:03,265 [IPC Server handler 83 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:03,354 [IPC Server handler 50 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:03,417 [IPC Server handler 88 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
datanode_6_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:284)
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:158)
datanode_6_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:185)
datanode_6_1  | 	... 18 more
datanode_6_1  | 2020-06-30 12:26:24,329 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "997168be-72df-4784-bd0d-a2d077235929"
datanode_6_1  | .
datanode_6_1  | 2020-06-30 12:26:28,323 [grpc-default-executor-0] INFO impl.FollowerInfo: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2: nextIndex: updateUnconditionally 1 -> 0
datanode_6_1  | 2020-06-30 12:27:28,324 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4,entriesCount=1,lastEntry=(t:1, i:0)
datanode_6_1  | 2020-06-30 12:27:42,797 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=10,entriesCount=1,lastEntry=(t:1, i:1)
datanode_6_1  | 2020-06-30 12:27:43,117 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=11,entriesCount=1,lastEntry=(t:1, i:2)
datanode_6_1  | 2020-06-30 12:27:44,297 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=12,entriesCount=1,lastEntry=(t:1, i:3)
datanode_6_1  | 2020-06-30 12:27:44,322 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=13,entriesCount=1,lastEntry=(t:1, i:4)
datanode_6_1  | 2020-06-30 12:27:47,018 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=15,entriesCount=1,lastEntry=(t:1, i:5)
datanode_6_1  | 2020-06-30 12:27:47,052 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=16,entriesCount=1,lastEntry=(t:1, i:6)
datanode_6_1  | 2020-06-30 12:27:47,053 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=17,entriesCount=1,lastEntry=(t:1, i:7)
datanode_6_1  | 2020-06-30 12:27:47,053 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=18,entriesCount=1,lastEntry=(t:1, i:8)
datanode_6_1  | 2020-06-30 12:27:49,757 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=20,entriesCount=1,lastEntry=(t:1, i:9)
datanode_6_1  | 2020-06-30 12:27:49,861 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=21,entriesCount=1,lastEntry=(t:1, i:10)
datanode_6_1  | 2020-06-30 12:27:49,861 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=22,entriesCount=1,lastEntry=(t:1, i:11)
datanode_6_1  | 2020-06-30 12:27:49,891 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=23,entriesCount=1,lastEntry=(t:1, i:12)
datanode_6_1  | 2020-06-30 12:27:52,445 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=25,entriesCount=1,lastEntry=(t:1, i:13)
datanode_6_1  | 2020-06-30 12:27:52,452 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=26,entriesCount=1,lastEntry=(t:1, i:14)
datanode_6_1  | 2020-06-30 12:27:52,461 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=27,entriesCount=1,lastEntry=(t:1, i:15)
datanode_6_1  | 2020-06-30 12:27:52,480 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=28,entriesCount=1,lastEntry=(t:1, i:16)
datanode_6_1  | 2020-06-30 12:27:55,018 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=30,entriesCount=1,lastEntry=(t:1, i:17)
datanode_6_1  | 2020-06-30 12:27:55,036 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=31,entriesCount=1,lastEntry=(t:1, i:18)
datanode_6_1  | 2020-06-30 12:27:55,053 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=32,entriesCount=1,lastEntry=(t:1, i:19)
scm_1         | 2020-06-30 12:28:03,491 [IPC Server handler 43 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:06,076 [IPC Server handler 71 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:08,444 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-06-30 12:28:08,444 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-06-30 12:28:08,661 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:08,721 [IPC Server handler 55 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:11,432 [IPC Server handler 93 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:11,500 [IPC Server handler 41 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:11,576 [IPC Server handler 49 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:14,165 [IPC Server handler 52 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:14,254 [IPC Server handler 98 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:16,843 [IPC Server handler 62 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:19,399 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:22,000 [IPC Server handler 52 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:22,077 [IPC Server handler 85 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:22,445 [IPC Server handler 43 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:25,283 [IPC Server handler 91 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:35,783 [IPC Server handler 38 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:40,976 [IPC Server handler 52 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:41,010 [IPC Server handler 85 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:41,070 [IPC Server handler 91 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:41,130 [IPC Server handler 37 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:28:51,207 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:29:06,381 [IPC Server handler 33 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:29:11,545 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:29:11,603 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:29:11,720 [IPC Server handler 44 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:29:11,790 [IPC Server handler 38 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:29:11,853 [IPC Server handler 93 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:29:21,942 [IPC Server handler 98 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:29:27,090 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:29:27,156 [IPC Server handler 91 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:29:27,250 [IPC Server handler 40 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:29:37,390 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:29:42,435 [IPC Server handler 58 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:29:52,539 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:29:57,596 [IPC Server handler 26 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:30:07,995 [IPC Server handler 31 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:30:08,458 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-06-30 12:30:08,459 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-06-30 12:30:23,087 [IPC Server handler 20 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:30:38,228 [IPC Server handler 62 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:30:53,793 [IPC Server handler 73 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:31:08,879 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:31:23,985 [IPC Server handler 7 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-30 12:31:23,986 [EventQueue-Delayed safe mode statusForReplicationManager] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1         | 2020-06-30 12:31:24,021 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1
scm_1         | 2020-06-30 12:31:24,022 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2
scm_1         | 2020-06-30 12:31:24,023 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #3
scm_1         | 2020-06-30 12:31:24,023 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #4
scm_1         | 2020-06-30 12:31:24,020 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 17 milliseconds for processing 13 containers.
datanode_6_1  | 2020-06-30 12:27:55,076 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=33,entriesCount=1,lastEntry=(t:1, i:20)
datanode_6_1  | 2020-06-30 12:27:57,630 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=35,entriesCount=1,lastEntry=(t:1, i:21)
datanode_6_1  | 2020-06-30 12:27:57,647 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=36,entriesCount=1,lastEntry=(t:1, i:22)
datanode_6_1  | 2020-06-30 12:27:57,658 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=37,entriesCount=1,lastEntry=(t:1, i:23)
datanode_6_1  | 2020-06-30 12:27:57,670 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=38,entriesCount=1,lastEntry=(t:1, i:24)
datanode_6_1  | 2020-06-30 12:28:00,490 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=40,entriesCount=1,lastEntry=(t:1, i:25)
datanode_6_1  | 2020-06-30 12:28:00,503 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=41,entriesCount=1,lastEntry=(t:1, i:26)
datanode_6_1  | 2020-06-30 12:28:00,509 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=42,entriesCount=1,lastEntry=(t:1, i:27)
datanode_6_1  | 2020-06-30 12:28:00,540 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=43,entriesCount=1,lastEntry=(t:1, i:28)
datanode_6_1  | 2020-06-30 12:28:03,455 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=45,entriesCount=1,lastEntry=(t:1, i:29)
datanode_6_1  | 2020-06-30 12:28:03,469 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=46,entriesCount=1,lastEntry=(t:1, i:30)
datanode_6_1  | 2020-06-30 12:28:03,487 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=47,entriesCount=1,lastEntry=(t:1, i:31)
datanode_6_1  | 2020-06-30 12:28:03,499 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=48,entriesCount=1,lastEntry=(t:1, i:32)
datanode_6_1  | 2020-06-30 12:28:06,223 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=50,entriesCount=1,lastEntry=(t:1, i:33)
datanode_6_1  | 2020-06-30 12:28:06,231 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=51,entriesCount=1,lastEntry=(t:1, i:34)
datanode_6_1  | 2020-06-30 12:28:06,237 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=52,entriesCount=1,lastEntry=(t:1, i:35)
datanode_6_1  | 2020-06-30 12:28:06,261 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=53,entriesCount=1,lastEntry=(t:1, i:36)
datanode_6_1  | 2020-06-30 12:28:08,996 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=55,entriesCount=1,lastEntry=(t:1, i:37)
datanode_6_1  | 2020-06-30 12:28:09,003 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=56,entriesCount=1,lastEntry=(t:1, i:38)
datanode_6_1  | 2020-06-30 12:28:09,009 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=57,entriesCount=1,lastEntry=(t:1, i:39)
datanode_6_1  | 2020-06-30 12:28:09,034 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=58,entriesCount=1,lastEntry=(t:1, i:40)
datanode_6_1  | 2020-06-30 12:28:11,590 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=60,entriesCount=1,lastEntry=(t:1, i:41)
scm_1         | 2020-06-30 12:31:24,023 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #5
scm_1         | 2020-06-30 12:31:24,024 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #6
scm_1         | 2020-06-30 12:31:24,024 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #7
scm_1         | 2020-06-30 12:31:24,024 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #8
scm_1         | 2020-06-30 12:31:24,024 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #9
scm_1         | 2020-06-30 12:31:24,025 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #10
scm_1         | 2020-06-30 12:31:24,025 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #11
scm_1         | 2020-06-30 12:31:24,025 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #12
scm_1         | 2020-06-30 12:31:24,025 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #13
datanode_6_1  | 2020-06-30 12:28:11,598 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=61,entriesCount=1,lastEntry=(t:1, i:42)
datanode_6_1  | 2020-06-30 12:28:11,600 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=62,entriesCount=1,lastEntry=(t:1, i:43)
datanode_6_1  | 2020-06-30 12:28:14,249 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=64,entriesCount=1,lastEntry=(t:1, i:44)
datanode_6_1  | 2020-06-30 12:28:14,254 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=65,entriesCount=1,lastEntry=(t:1, i:45)
datanode_6_1  | 2020-06-30 12:28:14,652 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=66,entriesCount=1,lastEntry=(t:1, i:46)
datanode_6_1  | 2020-06-30 12:28:17,188 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=68,entriesCount=1,lastEntry=(t:1, i:47)
datanode_6_1  | 2020-06-30 12:28:17,200 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=69,entriesCount=1,lastEntry=(t:1, i:48)
datanode_6_1  | 2020-06-30 12:28:17,213 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=70,entriesCount=1,lastEntry=(t:1, i:49)
datanode_6_1  | 2020-06-30 12:28:17,221 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=71,entriesCount=1,lastEntry=(t:1, i:50)
datanode_6_1  | 2020-06-30 12:28:19,768 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=73,entriesCount=1,lastEntry=(t:1, i:51)
datanode_6_1  | 2020-06-30 12:28:19,780 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=74,entriesCount=1,lastEntry=(t:1, i:52)
datanode_6_1  | 2020-06-30 12:28:19,792 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=75,entriesCount=1,lastEntry=(t:1, i:53)
datanode_6_1  | 2020-06-30 12:28:19,805 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=76,entriesCount=1,lastEntry=(t:1, i:54)
datanode_6_1  | 2020-06-30 12:28:22,615 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=78,entriesCount=1,lastEntry=(t:1, i:55)
datanode_6_1  | 2020-06-30 12:28:22,615 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=79,entriesCount=1,lastEntry=(t:1, i:56)
datanode_6_1  | 2020-06-30 12:28:22,615 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=80,entriesCount=1,lastEntry=(t:1, i:57)
datanode_6_1  | 2020-06-30 12:28:22,615 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=81,entriesCount=1,lastEntry=(t:1, i:58)
datanode_6_1  | 2020-06-30 12:28:25,758 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=83,entriesCount=1,lastEntry=(t:1, i:59)
datanode_6_1  | 2020-06-30 12:28:25,775 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=84,entriesCount=1,lastEntry=(t:1, i:60)
datanode_6_1  | 2020-06-30 12:28:25,775 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=85,entriesCount=1,lastEntry=(t:1, i:61)
datanode_6_1  | 2020-06-30 12:28:25,808 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=86,entriesCount=1,lastEntry=(t:1, i:62)
datanode_6_1  | 2020-06-30 12:28:28,339 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=88,entriesCount=1,lastEntry=(t:1, i:63)
datanode_6_1  | 2020-06-30 12:28:28,346 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=89,entriesCount=1,lastEntry=(t:1, i:64)
datanode_6_1  | 2020-06-30 12:28:28,346 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=90,entriesCount=1,lastEntry=(t:1, i:65)
datanode_6_1  | 2020-06-30 12:28:28,364 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=91,entriesCount=1,lastEntry=(t:1, i:66)
datanode_6_1  | 2020-06-30 12:28:30,967 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=93,entriesCount=1,lastEntry=(t:1, i:67)
datanode_6_1  | 2020-06-30 12:28:30,975 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=94,entriesCount=1,lastEntry=(t:1, i:68)
datanode_6_1  | 2020-06-30 12:28:30,986 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=95,entriesCount=1,lastEntry=(t:1, i:69)
datanode_6_1  | 2020-06-30 12:28:30,994 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=96,entriesCount=1,lastEntry=(t:1, i:70)
datanode_6_1  | 2020-06-30 12:28:33,525 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=98,entriesCount=1,lastEntry=(t:1, i:71)
datanode_6_1  | 2020-06-30 12:28:33,535 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=99,entriesCount=1,lastEntry=(t:1, i:72)
datanode_6_1  | 2020-06-30 12:28:33,548 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=100,entriesCount=1,lastEntry=(t:1, i:73)
datanode_6_1  | 2020-06-30 12:28:33,562 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=101,entriesCount=1,lastEntry=(t:1, i:74)
datanode_6_1  | 2020-06-30 12:28:36,699 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=103,entriesCount=1,lastEntry=(t:1, i:75)
datanode_6_1  | 2020-06-30 12:28:36,708 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=104,entriesCount=1,lastEntry=(t:1, i:76)
datanode_6_1  | 2020-06-30 12:28:36,725 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=105,entriesCount=1,lastEntry=(t:1, i:77)
datanode_6_1  | 2020-06-30 12:28:36,750 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=106,entriesCount=1,lastEntry=(t:1, i:78)
datanode_6_1  | 2020-06-30 12:28:42,035 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=109,entriesCount=1,lastEntry=(t:1, i:79)
datanode_6_1  | 2020-06-30 12:28:42,049 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=110,entriesCount=1,lastEntry=(t:1, i:80)
datanode_6_1  | 2020-06-30 12:28:42,057 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=111,entriesCount=1,lastEntry=(t:1, i:81)
datanode_6_1  | 2020-06-30 12:28:42,086 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=112,entriesCount=1,lastEntry=(t:1, i:82)
datanode_6_1  | 2020-06-30 12:28:44,706 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=114,entriesCount=1,lastEntry=(t:1, i:83)
datanode_6_1  | 2020-06-30 12:28:44,720 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=115,entriesCount=1,lastEntry=(t:1, i:84)
datanode_6_1  | 2020-06-30 12:28:44,732 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=116,entriesCount=1,lastEntry=(t:1, i:85)
datanode_6_1  | 2020-06-30 12:28:44,741 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=117,entriesCount=1,lastEntry=(t:1, i:86)
datanode_6_1  | 2020-06-30 12:28:47,718 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=119,entriesCount=1,lastEntry=(t:1, i:87)
datanode_6_1  | 2020-06-30 12:28:47,730 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=120,entriesCount=1,lastEntry=(t:1, i:88)
datanode_6_1  | 2020-06-30 12:28:47,741 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=121,entriesCount=1,lastEntry=(t:1, i:89)
datanode_6_1  | 2020-06-30 12:28:47,760 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=122,entriesCount=1,lastEntry=(t:1, i:90)
datanode_6_1  | 2020-06-30 12:28:50,299 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=124,entriesCount=1,lastEntry=(t:1, i:91)
datanode_6_1  | 2020-06-30 12:28:50,314 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=125,entriesCount=1,lastEntry=(t:1, i:92)
datanode_6_1  | 2020-06-30 12:28:50,320 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=126,entriesCount=1,lastEntry=(t:1, i:93)
datanode_6_1  | 2020-06-30 12:28:50,336 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=127,entriesCount=1,lastEntry=(t:1, i:94)
datanode_6_1  | 2020-06-30 12:28:52,892 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=129,entriesCount=1,lastEntry=(t:1, i:95)
datanode_6_1  | 2020-06-30 12:28:52,900 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=130,entriesCount=1,lastEntry=(t:1, i:96)
datanode_6_1  | 2020-06-30 12:28:52,926 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=131,entriesCount=1,lastEntry=(t:1, i:97)
datanode_6_1  | 2020-06-30 12:28:55,581 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=133,entriesCount=1,lastEntry=(t:1, i:98)
datanode_6_1  | 2020-06-30 12:28:55,583 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=134,entriesCount=1,lastEntry=(t:1, i:99)
datanode_6_1  | 2020-06-30 12:28:55,591 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=135,entriesCount=1,lastEntry=(t:1, i:100)
datanode_6_1  | 2020-06-30 12:28:55,602 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=136,entriesCount=1,lastEntry=(t:1, i:101)
datanode_6_1  | 2020-06-30 12:28:58,312 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=138,entriesCount=1,lastEntry=(t:1, i:102)
datanode_6_1  | 2020-06-30 12:28:58,314 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=139,entriesCount=1,lastEntry=(t:1, i:103)
datanode_6_1  | 2020-06-30 12:28:58,314 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=140,entriesCount=1,lastEntry=(t:1, i:104)
datanode_6_1  | 2020-06-30 12:28:58,314 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=141,entriesCount=1,lastEntry=(t:1, i:105)
datanode_6_1  | 2020-06-30 12:29:03,508 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=144,entriesCount=1,lastEntry=(t:1, i:106)
datanode_6_1  | 2020-06-30 12:29:03,516 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=145,entriesCount=1,lastEntry=(t:1, i:107)
datanode_6_1  | 2020-06-30 12:29:03,531 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=146,entriesCount=1,lastEntry=(t:1, i:108)
datanode_6_1  | 2020-06-30 12:29:03,537 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=147,entriesCount=1,lastEntry=(t:1, i:109)
datanode_6_1  | 2020-06-30 12:29:06,060 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=149,entriesCount=1,lastEntry=(t:1, i:110)
datanode_6_1  | 2020-06-30 12:29:06,065 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=150,entriesCount=1,lastEntry=(t:1, i:111)
datanode_6_1  | 2020-06-30 12:29:06,088 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=151,entriesCount=1,lastEntry=(t:1, i:112)
datanode_6_1  | 2020-06-30 12:29:06,096 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=152,entriesCount=1,lastEntry=(t:1, i:113)
datanode_6_1  | 2020-06-30 12:29:08,702 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=154,entriesCount=1,lastEntry=(t:1, i:114)
datanode_6_1  | 2020-06-30 12:29:08,710 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=155,entriesCount=1,lastEntry=(t:1, i:115)
datanode_6_1  | 2020-06-30 12:29:08,714 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=156,entriesCount=1,lastEntry=(t:1, i:116)
datanode_6_1  | 2020-06-30 12:29:11,586 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=158,entriesCount=1,lastEntry=(t:1, i:117)
datanode_6_1  | 2020-06-30 12:29:11,594 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=159,entriesCount=1,lastEntry=(t:1, i:118)
datanode_6_1  | 2020-06-30 12:29:11,598 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=160,entriesCount=1,lastEntry=(t:1, i:119)
datanode_6_1  | 2020-06-30 12:29:11,625 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=161,entriesCount=1,lastEntry=(t:1, i:120)
datanode_6_1  | 2020-06-30 12:29:19,409 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=165,entriesCount=1,lastEntry=(t:1, i:121)
datanode_6_1  | 2020-06-30 12:29:19,420 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=166,entriesCount=1,lastEntry=(t:1, i:122)
datanode_6_1  | 2020-06-30 12:29:19,468 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=167,entriesCount=1,lastEntry=(t:1, i:123)
datanode_6_1  | 2020-06-30 12:29:19,485 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=168,entriesCount=1,lastEntry=(t:1, i:124)
datanode_6_1  | 2020-06-30 12:29:22,499 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=170,entriesCount=1,lastEntry=(t:1, i:125)
datanode_6_1  | 2020-06-30 12:29:22,499 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=171,entriesCount=1,lastEntry=(t:1, i:126)
datanode_6_1  | 2020-06-30 12:29:22,672 [java.util.concurrent.ThreadPoolExecutor$Worker@3a116cf2[State = -1, empty queue]] WARN server.GrpcLogAppender: af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929->ae41103f-5e55-496f-aac5-65fab8cc3ad2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=172,entriesCount=1,lastEntry=(t:1, i:127)
datanode_6_1  | 2020-06-30 12:31:26,320 [Thread-204] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-16FFD83D3324->af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929, cid=213, seq=0, Watch-ALL_COMMITTED(130), Message:<EMPTY>, reply=RaftClientReply:client-16FFD83D3324->af137417-7801-4a96-9b21-1b6e75d3578d@group-A2D077235929, cid=213, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 213 and log index 130 is not yet replicated to ALL_COMMITTED, logIndex=130, commits[af137417-7801-4a96-9b21-1b6e75d3578d:c173, ae41103f-5e55-496f-aac5-65fab8cc3ad2:c127, 5d636ad6-6c45-4d25-921b-ebdea2d03333:c173]
