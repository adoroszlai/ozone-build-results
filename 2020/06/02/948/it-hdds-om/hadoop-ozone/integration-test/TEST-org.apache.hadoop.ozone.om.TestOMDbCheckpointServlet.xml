<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report.xsd" name="org.apache.hadoop.ozone.om.TestOMDbCheckpointServlet" time="120.34" tests="2" errors="2" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="ANSI_X3.4-1968"/>
    <property name="java.class.path" value="/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.6.0-SNAPSHOT/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.6.0-SNAPSHOT/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.10.3/jackson-annotations-2.10.3.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.6.0-cac3336-SNAPSHOT/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.4.0/ratis-thirdparty-misc-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.6.0-cac3336-SNAPSHOT/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.6.0-cac3336-SNAPSHOT/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.6.0-cac3336-SNAPSHOT/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.6.0-cac3336-SNAPSHOT/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/1.2.0/jaeger-client-1.2.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/1.2.0/jaeger-thrift-1.2.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.13.0/libthrift-0.13.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/4.2.2/okhttp-4.2.2.jar:/home/user/.m2/repository/com/squareup/okio/okio/2.2.2/okio-2.2.2.jar:/home/user/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.3.50/kotlin-stdlib-1.3.50.jar:/home/user/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.3.50/kotlin-stdlib-common-1.3.50.jar:/home/user/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/1.2.0/jaeger-core-1.2.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.2.0/jaeger-tracerresolver-1.2.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.6.0-SNAPSHOT/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-test-utils/0.6.0-SNAPSHOT/hadoop-hdds-test-utils-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/guava/guava/28.2-jre/guava-28.2-jre.jar:/home/user/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/user/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/checkerframework/checker-qual/2.10.0/checker-qual-2.10.0.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.6.0-SNAPSHOT/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-hadoop-dependency-server/0.6.0-SNAPSHOT/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.6.0-SNAPSHOT/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.6.4/rocksdbjni-6.6.4.jar:/home/user/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/user/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/user/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.10.3/jackson-datatype-jsr310-2.10.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.6.0-SNAPSHOT/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.1/hadoop-hdfs-client-3.2.1.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.6.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.2.1/hadoop-minikdc-3.2.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.6.0-SNAPSHOT/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.10.3/jackson-dataformat-xml-2.10.3.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.10.3/jackson-core-2.10.3.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.10.3/jackson-module-jaxb-annotations-2.10.3.jar:/home/user/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/user/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.6.0-SNAPSHOT/hadoop-ozone-csi-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.11.0/protobuf-java-util-3.11.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.6.0-SNAPSHOT/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.29.0/grpc-netty-1.29.0.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.29.0/grpc-core-1.29.0.jar:/home/user/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/user/.m2/repository/io/perfmark/perfmark-api/0.19.0/perfmark-api-0.19.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.48.Final/netty-codec-http2-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.29.0/grpc-protobuf-1.29.0.jar:/home/user/.m2/repository/io/grpc/grpc-api/1.29.0/grpc-api-1.29.0.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.29.0/grpc-context-1.29.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.18/animal-sniffer-annotations-1.18.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.17.0/proto-google-common-protos-1.17.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.29.0/grpc-protobuf-lite-1.29.0.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.29.0/grpc-stub-1.29.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.6.0-SNAPSHOT/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.6.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.2.5.RELEASE/spring-jdbc-5.2.5.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.2.5.RELEASE/spring-beans-5.2.5.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.2.5.RELEASE/spring-core-5.2.5.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.2.5.RELEASE/spring-jcl-5.2.5.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.2.5.RELEASE/spring-tx-5.2.5.RELEASE.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.6.0-SNAPSHOT/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-filesystem/0.6.0-SNAPSHOT/hadoop-ozone-filesystem-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-hadoop-dependency-client/0.6.0-SNAPSHOT/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-tools/0.6.0-SNAPSHOT/hadoop-ozone-tools-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1.jar:/home/user/.m2/repository/org/apache/ratis/ratis-tools/0.6.0-cac3336-SNAPSHOT/ratis-tools-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.6.0-cac3336-SNAPSHOT/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.6.0-cac3336-SNAPSHOT/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/com/amazonaws/aws-java-sdk-core/1.11.615/aws-java-sdk-core-1.11.615.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.10.3/jackson-dataformat-cbor-2.10.3.jar:/home/user/.m2/repository/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar:/home/user/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.11.615/aws-java-sdk-s3-1.11.615.jar:/home/user/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.11.615/aws-java-sdk-kms-1.11.615.jar:/home/user/.m2/repository/com/amazonaws/jmespath-java/1.11.615/jmespath-java-1.11.615.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.6.0-SNAPSHOT/hadoop-hdds-tools-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.6.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-core/1.19/jmh-core-1.19.jar:/home/user/.m2/repository/net/sf/jopt-simple/jopt-simple/4.6/jopt-simple-4.6.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-generator-annprocess/1.19/jmh-generator-annprocess-1.19.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.8.5/mockito-all-1.8.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.1/hadoop-auth-3.2.1.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/7.9/nimbus-jose-jwt-7.9.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.4.26.v20200117/jetty-server-9.4.26.v20200117.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.4.26.v20200117/jetty-http-9.4.26.v20200117.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.4.26.v20200117/jetty-io-9.4.26.v20200117.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.26.v20200117/jetty-webapp-9.4.26.v20200117.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.26.v20200117/jetty-xml-9.4.26.v20200117.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.26.v20200117/jetty-servlet-9.4.26.v20200117.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.4.26.v20200117/jetty-security-9.4.26.v20200117.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.1/hadoop-common-3.2.1.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.4.26.v20200117/jetty-util-9.4.26.v20200117.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.10.3/jackson-databind-2.10.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.6.0-SNAPSHOT/hadoop-hdds-server-scm-0.6.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.6.0-SNAPSHOT/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-hadoop-dependency-test/0.6.0-SNAPSHOT/hadoop-hdds-hadoop-dependency-test-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.1/hadoop-common-3.2.1-tests.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.26.v20200117/jetty-util-ajax-9.4.26.v20200117.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.1.48.Final/netty-all-4.1.48.Final.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.1/hadoop-distcp-3.2.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.1/hadoop-mapreduce-client-jobclient-3.2.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.1/hadoop-mapreduce-client-common-3.2.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.1/hadoop-yarn-common-3.2.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.1/hadoop-yarn-api-3.2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.10.3/jackson-jaxrs-json-provider-2.10.3.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.10.3/jackson-jaxrs-base-2.10.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.1/hadoop-yarn-client-3.2.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.1/hadoop-mapreduce-client-core-3.2.1.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.1/hadoop-annotations-3.2.1.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/jre/../lib/tools.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.1/hadoop-distcp-3.2.1-tests.jar:"/>
    <property name="java.vm.vendor" value="Oracle Corporation"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="user.timezone" value=""/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="user.country" value="US"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter5178215137537097251.jar /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/surefire 2020-06-02T22-40-03_939-jvmRun1 surefire1600866515971035162tmp surefire_62252699706188672458tmp"/>
    <property name="surefire.test.class.path" value="/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/classes:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-common/0.6.0-SNAPSHOT/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/user/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.6.0-SNAPSHOT/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/info/picocli/picocli/3.9.6/picocli-3.9.6.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.10.3/jackson-annotations-2.10.3.jar:/home/user/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/user/.m2/repository/org/apache/ratis/ratis-server/0.6.0-cac3336-SNAPSHOT/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/0.4.0/ratis-thirdparty-misc-0.4.0.jar:/home/user/.m2/repository/org/apache/ratis/ratis-client/0.6.0-cac3336-SNAPSHOT/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-metrics/0.6.0-cac3336-SNAPSHOT/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-netty/0.6.0-cac3336-SNAPSHOT/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-grpc/0.6.0-cac3336-SNAPSHOT/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.0/log4j-api-2.11.0.jar:/home/user/.m2/repository/org/apache/logging/log4j/log4j-core/2.11.0/log4j-core-2.11.0.jar:/home/user/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/user/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/user/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.60/bcpkix-jdk15on-1.60.jar:/home/user/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/user/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-client/1.2.0/jaeger-client-1.2.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-thrift/1.2.0/jaeger-thrift-1.2.0.jar:/home/user/.m2/repository/org/apache/thrift/libthrift/0.13.0/libthrift-0.13.0.jar:/home/user/.m2/repository/com/squareup/okhttp3/okhttp/4.2.2/okhttp-4.2.2.jar:/home/user/.m2/repository/com/squareup/okio/okio/2.2.2/okio-2.2.2.jar:/home/user/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.3.50/kotlin-stdlib-1.3.50.jar:/home/user/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.3.50/kotlin-stdlib-common-1.3.50.jar:/home/user/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-core/1.2.0/jaeger-core-1.2.0.jar:/home/user/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.2.0/jaeger-tracerresolver-1.2.0.jar:/home/user/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/user/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/user/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-client/0.6.0-SNAPSHOT/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-test-utils/0.6.0-SNAPSHOT/hadoop-hdds-test-utils-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/guava/guava/28.2-jre/guava-28.2-jre.jar:/home/user/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/user/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/user/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/user/.m2/repository/org/checkerframework/checker-qual/2.10.0/checker-qual-2.10.0.jar:/home/user/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/user/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/user/.m2/repository/commons-io/commons-io/2.5/commons-io-2.5.jar:/home/user/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/user/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/user/.m2/repository/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.6.0-SNAPSHOT/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-hadoop-dependency-server/0.6.0-SNAPSHOT/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-framework/0.6.0-SNAPSHOT/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/rocksdb/rocksdbjni/6.6.4/rocksdbjni-6.6.4.jar:/home/user/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/user/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/user/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.10.3/jackson-datatype-jsr310-2.10.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-docs/0.6.0-SNAPSHOT/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.1/hadoop-hdfs-client-3.2.1.jar:/home/user/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.60/bcprov-jdk15on-1.60.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.6.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.2.1/hadoop-minikdc-3.2.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/user/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/user/.m2/repository/org/slf4j/slf4j-log4j12/1.7.25/slf4j-log4j12-1.7.25.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-s3gateway/0.6.0-SNAPSHOT/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.27/jersey-container-servlet-core-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/external/javax.inject/2.5.0-b42/javax.inject-2.5.0-b42.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-common/2.27/jersey-common-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/user/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.1/javax.ws.rs-api-2.1.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.27/jersey-cdi1x-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.27/jersey-hk2-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-locator/2.5.0-b42/hk2-locator-2.5.0-b42.jar:/home/user/.m2/repository/org/javassist/javassist/3.22.0-CR2/javassist-3.22.0-CR2.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.5.0/jakarta.inject-2.5.0.jar:/home/user/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/user/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.4/jakarta.annotation-api-1.3.4.jar:/home/user/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.10.3/jackson-dataformat-xml-2.10.3.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.10.3/jackson-core-2.10.3.jar:/home/user/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.10.3/jackson-module-jaxb-annotations-2.10.3.jar:/home/user/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/home/user/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/user/.m2/repository/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/home/user/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/home/user/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/user/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/user/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/user/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-impl/2.3.0.1/jaxb-impl-2.3.0.1.jar:/home/user/.m2/repository/com/sun/xml/bind/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/user/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/user/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-csi/0.6.0-SNAPSHOT/hadoop-ozone-csi-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java-util/3.11.0/protobuf-java-util-3.11.0.jar:/home/user/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-config/0.6.0-SNAPSHOT/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/user/.m2/repository/io/grpc/grpc-netty/1.29.0/grpc-netty-1.29.0.jar:/home/user/.m2/repository/io/grpc/grpc-core/1.29.0/grpc-core-1.29.0.jar:/home/user/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/user/.m2/repository/io/perfmark/perfmark-api/0.19.0/perfmark-api-0.19.0.jar:/home/user/.m2/repository/io/netty/netty-codec-http2/4.1.48.Final/netty-codec-http2-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-codec/4.1.48.Final/netty-codec-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-handler/4.1.48.Final/netty-handler-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-http/4.1.48.Final/netty-codec-http-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-handler-proxy/4.1.48.Final/netty-handler-proxy-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-codec-socks/4.1.48.Final/netty-codec-socks-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-epoll/4.1.48.Final/netty-transport-native-epoll-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-common/4.1.48.Final/netty-common-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-buffer/4.1.48.Final/netty-buffer-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-transport/4.1.48.Final/netty-transport-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-resolver/4.1.48.Final/netty-resolver-4.1.48.Final.jar:/home/user/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.48.Final/netty-transport-native-unix-common-4.1.48.Final.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf/1.29.0/grpc-protobuf-1.29.0.jar:/home/user/.m2/repository/io/grpc/grpc-api/1.29.0/grpc-api-1.29.0.jar:/home/user/.m2/repository/io/grpc/grpc-context/1.29.0/grpc-context-1.29.0.jar:/home/user/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.18/animal-sniffer-annotations-1.18.jar:/home/user/.m2/repository/com/google/api/grpc/proto-google-common-protos/1.17.0/proto-google-common-protos-1.17.0.jar:/home/user/.m2/repository/io/grpc/grpc-protobuf-lite/1.29.0/grpc-protobuf-lite-1.29.0.jar:/home/user/.m2/repository/io/grpc/grpc-stub/1.29.0/grpc-stub-1.29.0.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-recon/0.6.0-SNAPSHOT/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-reconcodegen/0.6.0-SNAPSHOT/hadoop-ozone-reconcodegen-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/user/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/user/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/user/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/user/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.27/jersey-container-servlet-2.27.jar:/home/user/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-server/2.27/jersey-server-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/core/jersey-client/2.27/jersey-client-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.27/jersey-media-jaxb-2.27.jar:/home/user/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/user/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.27/jersey-media-json-jackson-2.27.jar:/home/user/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.27/jersey-entity-filtering-2.27.jar:/home/user/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/user/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/user/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/user/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/user/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/user/.m2/repository/org/springframework/spring-jdbc/5.2.5.RELEASE/spring-jdbc-5.2.5.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-beans/5.2.5.RELEASE/spring-beans-5.2.5.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-core/5.2.5.RELEASE/spring-core-5.2.5.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-jcl/5.2.5.RELEASE/spring-jcl-5.2.5.RELEASE.jar:/home/user/.m2/repository/org/springframework/spring-tx/5.2.5.RELEASE/spring-tx-5.2.5.RELEASE.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-client/0.6.0-SNAPSHOT/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-filesystem/0.6.0-SNAPSHOT/hadoop-ozone-filesystem-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-hadoop-dependency-client/0.6.0-SNAPSHOT/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-tools/0.6.0-SNAPSHOT/hadoop-ozone-tools-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1.jar:/home/user/.m2/repository/org/apache/ratis/ratis-tools/0.6.0-cac3336-SNAPSHOT/ratis-tools-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-proto/0.6.0-cac3336-SNAPSHOT/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/ratis/ratis-common/0.6.0-cac3336-SNAPSHOT/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/home/user/.m2/repository/com/amazonaws/aws-java-sdk-core/1.11.615/aws-java-sdk-core-1.11.615.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/home/user/.m2/repository/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/home/user/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/user/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.10.3/jackson-dataformat-cbor-2.10.3.jar:/home/user/.m2/repository/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar:/home/user/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.11.615/aws-java-sdk-s3-1.11.615.jar:/home/user/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.11.615/aws-java-sdk-kms-1.11.615.jar:/home/user/.m2/repository/com/amazonaws/jmespath-java/1.11.615/jmespath-java-1.11.615.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-tools/0.6.0-SNAPSHOT/hadoop-hdds-tools-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/user/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-ozone-ozone-manager/0.6.0-SNAPSHOT/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/junit/junit/4.11/junit-4.11.jar:/home/user/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-core/1.19/jmh-core-1.19.jar:/home/user/.m2/repository/net/sf/jopt-simple/jopt-simple/4.6/jopt-simple-4.6.jar:/home/user/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/user/.m2/repository/org/openjdk/jmh/jmh-generator-annprocess/1.19/jmh-generator-annprocess-1.19.jar:/home/user/.m2/repository/org/mockito/mockito-all/1.8.5/mockito-all-1.8.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-auth/3.2.1/hadoop-auth-3.2.1.jar:/home/user/.m2/repository/com/nimbusds/nimbus-jose-jwt/7.9/nimbus-jose-jwt-7.9.jar:/home/user/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/user/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/user/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/user/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/user/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/user/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/user/.m2/repository/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar:/home/user/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/user/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/user/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-server/9.4.26.v20200117/jetty-server-9.4.26.v20200117.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-http/9.4.26.v20200117/jetty-http-9.4.26.v20200117.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-io/9.4.26.v20200117/jetty-io-9.4.26.v20200117.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.26.v20200117/jetty-webapp-9.4.26.v20200117.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.26.v20200117/jetty-xml-9.4.26.v20200117.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.26.v20200117/jetty-servlet-9.4.26.v20200117.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-security/9.4.26.v20200117/jetty-security-9.4.26.v20200117.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.1/hadoop-common-3.2.1.jar:/home/user/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar:/home/user/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/user/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/user/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/user/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/user/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/user/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/user/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/user/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/user/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/user/.m2/repository/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar:/home/user/.m2/repository/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar:/home/user/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/user/.m2/repository/org/slf4j/jul-to-slf4j/1.7.25/jul-to-slf4j-1.7.25.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util/9.4.26.v20200117/jetty-util-9.4.26.v20200117.jar:/home/user/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.10.3/jackson-databind-2.10.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-server-scm/0.6.0-SNAPSHOT/hadoop-hdds-server-scm-0.6.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-common/0.6.0-SNAPSHOT/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/home/user/.m2/repository/org/yaml/snakeyaml/1.16/snakeyaml-1.16.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-hadoop-dependency-test/0.6.0-SNAPSHOT/hadoop-hdds-hadoop-dependency-test-0.6.0-SNAPSHOT.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-common/3.2.1/hadoop-common-3.2.1-tests.jar:/home/user/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar:/home/user/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.26.v20200117/jetty-util-ajax-9.4.26.v20200117.jar:/home/user/.m2/repository/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/home/user/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/user/.m2/repository/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar:/home/user/.m2/repository/io/netty/netty-all/4.1.48.Final/netty-all-4.1.48.Final.jar:/home/user/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/user/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.1/hadoop-distcp-3.2.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.1/hadoop-mapreduce-client-jobclient-3.2.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.1/hadoop-mapreduce-client-common-3.2.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.2.1/hadoop-yarn-common-3.2.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.2.1/hadoop-yarn-api-3.2.1.jar:/home/user/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/user/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.10.3/jackson-jaxrs-json-provider-2.10.3.jar:/home/user/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.10.3/jackson-jaxrs-base-2.10.3.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.2.1/hadoop-yarn-client-3.2.1.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.1/hadoop-mapreduce-client-core-3.2.1.jar:/home/user/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/user/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/user/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/user/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-annotations/3.2.1/hadoop-annotations-3.2.1.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/jre/../lib/tools.jar:/home/user/.m2/repository/org/apache/hadoop/hadoop-distcp/3.2.1/hadoop-distcp-3.2.1-tests.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/user"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/jre"/>
    <property name="java.security.krb5.conf" value="/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/krb5.conf"/>
    <property name="basedir" value="/github/workspace/mnt/ozone/hadoop-ozone/integration-test"/>
    <property name="file.separator" value="/"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.real.class.path" value="/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter5178215137537097251.jar:/home/user/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar"/>
    <property name="hadoop.log.dir" value="/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/jre/lib/resources.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/jre/lib/rt.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/jre/lib/jsse.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/jre/lib/jce.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/jre/lib/charsets.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/jre/lib/jfr.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/jre/classes"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_232-b09"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="user.name" value="jenkins1001"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="5.3.0-1020-azure"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="ANSI_X3.4-1968"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/user/.m2/repository"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.version" value="1.8.0_232"/>
    <property name="user.dir" value="/github/workspace/mnt/ozone/hadoop-ozone/integration-test"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="test.build.classes" value="/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="hadoop.tmp.dir" value="/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/tmp"/>
    <property name="java.library.path" value="/usr/lib:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vendor" value="Oracle Corporation"/>
    <property name="java.vm.version" value="25.232-b09"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.el7_7.x86_64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testWriteCheckpointToOutputStream" classname="org.apache.hadoop.ozone.om.TestOMDbCheckpointServlet" time="60.041">
    <error message="test timed out after 60000 milliseconds" type="java.lang.Exception">java.lang.Exception: test timed out after 60000 milliseconds
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:218)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.waitForClusterToBeReady(MiniOzoneClusterImpl.java:172)
	at org.apache.hadoop.ozone.om.TestOMDbCheckpointServlet.init(TestOMDbCheckpointServlet.java:97)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2020-06-02 23:11:18,963 [Thread-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 23:11:19,092 [Thread-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 23:11:19,246 [Thread-1] WARN  db.DBStoreBuilder (DBStoreBuilder.java:createDBStoreBuilder(277)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 23:11:19,442 [Thread-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(126)) - Loading file from sun.misc.CompoundEnumeration@65a9d941
2020-06-02 23:11:19,444 [Thread-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(172)) - Loading network topology layer schema file
2020-06-02 23:11:19,510 [Thread-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(73)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2020-06-02 23:11:19,510 [Thread-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(73)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2020-06-02 23:11:19,514 [Thread-1] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2020-06-02 23:11:19,626 [Thread-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(60)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2020-06-02 23:11:19,657 [Thread-1] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(158)) - No pipeline exists in current db
2020-06-02 23:11:19,743 [Thread-1] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:<init>(89)) - Total pipeline count is 0, healthy pipeline threshold count is 0
2020-06-02 23:11:19,749 [Thread-1] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:<init>(79)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2020-06-02 23:11:19,807 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
2020-06-02 23:11:20,198 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 23:11:20,223 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 23:11:20,265 [Listener at 0.0.0.0/33535] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 23:11:20,267 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 23:11:20,285 [Listener at 0.0.0.0/41471] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 23:11:20,286 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 23:11:20,308 [Listener at 0.0.0.0/45471] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for scm at: http://0.0.0.0:0
2020-06-02 23:11:20,308 [Listener at 0.0.0.0/45471] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 23:11:20,334 [Listener at 0.0.0.0/45471] INFO  util.log (Log.java:initialized(169)) - Logging initialized @2400ms to org.eclipse.jetty.util.log.Slf4jLog
2020-06-02 23:11:20,462 [Listener at 0.0.0.0/45471] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:11:20,477 [Listener at 0.0.0.0/45471] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 23:11:20,482 [Listener at 0.0.0.0/45471] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 23:11:20,484 [Listener at 0.0.0.0/45471] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2020-06-02 23:11:20,484 [Listener at 0.0.0.0/45471] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 23:11:20,484 [Listener at 0.0.0.0/45471] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 23:11:20,527 [Listener at 0.0.0.0/45471] INFO  server.StorageContainerManager (StorageContainerManager.java:start(781)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:45471
2020-06-02 23:11:20,581 [Listener at 0.0.0.0/45471] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2020-06-02 23:11:20,594 [Listener at 0.0.0.0/45471] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-06-02 23:11:20,594 [Listener at 0.0.0.0/45471] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2020-06-02 23:11:20,825 [Listener at 0.0.0.0/45471] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(157)) - RPC server for Client  is listening at /0.0.0.0:45471
2020-06-02 23:11:20,825 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 23:11:20,826 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 23:11:20,829 [Listener at 0.0.0.0/45471] INFO  server.StorageContainerManager (StorageContainerManager.java:start(793)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:41471
2020-06-02 23:11:20,830 [Listener at 0.0.0.0/45471] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(149)) - RPC server for Block Protocol is listening at /0.0.0.0:41471
2020-06-02 23:11:20,830 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 23:11:20,831 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 23:11:20,855 [Listener at 0.0.0.0/45471] INFO  server.StorageContainerManager (StorageContainerManager.java:start(799)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:33535
2020-06-02 23:11:20,855 [Listener at 0.0.0.0/45471] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(172)) - RPC server for DataNodes is listening at /0.0.0.0:33535
2020-06-02 23:11:20,857 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 23:11:20,857 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 23:11:20,862 [Listener at 0.0.0.0/45471] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 38345
2020-06-02 23:11:20,864 [Listener at 0.0.0.0/45471] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 23:11:20,893 [Listener at 0.0.0.0/45471] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 23:11:20,893 [Listener at 0.0.0.0/45471] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 23:11:20,895 [Listener at 0.0.0.0/45471] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-06-02 23:11:20,920 [Listener at 0.0.0.0/45471] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:11:20,924 [Listener at 0.0.0.0/45471] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@6878c095{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 23:11:20,925 [Listener at 0.0.0.0/45471] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@5684f55e{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2020-06-02 23:11:20,977 [Listener at 0.0.0.0/45471] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@508926e2{scm,/,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2020-06-02 23:11:20,990 [Listener at 0.0.0.0/45471] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@6841356f{HTTP/1.1,[http/1.1]}{0.0.0.0:38345}
2020-06-02 23:11:20,991 [Listener at 0.0.0.0/45471] INFO  server.Server (Server.java:doStart(399)) - Started @3057ms
2020-06-02 23:11:20,993 [Listener at 0.0.0.0/45471] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2020-06-02 23:11:20,993 [Listener at 0.0.0.0/45471] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2020-06-02 23:11:20,999 [Listener at 0.0.0.0/45471] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of scm listening at http://0.0.0.0:38345
2020-06-02 23:11:21,008 [Listener at 0.0.0.0/45471] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 23:11:21,022 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6e11a059] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 23:11:21,112 [Listener at 0.0.0.0/45471] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(104)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2020-06-02 23:11:21,114 [Listener at 0.0.0.0/45471] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(207)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2020-06-02 23:11:21,114 [Listener at 0.0.0.0/45471] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(237)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2020-06-02 23:11:21,116 [Listener at 0.0.0.0/45471] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 23:11:21,117 [Listener at 0.0.0.0/45471] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 23:11:21,864 [Listener at 0.0.0.0/45471] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 23:11:21,995 [Listener at 0.0.0.0/45471] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 23:11:21,997 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 23:11:22,031 [Listener at 127.0.0.1/45129] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2020-06-02 23:11:22,033 [Listener at 127.0.0.1/45129] INFO  om.OzoneManager (OzoneManager.java:start(1097)) - OzoneManager RPC server is listening at localhost/127.0.0.1:45129
2020-06-02 23:11:22,055 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 23:11:22,055 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 23:11:22,066 [Listener at 127.0.0.1/45129] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2020-06-02 23:11:22,067 [Listener at 127.0.0.1/45129] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 23:11:22,068 [Listener at 127.0.0.1/45129] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:11:22,069 [Listener at 127.0.0.1/45129] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 23:11:22,070 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 23:11:22,071 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
2020-06-02 23:11:22,071 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 23:11:22,071 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 23:11:22,075 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 39163
2020-06-02 23:11:22,075 [Listener at 127.0.0.1/45129] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 23:11:22,077 [Listener at 127.0.0.1/45129] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 23:11:22,077 [Listener at 127.0.0.1/45129] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 23:11:22,077 [Listener at 127.0.0.1/45129] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-06-02 23:11:22,078 [Listener at 127.0.0.1/45129] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:11:22,079 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@1b7c5f61{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 23:11:22,079 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@70231df2{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2020-06-02 23:11:22,084 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@4fdad8ae{ozoneManager,/,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2020-06-02 23:11:22,087 [Listener at 127.0.0.1/45129] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@15c0808f{HTTP/1.1,[http/1.1]}{0.0.0.0:39163}
2020-06-02 23:11:22,087 [Listener at 127.0.0.1/45129] INFO  server.Server (Server.java:doStart(399)) - Started @4153ms
2020-06-02 23:11:22,087 [Listener at 127.0.0.1/45129] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 23:11:22,092 [Listener at 127.0.0.1/45129] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of ozoneManager listening at http://0.0.0.0:39163
2020-06-02 23:11:22,103 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@59e2587e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 23:11:22,227 [Listener at 127.0.0.1/45129] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2020-06-02 23:11:22,230 [Listener at 127.0.0.1/45129] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-06-02 23:11:22,235 [Listener at 127.0.0.1/45129] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(205)) - HddsDatanodeService host:cc5e24879e7f ip:172.17.0.2
2020-06-02 23:11:22,306 [Listener at 127.0.0.1/45129] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-06-02 23:11:22,309 [Listener at 127.0.0.1/45129] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(181)) - Added Volume : /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data-0/containers/hdds to VolumeSet
2020-06-02 23:11:22,310 [Listener at 127.0.0.1/45129] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data-0/containers/hdds
2020-06-02 23:11:22,333 [Listener at 127.0.0.1/45129] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data-0/containers/hdds
2020-06-02 23:11:22,495 [Listener at 127.0.0.1/45129] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-06-02 23:11:22,556 [Listener at 127.0.0.1/45129] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-06-02 23:11:22,560 [Listener at 127.0.0.1/45129] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-06-02 23:11:22,561 [Listener at 127.0.0.1/45129] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-06-02 23:11:22,562 [Listener at 127.0.0.1/45129] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:11:22,563 [Listener at 127.0.0.1/45129] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-06-02 23:11:22,564 [Listener at 127.0.0.1/45129] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 23:11:22,732 [Listener at 127.0.0.1/45129] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis] (custom)
2020-06-02 23:11:22,829 [Listener at 127.0.0.1/45129] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-06-02 23:11:22,829 [Listener at 127.0.0.1/45129] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 23:11:22,830 [Listener at 127.0.0.1/45129] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:11:22,831 [Listener at 127.0.0.1/45129] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 23:11:22,832 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 23:11:22,833 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
2020-06-02 23:11:22,833 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 23:11:22,833 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 23:11:22,834 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 38503
2020-06-02 23:11:22,834 [Listener at 127.0.0.1/45129] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 23:11:22,841 [Listener at 127.0.0.1/45129] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 23:11:22,841 [Listener at 127.0.0.1/45129] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 23:11:22,842 [Listener at 127.0.0.1/45129] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-06-02 23:11:22,843 [Listener at 127.0.0.1/45129] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:11:22,843 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@6a3a1654{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 23:11:22,844 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@12a1a72e{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-06-02 23:11:22,875 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@2abde235{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-38503-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-9181381057137204788.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 23:11:22,877 [Listener at 127.0.0.1/45129] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@111c78fe{HTTP/1.1,[http/1.1]}{0.0.0.0:38503}
2020-06-02 23:11:22,877 [Listener at 127.0.0.1/45129] INFO  server.Server (Server.java:doStart(399)) - Started @4944ms
2020-06-02 23:11:22,877 [Listener at 127.0.0.1/45129] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 23:11:22,897 [Listener at 127.0.0.1/45129] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of hddsDatanode listening at http://0.0.0.0:38503
2020-06-02 23:11:22,899 [Listener at 127.0.0.1/45129] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-06-02 23:11:22,900 [Listener at 127.0.0.1/45129] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(205)) - HddsDatanodeService host:cc5e24879e7f ip:172.17.0.2
2020-06-02 23:11:22,904 [Listener at 127.0.0.1/45129] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-06-02 23:11:22,905 [Listener at 127.0.0.1/45129] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(181)) - Added Volume : /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data-0/containers/hdds to VolumeSet
2020-06-02 23:11:22,905 [Listener at 127.0.0.1/45129] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data-0/containers/hdds
2020-06-02 23:11:22,906 [Listener at 127.0.0.1/45129] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data-0/containers/hdds
2020-06-02 23:11:22,937 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@50282fb5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 23:11:22,942 [Listener at 127.0.0.1/45129] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-06-02 23:11:22,943 [Listener at 127.0.0.1/45129] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-06-02 23:11:22,943 [Listener at 127.0.0.1/45129] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-06-02 23:11:22,944 [Listener at 127.0.0.1/45129] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-06-02 23:11:22,944 [Listener at 127.0.0.1/45129] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:11:22,945 [Listener at 127.0.0.1/45129] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-06-02 23:11:22,945 [Listener at 127.0.0.1/45129] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 23:11:22,946 [Listener at 127.0.0.1/45129] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis] (custom)
2020-06-02 23:11:22,955 [Listener at 127.0.0.1/45129] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-06-02 23:11:22,955 [Listener at 127.0.0.1/45129] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 23:11:22,956 [Listener at 127.0.0.1/45129] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:11:22,961 [Listener at 127.0.0.1/45129] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 23:11:22,962 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 23:11:22,963 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
2020-06-02 23:11:22,963 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 23:11:22,963 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 23:11:22,964 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 42541
2020-06-02 23:11:22,964 [Listener at 127.0.0.1/45129] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 23:11:23,021 [Listener at 127.0.0.1/45129] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 23:11:23,022 [Listener at 127.0.0.1/45129] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 23:11:23,022 [Listener at 127.0.0.1/45129] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-06-02 23:11:23,029 [Listener at 127.0.0.1/45129] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:11:23,034 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@7b76ea62{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 23:11:23,034 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@51d25e0d{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-06-02 23:11:23,048 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(145)) - DatanodeDetails is persisted to /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/meta/datanode.id
2020-06-02 23:11:23,071 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@776b1332{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-42541-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-8006147680303686670.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 23:11:23,073 [Listener at 127.0.0.1/45129] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@6471a1c6{HTTP/1.1,[http/1.1]}{0.0.0.0:42541}
2020-06-02 23:11:23,073 [Listener at 127.0.0.1/45129] INFO  server.Server (Server.java:doStart(399)) - Started @5140ms
2020-06-02 23:11:23,074 [Listener at 127.0.0.1/45129] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 23:11:23,078 [Listener at 127.0.0.1/45129] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of hddsDatanode listening at http://0.0.0.0:42541
2020-06-02 23:11:23,079 [Listener at 127.0.0.1/45129] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-06-02 23:11:23,080 [Listener at 127.0.0.1/45129] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(205)) - HddsDatanodeService host:cc5e24879e7f ip:172.17.0.2
2020-06-02 23:11:23,091 [Listener at 127.0.0.1/45129] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-06-02 23:11:23,091 [Listener at 127.0.0.1/45129] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(181)) - Added Volume : /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data-0/containers/hdds to VolumeSet
2020-06-02 23:11:23,091 [Listener at 127.0.0.1/45129] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data-0/containers/hdds
2020-06-02 23:11:23,092 [Listener at 127.0.0.1/45129] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data-0/containers/hdds
2020-06-02 23:11:23,112 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6a617660] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 23:11:23,122 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(145)) - DatanodeDetails is persisted to /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/meta/datanode.id
2020-06-02 23:11:23,125 [Listener at 127.0.0.1/45129] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-06-02 23:11:23,126 [Listener at 127.0.0.1/45129] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-06-02 23:11:23,126 [Listener at 127.0.0.1/45129] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-06-02 23:11:23,126 [Listener at 127.0.0.1/45129] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-06-02 23:11:23,127 [Listener at 127.0.0.1/45129] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:11:23,127 [Listener at 127.0.0.1/45129] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-06-02 23:11:23,127 [Listener at 127.0.0.1/45129] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 23:11:23,128 [Listener at 127.0.0.1/45129] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis] (custom)
2020-06-02 23:11:23,136 [Listener at 127.0.0.1/45129] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-06-02 23:11:23,136 [Listener at 127.0.0.1/45129] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 23:11:23,139 [Listener at 127.0.0.1/45129] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:11:23,139 [Listener at 127.0.0.1/45129] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 23:11:23,140 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 23:11:23,142 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
2020-06-02 23:11:23,142 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 23:11:23,142 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 23:11:23,143 [Listener at 127.0.0.1/45129] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 41283
2020-06-02 23:11:23,143 [Listener at 127.0.0.1/45129] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 23:11:23,145 [Listener at 127.0.0.1/45129] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 23:11:23,146 [Listener at 127.0.0.1/45129] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 23:11:23,146 [Listener at 127.0.0.1/45129] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-06-02 23:11:23,147 [Listener at 127.0.0.1/45129] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:11:23,148 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@1c0bb9ca{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 23:11:23,148 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@6b9d527a{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-06-02 23:11:23,180 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@59427816{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-41283-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-2170623972209786545.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 23:11:23,183 [Listener at 127.0.0.1/45129] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@55123277{HTTP/1.1,[http/1.1]}{0.0.0.0:41283}
2020-06-02 23:11:23,183 [Listener at 127.0.0.1/45129] INFO  server.Server (Server.java:doStart(399)) - Started @5250ms
2020-06-02 23:11:23,183 [Listener at 127.0.0.1/45129] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 23:11:23,188 [Listener at 127.0.0.1/45129] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of hddsDatanode listening at http://0.0.0.0:41283
2020-06-02 23:11:23,189 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 23:11:23,189 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:23,197 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@644af14d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 23:11:23,202 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(145)) - DatanodeDetails is persisted to /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/meta/datanode.id
2020-06-02 23:11:24,189 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 23:11:24,190 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:25,000 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-06-02 23:11:25,001 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-06-02 23:11:25,001 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(425)) - Starting XceiverServerRatis 64cbb9bc-55ad-4bd6-90d7-16706f0bd234 at port 0
2020-06-02 23:11:25,015 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: start RPC server
2020-06-02 23:11:25,068 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(159)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: GrpcService started, listening on 0.0.0.0/0.0.0.0:38703
2020-06-02 23:11:25,069 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(437)) - XceiverServerRatis 64cbb9bc-55ad-4bd6-90d7-16706f0bd234 is started using port 38703
2020-06-02 23:11:25,072 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 64cbb9bc-55ad-4bd6-90d7-16706f0bd234 is started using port 45079
2020-06-02 23:11:25,116 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-06-02 23:11:25,119 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-06-02 23:11:25,119 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(425)) - Starting XceiverServerRatis cb97469d-781c-49b1-b566-b9439314fa8f at port 0
2020-06-02 23:11:25,121 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - cb97469d-781c-49b1-b566-b9439314fa8f: start RPC server
2020-06-02 23:11:25,129 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(159)) - cb97469d-781c-49b1-b566-b9439314fa8f: GrpcService started, listening on 0.0.0.0/0.0.0.0:38983
2020-06-02 23:11:25,130 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(437)) - XceiverServerRatis cb97469d-781c-49b1-b566-b9439314fa8f is started using port 38983
2020-06-02 23:11:25,132 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc cb97469d-781c-49b1-b566-b9439314fa8f is started using port 43955
2020-06-02 23:11:25,190 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 23:11:25,190 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:25,201 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-06-02 23:11:25,202 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-06-02 23:11:25,202 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(425)) - Starting XceiverServerRatis ea1e16a2-08f2-4e20-9425-d71c7ab3efe9 at port 0
2020-06-02 23:11:25,204 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: start RPC server
2020-06-02 23:11:25,215 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(159)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: GrpcService started, listening on 0.0.0.0/0.0.0.0:44223
2020-06-02 23:11:25,215 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(437)) - XceiverServerRatis ea1e16a2-08f2-4e20-9425-d71c7ab3efe9 is started using port 44223
2020-06-02 23:11:25,218 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc ea1e16a2-08f2-4e20-9425-d71c7ab3efe9 is started using port 35767
2020-06-02 23:11:26,191 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 23:11:26,191 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:26,965 [IPC Server handler 1 on default port 33535] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/64cbb9bc-55ad-4bd6-90d7-16706f0bd234
2020-06-02 23:11:26,966 [IPC Server handler 1 on default port 33535] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 64cbb9bc-55ad-4bd6-90d7-16706f0bd234{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}
2020-06-02 23:11:26,970 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - ContainerSafeModeRule rule is successfully validated
2020-06-02 23:11:26,971 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2020-06-02 23:11:26,971 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - DataNodeSafeModeRule rule is successfully validated
2020-06-02 23:11:26,971 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(241)) - All SCM safe mode pre check rules have passed
2020-06-02 23:11:26,982 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=7e7fc930-ceec-4c3e-aa3b-5dd255c8b606 to datanode:64cbb9bc-55ad-4bd6-90d7-16706f0bd234
2020-06-02 23:11:26,995 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 7e7fc930-ceec-4c3e-aa3b-5dd255c8b606, Nodes: 64cbb9bc-55ad-4bd6-90d7-16706f0bd234{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T23:11:26.979Z]
2020-06-02 23:11:26,998 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 1 nodes. Healthy nodes 1
2020-06-02 23:11:26,998 [RatisPipelineUtilsThread] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(133)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2020-06-02 23:11:26,998 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2020-06-02 23:11:27,115 [IPC Server handler 0 on default port 33535] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/cb97469d-781c-49b1-b566-b9439314fa8f
2020-06-02 23:11:27,115 [IPC Server handler 0 on default port 33535] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : cb97469d-781c-49b1-b566-b9439314fa8f{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}
2020-06-02 23:11:27,116 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - ContainerSafeModeRule rule is successfully validated
2020-06-02 23:11:27,116 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - DataNodeSafeModeRule rule is successfully validated
2020-06-02 23:11:27,117 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=2c05d2c6-9e37-4981-a88d-b4b248d0a7e8 to datanode:cb97469d-781c-49b1-b566-b9439314fa8f
2020-06-02 23:11:27,118 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 2c05d2c6-9e37-4981-a88d-b4b248d0a7e8, Nodes: cb97469d-781c-49b1-b566-b9439314fa8f{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T23:11:27.117Z]
2020-06-02 23:11:27,119 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
2020-06-02 23:11:27,119 [RatisPipelineUtilsThread] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(133)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2020-06-02 23:11:27,119 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2020-06-02 23:11:27,191 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 2 of 3 DN Heartbeats.
2020-06-02 23:11:27,192 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:27,200 [IPC Server handler 2 on default port 33535] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/ea1e16a2-08f2-4e20-9425-d71c7ab3efe9
2020-06-02 23:11:27,200 [IPC Server handler 2 on default port 33535] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : ea1e16a2-08f2-4e20-9425-d71c7ab3efe9{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}
2020-06-02 23:11:27,201 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=6d7a0520-e2c2-43e9-bd7d-a03b68a52862 to datanode:ea1e16a2-08f2-4e20-9425-d71c7ab3efe9
2020-06-02 23:11:27,201 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - ContainerSafeModeRule rule is successfully validated
2020-06-02 23:11:27,201 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - DataNodeSafeModeRule rule is successfully validated
2020-06-02 23:11:27,201 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 6d7a0520-e2c2-43e9-bd7d-a03b68a52862, Nodes: ea1e16a2-08f2-4e20-9425-d71c7ab3efe9{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T23:11:27.201Z]
2020-06-02 23:11:27,202 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
2020-06-02 23:11:27,207 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=942268b7-bff6-4625-9a57-94413d62f314 to datanode:64cbb9bc-55ad-4bd6-90d7-16706f0bd234
2020-06-02 23:11:27,207 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=942268b7-bff6-4625-9a57-94413d62f314 to datanode:cb97469d-781c-49b1-b566-b9439314fa8f
2020-06-02 23:11:27,207 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=942268b7-bff6-4625-9a57-94413d62f314 to datanode:ea1e16a2-08f2-4e20-9425-d71c7ab3efe9
2020-06-02 23:11:27,208 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 942268b7-bff6-4625-9a57-94413d62f314, Nodes: 64cbb9bc-55ad-4bd6-90d7-16706f0bd234{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}cb97469d-781c-49b1-b566-b9439314fa8f{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}ea1e16a2-08f2-4e20-9425-d71c7ab3efe9{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T23:11:27.207Z]
2020-06-02 23:11:27,208 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
2020-06-02 23:11:28,192 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:28,193 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:29,193 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:29,193 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:29,957 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: addNew group-5DD255C8B606:[64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703] returns group-5DD255C8B606:java.util.concurrent.CompletableFuture@37241468[Not completed]
2020-06-02 23:11:29,985 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: new RaftServerImpl for group-5DD255C8B606:[64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703] with ContainerStateMachine:uninitialized
2020-06-02 23:11:29,987 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 23:11:29,988 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 23:11:29,988 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 23:11:29,992 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 23:11:29,994 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:11:30,000 [pool-35-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606: ConfigurationManager, init=-1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703], old=null, confs=<EMPTY_MAP>
2020-06-02 23:11:30,000 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis] (custom)
2020-06-02 23:11:30,005 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 23:11:30,006 [pool-35-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis/7e7fc930-ceec-4c3e-aa3b-5dd255c8b606 does not exist. Creating ...
2020-06-02 23:11:30,011 [pool-35-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis/7e7fc930-ceec-4c3e-aa3b-5dd255c8b606/in_use.lock acquired by nodename 18775@cc5e24879e7f
2020-06-02 23:11:30,014 [pool-35-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis/7e7fc930-ceec-4c3e-aa3b-5dd255c8b606 has been successfully formatted.
2020-06-02 23:11:30,019 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(378)) - Unable to start the DatanodeState Machine
java.io.IOException: Unable to finish the execution.
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:375)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:212)
	... 2 more
2020-06-02 23:11:30,020 [pool-35-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-5DD255C8B606: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 23:11:30,021 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 23:11:30,023 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 23:11:30,028 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 23:11:30,028 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:11:30,031 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:11:30,034 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.64cbb9bc-55ad-4bd6-90d7-16706f0bd234
2020-06-02 23:11:30,047 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 23:11:30,051 [pool-35-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis/7e7fc930-ceec-4c3e-aa3b-5dd255c8b606
2020-06-02 23:11:30,059 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 23:11:30,060 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 23:11:30,061 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:11:30,061 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 23:11:30,062 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 23:11:30,063 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 23:11:30,064 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 23:11:30,064 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 23:11:30,065 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 23:11:30,077 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 23:11:30,083 [pool-35-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 23:11:30,093 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 23:11:30,094 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 23:11:30,095 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 23:11:30,099 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 23:11:30,100 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 23:11:30,118 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - cb97469d-781c-49b1-b566-b9439314fa8f: addNew group-B4B248D0A7E8:[cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983] returns group-B4B248D0A7E8:java.util.concurrent.CompletableFuture@311777a2[Not completed]
2020-06-02 23:11:30,132 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - cb97469d-781c-49b1-b566-b9439314fa8f: new RaftServerImpl for group-B4B248D0A7E8:[cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983] with ContainerStateMachine:uninitialized
2020-06-02 23:11:30,137 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 23:11:30,137 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 23:11:30,138 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 23:11:30,138 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 23:11:30,139 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:11:30,139 [pool-51-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8: ConfigurationManager, init=-1: [cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null, confs=<EMPTY_MAP>
2020-06-02 23:11:30,139 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis] (custom)
2020-06-02 23:11:30,140 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 23:11:30,140 [pool-51-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis/2c05d2c6-9e37-4981-a88d-b4b248d0a7e8 does not exist. Creating ...
2020-06-02 23:11:30,142 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606
2020-06-02 23:11:30,143 [pool-51-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis/2c05d2c6-9e37-4981-a88d-b4b248d0a7e8/in_use.lock acquired by nodename 18775@cc5e24879e7f
2020-06-02 23:11:30,146 [pool-51-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis/2c05d2c6-9e37-4981-a88d-b4b248d0a7e8 has been successfully formatted.
2020-06-02 23:11:30,147 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(378)) - Unable to start the DatanodeState Machine
java.io.IOException: Unable to finish the execution.
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:375)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:212)
	... 2 more
2020-06-02 23:11:30,147 [pool-51-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-B4B248D0A7E8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 23:11:30,148 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 23:11:30,148 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 23:11:30,148 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 23:11:30,148 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:11:30,148 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:11:30,148 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.cb97469d-781c-49b1-b566-b9439314fa8f
2020-06-02 23:11:30,151 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 23:11:30,151 [pool-51-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis/2c05d2c6-9e37-4981-a88d-b4b248d0a7e8
2020-06-02 23:11:30,153 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 23:11:30,153 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 23:11:30,153 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:11:30,153 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 23:11:30,154 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 23:11:30,154 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 23:11:30,154 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 23:11:30,154 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 23:11:30,156 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 23:11:30,158 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 23:11:30,162 [pool-51-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 23:11:30,162 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606
2020-06-02 23:11:30,166 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606: start as a follower, conf=-1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703], old=null
2020-06-02 23:11:30,168 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 23:11:30,169 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 23:11:30,169 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 23:11:30,169 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 23:11:30,169 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 23:11:30,170 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 23:11:30,170 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8
2020-06-02 23:11:30,170 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8
2020-06-02 23:11:30,171 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8: start as a follower, conf=-1: [cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null
2020-06-02 23:11:30,171 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 23:11:30,172 [pool-51-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cb97469d-781c-49b1-b566-b9439314fa8f: start FollowerState
2020-06-02 23:11:30,180 [pool-51-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B4B248D0A7E8,id=cb97469d-781c-49b1-b566-b9439314fa8f
2020-06-02 23:11:30,182 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8
2020-06-02 23:11:30,185 [pool-35-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: start FollowerState
2020-06-02 23:11:30,188 [pool-35-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5DD255C8B606,id=64cbb9bc-55ad-4bd6-90d7-16706f0bd234
2020-06-02 23:11:30,189 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606
2020-06-02 23:11:30,194 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:30,194 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:30,207 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS ONE #id: "7e7fc930-ceec-4c3e-aa3b-5dd255c8b606"
.
2020-06-02 23:11:30,207 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: addNew group-A03B68A52862:[ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223] returns group-A03B68A52862:java.util.concurrent.CompletableFuture@173faf39[Not completed]
2020-06-02 23:11:30,209 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: addNew group-94413D62F314:[64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983] returns group-94413D62F314:java.util.concurrent.CompletableFuture@1dda80cc[Not completed]
2020-06-02 23:11:30,208 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS ONE #id: "2c05d2c6-9e37-4981-a88d-b4b248d0a7e8"
.
2020-06-02 23:11:30,210 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - cb97469d-781c-49b1-b566-b9439314fa8f: addNew group-94413D62F314:[64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983] returns group-94413D62F314:java.util.concurrent.CompletableFuture@3528f558[Not completed]
2020-06-02 23:11:30,216 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: new RaftServerImpl for group-94413D62F314:[64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983] with ContainerStateMachine:uninitialized
2020-06-02 23:11:30,216 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 23:11:30,217 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 23:11:30,217 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 23:11:30,217 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 23:11:30,217 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:11:30,217 [pool-35-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314: ConfigurationManager, init=-1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null, confs=<EMPTY_MAP>
2020-06-02 23:11:30,217 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis] (custom)
2020-06-02 23:11:30,217 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 23:11:30,218 [pool-35-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis/942268b7-bff6-4625-9a57-94413d62f314 does not exist. Creating ...
2020-06-02 23:11:30,219 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - cb97469d-781c-49b1-b566-b9439314fa8f: new RaftServerImpl for group-94413D62F314:[64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983] with ContainerStateMachine:uninitialized
2020-06-02 23:11:30,219 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 23:11:30,219 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 23:11:30,219 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 23:11:30,219 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 23:11:30,219 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:11:30,220 [pool-51-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314: ConfigurationManager, init=-1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null, confs=<EMPTY_MAP>
2020-06-02 23:11:30,220 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis] (custom)
2020-06-02 23:11:30,220 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 23:11:30,220 [pool-51-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis/942268b7-bff6-4625-9a57-94413d62f314 does not exist. Creating ...
2020-06-02 23:11:30,221 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: new RaftServerImpl for group-A03B68A52862:[ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223] with ContainerStateMachine:uninitialized
2020-06-02 23:11:30,221 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 23:11:30,221 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 23:11:30,221 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 23:11:30,222 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 23:11:30,222 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:11:30,222 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862: ConfigurationManager, init=-1: [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223], old=null, confs=<EMPTY_MAP>
2020-06-02 23:11:30,222 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis] (custom)
2020-06-02 23:11:30,222 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 23:11:30,221 [pool-51-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis/942268b7-bff6-4625-9a57-94413d62f314/in_use.lock acquired by nodename 18775@cc5e24879e7f
2020-06-02 23:11:30,221 [pool-35-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis/942268b7-bff6-4625-9a57-94413d62f314/in_use.lock acquired by nodename 18775@cc5e24879e7f
2020-06-02 23:11:30,223 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis/6d7a0520-e2c2-43e9-bd7d-a03b68a52862 does not exist. Creating ...
2020-06-02 23:11:30,224 [pool-51-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis/942268b7-bff6-4625-9a57-94413d62f314 has been successfully formatted.
2020-06-02 23:11:30,224 [pool-51-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-94413D62F314: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 23:11:30,224 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 23:11:30,224 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 23:11:30,225 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 23:11:30,225 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:11:30,225 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:11:30,225 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 23:11:30,225 [pool-51-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis/942268b7-bff6-4625-9a57-94413d62f314
2020-06-02 23:11:30,225 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 23:11:30,225 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 23:11:30,225 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:11:30,226 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 23:11:30,226 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 23:11:30,226 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 23:11:30,226 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 23:11:30,226 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 23:11:30,226 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 23:11:30,227 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 23:11:30,227 [pool-51-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 23:11:30,225 [pool-35-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis/942268b7-bff6-4625-9a57-94413d62f314 has been successfully formatted.
2020-06-02 23:11:30,227 [pool-35-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-94413D62F314: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 23:11:30,228 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 23:11:30,228 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 23:11:30,228 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 23:11:30,228 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:11:30,228 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:11:30,228 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 23:11:30,228 [pool-35-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis/942268b7-bff6-4625-9a57-94413d62f314
2020-06-02 23:11:30,228 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 23:11:30,228 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 23:11:30,228 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:11:30,228 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 23:11:30,229 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 23:11:30,229 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 23:11:30,229 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 23:11:30,229 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 23:11:30,229 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 23:11:30,230 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 23:11:30,230 [pool-35-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 23:11:30,230 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis/6d7a0520-e2c2-43e9-bd7d-a03b68a52862/in_use.lock acquired by nodename 18775@cc5e24879e7f
2020-06-02 23:11:30,232 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis/6d7a0520-e2c2-43e9-bd7d-a03b68a52862 has been successfully formatted.
2020-06-02 23:11:30,239 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-A03B68A52862: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 23:11:30,239 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(378)) - Unable to start the DatanodeState Machine
java.io.IOException: Unable to finish the execution.
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:375)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:212)
	... 2 more
2020-06-02 23:11:30,239 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 23:11:30,242 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 23:11:30,239 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 23:11:30,242 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 23:11:30,242 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:11:30,242 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:11:30,242 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9
2020-06-02 23:11:30,242 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 23:11:30,242 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis/6d7a0520-e2c2-43e9-bd7d-a03b68a52862
2020-06-02 23:11:30,243 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 23:11:30,243 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 23:11:30,243 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:11:30,243 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 23:11:30,243 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 23:11:30,243 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 23:11:30,243 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 23:11:30,243 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 23:11:30,243 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 23:11:30,241 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 23:11:30,245 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 23:11:30,245 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 23:11:30,245 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 23:11:30,245 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 23:11:30,245 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 23:11:30,245 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 23:11:30,245 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 23:11:30,245 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 23:11:30,246 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 23:11:30,246 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 23:11:30,246 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 23:11:30,246 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 23:11:30,246 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 23:11:30,246 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862
2020-06-02 23:11:30,247 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862
2020-06-02 23:11:30,247 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862: start as a follower, conf=-1: [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223], old=null
2020-06-02 23:11:30,247 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 23:11:30,247 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: start FollowerState
2020-06-02 23:11:30,248 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A03B68A52862,id=ea1e16a2-08f2-4e20-9425-d71c7ab3efe9
2020-06-02 23:11:30,248 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862
2020-06-02 23:11:30,249 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 23:11:30,249 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314
2020-06-02 23:11:30,249 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS ONE #id: "6d7a0520-e2c2-43e9-bd7d-a03b68a52862"
.
2020-06-02 23:11:30,250 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: addNew group-94413D62F314:[64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983] returns group-94413D62F314:java.util.concurrent.CompletableFuture@13003906[Not completed]
2020-06-02 23:11:30,246 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 23:11:30,255 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314
2020-06-02 23:11:30,256 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: new RaftServerImpl for group-94413D62F314:[64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983] with ContainerStateMachine:uninitialized
2020-06-02 23:11:30,256 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 23:11:30,256 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 23:11:30,256 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 23:11:30,257 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 23:11:30,257 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:11:30,257 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314: ConfigurationManager, init=-1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null, confs=<EMPTY_MAP>
2020-06-02 23:11:30,257 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis] (custom)
2020-06-02 23:11:30,257 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 23:11:30,257 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis/942268b7-bff6-4625-9a57-94413d62f314 does not exist. Creating ...
2020-06-02 23:11:30,258 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314
2020-06-02 23:11:30,259 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314
2020-06-02 23:11:30,259 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis/942268b7-bff6-4625-9a57-94413d62f314/in_use.lock acquired by nodename 18775@cc5e24879e7f
2020-06-02 23:11:30,260 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314: start as a follower, conf=-1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null
2020-06-02 23:11:30,260 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 23:11:30,260 [pool-51-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cb97469d-781c-49b1-b566-b9439314fa8f: start FollowerState
2020-06-02 23:11:30,261 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314: start as a follower, conf=-1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null
2020-06-02 23:11:30,261 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 23:11:30,261 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis/942268b7-bff6-4625-9a57-94413d62f314 has been successfully formatted.
2020-06-02 23:11:30,265 [pool-51-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-94413D62F314,id=cb97469d-781c-49b1-b566-b9439314fa8f
2020-06-02 23:11:30,265 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314
2020-06-02 23:11:30,266 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-94413D62F314: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 23:11:30,266 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 23:11:30,266 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 23:11:30,266 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 23:11:30,266 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:11:30,266 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:11:30,266 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 23:11:30,266 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis/942268b7-bff6-4625-9a57-94413d62f314
2020-06-02 23:11:30,267 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 23:11:30,266 [pool-35-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: start FollowerState
2020-06-02 23:11:30,267 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 23:11:30,267 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:11:30,267 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 23:11:30,267 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 23:11:30,267 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 23:11:30,267 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 23:11:30,268 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 23:11:30,268 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 23:11:30,272 [pool-35-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-94413D62F314,id=64cbb9bc-55ad-4bd6-90d7-16706f0bd234
2020-06-02 23:11:30,272 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314
2020-06-02 23:11:30,276 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 23:11:30,276 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 23:11:30,283 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 23:11:30,283 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 23:11:30,283 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 23:11:30,283 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 23:11:30,283 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 23:11:30,283 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314
2020-06-02 23:11:30,284 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314
2020-06-02 23:11:30,285 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314: start as a follower, conf=-1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null
2020-06-02 23:11:30,285 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 23:11:30,285 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: start FollowerState
2020-06-02 23:11:30,285 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-94413D62F314,id=ea1e16a2-08f2-4e20-9425-d71c7ab3efe9
2020-06-02 23:11:30,285 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314
2020-06-02 23:11:30,861 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS THREE #id: "942268b7-bff6-4625-9a57-94413d62f314"
.
2020-06-02 23:11:30,867 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS THREE #id: "942268b7-bff6-4625-9a57-94413d62f314"
.
2020-06-02 23:11:30,875 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS THREE #id: "942268b7-bff6-4625-9a57-94413d62f314"
.
2020-06-02 23:11:31,194 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:31,195 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:32,195 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:32,195 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:33,195 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:33,196 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:34,196 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:34,196 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:35,196 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:35,196 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:35,229 [Thread-177] INFO  impl.FollowerState (FollowerState.java:run(108)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-FollowerState: change to CANDIDATE, lastRpcTime:5054ms, electionTimeout:5038ms
2020-06-02 23:11:35,230 [Thread-177] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: shutdown FollowerState
2020-06-02 23:11:35,230 [Thread-177] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 23:11:35,232 [Thread-177] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: start LeaderElection
2020-06-02 23:11:35,267 [Thread-183] INFO  impl.FollowerState (FollowerState.java:run(108)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-FollowerState: change to CANDIDATE, lastRpcTime:5019ms, electionTimeout:5013ms
2020-06-02 23:11:35,274 [Thread-183] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: shutdown FollowerState
2020-06-02 23:11:35,274 [Thread-183] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 23:11:35,274 [Thread-183] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: start LeaderElection
2020-06-02 23:11:35,277 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1: begin an election at term 1 for -1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703], old=null
2020-06-02 23:11:35,278 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: shutdown LeaderElection
2020-06-02 23:11:35,279 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 23:11:35,279 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-5DD255C8B606 with new leaderId: 64cbb9bc-55ad-4bd6-90d7-16706f0bd234
2020-06-02 23:11:35,279 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606: change Leader from null to 64cbb9bc-55ad-4bd6-90d7-16706f0bd234 at term 1 for becomeLeader, leader elected after 5258ms
2020-06-02 23:11:35,283 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 23:11:35,284 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 23:11:35,287 [Thread-179] INFO  impl.FollowerState (FollowerState.java:run(108)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-FollowerState: change to CANDIDATE, lastRpcTime:5116ms, electionTimeout:5102ms
2020-06-02 23:11:35,288 [Thread-179] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - cb97469d-781c-49b1-b566-b9439314fa8f: shutdown FollowerState
2020-06-02 23:11:35,288 [Thread-179] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 23:11:35,288 [Thread-179] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cb97469d-781c-49b1-b566-b9439314fa8f: start LeaderElection
2020-06-02 23:11:35,293 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606
2020-06-02 23:11:35,296 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 23:11:35,302 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 23:11:35,312 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 23:11:35,315 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3: begin an election at term 1 for -1: [cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null
2020-06-02 23:11:35,316 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - cb97469d-781c-49b1-b566-b9439314fa8f: shutdown LeaderElection
2020-06-02 23:11:35,316 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 23:11:35,316 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-B4B248D0A7E8 with new leaderId: cb97469d-781c-49b1-b566-b9439314fa8f
2020-06-02 23:11:35,316 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8: change Leader from null to cb97469d-781c-49b1-b566-b9439314fa8f at term 1 for becomeLeader, leader elected after 5167ms
2020-06-02 23:11:35,316 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 23:11:35,316 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 23:11:35,316 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8
2020-06-02 23:11:35,316 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 23:11:35,316 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 23:11:35,317 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 23:11:35,317 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 23:11:35,315 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2: begin an election at term 1 for -1: [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223], old=null
2020-06-02 23:11:35,317 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: shutdown LeaderElection
2020-06-02 23:11:35,317 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 23:11:35,317 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-A03B68A52862 with new leaderId: ea1e16a2-08f2-4e20-9425-d71c7ab3efe9
2020-06-02 23:11:35,318 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862: change Leader from null to ea1e16a2-08f2-4e20-9425-d71c7ab3efe9 at term 1 for becomeLeader, leader elected after 5078ms
2020-06-02 23:11:35,318 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 23:11:35,318 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 23:11:35,318 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862
2020-06-02 23:11:35,318 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 23:11:35,318 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 23:11:35,318 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 23:11:35,318 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 23:11:35,319 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 23:11:35,321 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 23:11:35,325 [Thread-184] INFO  impl.FollowerState (FollowerState.java:run(108)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-FollowerState: change to CANDIDATE, lastRpcTime:5064ms, electionTimeout:5057ms
2020-06-02 23:11:35,325 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - cb97469d-781c-49b1-b566-b9439314fa8f: shutdown FollowerState
2020-06-02 23:11:35,325 [Thread-184] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 23:11:35,325 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cb97469d-781c-49b1-b566-b9439314fa8f: start LeaderElection
2020-06-02 23:11:35,326 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 23:11:35,326 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 23:11:35,327 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: start LeaderState
2020-06-02 23:11:35,333 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: start LeaderState
2020-06-02 23:11:35,333 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cb97469d-781c-49b1-b566-b9439314fa8f: start LeaderState
2020-06-02 23:11:35,356 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection4: begin an election at term 1 for -1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null
2020-06-02 23:11:35,391 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 23:11:35,394 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 23:11:35,398 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 23:11:35,406 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606: set configuration 0: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703], old=null at 0
2020-06-02 23:11:35,412 [Thread-185] INFO  impl.FollowerState (FollowerState.java:run(108)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-FollowerState: change to CANDIDATE, lastRpcTime:5145ms, electionTimeout:5139ms
2020-06-02 23:11:35,412 [Thread-185] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: shutdown FollowerState
2020-06-02 23:11:35,412 [Thread-185] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 23:11:35,412 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862: set configuration 0: [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223], old=null at 0
2020-06-02 23:11:35,415 [Thread-185] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: start LeaderElection
2020-06-02 23:11:35,426 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8: set configuration 0: [cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null at 0
2020-06-02 23:11:35,452 [Thread-187] INFO  impl.FollowerState (FollowerState.java:run(108)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-FollowerState: change to CANDIDATE, lastRpcTime:5167ms, electionTimeout:5166ms
2020-06-02 23:11:35,452 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: shutdown FollowerState
2020-06-02 23:11:35,452 [Thread-187] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 23:11:35,452 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: start LeaderElection
2020-06-02 23:11:35,505 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-LeaderElection5: begin an election at term 1 for -1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null
2020-06-02 23:11:35,529 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-LeaderElection6: begin an election at term 1 for -1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null
2020-06-02 23:11:35,712 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis/7e7fc930-ceec-4c3e-aa3b-5dd255c8b606/current/log_inprogress_0
2020-06-02 23:11:35,718 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis/2c05d2c6-9e37-4981-a88d-b4b248d0a7e8/current/log_inprogress_0
2020-06-02 23:11:35,721 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis/6d7a0520-e2c2-43e9-bd7d-a03b68a52862/current/log_inprogress_0
2020-06-02 23:11:35,793 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection4: Election REJECTED; received 2 response(s) [cb97469d-781c-49b1-b566-b9439314fa8f<-64cbb9bc-55ad-4bd6-90d7-16706f0bd234#0:FAIL-t1, cb97469d-781c-49b1-b566-b9439314fa8f<-ea1e16a2-08f2-4e20-9425-d71c7ab3efe9#0:FAIL-t1] and 0 exception(s); cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314:t1, leader=null, voted=cb97469d-781c-49b1-b566-b9439314fa8f, raftlog=cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null
2020-06-02 23:11:35,793 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2020-06-02 23:11:35,799 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - cb97469d-781c-49b1-b566-b9439314fa8f: shutdown LeaderElection
2020-06-02 23:11:35,799 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cb97469d-781c-49b1-b566-b9439314fa8f: start FollowerState
2020-06-02 23:11:35,798 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-LeaderElection5: Election REJECTED; received 2 response(s) [64cbb9bc-55ad-4bd6-90d7-16706f0bd234<-ea1e16a2-08f2-4e20-9425-d71c7ab3efe9#0:FAIL-t1, 64cbb9bc-55ad-4bd6-90d7-16706f0bd234<-cb97469d-781c-49b1-b566-b9439314fa8f#0:FAIL-t1] and 0 exception(s); 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314:t1, leader=null, voted=64cbb9bc-55ad-4bd6-90d7-16706f0bd234, raftlog=64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null
2020-06-02 23:11:35,822 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2020-06-02 23:11:35,822 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: shutdown LeaderElection
2020-06-02 23:11:35,822 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: start FollowerState
2020-06-02 23:11:35,837 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-LeaderElection6: Election REJECTED; received 2 response(s) [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9<-64cbb9bc-55ad-4bd6-90d7-16706f0bd234#0:FAIL-t1, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9<-cb97469d-781c-49b1-b566-b9439314fa8f#0:FAIL-t1] and 0 exception(s); ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314:t1, leader=null, voted=ea1e16a2-08f2-4e20-9425-d71c7ab3efe9, raftlog=ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null
2020-06-02 23:11:35,838 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2020-06-02 23:11:35,838 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: shutdown LeaderElection
2020-06-02 23:11:35,838 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: start FollowerState
2020-06-02 23:11:36,196 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:36,203 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:37,203 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:37,203 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:38,203 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:38,203 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:39,203 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:39,204 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:40,204 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:40,204 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:40,909 [Thread-209] INFO  impl.FollowerState (FollowerState.java:run(108)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-FollowerState: change to CANDIDATE, lastRpcTime:5110ms, electionTimeout:5084ms
2020-06-02 23:11:40,910 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - cb97469d-781c-49b1-b566-b9439314fa8f: shutdown FollowerState
2020-06-02 23:11:40,910 [Thread-209] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2020-06-02 23:11:40,910 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cb97469d-781c-49b1-b566-b9439314fa8f: start LeaderElection
2020-06-02 23:11:40,913 [Thread-210] INFO  impl.FollowerState (FollowerState.java:run(108)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-FollowerState: change to CANDIDATE, lastRpcTime:5091ms, electionTimeout:5084ms
2020-06-02 23:11:40,913 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: shutdown FollowerState
2020-06-02 23:11:40,913 [Thread-210] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2020-06-02 23:11:40,919 [Thread-210] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: start LeaderElection
2020-06-02 23:11:40,935 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7: begin an election at term 2 for -1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null
2020-06-02 23:11:40,935 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-LeaderElection8: begin an election at term 2 for -1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null
2020-06-02 23:11:40,946 [Thread-211] INFO  impl.FollowerState (FollowerState.java:run(108)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-FollowerState: change to CANDIDATE, lastRpcTime:5107ms, electionTimeout:5091ms
2020-06-02 23:11:40,946 [Thread-211] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: shutdown FollowerState
2020-06-02 23:11:40,946 [Thread-211] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2020-06-02 23:11:40,987 [Thread-211] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: start LeaderElection
2020-06-02 23:11:41,006 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314: changes role from CANDIDATE to FOLLOWER at term 2 for recognizeCandidate:64cbb9bc-55ad-4bd6-90d7-16706f0bd234
2020-06-02 23:11:41,006 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: shutdown LeaderElection
2020-06-02 23:11:41,006 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: start FollowerState
2020-06-02 23:11:41,007 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:run(155)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-LeaderElection9: skip running since this is already CLOSING
2020-06-02 23:11:41,026 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:cb97469d-781c-49b1-b566-b9439314fa8f
2020-06-02 23:11:41,026 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: shutdown FollowerState
2020-06-02 23:11:41,026 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: start FollowerState
2020-06-02 23:11:41,026 [Thread-219] INFO  impl.FollowerState (FollowerState.java:run(117)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-06-02 23:11:41,046 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-LeaderElection8: Election REJECTED; received 2 response(s) [64cbb9bc-55ad-4bd6-90d7-16706f0bd234<-ea1e16a2-08f2-4e20-9425-d71c7ab3efe9#0:FAIL-t2, 64cbb9bc-55ad-4bd6-90d7-16706f0bd234<-cb97469d-781c-49b1-b566-b9439314fa8f#0:FAIL-t2] and 0 exception(s); 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314:t2, leader=null, voted=64cbb9bc-55ad-4bd6-90d7-16706f0bd234, raftlog=64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null
2020-06-02 23:11:41,048 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
2020-06-02 23:11:41,048 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: shutdown LeaderElection
2020-06-02 23:11:41,048 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: start FollowerState
2020-06-02 23:11:41,076 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7: Election PASSED; received 2 response(s) [cb97469d-781c-49b1-b566-b9439314fa8f<-64cbb9bc-55ad-4bd6-90d7-16706f0bd234#0:FAIL-t2, cb97469d-781c-49b1-b566-b9439314fa8f<-ea1e16a2-08f2-4e20-9425-d71c7ab3efe9#0:OK-t2] and 0 exception(s); cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314:t2, leader=null, voted=cb97469d-781c-49b1-b566-b9439314fa8f, raftlog=cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null
2020-06-02 23:11:41,078 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - cb97469d-781c-49b1-b566-b9439314fa8f: shutdown LeaderElection
2020-06-02 23:11:41,078 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2020-06-02 23:11:41,078 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-94413D62F314 with new leaderId: cb97469d-781c-49b1-b566-b9439314fa8f
2020-06-02 23:11:41,078 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314: change Leader from null to cb97469d-781c-49b1-b566-b9439314fa8f at term 2 for becomeLeader, leader elected after 10853ms
2020-06-02 23:11:41,078 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 23:11:41,078 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 23:11:41,078 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314
2020-06-02 23:11:41,078 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 23:11:41,078 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 23:11:41,079 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 23:11:41,079 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 23:11:41,079 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 23:11:41,081 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-06-02 23:11:41,081 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:11:41,082 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2020-06-02 23:11:41,085 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2020-06-02 23:11:41,093 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 23:11:41,094 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:11:41,115 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-06-02 23:11:41,121 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:11:41,121 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2020-06-02 23:11:41,121 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2020-06-02 23:11:41,121 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 23:11:41,122 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:11:41,128 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - cb97469d-781c-49b1-b566-b9439314fa8f: start LeaderState
2020-06-02 23:11:41,129 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 23:11:41,131 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis/942268b7-bff6-4625-9a57-94413d62f314/current/log_inprogress_0
2020-06-02 23:11:41,173 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314: set configuration 0: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null at 0
2020-06-02 23:11:41,204 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:41,204 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:41,205 [grpc-default-executor-1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-94413D62F314 with new leaderId: cb97469d-781c-49b1-b566-b9439314fa8f
2020-06-02 23:11:41,207 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314: change Leader from null to cb97469d-781c-49b1-b566-b9439314fa8f at term 2 for appendEntries, leader elected after 10939ms
2020-06-02 23:11:41,206 [grpc-default-executor-2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-94413D62F314 with new leaderId: cb97469d-781c-49b1-b566-b9439314fa8f
2020-06-02 23:11:41,208 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314: change Leader from null to cb97469d-781c-49b1-b566-b9439314fa8f at term 2 for appendEntries, leader elected after 10978ms
2020-06-02 23:11:41,254 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314: set configuration 0: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null at 0
2020-06-02 23:11:41,256 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314: set configuration 0: [64cbb9bc-55ad-4bd6-90d7-16706f0bd234:172.17.0.2:38703, ea1e16a2-08f2-4e20-9425-d71c7ab3efe9:172.17.0.2:44223, cb97469d-781c-49b1-b566-b9439314fa8f:172.17.0.2:38983], old=null at 0
2020-06-02 23:11:41,261 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 23:11:41,261 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 23:11:41,263 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis/942268b7-bff6-4625-9a57-94413d62f314/current/log_inprogress_0
2020-06-02 23:11:41,264 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis/942268b7-bff6-4625-9a57-94413d62f314/current/log_inprogress_0
2020-06-02 23:11:42,204 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:42,205 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:43,205 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:43,205 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:44,205 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:44,205 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:45,206 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:45,206 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:46,206 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:46,206 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:47,206 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:47,207 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:48,207 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:48,207 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:49,207 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:49,207 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:50,207 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:50,208 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:51,209 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:51,209 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:52,218 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:52,219 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:53,219 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:53,219 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:54,219 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:54,219 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:55,219 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:55,220 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:56,220 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:56,220 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:57,220 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:57,220 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:58,220 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:58,221 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:11:59,221 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:11:59,221 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:00,221 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:00,221 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:01,222 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:01,222 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:02,222 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:02,222 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:03,222 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:03,222 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:04,223 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:04,223 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:05,223 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:05,223 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:06,223 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:06,223 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:07,224 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:07,224 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:08,224 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:08,224 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:09,224 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:09,225 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:10,225 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:10,225 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:11,225 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:11,225 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:12,225 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:12,226 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:13,226 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:13,226 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:14,226 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:14,226 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:15,226 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:15,227 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:16,227 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:16,227 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:17,227 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:17,227 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:18,228 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:18,228 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:18,682 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(387)) - Shutting down the Mini Ozone Cluster
2020-06-02 23:12:18,682 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(402)) - Stopping the Mini Ozone Cluster
2020-06-02 23:12:18,682 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(484)) - Stopping the OzoneManager
2020-06-02 23:12:18,682 [Listener at 127.0.0.1/45129] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45129
2020-06-02 23:12:18,684 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-06-02 23:12:18,684 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-06-02 23:12:18,685 [Listener at 127.0.0.1/45129] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(410)) - Stopping OMDoubleBuffer flush thread
2020-06-02 23:12:18,686 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(342)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2020-06-02 23:12:18,686 [Listener at 127.0.0.1/45129] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service KeyDeletingService
2020-06-02 23:12:18,696 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@4fdad8ae{ozoneManager,/,null,UNAVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
]]></system-out>
    <system-err><![CDATA[ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
]]></system-err>
  </testcase>
  <testcase name="testDoGet" classname="org.apache.hadoop.ozone.om.TestOMDbCheckpointServlet" time="60.009">
    <error message="test timed out after 60000 milliseconds" type="java.lang.Exception">java.lang.Exception: test timed out after 60000 milliseconds
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:218)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl.waitForClusterToBeReady(MiniOzoneClusterImpl.java:172)
	at org.apache.hadoop.ozone.om.TestOMDbCheckpointServlet.init(TestOMDbCheckpointServlet.java:97)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
</error>
    <system-out><![CDATA[2020-06-02 23:12:18,706 [Listener at 127.0.0.1/45129] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@15c0808f{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-06-02 23:12:18,707 [Listener at 127.0.0.1/45129] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-06-02 23:12:18,709 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@70231df2{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2020-06-02 23:12:18,709 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@1b7c5f61{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-06-02 23:12:18,739 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(461)) - Stopping the HddsDatanodes
2020-06-02 23:12:18,825 [Thread-258] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 23:12:18,834 [Thread-258] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 23:12:18,835 [Thread-258] WARN  db.DBStoreBuilder (DBStoreBuilder.java:createDBStoreBuilder(277)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 23:12:18,875 [Thread-258] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(126)) - Loading file from sun.misc.CompoundEnumeration@19cd2550
2020-06-02 23:12:18,875 [Thread-258] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(172)) - Loading network topology layer schema file
2020-06-02 23:12:18,880 [Thread-258] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(73)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2020-06-02 23:12:18,880 [Thread-258] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(73)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2020-06-02 23:12:18,880 [Thread-258] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2020-06-02 23:12:18,882 [Thread-258] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(60)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2020-06-02 23:12:18,882 [Thread-258] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(158)) - No pipeline exists in current db
2020-06-02 23:12:18,884 [Thread-258] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:<init>(89)) - Total pipeline count is 0, healthy pipeline threshold count is 0
2020-06-02 23:12:18,885 [Thread-258] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:<init>(79)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2020-06-02 23:12:18,898 [Thread-258] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 23:12:18,906 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
2020-06-02 23:12:18,912 [Listener at 0.0.0.0/38529] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 23:12:18,912 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 23:12:18,913 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 23:12:18,914 [Listener at 0.0.0.0/39025] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 23:12:18,914 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 23:12:18,921 [Listener at 0.0.0.0/35635] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for scm at: http://0.0.0.0:0
2020-06-02 23:12:18,921 [Listener at 0.0.0.0/35635] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 23:12:18,923 [Listener at 0.0.0.0/35635] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:12:18,933 [Listener at 0.0.0.0/35635] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 23:12:18,934 [Listener at 0.0.0.0/35635] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 23:12:18,935 [Listener at 0.0.0.0/35635] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2020-06-02 23:12:18,935 [Listener at 0.0.0.0/35635] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 23:12:18,935 [Listener at 0.0.0.0/35635] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 23:12:18,950 [Listener at 0.0.0.0/35635] INFO  server.StorageContainerManager (StorageContainerManager.java:start(781)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:35635
2020-06-02 23:12:18,950 [Listener at 0.0.0.0/35635] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2020-06-02 23:12:18,953 [Listener at 0.0.0.0/35635] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(157)) - RPC server for Client  is listening at /0.0.0.0:35635
2020-06-02 23:12:18,955 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 23:12:18,958 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 23:12:18,960 [Listener at 0.0.0.0/35635] INFO  server.StorageContainerManager (StorageContainerManager.java:start(793)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:39025
2020-06-02 23:12:18,961 [Listener at 0.0.0.0/35635] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(149)) - RPC server for Block Protocol is listening at /0.0.0.0:39025
2020-06-02 23:12:18,961 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 23:12:18,961 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 23:12:18,969 [Listener at 0.0.0.0/35635] INFO  server.StorageContainerManager (StorageContainerManager.java:start(799)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:38529
2020-06-02 23:12:18,969 [Listener at 0.0.0.0/35635] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(172)) - RPC server for DataNodes is listening at /0.0.0.0:38529
2020-06-02 23:12:18,974 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 23:12:18,975 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 23:12:18,986 [Listener at 0.0.0.0/35635] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 43603
2020-06-02 23:12:18,986 [Listener at 0.0.0.0/35635] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 23:12:18,988 [Listener at 0.0.0.0/35635] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 23:12:18,988 [Listener at 0.0.0.0/35635] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 23:12:18,988 [Listener at 0.0.0.0/35635] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-06-02 23:12:18,989 [Listener at 0.0.0.0/35635] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:12:18,990 [Listener at 0.0.0.0/35635] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@8257fa0{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 23:12:18,990 [Listener at 0.0.0.0/35635] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@72d96034{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2020-06-02 23:12:19,002 [Listener at 0.0.0.0/35635] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@506cd762{scm,/,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2020-06-02 23:12:19,006 [Listener at 0.0.0.0/35635] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@53b4d9aa{HTTP/1.1,[http/1.1]}{0.0.0.0:43603}
2020-06-02 23:12:19,009 [Listener at 0.0.0.0/35635] INFO  server.Server (Server.java:doStart(399)) - Started @61075ms
2020-06-02 23:12:19,009 [Listener at 0.0.0.0/35635] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 23:12:19,014 [Listener at 0.0.0.0/35635] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of scm listening at http://0.0.0.0:43603
2020-06-02 23:12:19,018 [Listener at 0.0.0.0/35635] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 23:12:19,018 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3784cf29] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 23:12:19,019 [Listener at 0.0.0.0/35635] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(104)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2020-06-02 23:12:19,019 [Listener at 0.0.0.0/35635] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(207)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2020-06-02 23:12:19,019 [Listener at 0.0.0.0/35635] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(237)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2020-06-02 23:12:19,020 [Listener at 0.0.0.0/35635] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 23:12:19,020 [Listener at 0.0.0.0/35635] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 23:12:19,031 [Listener at 0.0.0.0/35635] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 23:12:19,097 [Listener at 0.0.0.0/35635] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 23:12:19,098 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 23:12:19,118 [Listener at 127.0.0.1/33481] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2020-06-02 23:12:19,119 [Listener at 127.0.0.1/33481] INFO  om.OzoneManager (OzoneManager.java:start(1097)) - OzoneManager RPC server is listening at localhost/127.0.0.1:33481
2020-06-02 23:12:19,121 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 23:12:19,121 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 23:12:19,129 [Listener at 127.0.0.1/33481] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2020-06-02 23:12:19,129 [Listener at 127.0.0.1/33481] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 23:12:19,131 [Listener at 127.0.0.1/33481] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:12:19,132 [Listener at 127.0.0.1/33481] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 23:12:19,133 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 23:12:19,134 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
2020-06-02 23:12:19,134 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 23:12:19,134 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 23:12:19,134 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 40311
2020-06-02 23:12:19,134 [Listener at 127.0.0.1/33481] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 23:12:19,157 [Listener at 127.0.0.1/33481] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 23:12:19,157 [Listener at 127.0.0.1/33481] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 23:12:19,158 [Listener at 127.0.0.1/33481] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-06-02 23:12:19,158 [Listener at 127.0.0.1/33481] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:12:19,159 [Listener at 127.0.0.1/33481] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@500d0039{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 23:12:19,159 [Listener at 127.0.0.1/33481] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@47908724{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2020-06-02 23:12:19,162 [Listener at 127.0.0.1/33481] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@5a01b0a{ozoneManager,/,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2020-06-02 23:12:19,167 [Listener at 127.0.0.1/33481] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@612f62ad{HTTP/1.1,[http/1.1]}{0.0.0.0:40311}
2020-06-02 23:12:19,167 [Listener at 127.0.0.1/33481] INFO  server.Server (Server.java:doStart(399)) - Started @61233ms
2020-06-02 23:12:19,167 [Listener at 127.0.0.1/33481] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 23:12:19,172 [Listener at 127.0.0.1/33481] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of ozoneManager listening at http://0.0.0.0:40311
2020-06-02 23:12:19,179 [Listener at 127.0.0.1/33481] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-06-02 23:12:19,188 [Listener at 127.0.0.1/33481] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(205)) - HddsDatanodeService host:cc5e24879e7f ip:172.17.0.2
2020-06-02 23:12:19,186 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@17ba035f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 23:12:19,201 [Listener at 127.0.0.1/33481] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-06-02 23:12:19,203 [Listener at 127.0.0.1/33481] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(181)) - Added Volume : /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data-0/containers/hdds to VolumeSet
2020-06-02 23:12:19,203 [Listener at 127.0.0.1/33481] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data-0/containers/hdds
2020-06-02 23:12:19,207 [Listener at 127.0.0.1/33481] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data-0/containers/hdds
2020-06-02 23:12:19,256 [Listener at 127.0.0.1/33481] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-06-02 23:12:19,256 [Listener at 127.0.0.1/33481] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-06-02 23:12:19,258 [Listener at 127.0.0.1/33481] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-06-02 23:12:19,258 [Listener at 127.0.0.1/33481] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-06-02 23:12:19,258 [Listener at 127.0.0.1/33481] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:12:19,258 [Listener at 127.0.0.1/33481] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-06-02 23:12:19,258 [Listener at 127.0.0.1/33481] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 23:12:19,259 [Listener at 127.0.0.1/33481] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data/ratis] (custom)
2020-06-02 23:12:19,265 [Listener at 127.0.0.1/33481] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-06-02 23:12:19,265 [Listener at 127.0.0.1/33481] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 23:12:19,267 [Listener at 127.0.0.1/33481] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:12:19,267 [Listener at 127.0.0.1/33481] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 23:12:19,268 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 23:12:19,269 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
2020-06-02 23:12:19,269 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 23:12:19,269 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 23:12:19,269 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 41013
2020-06-02 23:12:19,270 [Listener at 127.0.0.1/33481] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 23:12:19,273 [Listener at 127.0.0.1/33481] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 23:12:19,274 [Listener at 127.0.0.1/33481] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 23:12:19,274 [Listener at 127.0.0.1/33481] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-06-02 23:12:19,274 [Listener at 127.0.0.1/33481] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:12:19,276 [Listener at 127.0.0.1/33481] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@21382b97{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 23:12:19,276 [Listener at 127.0.0.1/33481] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@b10950a{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-06-02 23:12:19,334 [Listener at 127.0.0.1/33481] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@317dcae9{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-41013-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-4543926380692953341.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 23:12:19,344 [Listener at 127.0.0.1/33481] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@1631f2e9{HTTP/1.1,[http/1.1]}{0.0.0.0:41013}
2020-06-02 23:12:19,344 [Listener at 127.0.0.1/33481] INFO  server.Server (Server.java:doStart(399)) - Started @61411ms
2020-06-02 23:12:19,344 [Listener at 127.0.0.1/33481] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 23:12:19,361 [Listener at 127.0.0.1/33481] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of hddsDatanode listening at http://0.0.0.0:41013
2020-06-02 23:12:19,362 [Listener at 127.0.0.1/33481] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-06-02 23:12:19,366 [Listener at 127.0.0.1/33481] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(205)) - HddsDatanodeService host:cc5e24879e7f ip:172.17.0.2
2020-06-02 23:12:19,381 [Listener at 127.0.0.1/33481] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-06-02 23:12:19,381 [Listener at 127.0.0.1/33481] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(181)) - Added Volume : /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data-0/containers/hdds to VolumeSet
2020-06-02 23:12:19,381 [Listener at 127.0.0.1/33481] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data-0/containers/hdds
2020-06-02 23:12:19,421 [Listener at 127.0.0.1/33481] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data-0/containers/hdds
2020-06-02 23:12:19,433 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@767b11a8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 23:12:19,435 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(145)) - DatanodeDetails is persisted to /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/meta/datanode.id
2020-06-02 23:12:19,454 [Listener at 127.0.0.1/33481] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-06-02 23:12:19,457 [Listener at 127.0.0.1/33481] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-06-02 23:12:19,457 [Listener at 127.0.0.1/33481] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-06-02 23:12:19,457 [Listener at 127.0.0.1/33481] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-06-02 23:12:19,458 [Listener at 127.0.0.1/33481] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:12:19,458 [Listener at 127.0.0.1/33481] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-06-02 23:12:19,458 [Listener at 127.0.0.1/33481] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 23:12:19,459 [Listener at 127.0.0.1/33481] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data/ratis] (custom)
2020-06-02 23:12:19,467 [Listener at 127.0.0.1/33481] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-06-02 23:12:19,467 [Listener at 127.0.0.1/33481] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 23:12:19,469 [Listener at 127.0.0.1/33481] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:12:19,469 [Listener at 127.0.0.1/33481] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 23:12:19,470 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 23:12:19,471 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
2020-06-02 23:12:19,471 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 23:12:19,471 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 23:12:19,472 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 35857
2020-06-02 23:12:19,472 [Listener at 127.0.0.1/33481] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 23:12:19,483 [Listener at 127.0.0.1/33481] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 23:12:19,483 [Listener at 127.0.0.1/33481] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 23:12:19,483 [Listener at 127.0.0.1/33481] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-06-02 23:12:19,484 [Listener at 127.0.0.1/33481] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:12:19,485 [Listener at 127.0.0.1/33481] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@3b95bc82{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 23:12:19,486 [Listener at 127.0.0.1/33481] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@553319b4{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-06-02 23:12:19,534 [Listener at 127.0.0.1/33481] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@5b5f977b{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-35857-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-983262677022918588.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 23:12:19,539 [Listener at 127.0.0.1/33481] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@2a3d3ee8{HTTP/1.1,[http/1.1]}{0.0.0.0:35857}
2020-06-02 23:12:19,539 [Listener at 127.0.0.1/33481] INFO  server.Server (Server.java:doStart(399)) - Started @61606ms
2020-06-02 23:12:19,539 [Listener at 127.0.0.1/33481] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 23:12:19,544 [Listener at 127.0.0.1/33481] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of hddsDatanode listening at http://0.0.0.0:35857
2020-06-02 23:12:19,544 [Listener at 127.0.0.1/33481] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-06-02 23:12:19,546 [Listener at 127.0.0.1/33481] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(205)) - HddsDatanodeService host:cc5e24879e7f ip:172.17.0.2
2020-06-02 23:12:19,547 [Listener at 127.0.0.1/33481] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-06-02 23:12:19,547 [Listener at 127.0.0.1/33481] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(181)) - Added Volume : /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data-0/containers/hdds to VolumeSet
2020-06-02 23:12:19,547 [Listener at 127.0.0.1/33481] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data-0/containers/hdds
2020-06-02 23:12:19,548 [Listener at 127.0.0.1/33481] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data-0/containers/hdds
2020-06-02 23:12:19,578 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(145)) - DatanodeDetails is persisted to /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/meta/datanode.id
2020-06-02 23:12:19,579 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@71e56f12] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 23:12:19,582 [Listener at 127.0.0.1/33481] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-06-02 23:12:19,582 [Listener at 127.0.0.1/33481] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-06-02 23:12:19,582 [Listener at 127.0.0.1/33481] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-06-02 23:12:19,582 [Listener at 127.0.0.1/33481] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-06-02 23:12:19,582 [Listener at 127.0.0.1/33481] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:12:19,582 [Listener at 127.0.0.1/33481] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-06-02 23:12:19,582 [Listener at 127.0.0.1/33481] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 23:12:19,583 [Listener at 127.0.0.1/33481] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data/ratis] (custom)
2020-06-02 23:12:19,591 [Listener at 127.0.0.1/33481] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-06-02 23:12:19,591 [Listener at 127.0.0.1/33481] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 23:12:19,592 [Listener at 127.0.0.1/33481] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:12:19,593 [Listener at 127.0.0.1/33481] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 23:12:19,594 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 23:12:19,595 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
2020-06-02 23:12:19,595 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 23:12:19,595 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 23:12:19,596 [Listener at 127.0.0.1/33481] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 38473
2020-06-02 23:12:19,596 [Listener at 127.0.0.1/33481] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 23:12:19,599 [Listener at 127.0.0.1/33481] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 23:12:19,599 [Listener at 127.0.0.1/33481] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 23:12:19,599 [Listener at 127.0.0.1/33481] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-06-02 23:12:19,601 [Listener at 127.0.0.1/33481] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 23:12:19,602 [Listener at 127.0.0.1/33481] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@48ef5d23{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 23:12:19,602 [Listener at 127.0.0.1/33481] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@2ec95131{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-06-02 23:12:19,645 [Listener at 127.0.0.1/33481] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@256e27e2{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-38473-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-7003833001658817371.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 23:12:19,653 [Listener at 127.0.0.1/33481] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@1a7aabd9{HTTP/1.1,[http/1.1]}{0.0.0.0:38473}
2020-06-02 23:12:19,653 [Listener at 127.0.0.1/33481] INFO  server.Server (Server.java:doStart(399)) - Started @61720ms
2020-06-02 23:12:19,654 [Listener at 127.0.0.1/33481] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 23:12:19,657 [Listener at 127.0.0.1/33481] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of hddsDatanode listening at http://0.0.0.0:38473
2020-06-02 23:12:19,658 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 23:12:19,658 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:19,669 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7b1322d3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 23:12:19,670 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(145)) - DatanodeDetails is persisted to /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/meta/datanode.id
2020-06-02 23:12:20,658 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 23:12:20,658 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:21,450 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-06-02 23:12:21,450 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-06-02 23:12:21,450 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(425)) - Starting XceiverServerRatis f35fd5b3-f20d-428f-8442-dfc8a30d644d at port 0
2020-06-02 23:12:21,454 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: start RPC server
2020-06-02 23:12:21,458 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(159)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: GrpcService started, listening on 0.0.0.0/0.0.0.0:44907
2020-06-02 23:12:21,458 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(437)) - XceiverServerRatis f35fd5b3-f20d-428f-8442-dfc8a30d644d is started using port 44907
2020-06-02 23:12:21,459 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc f35fd5b3-f20d-428f-8442-dfc8a30d644d is started using port 33759
2020-06-02 23:12:21,585 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-06-02 23:12:21,585 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-06-02 23:12:21,585 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(425)) - Starting XceiverServerRatis 64686ae2-d3de-4265-80d8-19029de0d313 at port 0
2020-06-02 23:12:21,586 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 64686ae2-d3de-4265-80d8-19029de0d313: start RPC server
2020-06-02 23:12:21,587 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(159)) - 64686ae2-d3de-4265-80d8-19029de0d313: GrpcService started, listening on 0.0.0.0/0.0.0.0:34421
2020-06-02 23:12:21,587 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(437)) - XceiverServerRatis 64686ae2-d3de-4265-80d8-19029de0d313 is started using port 34421
2020-06-02 23:12:21,588 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 64686ae2-d3de-4265-80d8-19029de0d313 is started using port 36579
2020-06-02 23:12:21,658 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 23:12:21,659 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:21,681 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-06-02 23:12:21,681 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-06-02 23:12:21,681 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(425)) - Starting XceiverServerRatis b8d14a52-4151-456e-8249-7fd2481d3769 at port 0
2020-06-02 23:12:21,682 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - b8d14a52-4151-456e-8249-7fd2481d3769: start RPC server
2020-06-02 23:12:21,686 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(159)) - b8d14a52-4151-456e-8249-7fd2481d3769: GrpcService started, listening on 0.0.0.0/0.0.0.0:44737
2020-06-02 23:12:21,686 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(437)) - XceiverServerRatis b8d14a52-4151-456e-8249-7fd2481d3769 is started using port 44737
2020-06-02 23:12:21,693 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc b8d14a52-4151-456e-8249-7fd2481d3769 is started using port 43445
2020-06-02 23:12:22,659 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 23:12:22,659 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:23,438 [IPC Server handler 0 on default port 38529] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/f35fd5b3-f20d-428f-8442-dfc8a30d644d
2020-06-02 23:12:23,438 [IPC Server handler 0 on default port 38529] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : f35fd5b3-f20d-428f-8442-dfc8a30d644d{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}
2020-06-02 23:12:23,439 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2020-06-02 23:12:23,439 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - DataNodeSafeModeRule rule is successfully validated
2020-06-02 23:12:23,439 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(241)) - All SCM safe mode pre check rules have passed
2020-06-02 23:12:23,446 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=b3fd9059-93d8-4d11-8433-8c8042690848 to datanode:f35fd5b3-f20d-428f-8442-dfc8a30d644d
2020-06-02 23:12:23,446 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - ContainerSafeModeRule rule is successfully validated
2020-06-02 23:12:23,447 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: b3fd9059-93d8-4d11-8433-8c8042690848, Nodes: f35fd5b3-f20d-428f-8442-dfc8a30d644d{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T23:12:23.446Z]
2020-06-02 23:12:23,447 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 1 nodes. Healthy nodes 1
2020-06-02 23:12:23,447 [RatisPipelineUtilsThread] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(133)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2020-06-02 23:12:23,447 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2020-06-02 23:12:23,584 [IPC Server handler 3 on default port 38529] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/64686ae2-d3de-4265-80d8-19029de0d313
2020-06-02 23:12:23,584 [IPC Server handler 3 on default port 38529] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 64686ae2-d3de-4265-80d8-19029de0d313{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}
2020-06-02 23:12:23,584 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=b37a4cf8-1cb0-4f2d-b7ed-d1c29487bca2 to datanode:64686ae2-d3de-4265-80d8-19029de0d313
2020-06-02 23:12:23,585 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: b37a4cf8-1cb0-4f2d-b7ed-d1c29487bca2, Nodes: 64686ae2-d3de-4265-80d8-19029de0d313{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T23:12:23.584Z]
2020-06-02 23:12:23,585 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - ContainerSafeModeRule rule is successfully validated
2020-06-02 23:12:23,585 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
2020-06-02 23:12:23,585 [RatisPipelineUtilsThread] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(133)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2020-06-02 23:12:23,585 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2020-06-02 23:12:23,585 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - DataNodeSafeModeRule rule is successfully validated
2020-06-02 23:12:23,659 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 2 of 3 DN Heartbeats.
2020-06-02 23:12:23,659 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:23,674 [IPC Server handler 2 on default port 38529] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/b8d14a52-4151-456e-8249-7fd2481d3769
2020-06-02 23:12:23,675 [IPC Server handler 2 on default port 38529] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : b8d14a52-4151-456e-8249-7fd2481d3769{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}
2020-06-02 23:12:23,675 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - ContainerSafeModeRule rule is successfully validated
2020-06-02 23:12:23,676 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=c5024fd7-d750-48bd-9d1a-f1f2f39dfed0 to datanode:b8d14a52-4151-456e-8249-7fd2481d3769
2020-06-02 23:12:23,676 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: c5024fd7-d750-48bd-9d1a-f1f2f39dfed0, Nodes: b8d14a52-4151-456e-8249-7fd2481d3769{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T23:12:23.676Z]
2020-06-02 23:12:23,676 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
2020-06-02 23:12:23,677 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83 to datanode:b8d14a52-4151-456e-8249-7fd2481d3769
2020-06-02 23:12:23,677 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83 to datanode:f35fd5b3-f20d-428f-8442-dfc8a30d644d
2020-06-02 23:12:23,677 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83 to datanode:64686ae2-d3de-4265-80d8-19029de0d313
2020-06-02 23:12:23,677 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - DataNodeSafeModeRule rule is successfully validated
2020-06-02 23:12:23,678 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83, Nodes: b8d14a52-4151-456e-8249-7fd2481d3769{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}f35fd5b3-f20d-428f-8442-dfc8a30d644d{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}64686ae2-d3de-4265-80d8-19029de0d313{ip: 172.17.0.2, host: cc5e24879e7f, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T23:12:23.677Z]
2020-06-02 23:12:23,678 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
2020-06-02 23:12:23,751 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(246)) - Attempting to stop container services.
2020-06-02 23:12:23,752 [Listener at 127.0.0.1/45129] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(246)) - Attempting to stop container services.
2020-06-02 23:12:23,753 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: close
2020-06-02 23:12:23,754 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314: shutdown
2020-06-02 23:12:23,755 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-94413D62F314,id=64cbb9bc-55ad-4bd6-90d7-16706f0bd234
2020-06-02 23:12:23,755 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: shutdown FollowerState
2020-06-02 23:12:23,755 [Thread-221] INFO  impl.FollowerState (FollowerState.java:run(117)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-06-02 23:12:23,755 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(288)) - group-94413D62F314: Taking a snapshot at:(t:2, i:0) file /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis/942268b7-bff6-4625-9a57-94413d62f314/sm/snapshot.2_0
2020-06-02 23:12:23,753 [Listener at 127.0.0.1/45129] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - cb97469d-781c-49b1-b566-b9439314fa8f: close
2020-06-02 23:12:23,757 [Listener at 127.0.0.1/45129] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8: shutdown
2020-06-02 23:12:23,757 [Listener at 127.0.0.1/45129] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B4B248D0A7E8,id=cb97469d-781c-49b1-b566-b9439314fa8f
2020-06-02 23:12:23,757 [Listener at 127.0.0.1/45129] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - cb97469d-781c-49b1-b566-b9439314fa8f: shutdown LeaderState
2020-06-02 23:12:23,758 [Listener at 127.0.0.1/45129] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(242)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-PendingRequests: sendNotLeaderResponses
2020-06-02 23:12:23,759 [Listener at 127.0.0.1/45129] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_appender.cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8
2020-06-02 23:12:23,762 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(288)) - group-B4B248D0A7E8: Taking a snapshot at:(t:1, i:0) file /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis/2c05d2c6-9e37-4981-a88d-b4b248d0a7e8/sm/snapshot.1_0
2020-06-02 23:12:23,762 [Listener at 127.0.0.1/45129] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(142)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-StateMachineUpdater: set stopIndex = 0
2020-06-02 23:12:23,762 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(142)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-StateMachineUpdater: set stopIndex = 0
2020-06-02 23:12:24,086 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-B4B248D0A7E8: Finished taking a snapshot at:(t:1, i:0) file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis/2c05d2c6-9e37-4981-a88d-b4b248d0a7e8/sm/snapshot.1_0 time:324
2020-06-02 23:12:24,087 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(277)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-StateMachineUpdater: Took a snapshot at index 0
2020-06-02 23:12:24,087 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(87)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-06-02 23:12:24,093 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-94413D62F314: Finished taking a snapshot at:(t:2, i:0) file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis/942268b7-bff6-4625-9a57-94413d62f314/sm/snapshot.2_0 time:337
2020-06-02 23:12:24,093 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(277)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-StateMachineUpdater: Took a snapshot at index 0
2020-06-02 23:12:24,093 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(87)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-06-02 23:12:24,093 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314
2020-06-02 23:12:24,094 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314: closes. applyIndex: 0
2020-06-02 23:12:24,095 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-06-02 23:12:24,096 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-SegmentedRaftLogWorker close()
2020-06-02 23:12:24,097 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.64cbb9bc-55ad-4bd6-90d7-16706f0bd234
2020-06-02 23:12:24,098 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314
2020-06-02 23:12:24,098 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314
2020-06-02 23:12:24,098 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606: shutdown
2020-06-02 23:12:24,098 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5DD255C8B606,id=64cbb9bc-55ad-4bd6-90d7-16706f0bd234
2020-06-02 23:12:24,098 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: shutdown LeaderState
2020-06-02 23:12:24,098 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(242)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-PendingRequests: sendNotLeaderResponses
2020-06-02 23:12:24,099 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_appender.64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606
2020-06-02 23:12:24,099 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(142)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-StateMachineUpdater: set stopIndex = 0
2020-06-02 23:12:24,099 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(288)) - group-5DD255C8B606: Taking a snapshot at:(t:1, i:0) file /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis/7e7fc930-ceec-4c3e-aa3b-5dd255c8b606/sm/snapshot.1_0
2020-06-02 23:12:24,100 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8
2020-06-02 23:12:24,100 [Listener at 127.0.0.1/45129] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8: closes. applyIndex: 0
2020-06-02 23:12:24,100 [cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-06-02 23:12:24,101 [Listener at 127.0.0.1/45129] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-SegmentedRaftLogWorker close()
2020-06-02 23:12:24,102 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-5DD255C8B606: Finished taking a snapshot at:(t:1, i:0) file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-0/data/ratis/7e7fc930-ceec-4c3e-aa3b-5dd255c8b606/sm/snapshot.1_0 time:3
2020-06-02 23:12:24,102 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(277)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-StateMachineUpdater: Took a snapshot at index 0
2020-06-02 23:12:24,102 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(87)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-06-02 23:12:24,103 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606
2020-06-02 23:12:24,103 [Listener at 127.0.0.1/45129] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.cb97469d-781c-49b1-b566-b9439314fa8f
2020-06-02 23:12:24,103 [Listener at 127.0.0.1/45129] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8
2020-06-02 23:12:24,103 [Listener at 127.0.0.1/45129] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8
2020-06-02 23:12:24,103 [Listener at 127.0.0.1/45129] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314: shutdown
2020-06-02 23:12:24,105 [Listener at 127.0.0.1/45129] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-94413D62F314,id=cb97469d-781c-49b1-b566-b9439314fa8f
2020-06-02 23:12:24,105 [Listener at 127.0.0.1/45129] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - cb97469d-781c-49b1-b566-b9439314fa8f: shutdown LeaderState
2020-06-02 23:12:24,105 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606: closes. applyIndex: 0
2020-06-02 23:12:24,107 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$465/1915571952@65a93d09] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(153)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314->ea1e16a2-08f2-4e20-9425-d71c7ab3efe9-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2020-06-02 23:12:24,107 [Listener at 127.0.0.1/45129] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(242)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-PendingRequests: sendNotLeaderResponses
2020-06-02 23:12:24,109 [Listener at 127.0.0.1/45129] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_appender.cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314
2020-06-02 23:12:24,109 [Listener at 127.0.0.1/45129] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(142)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-StateMachineUpdater: set stopIndex = 0
2020-06-02 23:12:24,106 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$465/1915571952@232972eb] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(153)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314->64cbb9bc-55ad-4bd6-90d7-16706f0bd234-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2020-06-02 23:12:24,109 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(288)) - group-94413D62F314: Taking a snapshot at:(t:2, i:0) file /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis/942268b7-bff6-4625-9a57-94413d62f314/sm/snapshot.2_0
2020-06-02 23:12:24,111 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-94413D62F314: Finished taking a snapshot at:(t:2, i:0) file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-1/data/ratis/942268b7-bff6-4625-9a57-94413d62f314/sm/snapshot.2_0 time:1
2020-06-02 23:12:24,111 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(277)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-StateMachineUpdater: Took a snapshot at index 0
2020-06-02 23:12:24,111 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(87)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-06-02 23:12:24,111 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314
2020-06-02 23:12:24,111 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(137)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: Completed APPEND_ENTRIES, lastRequest: cb97469d-781c-49b1-b566-b9439314fa8f->ea1e16a2-08f2-4e20-9425-d71c7ab3efe9#1-t2, previous=(t:0, i:0), leaderCommit=0, initializing? false, entries: size=1, first=(t:2, i:0), CONFIGURATIONENTRY
2020-06-02 23:12:24,112 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(309)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314->ea1e16a2-08f2-4e20-9425-d71c7ab3efe9-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2020-06-02 23:12:24,112 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(137)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: Completed APPEND_ENTRIES, lastRequest: cb97469d-781c-49b1-b566-b9439314fa8f->64cbb9bc-55ad-4bd6-90d7-16706f0bd234#1-t2, previous=(t:0, i:0), leaderCommit=0, initializing? false, entries: size=1, first=(t:2, i:0), CONFIGURATIONENTRY
2020-06-02 23:12:24,115 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314->ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: nextIndex: updateUnconditionally 1 -> 0
2020-06-02 23:12:24,121 [Listener at 127.0.0.1/45129] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314: closes. applyIndex: 0
2020-06-02 23:12:24,121 [cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-06-02 23:12:24,125 [64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-06-02 23:12:24,126 [Listener at 127.0.0.1/45129] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-SegmentedRaftLogWorker close()
2020-06-02 23:12:24,126 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(309)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314->64cbb9bc-55ad-4bd6-90d7-16706f0bd234-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2020-06-02 23:12:24,127 [Listener at 127.0.0.1/45129] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.cb97469d-781c-49b1-b566-b9439314fa8f
2020-06-02 23:12:24,127 [Listener at 127.0.0.1/45129] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314
2020-06-02 23:12:24,127 [Listener at 127.0.0.1/45129] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314
2020-06-02 23:12:24,128 [Listener at 127.0.0.1/45129] INFO  server.GrpcService (GrpcService.java:closeImpl(165)) - cb97469d-781c-49b1-b566-b9439314fa8f: shutdown server with port 38983 now
2020-06-02 23:12:24,132 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-SegmentedRaftLogWorker close()
2020-06-02 23:12:24,140 [Listener at 127.0.0.1/45129] INFO  server.GrpcService (GrpcService.java:closeImpl(173)) - cb97469d-781c-49b1-b566-b9439314fa8f: shutdown server with port 38983 successfully
2020-06-02 23:12:24,143 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.64cbb9bc-55ad-4bd6-90d7-16706f0bd234
2020-06-02 23:12:24,143 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606
2020-06-02 23:12:24,143 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606
2020-06-02 23:12:24,143 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(165)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: shutdown server with port 38703 now
2020-06-02 23:12:24,144 [Listener at 127.0.0.1/45129] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service BlockDeletingService
2020-06-02 23:12:24,148 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314->64cbb9bc-55ad-4bd6-90d7-16706f0bd234: nextIndex: updateUnconditionally 1 -> 0
2020-06-02 23:12:24,149 [Listener at 127.0.0.1/45129] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(424)) - Ozone container server stopped.
2020-06-02 23:12:24,150 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@776b1332{hddsDatanode,/,null,UNAVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 23:12:24,151 [Listener at 127.0.0.1/45129] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@6471a1c6{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-06-02 23:12:24,151 [Listener at 127.0.0.1/45129] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-06-02 23:12:24,151 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@51d25e0d{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2020-06-02 23:12:24,152 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@7b76ea62{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-06-02 23:12:24,155 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(173)) - 64cbb9bc-55ad-4bd6-90d7-16706f0bd234: shutdown server with port 38703 successfully
2020-06-02 23:12:24,156 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service BlockDeletingService
2020-06-02 23:12:24,158 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(424)) - Ozone container server stopped.
2020-06-02 23:12:24,161 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@2abde235{hddsDatanode,/,null,UNAVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 23:12:24,162 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@111c78fe{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-06-02 23:12:24,162 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-06-02 23:12:24,162 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@12a1a72e{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2020-06-02 23:12:24,163 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@6a3a1654{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-06-02 23:12:24,660 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:24,660 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:25,660 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:25,660 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:26,446 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: addNew group-8C8042690848:[f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907] returns group-8C8042690848:java.util.concurrent.CompletableFuture@cdaeba0[Not completed]
2020-06-02 23:12:26,447 [pool-106-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: new RaftServerImpl for group-8C8042690848:[f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907] with ContainerStateMachine:uninitialized
2020-06-02 23:12:26,448 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 23:12:26,448 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 23:12:26,448 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 23:12:26,448 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 23:12:26,448 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:12:26,448 [pool-106-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848: ConfigurationManager, init=-1: [f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907], old=null, confs=<EMPTY_MAP>
2020-06-02 23:12:26,448 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data/ratis] (custom)
2020-06-02 23:12:26,448 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 23:12:26,449 [pool-106-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data/ratis/b3fd9059-93d8-4d11-8433-8c8042690848 does not exist. Creating ...
2020-06-02 23:12:26,450 [pool-106-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data/ratis/b3fd9059-93d8-4d11-8433-8c8042690848/in_use.lock acquired by nodename 18775@cc5e24879e7f
2020-06-02 23:12:26,451 [pool-106-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data/ratis/b3fd9059-93d8-4d11-8433-8c8042690848 has been successfully formatted.
2020-06-02 23:12:26,452 [pool-106-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-8C8042690848: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 23:12:26,452 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 23:12:26,452 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 23:12:26,452 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(378)) - Unable to start the DatanodeState Machine
java.io.IOException: Unable to finish the execution.
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:375)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:212)
	... 2 more
2020-06-02 23:12:26,452 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 23:12:26,452 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:12:26,452 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:12:26,452 [pool-106-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.f35fd5b3-f20d-428f-8442-dfc8a30d644d
2020-06-02 23:12:26,453 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 23:12:26,453 [pool-106-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data/ratis/b3fd9059-93d8-4d11-8433-8c8042690848
2020-06-02 23:12:26,453 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 23:12:26,453 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 23:12:26,453 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:12:26,453 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 23:12:26,453 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 23:12:26,453 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 23:12:26,453 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 23:12:26,453 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 23:12:26,453 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 23:12:26,454 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 23:12:26,455 [pool-106-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 23:12:26,461 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 23:12:26,461 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 23:12:26,461 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 23:12:26,461 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 23:12:26,462 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 23:12:26,462 [pool-106-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848
2020-06-02 23:12:26,462 [pool-106-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848
2020-06-02 23:12:26,463 [pool-106-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848: start as a follower, conf=-1: [f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907], old=null
2020-06-02 23:12:26,463 [pool-106-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 23:12:26,463 [pool-106-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: start FollowerState
2020-06-02 23:12:26,464 [pool-106-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8C8042690848,id=f35fd5b3-f20d-428f-8442-dfc8a30d644d
2020-06-02 23:12:26,464 [pool-106-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848
2020-06-02 23:12:26,467 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS ONE #id: "b3fd9059-93d8-4d11-8433-8c8042690848"
.
2020-06-02 23:12:26,467 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: addNew group-DDD4F79A9D83:[64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737] returns group-DDD4F79A9D83:java.util.concurrent.CompletableFuture@8e56ee3[Not completed]
2020-06-02 23:12:26,468 [pool-106-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: new RaftServerImpl for group-DDD4F79A9D83:[64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737] with ContainerStateMachine:uninitialized
2020-06-02 23:12:26,468 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 23:12:26,469 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 23:12:26,469 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 23:12:26,469 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 23:12:26,469 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:12:26,469 [pool-106-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83: ConfigurationManager, init=-1: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null, confs=<EMPTY_MAP>
2020-06-02 23:12:26,469 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data/ratis] (custom)
2020-06-02 23:12:26,469 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 23:12:26,469 [pool-106-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data/ratis/3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83 does not exist. Creating ...
2020-06-02 23:12:26,471 [pool-106-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data/ratis/3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83/in_use.lock acquired by nodename 18775@cc5e24879e7f
2020-06-02 23:12:26,472 [pool-106-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data/ratis/3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83 has been successfully formatted.
2020-06-02 23:12:26,472 [pool-106-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-DDD4F79A9D83: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 23:12:26,472 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 23:12:26,472 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 23:12:26,472 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 23:12:26,472 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:12:26,472 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:12:26,473 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 23:12:26,473 [pool-106-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data/ratis/3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83
2020-06-02 23:12:26,473 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 23:12:26,473 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 23:12:26,473 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:12:26,473 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 23:12:26,473 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 23:12:26,473 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 23:12:26,473 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 23:12:26,473 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 23:12:26,473 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 23:12:26,474 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 23:12:26,474 [pool-106-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 23:12:26,479 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 23:12:26,479 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 23:12:26,479 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 23:12:26,479 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 23:12:26,479 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 23:12:26,479 [pool-106-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83
2020-06-02 23:12:26,480 [pool-106-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83
2020-06-02 23:12:26,480 [pool-106-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83: start as a follower, conf=-1: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null
2020-06-02 23:12:26,480 [pool-106-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 23:12:26,480 [pool-106-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: start FollowerState
2020-06-02 23:12:26,481 [pool-106-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DDD4F79A9D83,id=f35fd5b3-f20d-428f-8442-dfc8a30d644d
2020-06-02 23:12:26,481 [pool-106-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83
2020-06-02 23:12:26,493 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b8d14a52-4151-456e-8249-7fd2481d3769: addNew group-DDD4F79A9D83:[64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737] returns group-DDD4F79A9D83:java.util.concurrent.CompletableFuture@6780853d[Not completed]
2020-06-02 23:12:26,494 [pool-138-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - b8d14a52-4151-456e-8249-7fd2481d3769: new RaftServerImpl for group-DDD4F79A9D83:[64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737] with ContainerStateMachine:uninitialized
2020-06-02 23:12:26,496 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 23:12:26,496 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 23:12:26,496 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 23:12:26,496 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 23:12:26,496 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:12:26,496 [pool-138-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83: ConfigurationManager, init=-1: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null, confs=<EMPTY_MAP>
2020-06-02 23:12:26,496 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data/ratis] (custom)
2020-06-02 23:12:26,496 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 23:12:26,497 [pool-138-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data/ratis/3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83 does not exist. Creating ...
2020-06-02 23:12:26,498 [pool-138-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data/ratis/3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83/in_use.lock acquired by nodename 18775@cc5e24879e7f
2020-06-02 23:12:26,499 [pool-138-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data/ratis/3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83 has been successfully formatted.
2020-06-02 23:12:26,500 [pool-138-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-DDD4F79A9D83: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 23:12:26,500 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(378)) - Unable to start the DatanodeState Machine
java.io.IOException: Unable to finish the execution.
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:375)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:212)
	... 2 more
2020-06-02 23:12:26,500 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 23:12:26,500 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 23:12:26,500 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 23:12:26,500 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:12:26,500 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:12:26,501 [pool-138-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.b8d14a52-4151-456e-8249-7fd2481d3769
2020-06-02 23:12:26,501 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 23:12:26,501 [pool-138-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data/ratis/3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83
2020-06-02 23:12:26,501 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 23:12:26,501 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 23:12:26,501 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:12:26,501 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 23:12:26,501 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 23:12:26,501 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 23:12:26,501 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 23:12:26,501 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 23:12:26,502 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 23:12:26,503 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 23:12:26,503 [pool-138-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 23:12:26,503 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 23:12:26,503 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 23:12:26,504 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 23:12:26,504 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 23:12:26,504 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 23:12:26,504 [pool-138-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83
2020-06-02 23:12:26,504 [pool-138-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83
2020-06-02 23:12:26,505 [pool-138-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83: start as a follower, conf=-1: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null
2020-06-02 23:12:26,505 [pool-138-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 23:12:26,505 [pool-138-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b8d14a52-4151-456e-8249-7fd2481d3769: start FollowerState
2020-06-02 23:12:26,505 [pool-138-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DDD4F79A9D83,id=b8d14a52-4151-456e-8249-7fd2481d3769
2020-06-02 23:12:26,505 [pool-138-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83
2020-06-02 23:12:26,532 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 64686ae2-d3de-4265-80d8-19029de0d313: addNew group-DDD4F79A9D83:[64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737] returns group-DDD4F79A9D83:java.util.concurrent.CompletableFuture@c87a56d[Not completed]
2020-06-02 23:12:26,533 [pool-122-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 64686ae2-d3de-4265-80d8-19029de0d313: new RaftServerImpl for group-DDD4F79A9D83:[64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737] with ContainerStateMachine:uninitialized
2020-06-02 23:12:26,534 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 23:12:26,538 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 23:12:26,538 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 23:12:26,538 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 23:12:26,538 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:12:26,538 [pool-122-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83: ConfigurationManager, init=-1: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null, confs=<EMPTY_MAP>
2020-06-02 23:12:26,539 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data/ratis] (custom)
2020-06-02 23:12:26,539 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 23:12:26,539 [pool-122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data/ratis/3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83 does not exist. Creating ...
2020-06-02 23:12:26,541 [pool-122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data/ratis/3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83/in_use.lock acquired by nodename 18775@cc5e24879e7f
2020-06-02 23:12:26,542 [pool-122-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data/ratis/3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83 has been successfully formatted.
2020-06-02 23:12:26,542 [pool-122-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-DDD4F79A9D83: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 23:12:26,542 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(378)) - Unable to start the DatanodeState Machine
java.io.IOException: Unable to finish the execution.
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:375)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:212)
	... 2 more
2020-06-02 23:12:26,542 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 23:12:26,543 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 23:12:26,543 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 23:12:26,543 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:12:26,543 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:12:26,543 [pool-122-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.64686ae2-d3de-4265-80d8-19029de0d313
2020-06-02 23:12:26,543 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 23:12:26,543 [pool-122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data/ratis/3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83
2020-06-02 23:12:26,544 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 23:12:26,544 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 23:12:26,544 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:12:26,544 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 23:12:26,544 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 23:12:26,544 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 23:12:26,544 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 23:12:26,544 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 23:12:26,544 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 23:12:26,546 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 23:12:26,546 [pool-122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 23:12:26,546 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 23:12:26,546 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 23:12:26,546 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 23:12:26,546 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 23:12:26,546 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 23:12:26,546 [pool-122-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83
2020-06-02 23:12:26,547 [pool-122-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83
2020-06-02 23:12:26,547 [pool-122-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83: start as a follower, conf=-1: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null
2020-06-02 23:12:26,547 [pool-122-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 23:12:26,548 [pool-122-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 64686ae2-d3de-4265-80d8-19029de0d313: start FollowerState
2020-06-02 23:12:26,549 [pool-122-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DDD4F79A9D83,id=64686ae2-d3de-4265-80d8-19029de0d313
2020-06-02 23:12:26,549 [pool-122-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83
2020-06-02 23:12:26,555 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS THREE #id: "3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83"
.
2020-06-02 23:12:26,578 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 64686ae2-d3de-4265-80d8-19029de0d313: addNew group-D1C29487BCA2:[64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421] returns group-D1C29487BCA2:java.util.concurrent.CompletableFuture@6996ca64[Not completed]
2020-06-02 23:12:26,579 [pool-122-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 64686ae2-d3de-4265-80d8-19029de0d313: new RaftServerImpl for group-D1C29487BCA2:[64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421] with ContainerStateMachine:uninitialized
2020-06-02 23:12:26,579 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 23:12:26,579 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 23:12:26,579 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 23:12:26,579 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 23:12:26,579 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:12:26,580 [pool-122-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2: ConfigurationManager, init=-1: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421], old=null, confs=<EMPTY_MAP>
2020-06-02 23:12:26,580 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data/ratis] (custom)
2020-06-02 23:12:26,580 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 23:12:26,580 [pool-122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data/ratis/b37a4cf8-1cb0-4f2d-b7ed-d1c29487bca2 does not exist. Creating ...
2020-06-02 23:12:26,581 [pool-122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data/ratis/b37a4cf8-1cb0-4f2d-b7ed-d1c29487bca2/in_use.lock acquired by nodename 18775@cc5e24879e7f
2020-06-02 23:12:26,582 [pool-122-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data/ratis/b37a4cf8-1cb0-4f2d-b7ed-d1c29487bca2 has been successfully formatted.
2020-06-02 23:12:26,583 [pool-122-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-D1C29487BCA2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 23:12:26,583 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 23:12:26,583 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 23:12:26,583 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 23:12:26,583 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:12:26,583 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:12:26,583 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 23:12:26,583 [pool-122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data/ratis/b37a4cf8-1cb0-4f2d-b7ed-d1c29487bca2
2020-06-02 23:12:26,584 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 23:12:26,584 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 23:12:26,584 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:12:26,584 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 23:12:26,584 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 23:12:26,584 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 23:12:26,584 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 23:12:26,584 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 23:12:26,584 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 23:12:26,585 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 23:12:26,585 [pool-122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 23:12:26,585 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 23:12:26,585 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 23:12:26,585 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 23:12:26,585 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 23:12:26,586 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 23:12:26,586 [pool-122-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2
2020-06-02 23:12:26,586 [pool-122-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2
2020-06-02 23:12:26,587 [pool-122-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2: start as a follower, conf=-1: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421], old=null
2020-06-02 23:12:26,587 [pool-122-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 23:12:26,587 [pool-122-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 64686ae2-d3de-4265-80d8-19029de0d313: start FollowerState
2020-06-02 23:12:26,587 [pool-122-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D1C29487BCA2,id=64686ae2-d3de-4265-80d8-19029de0d313
2020-06-02 23:12:26,587 [pool-122-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2
2020-06-02 23:12:26,589 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS ONE #id: "b37a4cf8-1cb0-4f2d-b7ed-d1c29487bca2"
.
2020-06-02 23:12:26,661 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:26,661 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:26,670 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - b8d14a52-4151-456e-8249-7fd2481d3769: addNew group-F1F2F39DFED0:[b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737] returns group-F1F2F39DFED0:java.util.concurrent.CompletableFuture@5bb832ae[Not completed]
2020-06-02 23:12:26,671 [pool-138-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - b8d14a52-4151-456e-8249-7fd2481d3769: new RaftServerImpl for group-F1F2F39DFED0:[b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737] with ContainerStateMachine:uninitialized
2020-06-02 23:12:26,672 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 23:12:26,672 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 23:12:26,672 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 23:12:26,672 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 23:12:26,672 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:12:26,672 [pool-138-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0: ConfigurationManager, init=-1: [b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null, confs=<EMPTY_MAP>
2020-06-02 23:12:26,672 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data/ratis] (custom)
2020-06-02 23:12:26,672 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 23:12:26,672 [pool-138-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data/ratis/c5024fd7-d750-48bd-9d1a-f1f2f39dfed0 does not exist. Creating ...
2020-06-02 23:12:26,674 [pool-138-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data/ratis/c5024fd7-d750-48bd-9d1a-f1f2f39dfed0/in_use.lock acquired by nodename 18775@cc5e24879e7f
2020-06-02 23:12:26,675 [pool-138-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data/ratis/c5024fd7-d750-48bd-9d1a-f1f2f39dfed0 has been successfully formatted.
2020-06-02 23:12:26,676 [pool-138-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-F1F2F39DFED0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 23:12:26,676 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 23:12:26,676 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 23:12:26,676 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 23:12:26,676 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:12:26,676 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:12:26,677 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 23:12:26,677 [pool-138-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data/ratis/c5024fd7-d750-48bd-9d1a-f1f2f39dfed0
2020-06-02 23:12:26,677 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 23:12:26,677 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 23:12:26,677 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 23:12:26,677 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 23:12:26,677 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 23:12:26,677 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 23:12:26,677 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 23:12:26,677 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 23:12:26,677 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 23:12:26,678 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 23:12:26,678 [pool-138-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 23:12:26,679 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 23:12:26,679 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 23:12:26,679 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 23:12:26,679 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 23:12:26,679 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 23:12:26,680 [pool-138-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0
2020-06-02 23:12:26,680 [pool-138-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0
2020-06-02 23:12:26,681 [pool-138-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0: start as a follower, conf=-1: [b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null
2020-06-02 23:12:26,681 [pool-138-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 23:12:26,681 [pool-138-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b8d14a52-4151-456e-8249-7fd2481d3769: start FollowerState
2020-06-02 23:12:26,689 [pool-138-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F1F2F39DFED0,id=b8d14a52-4151-456e-8249-7fd2481d3769
2020-06-02 23:12:26,689 [pool-138-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0
2020-06-02 23:12:26,694 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS ONE #id: "c5024fd7-d750-48bd-9d1a-f1f2f39dfed0"
.
2020-06-02 23:12:27,661 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:27,661 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:28,661 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:28,662 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:29,155 [Listener at 127.0.0.1/45129] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(246)) - Attempting to stop container services.
2020-06-02 23:12:29,155 [Listener at 127.0.0.1/45129] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: close
2020-06-02 23:12:29,165 [Listener at 127.0.0.1/45129] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862: shutdown
2020-06-02 23:12:29,165 [Listener at 127.0.0.1/45129] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A03B68A52862,id=ea1e16a2-08f2-4e20-9425-d71c7ab3efe9
2020-06-02 23:12:29,165 [Listener at 127.0.0.1/45129] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: shutdown LeaderState
2020-06-02 23:12:29,166 [Listener at 127.0.0.1/45129] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(242)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-PendingRequests: sendNotLeaderResponses
2020-06-02 23:12:29,166 [Listener at 127.0.0.1/45129] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_appender.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862
2020-06-02 23:12:29,166 [Listener at 127.0.0.1/45129] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(142)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-StateMachineUpdater: set stopIndex = 0
2020-06-02 23:12:29,166 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(288)) - group-A03B68A52862: Taking a snapshot at:(t:1, i:0) file /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis/6d7a0520-e2c2-43e9-bd7d-a03b68a52862/sm/snapshot.1_0
2020-06-02 23:12:29,168 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-A03B68A52862: Finished taking a snapshot at:(t:1, i:0) file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis/6d7a0520-e2c2-43e9-bd7d-a03b68a52862/sm/snapshot.1_0 time:1
2020-06-02 23:12:29,168 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(277)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-StateMachineUpdater: Took a snapshot at index 0
2020-06-02 23:12:29,168 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(87)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-06-02 23:12:29,168 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862
2020-06-02 23:12:29,169 [Listener at 127.0.0.1/45129] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862: closes. applyIndex: 0
2020-06-02 23:12:29,169 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-06-02 23:12:29,174 [Listener at 127.0.0.1/45129] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-SegmentedRaftLogWorker close()
2020-06-02 23:12:29,175 [Listener at 127.0.0.1/45129] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9
2020-06-02 23:12:29,175 [Listener at 127.0.0.1/45129] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862
2020-06-02 23:12:29,175 [Listener at 127.0.0.1/45129] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862
2020-06-02 23:12:29,175 [Listener at 127.0.0.1/45129] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314: shutdown
2020-06-02 23:12:29,175 [Listener at 127.0.0.1/45129] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-94413D62F314,id=ea1e16a2-08f2-4e20-9425-d71c7ab3efe9
2020-06-02 23:12:29,176 [Listener at 127.0.0.1/45129] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: shutdown FollowerState
2020-06-02 23:12:29,176 [Listener at 127.0.0.1/45129] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(142)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-StateMachineUpdater: set stopIndex = 0
2020-06-02 23:12:29,176 [Thread-220] INFO  impl.FollowerState (FollowerState.java:run(117)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-06-02 23:12:29,176 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(288)) - group-94413D62F314: Taking a snapshot at:(t:2, i:0) file /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis/942268b7-bff6-4625-9a57-94413d62f314/sm/snapshot.2_0
2020-06-02 23:12:29,177 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-94413D62F314: Finished taking a snapshot at:(t:2, i:0) file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-2695e145-105d-46f6-80df-05d5e174bece/datanode-2/data/ratis/942268b7-bff6-4625-9a57-94413d62f314/sm/snapshot.2_0 time:0
2020-06-02 23:12:29,177 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(277)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-StateMachineUpdater: Took a snapshot at index 0
2020-06-02 23:12:29,177 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(87)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-06-02 23:12:29,177 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314
2020-06-02 23:12:29,177 [Listener at 127.0.0.1/45129] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314: closes. applyIndex: 0
2020-06-02 23:12:29,178 [ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-06-02 23:12:29,178 [Listener at 127.0.0.1/45129] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-SegmentedRaftLogWorker close()
2020-06-02 23:12:29,179 [Listener at 127.0.0.1/45129] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9
2020-06-02 23:12:29,179 [Listener at 127.0.0.1/45129] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314
2020-06-02 23:12:29,179 [Listener at 127.0.0.1/45129] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314
2020-06-02 23:12:29,180 [Listener at 127.0.0.1/45129] INFO  server.GrpcService (GrpcService.java:closeImpl(165)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: shutdown server with port 44223 now
2020-06-02 23:12:29,181 [Listener at 127.0.0.1/45129] INFO  server.GrpcService (GrpcService.java:closeImpl(173)) - ea1e16a2-08f2-4e20-9425-d71c7ab3efe9: shutdown server with port 44223 successfully
2020-06-02 23:12:29,183 [Listener at 127.0.0.1/45129] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service BlockDeletingService
2020-06-02 23:12:29,193 [Listener at 127.0.0.1/45129] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(424)) - Ozone container server stopped.
2020-06-02 23:12:29,194 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@59427816{hddsDatanode,/,null,UNAVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 23:12:29,195 [Listener at 127.0.0.1/45129] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@55123277{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-06-02 23:12:29,195 [Listener at 127.0.0.1/45129] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-06-02 23:12:29,195 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@6b9d527a{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2020-06-02 23:12:29,195 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@1c0bb9ca{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-06-02 23:12:29,196 [Listener at 127.0.0.1/45129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(476)) - Stopping the StorageContainerManager
2020-06-02 23:12:29,197 [Listener at 127.0.0.1/45129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(824)) - Stopping Replication Manager Service.
2020-06-02 23:12:29,197 [Listener at 127.0.0.1/45129] INFO  container.ReplicationManager (ReplicationManager.java:stop(215)) - Replication Monitor Thread is not running.
2020-06-02 23:12:29,197 [Listener at 127.0.0.1/45129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(831)) - Stopping Lease Manager of the command watchers
2020-06-02 23:12:29,197 [Listener at 127.0.0.1/45129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(838)) - Stopping datanode service RPC server
2020-06-02 23:12:29,197 [CommandWatcher-LeaseManager#LeaseMonitor] ERROR lease.LeaseManager (LeaseManager.java:run(238)) - Execution was interrupted 
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:234)
	at java.lang.Thread.run(Thread.java:748)
2020-06-02 23:12:29,197 [Listener at 127.0.0.1/45129] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(361)) - Stopping the RPC server for DataNodes
2020-06-02 23:12:29,197 [Listener at 127.0.0.1/45129] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33535
2020-06-02 23:12:29,198 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-06-02 23:12:29,201 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-06-02 23:12:29,286 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(661)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2020-06-02 23:12:29,286 [Listener at 127.0.0.1/45129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(846)) - Stopping block service RPC server
2020-06-02 23:12:29,286 [Listener at 127.0.0.1/45129] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(158)) - Stopping the RPC server for Block Protocol
2020-06-02 23:12:29,286 [Listener at 127.0.0.1/45129] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41471
2020-06-02 23:12:29,289 [Listener at 127.0.0.1/45129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(853)) - Stopping the StorageContainerLocationProtocol RPC server
2020-06-02 23:12:29,289 [Listener at 127.0.0.1/45129] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(166)) - Stopping the RPC server for Client Protocol
2020-06-02 23:12:29,289 [Listener at 127.0.0.1/45129] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45471
2020-06-02 23:12:29,289 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-06-02 23:12:29,290 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-06-02 23:12:29,290 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-06-02 23:12:29,290 [Listener at 127.0.0.1/45129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(860)) - Stopping Storage Container Manager HTTP server.
2020-06-02 23:12:29,291 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@508926e2{scm,/,null,UNAVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2020-06-02 23:12:29,291 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-06-02 23:12:29,294 [Listener at 127.0.0.1/45129] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@6841356f{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-06-02 23:12:29,294 [Listener at 127.0.0.1/45129] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-06-02 23:12:29,295 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@5684f55e{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2020-06-02 23:12:29,295 [Listener at 127.0.0.1/45129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@6878c095{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-06-02 23:12:29,296 [Listener at 127.0.0.1/45129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(871)) - Stopping Block Manager Service.
2020-06-02 23:12:29,296 [Listener at 127.0.0.1/45129] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service SCMBlockDeletingService
2020-06-02 23:12:29,297 [Listener at 127.0.0.1/45129] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service SCMBlockDeletingService
2020-06-02 23:12:29,297 [Listener at 127.0.0.1/45129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(896)) - Stopping SCM Event Queue.
2020-06-02 23:12:29,312 [Listener at 127.0.0.1/45129] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2020-06-02 23:12:29,465 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2020-06-02 23:12:29,465 [Listener at 127.0.0.1/45129] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2020-06-02 23:12:29,662 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:29,662 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:30,662 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:30,662 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:31,486 [Thread-437] INFO  impl.FollowerState (FollowerState.java:run(108)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-FollowerState: change to CANDIDATE, lastRpcTime:5005ms, electionTimeout:5005ms
2020-06-02 23:12:31,486 [Thread-437] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: shutdown FollowerState
2020-06-02 23:12:31,487 [Thread-437] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 23:12:31,487 [Thread-437] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: start LeaderElection
2020-06-02 23:12:31,533 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10: begin an election at term 1 for -1: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null
2020-06-02 23:12:31,583 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:f35fd5b3-f20d-428f-8442-dfc8a30d644d
2020-06-02 23:12:31,583 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 64686ae2-d3de-4265-80d8-19029de0d313: shutdown FollowerState
2020-06-02 23:12:31,583 [Thread-435] INFO  impl.FollowerState (FollowerState.java:run(108)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-FollowerState: change to CANDIDATE, lastRpcTime:5120ms, electionTimeout:5119ms
2020-06-02 23:12:31,584 [Thread-442] INFO  impl.FollowerState (FollowerState.java:run(117)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-06-02 23:12:31,583 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 64686ae2-d3de-4265-80d8-19029de0d313: start FollowerState
2020-06-02 23:12:31,584 [Thread-435] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: shutdown FollowerState
2020-06-02 23:12:31,584 [Thread-435] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 23:12:31,584 [Thread-435] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: start LeaderElection
2020-06-02 23:12:31,597 [Thread-439] INFO  impl.FollowerState (FollowerState.java:run(108)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83-FollowerState: change to CANDIDATE, lastRpcTime:5092ms, electionTimeout:5079ms
2020-06-02 23:12:31,597 [Thread-439] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b8d14a52-4151-456e-8249-7fd2481d3769: shutdown FollowerState
2020-06-02 23:12:31,597 [Thread-439] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 23:12:31,597 [Thread-439] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b8d14a52-4151-456e-8249-7fd2481d3769: start LeaderElection
2020-06-02 23:12:31,638 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10: Election PASSED; received 1 response(s) [f35fd5b3-f20d-428f-8442-dfc8a30d644d<-64686ae2-d3de-4265-80d8-19029de0d313#0:OK-t1] and 0 exception(s); f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83:t1, leader=null, voted=f35fd5b3-f20d-428f-8442-dfc8a30d644d, raftlog=f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null
2020-06-02 23:12:31,638 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: shutdown LeaderElection
2020-06-02 23:12:31,638 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 23:12:31,642 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-DDD4F79A9D83 with new leaderId: f35fd5b3-f20d-428f-8442-dfc8a30d644d
2020-06-02 23:12:31,642 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83: change Leader from null to f35fd5b3-f20d-428f-8442-dfc8a30d644d at term 1 for becomeLeader, leader elected after 5169ms
2020-06-02 23:12:31,642 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 23:12:31,642 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 23:12:31,648 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83
2020-06-02 23:12:31,648 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 23:12:31,648 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 23:12:31,648 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 23:12:31,648 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 23:12:31,648 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 23:12:31,648 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-06-02 23:12:31,649 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:12:31,649 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2020-06-02 23:12:31,649 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2020-06-02 23:12:31,649 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 23:12:31,649 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:12:31,649 [b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83-LeaderElection12: begin an election at term 1 for -1: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null
2020-06-02 23:12:31,647 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11: begin an election at term 1 for -1: [f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907], old=null
2020-06-02 23:12:31,658 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: shutdown LeaderElection
2020-06-02 23:12:31,658 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 23:12:31,658 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-8C8042690848 with new leaderId: f35fd5b3-f20d-428f-8442-dfc8a30d644d
2020-06-02 23:12:31,650 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-06-02 23:12:31,659 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 23:12:31,659 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2020-06-02 23:12:31,662 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:31,662 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:31,675 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848: change Leader from null to f35fd5b3-f20d-428f-8442-dfc8a30d644d at term 1 for becomeLeader, leader elected after 5206ms
2020-06-02 23:12:31,675 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2020-06-02 23:12:31,675 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 23:12:31,676 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 23:12:31,676 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848
2020-06-02 23:12:31,676 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 23:12:31,676 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 23:12:31,676 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 23:12:31,676 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 23:12:31,676 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 23:12:31,677 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 23:12:31,677 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 23:12:31,677 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: start LeaderState
2020-06-02 23:12:31,677 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d: start LeaderState
2020-06-02 23:12:31,677 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 23:12:31,677 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 23:12:31,679 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data/ratis/3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83/current/log_inprogress_0
2020-06-02 23:12:31,679 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-0/data/ratis/b3fd9059-93d8-4d11-8433-8c8042690848/current/log_inprogress_0
2020-06-02 23:12:31,680 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-LeaderElection10] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83: set configuration 0: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null at 0
2020-06-02 23:12:31,694 [f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848-LeaderElection11] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-8C8042690848: set configuration 0: [f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907], old=null at 0
2020-06-02 23:12:31,711 [Thread-445] INFO  impl.FollowerState (FollowerState.java:run(108)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-FollowerState: change to CANDIDATE, lastRpcTime:5124ms, electionTimeout:5123ms
2020-06-02 23:12:31,711 [Thread-445] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 64686ae2-d3de-4265-80d8-19029de0d313: shutdown FollowerState
2020-06-02 23:12:31,711 [Thread-445] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 23:12:31,711 [Thread-445] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 64686ae2-d3de-4265-80d8-19029de0d313: start LeaderElection
2020-06-02 23:12:31,727 [grpc-default-executor-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-DDD4F79A9D83 with new leaderId: f35fd5b3-f20d-428f-8442-dfc8a30d644d
2020-06-02 23:12:31,727 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83: change Leader from null to f35fd5b3-f20d-428f-8442-dfc8a30d644d at term 1 for appendEntries, leader elected after 5184ms
2020-06-02 23:12:31,745 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:requestVote(818)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83- FOLLOWER: Withhold vote from candidate b8d14a52-4151-456e-8249-7fd2481d3769 with term 1. State: leader=f35fd5b3-f20d-428f-8442-dfc8a30d644d, term=1, lastRpcElapsed=7ms
2020-06-02 23:12:31,745 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83: set configuration 0: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null at 0
2020-06-02 23:12:31,746 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 23:12:31,746 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83: changes role from CANDIDATE to FOLLOWER at term 1 for appendEntries
2020-06-02 23:12:31,746 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b8d14a52-4151-456e-8249-7fd2481d3769: shutdown LeaderElection
2020-06-02 23:12:31,747 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b8d14a52-4151-456e-8249-7fd2481d3769: start FollowerState
2020-06-02 23:12:31,748 [grpc-default-executor-2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-DDD4F79A9D83 with new leaderId: f35fd5b3-f20d-428f-8442-dfc8a30d644d
2020-06-02 23:12:31,748 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83: change Leader from null to f35fd5b3-f20d-428f-8442-dfc8a30d644d at term 1 for appendEntries, leader elected after 5248ms
2020-06-02 23:12:31,749 [64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-DDD4F79A9D83-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data/ratis/3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83/current/log_inprogress_0
2020-06-02 23:12:31,766 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:requestVote(818)) - f35fd5b3-f20d-428f-8442-dfc8a30d644d@group-DDD4F79A9D83-   LEADER: Withhold vote from candidate b8d14a52-4151-456e-8249-7fd2481d3769 with term 1. State: leader=f35fd5b3-f20d-428f-8442-dfc8a30d644d, term=1, lastRpcElapsed=null
2020-06-02 23:12:31,768 [b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83-LeaderElection12: Election REJECTED; received 1 response(s) [b8d14a52-4151-456e-8249-7fd2481d3769<-64686ae2-d3de-4265-80d8-19029de0d313#0:FAIL-t1] and 0 exception(s); b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83:t1, leader=f35fd5b3-f20d-428f-8442-dfc8a30d644d, voted=b8d14a52-4151-456e-8249-7fd2481d3769, raftlog=b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null
2020-06-02 23:12:31,769 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83: set configuration 0: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421, f35fd5b3-f20d-428f-8442-dfc8a30d644d:172.17.0.2:44907, b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null at 0
2020-06-02 23:12:31,769 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 23:12:31,771 [b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-DDD4F79A9D83-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data/ratis/3f80fbe7-a1fb-41a2-8574-ddd4f79a9d83/current/log_inprogress_0
2020-06-02 23:12:31,789 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13: begin an election at term 1 for -1: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421], old=null
2020-06-02 23:12:31,789 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 64686ae2-d3de-4265-80d8-19029de0d313: shutdown LeaderElection
2020-06-02 23:12:31,789 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 23:12:31,789 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-D1C29487BCA2 with new leaderId: 64686ae2-d3de-4265-80d8-19029de0d313
2020-06-02 23:12:31,789 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2: change Leader from null to 64686ae2-d3de-4265-80d8-19029de0d313 at term 1 for becomeLeader, leader elected after 5206ms
2020-06-02 23:12:31,790 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 23:12:31,790 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 23:12:31,790 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2
2020-06-02 23:12:31,790 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 23:12:31,790 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 23:12:31,790 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 23:12:31,790 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 23:12:31,790 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 23:12:31,790 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 64686ae2-d3de-4265-80d8-19029de0d313: start LeaderState
2020-06-02 23:12:31,791 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 23:12:31,792 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-1/data/ratis/b37a4cf8-1cb0-4f2d-b7ed-d1c29487bca2/current/log_inprogress_0
2020-06-02 23:12:31,809 [64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2-LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 64686ae2-d3de-4265-80d8-19029de0d313@group-D1C29487BCA2: set configuration 0: [64686ae2-d3de-4265-80d8-19029de0d313:172.17.0.2:34421], old=null at 0
2020-06-02 23:12:31,877 [Thread-447] INFO  impl.FollowerState (FollowerState.java:run(108)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-FollowerState: change to CANDIDATE, lastRpcTime:5196ms, electionTimeout:5187ms
2020-06-02 23:12:31,877 [Thread-447] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - b8d14a52-4151-456e-8249-7fd2481d3769: shutdown FollowerState
2020-06-02 23:12:31,877 [Thread-447] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 23:12:31,877 [Thread-447] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b8d14a52-4151-456e-8249-7fd2481d3769: start LeaderElection
2020-06-02 23:12:31,920 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14: begin an election at term 1 for -1: [b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null
2020-06-02 23:12:31,920 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - b8d14a52-4151-456e-8249-7fd2481d3769: shutdown LeaderElection
2020-06-02 23:12:31,920 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 23:12:31,920 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-F1F2F39DFED0 with new leaderId: b8d14a52-4151-456e-8249-7fd2481d3769
2020-06-02 23:12:31,921 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0: change Leader from null to b8d14a52-4151-456e-8249-7fd2481d3769 at term 1 for becomeLeader, leader elected after 5244ms
2020-06-02 23:12:31,921 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 23:12:31,921 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 23:12:31,921 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0
2020-06-02 23:12:31,921 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 23:12:31,921 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 23:12:31,921 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 23:12:31,921 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 23:12:31,922 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 23:12:31,923 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - b8d14a52-4151-456e-8249-7fd2481d3769: start LeaderState
2020-06-02 23:12:31,923 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 23:12:31,925 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5e1a6f33-87fd-4deb-bcef-c2e73f255474/datanode-2/data/ratis/c5024fd7-d750-48bd-9d1a-f1f2f39dfed0/current/log_inprogress_0
2020-06-02 23:12:31,937 [b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0-LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - b8d14a52-4151-456e-8249-7fd2481d3769@group-F1F2F39DFED0: set configuration 0: [b8d14a52-4151-456e-8249-7fd2481d3769:172.17.0.2:44737], old=null at 0
2020-06-02 23:12:32,663 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:32,663 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:33,663 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:33,663 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:34,663 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:34,664 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:35,664 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:35,664 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:36,664 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:36,664 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:37,664 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:37,665 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:38,665 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:38,665 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:39,665 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:39,665 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:40,666 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:40,666 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:41,666 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:41,666 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:42,667 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:42,668 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:43,668 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:43,668 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:44,668 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:44,669 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:45,669 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:45,670 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:46,670 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:46,671 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:47,671 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:47,672 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:48,672 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:48,673 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:49,673 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:49,674 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:50,674 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:50,675 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:51,675 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:51,675 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:52,675 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:52,675 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:53,675 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:53,676 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:54,676 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:54,676 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:55,676 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:55,676 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:56,677 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:56,677 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:57,677 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:57,677 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:58,677 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:58,677 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:12:59,678 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:12:59,678 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:00,678 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:00,678 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:01,678 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:01,678 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:02,679 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:02,679 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:03,679 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:03,679 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:04,679 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:04,679 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:05,680 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:05,680 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:06,680 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:06,680 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:07,680 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:07,681 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:08,681 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:08,681 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:09,681 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:09,681 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:10,681 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:10,682 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:11,682 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:11,682 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:12,682 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:12,682 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:13,682 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:13,683 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:14,683 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:14,683 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:15,683 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:15,683 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:16,683 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:16,684 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:17,684 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:17,684 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 23:13:18,684 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 23:13:18,684 [Listener at 127.0.0.1/33481] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
]]></system-out>
    <system-err><![CDATA[====> TEST TIMED OUT. PRINTING THREAD DUMP. <====

Timestamp: 2020-06-02 11:12:18,707

"Datanode State Machine Thread - 0" daemon prio=5 tid=181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-35-thread-1"  prio=5 tid=252 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode State Machine Thread - 0" daemon prio=5 tid=224 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1525834420-97" daemon prio=5 tid=97 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp1525834420-103" daemon prio=5 tid=103 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-2-0" daemon prio=5 tid=241 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server Responder" daemon prio=5 tid=24 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"IPC Server Responder" daemon prio=5 tid=28 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"ChunkWriter-1-0" daemon prio=5 tid=227 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Command processor thread" daemon prio=5 tid=222 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$171/944075807.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"Thread-222" daemon prio=5 tid=314 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"qtp187096820-208-acceptor-0@50c85ddb-ServerConnector@55123277{HTTP/1.1,[http/1.1]}{0.0.0.0:41283}" daemon prio=3 tid=208 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"BlockDeletingService#1" daemon prio=5 tid=232 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-StateMachineUpdater" daemon prio=5 tid=265 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 5 on default port 41471" daemon prio=5 tid=61 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp708133671-163" daemon prio=5 tid=163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 0 on default port 33535" daemon prio=5 tid=76 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=201 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 16 on default port 33535" daemon prio=5 tid=92 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 3 on default port 33535" daemon prio=5 tid=79 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-StateMachineUpdater" daemon prio=5 tid=264 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"qtp708133671-162" daemon prio=5 tid=162 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Listener at 127.0.0.1/45129"  prio=5 tid=12 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at org.eclipse.jetty.util.BlockingArrayQueue.offer(BlockingArrayQueue.java:282)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.doStop(QueuedThreadPool.java:207)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:93)
        at org.eclipse.jetty.util.component.ContainerLifeCycle.stop(ContainerLifeCycle.java:180)
        at org.eclipse.jetty.util.component.ContainerLifeCycle.doStop(ContainerLifeCycle.java:201)
        at org.eclipse.jetty.server.handler.AbstractHandler.doStop(AbstractHandler.java:108)
        at org.eclipse.jetty.server.Server.doStop(Server.java:454)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:93)
        at org.apache.hadoop.hdds.server.http.HttpServer2.stop(HttpServer2.java:1338)
        at org.apache.hadoop.hdds.server.http.BaseHttpServer.stop(BaseHttpServer.java:310)
        at org.apache.hadoop.ozone.om.OzoneManager.stop(OzoneManager.java:1290)
        at org.apache.hadoop.ozone.MiniOzoneClusterImpl.stopOM(MiniOzoneClusterImpl.java:485)
        at org.apache.hadoop.ozone.MiniOzoneClusterImpl.stop(MiniOzoneClusterImpl.java:403)
        at org.apache.hadoop.ozone.MiniOzoneClusterImpl.shutdown(MiniOzoneClusterImpl.java:391)
        at org.apache.hadoop.ozone.om.TestOMDbCheckpointServlet.shutdown(TestOMDbCheckpointServlet.java:107)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
        at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
"grpc-nio-worker-ELG-3-2" daemon prio=5 tid=274 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:807)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@6e11a059" daemon prio=5 tid=108 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server idle connection scanner for port 45471" daemon prio=5 tid=27 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 17 on default port 33535" daemon prio=5 tid=93 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Socket Reader #1 for port 0"  prio=5 tid=18 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"qtp708133671-165" daemon prio=5 tid=165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 9 on default port 45471" daemon prio=5 tid=45 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 10 on default port 33535" daemon prio=5 tid=86 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 4 on default port 33535" daemon prio=5 tid=80 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Datanode State Machine Thread - 0" daemon prio=5 tid=204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Thread-221" daemon prio=5 tid=313 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:243)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:97)
"grpc-default-executor-0" daemon prio=5 tid=275 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"grpc-nio-boss-ELG-1-1" daemon prio=5 tid=230 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
"qtp74777304-186" daemon prio=5 tid=186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-38d838b-1"  prio=5 tid=104 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp187096820-211" daemon prio=5 tid=211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 14 on default port 33535" daemon prio=5 tid=90 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"CommandWatcher-LeaseManager#LeaseMonitor" daemon prio=5 tid=35 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:234)
        at java.lang.Thread.run(Thread.java:748)
"DataNode DiskChecker thread 0" daemon prio=5 tid=172 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@644af14d" daemon prio=5 tid=223 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"qtp187096820-212" daemon prio=5 tid=212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=219 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 3 on default port 45471" daemon prio=5 tid=39 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$465/1915571952@65a93d09" daemon prio=5 tid=316 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:151)
        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:105)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:77)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$465/1915571952.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"qtp708133671-160-acceptor-0@207ede47-ServerConnector@111c78fe{HTTP/1.1,[http/1.1]}{0.0.0.0:38503}" daemon prio=3 tid=160 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"Thread-196" daemon prio=5 tid=287 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"Thread-220" daemon prio=5 tid=312 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:243)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:97)
"Periodic HDDS volume checker" daemon prio=5 tid=195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1525834420-101" daemon prio=5 tid=101 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 17 on default port 41471" daemon prio=5 tid=73 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=221 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 2 on default port 45471" daemon prio=5 tid=38 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"grpc-default-executor-1" daemon prio=5 tid=276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-3-0" daemon prio=5 tid=229 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 6 on default port 45471" daemon prio=5 tid=42 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp74777304-183" daemon prio=5 tid=183 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/959322083.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 11 on default port 33535" daemon prio=5 tid=87 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 1 on default port 41471" daemon prio=5 tid=57 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 0 on default port 45471" daemon prio=5 tid=36 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server idle connection scanner for port 33535" daemon prio=5 tid=19 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"pool-71-thread-1"  prio=5 tid=206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1949177487-149" daemon prio=5 tid=149 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=10 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 2 on default port 33535" daemon prio=5 tid=78 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Session-HouseKeeper-48612817-1"  prio=5 tid=191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-StateMachineUpdater" daemon prio=5 tid=254 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"pool-67-thread-1"  prio=5 tid=260 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-56-thread-1"  prio=5 tid=192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-ContainerReportForContainerReportHandler" daemon prio=5 tid=246 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 18 on default port 41471" daemon prio=5 tid=74 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp708133671-164" daemon prio=5 tid=164 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"pool-40-thread-1"  prio=5 tid=168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 7 on default port 45471" daemon prio=5 tid=43 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp74777304-187" daemon prio=5 tid=187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 8 on default port 41471" daemon prio=5 tid=64 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 7 on default port 41471" daemon prio=5 tid=63 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp187096820-207" daemon prio=5 tid=207 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/959322083.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server idle connection scanner for port 41471" daemon prio=5 tid=23 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Thread-198" daemon prio=5 tid=289 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-A03B68A52862-SegmentedRaftLogWorker"  prio=5 tid=263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 16 on default port 45471" daemon prio=5 tid=52 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 14 on default port 41471" daemon prio=5 tid=70 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"BlockDeletingService#1" daemon prio=5 tid=238 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 1 on default port 45471" daemon prio=5 tid=37 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-28-thread-1" daemon prio=5 tid=156 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp74777304-185" daemon prio=5 tid=185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 13 on default port 41471" daemon prio=5 tid=69 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"main"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1610)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:93)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:79)
        at org.apache.hadoop.test.TimedOutTestsListener.testFailure(TimedOutTestsListener.java:67)
        at org.junit.runner.notification.RunNotifier$4.notifyListener(RunNotifier.java:139)
        at org.junit.runner.notification.RunNotifier$SafeNotifier.run(RunNotifier.java:61)
        at org.junit.runner.notification.RunNotifier.fireTestFailures(RunNotifier.java:134)
        at org.junit.runner.notification.RunNotifier.fireTestFailure(RunNotifier.java:128)
        at org.apache.maven.surefire.common.junit4.Notifier.fireTestFailure(Notifier.java:114)
        at org.junit.internal.runners.model.EachTestNotifier.addFailure(EachTestNotifier.java:23)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:275)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
"pool-72-thread-1"  prio=5 tid=216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-SegmentedRaftLogWorker"  prio=5 tid=261 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"qtp1525834420-99" daemon prio=5 tid=99 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-2baf80ba-1"  prio=5 tid=167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"process reaper" daemon prio=10 tid=11 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 9 on default port 41471" daemon prio=5 tid=65 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 6 on default port 41471" daemon prio=5 tid=62 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 8 on default port 45471" daemon prio=5 tid=44 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"SCMBlockDeletingService#1" daemon prio=5 tid=109 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=198 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"DataNode DiskChecker thread 0" daemon prio=5 tid=196 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)
"BlockDeletingService#1" daemon prio=5 tid=244 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"SCMBlockDeletingService#0" daemon prio=5 tid=107 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Thread-199" daemon prio=5 tid=290 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"Periodic HDDS volume checker" daemon prio=5 tid=171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=245 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-49614e19-1"  prio=5 tid=215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"ea1e16a2-08f2-4e20-9425-d71c7ab3efe9@group-94413D62F314-StateMachineUpdater" daemon prio=5 tid=271 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-Delayed safe mode statusForReplicationManager"  prio=5 tid=33 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 8 on default port 33535" daemon prio=5 tid=84 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"EventQueue-Delayed safe mode statusForSCMPipelineManager"  prio=5 tid=32 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 6 on default port 33535" daemon prio=5 tid=82 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=175 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 9 on default port 33535" daemon prio=5 tid=85 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 11 on default port 45471" daemon prio=5 tid=47 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp1949177487-143" daemon prio=5 tid=143 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-0-0" daemon prio=5 tid=239 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-60-thread-1" daemon prio=5 tid=197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Socket Reader #1 for port 0"  prio=5 tid=22 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"qtp708133671-161" daemon prio=5 tid=161 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-0-0" daemon prio=5 tid=226 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp74777304-188" daemon prio=5 tid=188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=174 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=176 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=220 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 17 on default port 45471" daemon prio=5 tid=53 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server listener on 0" daemon prio=5 tid=17 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"qtp187096820-209" daemon prio=5 tid=209 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-2-0" daemon prio=5 tid=235 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp74777304-184-acceptor-0@7b4199d8-ServerConnector@6471a1c6{HTTP/1.1,[http/1.1]}{0.0.0.0:42541}" daemon prio=3 tid=184 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 15 on default port 45471" daemon prio=5 tid=51 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server listener on 0" daemon prio=5 tid=21 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"IPC Server Responder" daemon prio=5 tid=20 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=177 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=199 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 3 on default port 41471" daemon prio=5 tid=59 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 5 on default port 33535" daemon prio=5 tid=81 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"grpc-nio-worker-ELG-3-1" daemon prio=5 tid=273 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:807)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 15 on default port 41471" daemon prio=5 tid=71 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 5 on default port 45471" daemon prio=5 tid=41 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp1525834420-102" daemon prio=5 tid=102 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp708133671-159" daemon prio=5 tid=159 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/959322083.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 15 on default port 33535" daemon prio=5 tid=91 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"EventQueue-Safe mode statusForSCMClientProtocolServer"  prio=5 tid=30 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-51-thread-1"  prio=5 tid=255 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 13 on default port 45471" daemon prio=5 tid=49 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 10 on default port 41471" daemon prio=5 tid=66 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-55-thread-1"  prio=5 tid=182 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1949177487-142" daemon prio=5 tid=142 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-1-0" daemon prio=5 tid=240 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 19 on default port 33535" daemon prio=5 tid=95 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp187096820-210" daemon prio=5 tid=210 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"RatisPipelineUtilsThread"  prio=5 tid=16 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"BlockDeletingService#0" daemon prio=5 tid=231 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1949177487-147" daemon prio=5 tid=147 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp187096820-214" daemon prio=5 tid=214 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 19 on default port 41471" daemon prio=5 tid=75 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp1949177487-146" daemon prio=5 tid=146 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-5DD255C8B606-SegmentedRaftLogWorker"  prio=5 tid=253 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=200 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Timer for 'StorageContainerManager' metrics system" daemon prio=5 tid=34 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"EventQueue-Safe mode statusForBlockManagerImpl"  prio=5 tid=31 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=15 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@6a617660" daemon prio=5 tid=203 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"pool-44-thread-1" daemon prio=5 tid=173 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"cb97469d-781c-49b1-b566-b9439314fa8f@group-B4B248D0A7E8-StateMachineUpdater" daemon prio=5 tid=257 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"IPC Parameter Sending Thread #0" daemon prio=5 tid=111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 14 on default port 45471" daemon prio=5 tid=50 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 12 on default port 33535" daemon prio=5 tid=88 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-3-0" daemon prio=5 tid=236 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 10 on default port 45471" daemon prio=5 tid=46 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-39-thread-1"  prio=5 tid=158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Periodic HDDS volume checker" daemon prio=5 tid=154 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"grpc-default-executor-3" daemon prio=5 tid=300 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp74777304-190" daemon prio=5 tid=190 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 4 on default port 45471" daemon prio=5 tid=40 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-3-0" daemon prio=5 tid=242 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"IPC Server listener on 0" daemon prio=5 tid=25 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"BlockDeletingService#0" daemon prio=5 tid=237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1525834420-100" daemon prio=5 tid=100 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp187096820-213" daemon prio=5 tid=213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Socket Reader #1 for port 0"  prio=5 tid=26 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"64cbb9bc-55ad-4bd6-90d7-16706f0bd234@group-94413D62F314-SegmentedRaftLogWorker"  prio=5 tid=262 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"qtp1525834420-98-acceptor-0@1c5f5711-ServerConnector@6841356f{HTTP/1.1,[http/1.1]}{0.0.0.0:38345}" daemon prio=3 tid=98 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"BlockDeletingService#0" daemon prio=5 tid=243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp708133671-166" daemon prio=5 tid=166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=250 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"cb97469d-781c-49b1-b566-b9439314fa8f@group-94413D62F314-StateMachineUpdater" daemon prio=5 tid=267 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"qtp74777304-189" daemon prio=5 tid=189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-0-0" daemon prio=5 tid=233 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 19 on default port 45471" daemon prio=5 tid=55 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@50282fb5" daemon prio=5 tid=179 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 1 on default port 33535" daemon prio=5 tid=77 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"grpc-default-executor-2" daemon prio=5 tid=277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"prometheus" daemon prio=5 tid=106 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.metrics2.impl.SinkQueue.waitForData(SinkQueue.java:114)
        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:83)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:135)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:89)
"IPC Server handler 13 on default port 33535" daemon prio=5 tid=89 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 7 on default port 33535" daemon prio=5 tid=83 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp1949177487-148" daemon prio=5 tid=148 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp1949177487-145" daemon prio=5 tid=145 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp1525834420-96" daemon prio=5 tid=96 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/959322083.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"java.util.concurrent.ThreadPoolExecutor$Worker@222cc6cb[State = -1, empty queue]" daemon prio=5 tid=317 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=249 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Command processor thread" daemon prio=5 tid=178 terminated
java.lang.Thread.State: TERMINATED
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$171/944075807.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 0 on default port 41471" daemon prio=5 tid=56 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-1-0" daemon prio=5 tid=234 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 16 on default port 41471" daemon prio=5 tid=72 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 4 on default port 41471" daemon prio=5 tid=60 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 12 on default port 41471" daemon prio=5 tid=68 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurr]]></system-err>
  </testcase>
</testsuite>