2020-06-02 22:55:10,139 [Thread-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 22:55:10,214 [Thread-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 22:55:10,243 [Thread-1] WARN  db.DBStoreBuilder (DBStoreBuilder.java:createDBStoreBuilder(277)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 22:55:10,403 [Thread-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(126)) - Loading file from sun.misc.CompoundEnumeration@69a11246
2020-06-02 22:55:10,405 [Thread-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(172)) - Loading network topology layer schema file
2020-06-02 22:55:10,466 [Thread-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(73)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2020-06-02 22:55:10,467 [Thread-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(73)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2020-06-02 22:55:10,469 [Thread-1] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2020-06-02 22:55:10,561 [Thread-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(60)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2020-06-02 22:55:10,586 [Thread-1] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(158)) - No pipeline exists in current db
2020-06-02 22:55:10,650 [Thread-1] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:<init>(89)) - Total pipeline count is 0, healthy pipeline threshold count is 0
2020-06-02 22:55:10,657 [Thread-1] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:<init>(79)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2020-06-02 22:55:10,721 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2020-06-02 22:55:11,064 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 22:55:11,086 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 22:55:11,119 [Listener at 0.0.0.0/34535] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 22:55:11,121 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 22:55:11,132 [Listener at 0.0.0.0/34321] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 22:55:11,133 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 22:55:11,162 [Listener at 0.0.0.0/37781] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for scm at: http://0.0.0.0:0
2020-06-02 22:55:11,162 [Listener at 0.0.0.0/37781] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 22:55:11,195 [Listener at 0.0.0.0/37781] INFO  util.log (Log.java:initialized(169)) - Logging initialized @2043ms to org.eclipse.jetty.util.log.Slf4jLog
2020-06-02 22:55:11,337 [Listener at 0.0.0.0/37781] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 22:55:11,352 [Listener at 0.0.0.0/37781] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 22:55:11,358 [Listener at 0.0.0.0/37781] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 22:55:11,361 [Listener at 0.0.0.0/37781] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2020-06-02 22:55:11,361 [Listener at 0.0.0.0/37781] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 22:55:11,361 [Listener at 0.0.0.0/37781] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 22:55:11,413 [Listener at 0.0.0.0/37781] INFO  server.StorageContainerManager (StorageContainerManager.java:start(781)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:37781
2020-06-02 22:55:11,465 [Listener at 0.0.0.0/37781] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2020-06-02 22:55:11,480 [Listener at 0.0.0.0/37781] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-06-02 22:55:11,480 [Listener at 0.0.0.0/37781] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2020-06-02 22:55:11,702 [Listener at 0.0.0.0/37781] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(157)) - RPC server for Client  is listening at /0.0.0.0:37781
2020-06-02 22:55:11,704 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 22:55:11,705 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 22:55:11,713 [Listener at 0.0.0.0/37781] INFO  server.StorageContainerManager (StorageContainerManager.java:start(793)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:34321
2020-06-02 22:55:11,714 [Listener at 0.0.0.0/37781] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(149)) - RPC server for Block Protocol is listening at /0.0.0.0:34321
2020-06-02 22:55:11,718 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 22:55:11,718 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 22:55:11,722 [Listener at 0.0.0.0/37781] INFO  server.StorageContainerManager (StorageContainerManager.java:start(799)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:34535
2020-06-02 22:55:11,722 [Listener at 0.0.0.0/37781] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(172)) - RPC server for DataNodes is listening at /0.0.0.0:34535
2020-06-02 22:55:11,723 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 22:55:11,724 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 22:55:11,727 [Listener at 0.0.0.0/37781] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 40117
2020-06-02 22:55:11,729 [Listener at 0.0.0.0/37781] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 22:55:11,767 [Listener at 0.0.0.0/37781] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 22:55:11,767 [Listener at 0.0.0.0/37781] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 22:55:11,769 [Listener at 0.0.0.0/37781] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-06-02 22:55:11,783 [Listener at 0.0.0.0/37781] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 22:55:11,786 [Listener at 0.0.0.0/37781] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@7a1474ae{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 22:55:11,786 [Listener at 0.0.0.0/37781] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@7ca362c{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2020-06-02 22:55:11,827 [Listener at 0.0.0.0/37781] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@63606336{scm,/,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2020-06-02 22:55:11,835 [Listener at 0.0.0.0/37781] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@16d9381c{HTTP/1.1,[http/1.1]}{0.0.0.0:40117}
2020-06-02 22:55:11,836 [Listener at 0.0.0.0/37781] INFO  server.Server (Server.java:doStart(399)) - Started @2684ms
2020-06-02 22:55:11,838 [Listener at 0.0.0.0/37781] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2020-06-02 22:55:11,839 [Listener at 0.0.0.0/37781] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2020-06-02 22:55:11,842 [Listener at 0.0.0.0/37781] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of scm listening at http://0.0.0.0:40117
2020-06-02 22:55:11,850 [Listener at 0.0.0.0/37781] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 22:55:11,861 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@667c982a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 22:55:11,952 [Listener at 0.0.0.0/37781] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(104)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2020-06-02 22:55:11,957 [Listener at 0.0.0.0/37781] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(207)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2020-06-02 22:55:11,957 [Listener at 0.0.0.0/37781] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(237)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2020-06-02 22:55:11,960 [Listener at 0.0.0.0/37781] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 22:55:11,960 [Listener at 0.0.0.0/37781] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 22:55:12,617 [Listener at 0.0.0.0/37781] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 22:55:12,757 [Listener at 0.0.0.0/37781] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 22:55:12,758 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 22:55:12,790 [Listener at 127.0.0.1/42381] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2020-06-02 22:55:12,792 [Listener at 127.0.0.1/42381] INFO  om.OzoneManager (OzoneManager.java:start(1097)) - OzoneManager RPC server is listening at localhost/127.0.0.1:42381
2020-06-02 22:55:12,810 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 22:55:12,811 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 22:55:12,817 [Listener at 127.0.0.1/42381] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2020-06-02 22:55:12,818 [Listener at 127.0.0.1/42381] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 22:55:12,819 [Listener at 127.0.0.1/42381] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 22:55:12,820 [Listener at 127.0.0.1/42381] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 22:55:12,821 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 22:55:12,822 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
2020-06-02 22:55:12,822 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 22:55:12,822 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 22:55:12,825 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 40603
2020-06-02 22:55:12,825 [Listener at 127.0.0.1/42381] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 22:55:12,827 [Listener at 127.0.0.1/42381] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 22:55:12,827 [Listener at 127.0.0.1/42381] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 22:55:12,827 [Listener at 127.0.0.1/42381] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-06-02 22:55:12,828 [Listener at 127.0.0.1/42381] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 22:55:12,829 [Listener at 127.0.0.1/42381] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@2dca5d2c{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 22:55:12,829 [Listener at 127.0.0.1/42381] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@313098cb{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2020-06-02 22:55:12,833 [Listener at 127.0.0.1/42381] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@fabab4c{ozoneManager,/,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2020-06-02 22:55:12,834 [Listener at 127.0.0.1/42381] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@30502477{HTTP/1.1,[http/1.1]}{0.0.0.0:40603}
2020-06-02 22:55:12,834 [Listener at 127.0.0.1/42381] INFO  server.Server (Server.java:doStart(399)) - Started @3682ms
2020-06-02 22:55:12,834 [Listener at 127.0.0.1/42381] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 22:55:12,836 [Listener at 127.0.0.1/42381] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of ozoneManager listening at http://0.0.0.0:40603
2020-06-02 22:55:12,844 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@54919b12] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 22:55:12,961 [Listener at 127.0.0.1/42381] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2020-06-02 22:55:12,964 [Listener at 127.0.0.1/42381] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-06-02 22:55:12,969 [Listener at 127.0.0.1/42381] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(205)) - HddsDatanodeService host:32d60ebb3871 ip:172.17.0.2
2020-06-02 22:55:13,031 [Listener at 127.0.0.1/42381] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-06-02 22:55:13,034 [Listener at 127.0.0.1/42381] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(181)) - Added Volume : /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data-0/containers/hdds to VolumeSet
2020-06-02 22:55:13,035 [Listener at 127.0.0.1/42381] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data-0/containers/hdds
2020-06-02 22:55:13,061 [Listener at 127.0.0.1/42381] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data-0/containers/hdds
2020-06-02 22:55:13,226 [Listener at 127.0.0.1/42381] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-06-02 22:55:13,293 [Listener at 127.0.0.1/42381] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-06-02 22:55:13,298 [Listener at 127.0.0.1/42381] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-06-02 22:55:13,299 [Listener at 127.0.0.1/42381] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-06-02 22:55:13,300 [Listener at 127.0.0.1/42381] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 22:55:13,301 [Listener at 127.0.0.1/42381] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-06-02 22:55:13,302 [Listener at 127.0.0.1/42381] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 22:55:13,467 [Listener at 127.0.0.1/42381] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data/ratis] (custom)
2020-06-02 22:55:13,549 [Listener at 127.0.0.1/42381] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-06-02 22:55:13,551 [Listener at 127.0.0.1/42381] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 22:55:13,553 [Listener at 127.0.0.1/42381] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 22:55:13,553 [Listener at 127.0.0.1/42381] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 22:55:13,554 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 22:55:13,555 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
2020-06-02 22:55:13,555 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 22:55:13,555 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 22:55:13,556 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 40545
2020-06-02 22:55:13,556 [Listener at 127.0.0.1/42381] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 22:55:13,560 [Listener at 127.0.0.1/42381] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 22:55:13,560 [Listener at 127.0.0.1/42381] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 22:55:13,561 [Listener at 127.0.0.1/42381] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-06-02 22:55:13,562 [Listener at 127.0.0.1/42381] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 22:55:13,562 [Listener at 127.0.0.1/42381] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@58aa21d4{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 22:55:13,563 [Listener at 127.0.0.1/42381] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@6959535d{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-06-02 22:55:13,604 [Listener at 127.0.0.1/42381] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@66d73668{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-40545-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-1038088855981988895.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 22:55:13,609 [Listener at 127.0.0.1/42381] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@6732c808{HTTP/1.1,[http/1.1]}{0.0.0.0:40545}
2020-06-02 22:55:13,610 [Listener at 127.0.0.1/42381] INFO  server.Server (Server.java:doStart(399)) - Started @4458ms
2020-06-02 22:55:13,610 [Listener at 127.0.0.1/42381] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 22:55:13,614 [Listener at 127.0.0.1/42381] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of hddsDatanode listening at http://0.0.0.0:40545
2020-06-02 22:55:13,614 [Listener at 127.0.0.1/42381] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-06-02 22:55:13,615 [Listener at 127.0.0.1/42381] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(205)) - HddsDatanodeService host:32d60ebb3871 ip:172.17.0.2
2020-06-02 22:55:13,618 [Listener at 127.0.0.1/42381] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-06-02 22:55:13,618 [Listener at 127.0.0.1/42381] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(181)) - Added Volume : /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data-0/containers/hdds to VolumeSet
2020-06-02 22:55:13,618 [Listener at 127.0.0.1/42381] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data-0/containers/hdds
2020-06-02 22:55:13,619 [Listener at 127.0.0.1/42381] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data-0/containers/hdds
2020-06-02 22:55:13,662 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@15f275fb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 22:55:13,675 [Listener at 127.0.0.1/42381] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-06-02 22:55:13,675 [Listener at 127.0.0.1/42381] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-06-02 22:55:13,675 [Listener at 127.0.0.1/42381] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-06-02 22:55:13,675 [Listener at 127.0.0.1/42381] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-06-02 22:55:13,675 [Listener at 127.0.0.1/42381] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 22:55:13,676 [Listener at 127.0.0.1/42381] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-06-02 22:55:13,676 [Listener at 127.0.0.1/42381] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 22:55:13,677 [Listener at 127.0.0.1/42381] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data/ratis] (custom)
2020-06-02 22:55:13,682 [Listener at 127.0.0.1/42381] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-06-02 22:55:13,682 [Listener at 127.0.0.1/42381] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 22:55:13,683 [Listener at 127.0.0.1/42381] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 22:55:13,688 [Listener at 127.0.0.1/42381] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 22:55:13,689 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 22:55:13,691 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
2020-06-02 22:55:13,692 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 22:55:13,692 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 22:55:13,693 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 45283
2020-06-02 22:55:13,693 [Listener at 127.0.0.1/42381] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 22:55:13,757 [Listener at 127.0.0.1/42381] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 22:55:13,757 [Listener at 127.0.0.1/42381] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 22:55:13,758 [Listener at 127.0.0.1/42381] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-06-02 22:55:13,764 [Listener at 127.0.0.1/42381] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 22:55:13,768 [Listener at 127.0.0.1/42381] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@429e70a1{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 22:55:13,769 [Listener at 127.0.0.1/42381] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@12fe3254{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-06-02 22:55:13,816 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(145)) - DatanodeDetails is persisted to /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/meta/datanode.id
2020-06-02 22:55:13,825 [Listener at 127.0.0.1/42381] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@57596414{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-45283-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-6250674902496155577.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 22:55:13,831 [Listener at 127.0.0.1/42381] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@1dfcb4eb{HTTP/1.1,[http/1.1]}{0.0.0.0:45283}
2020-06-02 22:55:13,831 [Listener at 127.0.0.1/42381] INFO  server.Server (Server.java:doStart(399)) - Started @4680ms
2020-06-02 22:55:13,831 [Listener at 127.0.0.1/42381] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 22:55:13,835 [Listener at 127.0.0.1/42381] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of hddsDatanode listening at http://0.0.0.0:45283
2020-06-02 22:55:13,835 [Listener at 127.0.0.1/42381] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-06-02 22:55:13,836 [Listener at 127.0.0.1/42381] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(205)) - HddsDatanodeService host:32d60ebb3871 ip:172.17.0.2
2020-06-02 22:55:13,840 [Listener at 127.0.0.1/42381] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-06-02 22:55:13,843 [Listener at 127.0.0.1/42381] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(181)) - Added Volume : /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data-0/containers/hdds to VolumeSet
2020-06-02 22:55:13,843 [Listener at 127.0.0.1/42381] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data-0/containers/hdds
2020-06-02 22:55:13,844 [Listener at 127.0.0.1/42381] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data-0/containers/hdds
2020-06-02 22:55:13,868 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1afa59de] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 22:55:13,875 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(145)) - DatanodeDetails is persisted to /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/meta/datanode.id
2020-06-02 22:55:13,878 [Listener at 127.0.0.1/42381] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-06-02 22:55:13,880 [Listener at 127.0.0.1/42381] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-06-02 22:55:13,880 [Listener at 127.0.0.1/42381] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-06-02 22:55:13,880 [Listener at 127.0.0.1/42381] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-06-02 22:55:13,881 [Listener at 127.0.0.1/42381] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 22:55:13,881 [Listener at 127.0.0.1/42381] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-06-02 22:55:13,881 [Listener at 127.0.0.1/42381] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 22:55:13,882 [Listener at 127.0.0.1/42381] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data/ratis] (custom)
2020-06-02 22:55:13,886 [Listener at 127.0.0.1/42381] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-06-02 22:55:13,887 [Listener at 127.0.0.1/42381] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 22:55:13,889 [Listener at 127.0.0.1/42381] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 22:55:13,889 [Listener at 127.0.0.1/42381] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 22:55:13,890 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 22:55:13,891 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
2020-06-02 22:55:13,891 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 22:55:13,891 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 22:55:13,892 [Listener at 127.0.0.1/42381] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 38519
2020-06-02 22:55:13,892 [Listener at 127.0.0.1/42381] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 22:55:13,894 [Listener at 127.0.0.1/42381] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 22:55:13,894 [Listener at 127.0.0.1/42381] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 22:55:13,894 [Listener at 127.0.0.1/42381] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-06-02 22:55:13,895 [Listener at 127.0.0.1/42381] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 22:55:13,896 [Listener at 127.0.0.1/42381] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@7cf728c7{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 22:55:13,896 [Listener at 127.0.0.1/42381] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@41cb8ca2{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-06-02 22:55:13,923 [Listener at 127.0.0.1/42381] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@775024a6{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-38519-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-986194636844657910.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 22:55:13,925 [Listener at 127.0.0.1/42381] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@3b9fc304{HTTP/1.1,[http/1.1]}{0.0.0.0:38519}
2020-06-02 22:55:13,925 [Listener at 127.0.0.1/42381] INFO  server.Server (Server.java:doStart(399)) - Started @4774ms
2020-06-02 22:55:13,925 [Listener at 127.0.0.1/42381] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 22:55:13,928 [Listener at 127.0.0.1/42381] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of hddsDatanode listening at http://0.0.0.0:38519
2020-06-02 22:55:13,929 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 22:55:13,929 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:13,938 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(145)) - DatanodeDetails is persisted to /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/meta/datanode.id
2020-06-02 22:55:13,938 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3fd5cc4a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 22:55:14,929 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 22:55:14,929 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:15,718 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-06-02 22:55:15,719 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-06-02 22:55:15,720 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(425)) - Starting XceiverServerRatis e3859357-2f16-4cf9-861f-4aa398f9f998 at port 0
2020-06-02 22:55:15,728 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - e3859357-2f16-4cf9-861f-4aa398f9f998: start RPC server
2020-06-02 22:55:15,774 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(159)) - e3859357-2f16-4cf9-861f-4aa398f9f998: GrpcService started, listening on 0.0.0.0/0.0.0.0:33361
2020-06-02 22:55:15,775 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(437)) - XceiverServerRatis e3859357-2f16-4cf9-861f-4aa398f9f998 is started using port 33361
2020-06-02 22:55:15,778 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc e3859357-2f16-4cf9-861f-4aa398f9f998 is started using port 35303
2020-06-02 22:55:15,871 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-06-02 22:55:15,874 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-06-02 22:55:15,874 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(425)) - Starting XceiverServerRatis 4c7e11ca-10b9-4e9c-a049-cdafb338d54c at port 0
2020-06-02 22:55:15,875 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: start RPC server
2020-06-02 22:55:15,878 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(159)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: GrpcService started, listening on 0.0.0.0/0.0.0.0:46607
2020-06-02 22:55:15,878 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(437)) - XceiverServerRatis 4c7e11ca-10b9-4e9c-a049-cdafb338d54c is started using port 46607
2020-06-02 22:55:15,880 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 4c7e11ca-10b9-4e9c-a049-cdafb338d54c is started using port 39563
2020-06-02 22:55:15,930 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 22:55:15,930 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:15,940 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-06-02 22:55:15,941 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-06-02 22:55:15,941 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(425)) - Starting XceiverServerRatis d359667a-5381-4980-9e71-849ae1684b39 at port 0
2020-06-02 22:55:15,942 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - d359667a-5381-4980-9e71-849ae1684b39: start RPC server
2020-06-02 22:55:15,950 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(159)) - d359667a-5381-4980-9e71-849ae1684b39: GrpcService started, listening on 0.0.0.0/0.0.0.0:41663
2020-06-02 22:55:15,950 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(437)) - XceiverServerRatis d359667a-5381-4980-9e71-849ae1684b39 is started using port 41663
2020-06-02 22:55:15,952 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc d359667a-5381-4980-9e71-849ae1684b39 is started using port 45253
2020-06-02 22:55:16,930 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 22:55:16,931 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:17,671 [IPC Server handler 2 on default port 34535] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/e3859357-2f16-4cf9-861f-4aa398f9f998
2020-06-02 22:55:17,671 [IPC Server handler 2 on default port 34535] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : e3859357-2f16-4cf9-861f-4aa398f9f998{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}
2020-06-02 22:55:17,678 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - ContainerSafeModeRule rule is successfully validated
2020-06-02 22:55:17,680 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2020-06-02 22:55:17,680 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - DataNodeSafeModeRule rule is successfully validated
2020-06-02 22:55:17,680 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(241)) - All SCM safe mode pre check rules have passed
2020-06-02 22:55:17,689 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=5cbf5e4f-0eb8-4bc5-936a-662233e84282 to datanode:e3859357-2f16-4cf9-861f-4aa398f9f998
2020-06-02 22:55:17,701 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 5cbf5e4f-0eb8-4bc5-936a-662233e84282, Nodes: e3859357-2f16-4cf9-861f-4aa398f9f998{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T22:55:17.686Z]
2020-06-02 22:55:17,704 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 1 nodes. Healthy nodes 1
2020-06-02 22:55:17,704 [RatisPipelineUtilsThread] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(133)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2020-06-02 22:55:17,704 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2020-06-02 22:55:17,870 [IPC Server handler 0 on default port 34535] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/4c7e11ca-10b9-4e9c-a049-cdafb338d54c
2020-06-02 22:55:17,870 [IPC Server handler 0 on default port 34535] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 4c7e11ca-10b9-4e9c-a049-cdafb338d54c{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}
2020-06-02 22:55:17,872 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - DataNodeSafeModeRule rule is successfully validated
2020-06-02 22:55:17,872 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - ContainerSafeModeRule rule is successfully validated
2020-06-02 22:55:17,873 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=bd8057a2-539e-4036-877f-76ffdca17148 to datanode:4c7e11ca-10b9-4e9c-a049-cdafb338d54c
2020-06-02 22:55:17,873 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: bd8057a2-539e-4036-877f-76ffdca17148, Nodes: 4c7e11ca-10b9-4e9c-a049-cdafb338d54c{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T22:55:17.873Z]
2020-06-02 22:55:17,874 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
2020-06-02 22:55:17,874 [RatisPipelineUtilsThread] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(133)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2020-06-02 22:55:17,874 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2020-06-02 22:55:17,931 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 2 of 3 DN Heartbeats.
2020-06-02 22:55:17,931 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:17,939 [IPC Server handler 1 on default port 34535] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/d359667a-5381-4980-9e71-849ae1684b39
2020-06-02 22:55:17,939 [IPC Server handler 1 on default port 34535] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : d359667a-5381-4980-9e71-849ae1684b39{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}
2020-06-02 22:55:17,939 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=97765be9-3889-4e13-bef5-94c63df86725 to datanode:d359667a-5381-4980-9e71-849ae1684b39
2020-06-02 22:55:17,940 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 97765be9-3889-4e13-bef5-94c63df86725, Nodes: d359667a-5381-4980-9e71-849ae1684b39{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T22:55:17.939Z]
2020-06-02 22:55:17,940 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
2020-06-02 22:55:17,940 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - ContainerSafeModeRule rule is successfully validated
2020-06-02 22:55:17,941 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - DataNodeSafeModeRule rule is successfully validated
2020-06-02 22:55:17,944 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=22adb0f4-24d2-408f-b2db-322c8c70d8ab to datanode:e3859357-2f16-4cf9-861f-4aa398f9f998
2020-06-02 22:55:17,945 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=22adb0f4-24d2-408f-b2db-322c8c70d8ab to datanode:4c7e11ca-10b9-4e9c-a049-cdafb338d54c
2020-06-02 22:55:17,945 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=22adb0f4-24d2-408f-b2db-322c8c70d8ab to datanode:d359667a-5381-4980-9e71-849ae1684b39
2020-06-02 22:55:17,946 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 22adb0f4-24d2-408f-b2db-322c8c70d8ab, Nodes: e3859357-2f16-4cf9-861f-4aa398f9f998{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}4c7e11ca-10b9-4e9c-a049-cdafb338d54c{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}d359667a-5381-4980-9e71-849ae1684b39{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T22:55:17.944Z]
2020-06-02 22:55:17,946 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
2020-06-02 22:55:18,932 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:18,933 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:19,933 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:19,933 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:20,664 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e3859357-2f16-4cf9-861f-4aa398f9f998: addNew group-662233E84282:[e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361] returns group-662233E84282:java.util.concurrent.CompletableFuture@6d46ddc6[Not completed]
2020-06-02 22:55:20,677 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - e3859357-2f16-4cf9-861f-4aa398f9f998: new RaftServerImpl for group-662233E84282:[e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361] with ContainerStateMachine:uninitialized
2020-06-02 22:55:20,678 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 22:55:20,678 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 22:55:20,679 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 22:55:20,679 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 22:55:20,680 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 22:55:20,685 [pool-35-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282: ConfigurationManager, init=-1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361], old=null, confs=<EMPTY_MAP>
2020-06-02 22:55:20,685 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data/ratis] (custom)
2020-06-02 22:55:20,688 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 22:55:20,689 [pool-35-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data/ratis/5cbf5e4f-0eb8-4bc5-936a-662233e84282 does not exist. Creating ...
2020-06-02 22:55:20,693 [pool-35-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data/ratis/5cbf5e4f-0eb8-4bc5-936a-662233e84282/in_use.lock acquired by nodename 47628@32d60ebb3871
2020-06-02 22:55:20,695 [pool-35-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data/ratis/5cbf5e4f-0eb8-4bc5-936a-662233e84282 has been successfully formatted.
2020-06-02 22:55:20,699 [pool-35-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-662233E84282: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 22:55:20,699 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(378)) - Unable to start the DatanodeState Machine
java.io.IOException: Unable to finish the execution.
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:375)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:212)
	... 2 more
2020-06-02 22:55:20,699 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 22:55:20,702 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 22:55:20,706 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 22:55:20,706 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 22:55:20,708 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 22:55:20,711 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.e3859357-2f16-4cf9-861f-4aa398f9f998
2020-06-02 22:55:20,721 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 22:55:20,725 [pool-35-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data/ratis/5cbf5e4f-0eb8-4bc5-936a-662233e84282
2020-06-02 22:55:20,726 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 22:55:20,726 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 22:55:20,727 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 22:55:20,727 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 22:55:20,728 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 22:55:20,728 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 22:55:20,729 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 22:55:20,729 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 22:55:20,730 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 22:55:20,740 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 22:55:20,745 [pool-35-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 22:55:20,751 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 22:55:20,752 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 22:55:20,752 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 22:55:20,753 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 22:55:20,753 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 22:55:20,769 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282
2020-06-02 22:55:20,772 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282
2020-06-02 22:55:20,775 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282: start as a follower, conf=-1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361], old=null
2020-06-02 22:55:20,776 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 22:55:20,777 [pool-35-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e3859357-2f16-4cf9-861f-4aa398f9f998: start FollowerState
2020-06-02 22:55:20,778 [pool-35-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-662233E84282,id=e3859357-2f16-4cf9-861f-4aa398f9f998
2020-06-02 22:55:20,780 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282
2020-06-02 22:55:20,791 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS ONE #id: "5cbf5e4f-0eb8-4bc5-936a-662233e84282"
.
2020-06-02 22:55:20,791 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - e3859357-2f16-4cf9-861f-4aa398f9f998: addNew group-322C8C70D8AB:[e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607] returns group-322C8C70D8AB:java.util.concurrent.CompletableFuture@719f74e8[Not completed]
2020-06-02 22:55:20,793 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - e3859357-2f16-4cf9-861f-4aa398f9f998: new RaftServerImpl for group-322C8C70D8AB:[e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607] with ContainerStateMachine:uninitialized
2020-06-02 22:55:20,793 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 22:55:20,793 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 22:55:20,793 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 22:55:20,793 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 22:55:20,793 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 22:55:20,793 [pool-35-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB: ConfigurationManager, init=-1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null, confs=<EMPTY_MAP>
2020-06-02 22:55:20,793 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data/ratis] (custom)
2020-06-02 22:55:20,794 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 22:55:20,794 [pool-35-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data/ratis/22adb0f4-24d2-408f-b2db-322c8c70d8ab does not exist. Creating ...
2020-06-02 22:55:20,795 [pool-35-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data/ratis/22adb0f4-24d2-408f-b2db-322c8c70d8ab/in_use.lock acquired by nodename 47628@32d60ebb3871
2020-06-02 22:55:20,796 [pool-35-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data/ratis/22adb0f4-24d2-408f-b2db-322c8c70d8ab has been successfully formatted.
2020-06-02 22:55:20,796 [pool-35-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-322C8C70D8AB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 22:55:20,796 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 22:55:20,796 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 22:55:20,796 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 22:55:20,796 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 22:55:20,797 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 22:55:20,797 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 22:55:20,797 [pool-35-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data/ratis/22adb0f4-24d2-408f-b2db-322c8c70d8ab
2020-06-02 22:55:20,797 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 22:55:20,797 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 22:55:20,797 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 22:55:20,797 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 22:55:20,797 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 22:55:20,797 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 22:55:20,797 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 22:55:20,798 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 22:55:20,798 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 22:55:20,798 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 22:55:20,798 [pool-35-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 22:55:20,800 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 22:55:20,800 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 22:55:20,800 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 22:55:20,800 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 22:55:20,800 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 22:55:20,801 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB
2020-06-02 22:55:20,801 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB
2020-06-02 22:55:20,802 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB: start as a follower, conf=-1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null
2020-06-02 22:55:20,802 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 22:55:20,802 [pool-35-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e3859357-2f16-4cf9-861f-4aa398f9f998: start FollowerState
2020-06-02 22:55:20,804 [pool-35-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-322C8C70D8AB,id=e3859357-2f16-4cf9-861f-4aa398f9f998
2020-06-02 22:55:20,804 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB
2020-06-02 22:55:20,874 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: addNew group-76FFDCA17148:[4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607] returns group-76FFDCA17148:java.util.concurrent.CompletableFuture@219641f1[Not completed]
2020-06-02 22:55:20,894 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: new RaftServerImpl for group-76FFDCA17148:[4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607] with ContainerStateMachine:uninitialized
2020-06-02 22:55:20,896 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 22:55:20,896 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 22:55:20,896 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 22:55:20,897 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 22:55:20,897 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 22:55:20,898 [pool-51-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148: ConfigurationManager, init=-1: [4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null, confs=<EMPTY_MAP>
2020-06-02 22:55:20,898 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data/ratis] (custom)
2020-06-02 22:55:20,898 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 22:55:20,899 [pool-51-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data/ratis/bd8057a2-539e-4036-877f-76ffdca17148 does not exist. Creating ...
2020-06-02 22:55:20,900 [pool-51-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data/ratis/bd8057a2-539e-4036-877f-76ffdca17148/in_use.lock acquired by nodename 47628@32d60ebb3871
2020-06-02 22:55:20,902 [pool-51-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data/ratis/bd8057a2-539e-4036-877f-76ffdca17148 has been successfully formatted.
2020-06-02 22:55:20,904 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(378)) - Unable to start the DatanodeState Machine
java.io.IOException: Unable to finish the execution.
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:375)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:212)
	... 2 more
2020-06-02 22:55:20,904 [pool-51-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-76FFDCA17148: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 22:55:20,904 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 22:55:20,904 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 22:55:20,904 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 22:55:20,905 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 22:55:20,905 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 22:55:20,905 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.4c7e11ca-10b9-4e9c-a049-cdafb338d54c
2020-06-02 22:55:20,909 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 22:55:20,910 [pool-51-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data/ratis/bd8057a2-539e-4036-877f-76ffdca17148
2020-06-02 22:55:20,911 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 22:55:20,911 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 22:55:20,911 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 22:55:20,911 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 22:55:20,911 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 22:55:20,911 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 22:55:20,911 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 22:55:20,911 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 22:55:20,911 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 22:55:20,913 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 22:55:20,924 [pool-51-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 22:55:20,933 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:20,933 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:20,936 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 22:55:20,936 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 22:55:20,936 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 22:55:20,936 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 22:55:20,936 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 22:55:20,937 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148
2020-06-02 22:55:20,937 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148
2020-06-02 22:55:20,938 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148: start as a follower, conf=-1: [4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null
2020-06-02 22:55:20,938 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 22:55:20,938 [pool-51-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: start FollowerState
2020-06-02 22:55:20,948 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d359667a-5381-4980-9e71-849ae1684b39: addNew group-94C63DF86725:[d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663] returns group-94C63DF86725:java.util.concurrent.CompletableFuture@5e0a319b[Not completed]
2020-06-02 22:55:20,949 [pool-51-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-76FFDCA17148,id=4c7e11ca-10b9-4e9c-a049-cdafb338d54c
2020-06-02 22:55:20,954 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148
2020-06-02 22:55:20,955 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS ONE #id: "bd8057a2-539e-4036-877f-76ffdca17148"
.
2020-06-02 22:55:20,985 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: addNew group-322C8C70D8AB:[e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607] returns group-322C8C70D8AB:java.util.concurrent.CompletableFuture@25a9d11b[Not completed]
2020-06-02 22:55:20,993 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - d359667a-5381-4980-9e71-849ae1684b39: new RaftServerImpl for group-94C63DF86725:[d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663] with ContainerStateMachine:uninitialized
2020-06-02 22:55:20,994 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: new RaftServerImpl for group-322C8C70D8AB:[e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607] with ContainerStateMachine:uninitialized
2020-06-02 22:55:20,994 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 22:55:20,994 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 22:55:20,994 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 22:55:20,994 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 22:55:20,994 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 22:55:20,995 [pool-51-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB: ConfigurationManager, init=-1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null, confs=<EMPTY_MAP>
2020-06-02 22:55:20,995 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data/ratis] (custom)
2020-06-02 22:55:20,995 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 22:55:20,995 [pool-51-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data/ratis/22adb0f4-24d2-408f-b2db-322c8c70d8ab does not exist. Creating ...
2020-06-02 22:55:20,996 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 22:55:20,996 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 22:55:20,996 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 22:55:20,996 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 22:55:20,996 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 22:55:20,996 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725: ConfigurationManager, init=-1: [d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663], old=null, confs=<EMPTY_MAP>
2020-06-02 22:55:20,996 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data/ratis] (custom)
2020-06-02 22:55:20,997 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 22:55:20,997 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data/ratis/97765be9-3889-4e13-bef5-94c63df86725 does not exist. Creating ...
2020-06-02 22:55:20,997 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data/ratis/97765be9-3889-4e13-bef5-94c63df86725/in_use.lock acquired by nodename 47628@32d60ebb3871
2020-06-02 22:55:20,998 [pool-51-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data/ratis/22adb0f4-24d2-408f-b2db-322c8c70d8ab/in_use.lock acquired by nodename 47628@32d60ebb3871
2020-06-02 22:55:20,999 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data/ratis/97765be9-3889-4e13-bef5-94c63df86725 has been successfully formatted.
2020-06-02 22:55:21,000 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-94C63DF86725: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 22:55:21,000 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(378)) - Unable to start the DatanodeState Machine
java.io.IOException: Unable to finish the execution.
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:375)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:212)
	... 2 more
2020-06-02 22:55:21,000 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 22:55:21,001 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 22:55:21,001 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 22:55:21,001 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 22:55:21,001 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 22:55:21,001 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.d359667a-5381-4980-9e71-849ae1684b39
2020-06-02 22:55:21,001 [pool-51-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data/ratis/22adb0f4-24d2-408f-b2db-322c8c70d8ab has been successfully formatted.
2020-06-02 22:55:21,002 [pool-51-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-322C8C70D8AB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 22:55:21,002 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 22:55:21,002 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 22:55:21,002 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 22:55:21,002 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 22:55:21,002 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 22:55:21,002 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 22:55:21,002 [pool-51-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data/ratis/22adb0f4-24d2-408f-b2db-322c8c70d8ab
2020-06-02 22:55:21,002 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 22:55:21,003 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 22:55:21,003 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 22:55:21,003 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 22:55:21,003 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 22:55:21,003 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 22:55:21,003 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 22:55:21,003 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 22:55:21,003 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 22:55:21,004 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 22:55:21,004 [pool-51-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 22:55:21,011 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 22:55:21,011 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 22:55:21,011 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data/ratis/97765be9-3889-4e13-bef5-94c63df86725
2020-06-02 22:55:21,011 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 22:55:21,011 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 22:55:21,011 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 22:55:21,011 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 22:55:21,012 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 22:55:21,012 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 22:55:21,012 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 22:55:21,012 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 22:55:21,012 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 22:55:21,013 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 22:55:21,013 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 22:55:21,011 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 22:55:21,013 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 22:55:21,013 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 22:55:21,020 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 22:55:21,020 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 22:55:21,020 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 22:55:21,020 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 22:55:21,020 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 22:55:21,021 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725
2020-06-02 22:55:21,021 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725
2020-06-02 22:55:21,022 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725: start as a follower, conf=-1: [d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663], old=null
2020-06-02 22:55:21,022 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 22:55:21,022 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d359667a-5381-4980-9e71-849ae1684b39: start FollowerState
2020-06-02 22:55:21,032 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 22:55:21,032 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB
2020-06-02 22:55:21,033 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-94C63DF86725,id=d359667a-5381-4980-9e71-849ae1684b39
2020-06-02 22:55:21,033 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725
2020-06-02 22:55:21,039 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS ONE #id: "97765be9-3889-4e13-bef5-94c63df86725"
.
2020-06-02 22:55:21,040 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d359667a-5381-4980-9e71-849ae1684b39: addNew group-322C8C70D8AB:[e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607] returns group-322C8C70D8AB:java.util.concurrent.CompletableFuture@5a35ae82[Not completed]
2020-06-02 22:55:21,040 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB
2020-06-02 22:55:21,042 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB: start as a follower, conf=-1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null
2020-06-02 22:55:21,042 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 22:55:21,042 [pool-51-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: start FollowerState
2020-06-02 22:55:21,043 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - d359667a-5381-4980-9e71-849ae1684b39: new RaftServerImpl for group-322C8C70D8AB:[e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607] with ContainerStateMachine:uninitialized
2020-06-02 22:55:21,043 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 22:55:21,043 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 22:55:21,043 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 22:55:21,043 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 22:55:21,044 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 22:55:21,044 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB: ConfigurationManager, init=-1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null, confs=<EMPTY_MAP>
2020-06-02 22:55:21,044 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data/ratis] (custom)
2020-06-02 22:55:21,044 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 22:55:21,044 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data/ratis/22adb0f4-24d2-408f-b2db-322c8c70d8ab does not exist. Creating ...
2020-06-02 22:55:21,045 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data/ratis/22adb0f4-24d2-408f-b2db-322c8c70d8ab/in_use.lock acquired by nodename 47628@32d60ebb3871
2020-06-02 22:55:21,046 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data/ratis/22adb0f4-24d2-408f-b2db-322c8c70d8ab has been successfully formatted.
2020-06-02 22:55:21,058 [pool-51-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-322C8C70D8AB,id=4c7e11ca-10b9-4e9c-a049-cdafb338d54c
2020-06-02 22:55:21,058 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB
2020-06-02 22:55:21,068 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-322C8C70D8AB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 22:55:21,068 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 22:55:21,068 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 22:55:21,068 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 22:55:21,068 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 22:55:21,069 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 22:55:21,069 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 22:55:21,069 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data/ratis/22adb0f4-24d2-408f-b2db-322c8c70d8ab
2020-06-02 22:55:21,069 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 22:55:21,069 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 22:55:21,069 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 22:55:21,069 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 22:55:21,069 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 22:55:21,069 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 22:55:21,069 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 22:55:21,069 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 22:55:21,069 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 22:55:21,070 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 22:55:21,070 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 22:55:21,084 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 22:55:21,084 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 22:55:21,084 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 22:55:21,084 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 22:55:21,084 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 22:55:21,084 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB
2020-06-02 22:55:21,085 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB
2020-06-02 22:55:21,086 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB: start as a follower, conf=-1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null
2020-06-02 22:55:21,086 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 22:55:21,086 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d359667a-5381-4980-9e71-849ae1684b39: start FollowerState
2020-06-02 22:55:21,086 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-322C8C70D8AB,id=d359667a-5381-4980-9e71-849ae1684b39
2020-06-02 22:55:21,086 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB
2020-06-02 22:55:21,428 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS THREE #id: "22adb0f4-24d2-408f-b2db-322c8c70d8ab"
.
2020-06-02 22:55:21,430 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS THREE #id: "22adb0f4-24d2-408f-b2db-322c8c70d8ab"
.
2020-06-02 22:55:21,434 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS THREE #id: "22adb0f4-24d2-408f-b2db-322c8c70d8ab"
.
2020-06-02 22:55:21,934 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:21,934 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:22,934 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:22,934 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:23,938 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:23,938 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:24,938 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:24,938 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:25,868 [Thread-177] INFO  impl.FollowerState (FollowerState.java:run(108)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-FollowerState: change to CANDIDATE, lastRpcTime:5091ms, electionTimeout:5087ms
2020-06-02 22:55:25,875 [Thread-177] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e3859357-2f16-4cf9-861f-4aa398f9f998: shutdown FollowerState
2020-06-02 22:55:25,876 [Thread-177] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 22:55:25,878 [Thread-177] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e3859357-2f16-4cf9-861f-4aa398f9f998: start LeaderElection
2020-06-02 22:55:25,889 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1: begin an election at term 1 for -1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361], old=null
2020-06-02 22:55:25,890 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e3859357-2f16-4cf9-861f-4aa398f9f998: shutdown LeaderElection
2020-06-02 22:55:25,890 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 22:55:25,890 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-662233E84282 with new leaderId: e3859357-2f16-4cf9-861f-4aa398f9f998
2020-06-02 22:55:25,890 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282: change Leader from null to e3859357-2f16-4cf9-861f-4aa398f9f998 at term 1 for becomeLeader, leader elected after 5191ms
2020-06-02 22:55:25,894 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 22:55:25,904 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 22:55:25,906 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282
2020-06-02 22:55:25,908 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 22:55:25,909 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 22:55:25,922 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 22:55:25,922 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 22:55:25,923 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 22:55:25,927 [Thread-179] INFO  impl.FollowerState (FollowerState.java:run(108)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-FollowerState: change to CANDIDATE, lastRpcTime:5124ms, electionTimeout:5122ms
2020-06-02 22:55:25,933 [Thread-179] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e3859357-2f16-4cf9-861f-4aa398f9f998: shutdown FollowerState
2020-06-02 22:55:25,933 [Thread-179] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 22:55:25,933 [Thread-179] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e3859357-2f16-4cf9-861f-4aa398f9f998: start LeaderElection
2020-06-02 22:55:25,945 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e3859357-2f16-4cf9-861f-4aa398f9f998: start LeaderState
2020-06-02 22:55:25,958 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:25,958 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:26,025 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-LeaderElection2: begin an election at term 1 for -1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null
2020-06-02 22:55:26,031 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 22:55:26,060 [Thread-181] INFO  impl.FollowerState (FollowerState.java:run(108)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-FollowerState: change to CANDIDATE, lastRpcTime:5122ms, electionTimeout:5107ms
2020-06-02 22:55:26,061 [Thread-181] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: shutdown FollowerState
2020-06-02 22:55:26,061 [Thread-181] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 22:55:26,078 [Thread-185] INFO  impl.FollowerState (FollowerState.java:run(108)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-FollowerState: change to CANDIDATE, lastRpcTime:5035ms, electionTimeout:5020ms
2020-06-02 22:55:26,078 [Thread-185] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: shutdown FollowerState
2020-06-02 22:55:26,078 [Thread-185] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 22:55:26,088 [Thread-185] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: start LeaderElection
2020-06-02 22:55:26,108 [Thread-181] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: start LeaderElection
2020-06-02 22:55:26,125 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282: set configuration 0: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361], old=null at 0
2020-06-02 22:55:26,170 [Thread-187] INFO  impl.FollowerState (FollowerState.java:run(108)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-FollowerState: change to CANDIDATE, lastRpcTime:5083ms, electionTimeout:5041ms
2020-06-02 22:55:26,170 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d359667a-5381-4980-9e71-849ae1684b39: shutdown FollowerState
2020-06-02 22:55:26,170 [Thread-187] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 22:55:26,170 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d359667a-5381-4980-9e71-849ae1684b39: start LeaderElection
2020-06-02 22:55:26,171 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3: begin an election at term 1 for -1: [4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null
2020-06-02 22:55:26,181 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: shutdown LeaderElection
2020-06-02 22:55:26,181 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 22:55:26,181 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-76FFDCA17148 with new leaderId: 4c7e11ca-10b9-4e9c-a049-cdafb338d54c
2020-06-02 22:55:26,171 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-LeaderElection4: begin an election at term 1 for -1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null
2020-06-02 22:55:26,205 [Thread-184] INFO  impl.FollowerState (FollowerState.java:run(108)) - d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-FollowerState: change to CANDIDATE, lastRpcTime:5182ms, electionTimeout:5172ms
2020-06-02 22:55:26,205 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d359667a-5381-4980-9e71-849ae1684b39: shutdown FollowerState
2020-06-02 22:55:26,205 [Thread-184] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 22:55:26,224 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148: change Leader from null to 4c7e11ca-10b9-4e9c-a049-cdafb338d54c at term 1 for becomeLeader, leader elected after 5277ms
2020-06-02 22:55:26,224 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 22:55:26,224 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 22:55:26,224 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148
2020-06-02 22:55:26,225 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 22:55:26,225 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 22:55:26,225 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 22:55:26,225 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 22:55:26,225 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 22:55:26,225 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: start LeaderState
2020-06-02 22:55:26,226 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 22:55:26,232 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148: set configuration 0: [4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null at 0
2020-06-02 22:55:26,240 [Thread-184] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d359667a-5381-4980-9e71-849ae1684b39: start LeaderElection
2020-06-02 22:55:26,290 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection5: begin an election at term 1 for -1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null
2020-06-02 22:55:26,307 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6: begin an election at term 1 for -1: [d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663], old=null
2020-06-02 22:55:26,307 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d359667a-5381-4980-9e71-849ae1684b39: shutdown LeaderElection
2020-06-02 22:55:26,307 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 22:55:26,307 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-94C63DF86725 with new leaderId: d359667a-5381-4980-9e71-849ae1684b39
2020-06-02 22:55:26,307 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725: change Leader from null to d359667a-5381-4980-9e71-849ae1684b39 at term 1 for becomeLeader, leader elected after 5307ms
2020-06-02 22:55:26,307 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 22:55:26,307 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 22:55:26,307 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725
2020-06-02 22:55:26,308 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 22:55:26,308 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 22:55:26,308 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 22:55:26,308 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 22:55:26,308 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 22:55:26,309 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d359667a-5381-4980-9e71-849ae1684b39: start LeaderState
2020-06-02 22:55:26,309 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 22:55:26,321 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725: set configuration 0: [d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663], old=null at 0
2020-06-02 22:55:26,413 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data/ratis/bd8057a2-539e-4036-877f-76ffdca17148/current/log_inprogress_0
2020-06-02 22:55:26,416 [d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data/ratis/97765be9-3889-4e13-bef5-94c63df86725/current/log_inprogress_0
2020-06-02 22:55:26,433 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data/ratis/5cbf5e4f-0eb8-4bc5-936a-662233e84282/current/log_inprogress_0
2020-06-02 22:55:26,522 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection5: Election REJECTED; received 2 response(s) [d359667a-5381-4980-9e71-849ae1684b39<-e3859357-2f16-4cf9-861f-4aa398f9f998#0:FAIL-t1, d359667a-5381-4980-9e71-849ae1684b39<-4c7e11ca-10b9-4e9c-a049-cdafb338d54c#0:FAIL-t1] and 0 exception(s); d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB:t1, leader=null, voted=d359667a-5381-4980-9e71-849ae1684b39, raftlog=d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null
2020-06-02 22:55:26,523 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2020-06-02 22:55:26,523 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d359667a-5381-4980-9e71-849ae1684b39: shutdown LeaderElection
2020-06-02 22:55:26,523 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d359667a-5381-4980-9e71-849ae1684b39: start FollowerState
2020-06-02 22:55:26,549 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-LeaderElection2: Election REJECTED; received 2 response(s) [e3859357-2f16-4cf9-861f-4aa398f9f998<-d359667a-5381-4980-9e71-849ae1684b39#0:FAIL-t1, e3859357-2f16-4cf9-861f-4aa398f9f998<-4c7e11ca-10b9-4e9c-a049-cdafb338d54c#0:FAIL-t1] and 0 exception(s); e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB:t1, leader=null, voted=e3859357-2f16-4cf9-861f-4aa398f9f998, raftlog=e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null
2020-06-02 22:55:26,553 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2020-06-02 22:55:26,553 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - e3859357-2f16-4cf9-861f-4aa398f9f998: shutdown LeaderElection
2020-06-02 22:55:26,553 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e3859357-2f16-4cf9-861f-4aa398f9f998: start FollowerState
2020-06-02 22:55:26,569 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-LeaderElection4: Election REJECTED; received 2 response(s) [4c7e11ca-10b9-4e9c-a049-cdafb338d54c<-e3859357-2f16-4cf9-861f-4aa398f9f998#0:FAIL-t1, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c<-d359667a-5381-4980-9e71-849ae1684b39#0:FAIL-t1] and 0 exception(s); 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB:t1, leader=null, voted=4c7e11ca-10b9-4e9c-a049-cdafb338d54c, raftlog=4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null
2020-06-02 22:55:26,573 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2020-06-02 22:55:26,573 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: shutdown LeaderElection
2020-06-02 22:55:26,573 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: start FollowerState
2020-06-02 22:55:26,958 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:26,963 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:27,963 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:27,963 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:28,963 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:28,963 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:29,964 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:29,964 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:30,964 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:30,964 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:31,642 [Thread-209] INFO  impl.FollowerState (FollowerState.java:run(108)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-FollowerState: change to CANDIDATE, lastRpcTime:5119ms, electionTimeout:5099ms
2020-06-02 22:55:31,643 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d359667a-5381-4980-9e71-849ae1684b39: shutdown FollowerState
2020-06-02 22:55:31,643 [Thread-209] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2020-06-02 22:55:31,643 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d359667a-5381-4980-9e71-849ae1684b39: start LeaderElection
2020-06-02 22:55:31,661 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7: begin an election at term 2 for -1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null
2020-06-02 22:55:31,685 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:d359667a-5381-4980-9e71-849ae1684b39
2020-06-02 22:55:31,685 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - e3859357-2f16-4cf9-861f-4aa398f9f998: shutdown FollowerState
2020-06-02 22:55:31,685 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - e3859357-2f16-4cf9-861f-4aa398f9f998: start FollowerState
2020-06-02 22:55:31,685 [Thread-210] INFO  impl.FollowerState (FollowerState.java:run(117)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-06-02 22:55:31,701 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7: Election PASSED; received 1 response(s) [d359667a-5381-4980-9e71-849ae1684b39<-e3859357-2f16-4cf9-861f-4aa398f9f998#0:OK-t2] and 0 exception(s); d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB:t2, leader=null, voted=d359667a-5381-4980-9e71-849ae1684b39, raftlog=d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null
2020-06-02 22:55:31,701 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d359667a-5381-4980-9e71-849ae1684b39: shutdown LeaderElection
2020-06-02 22:55:31,701 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2020-06-02 22:55:31,701 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-322C8C70D8AB with new leaderId: d359667a-5381-4980-9e71-849ae1684b39
2020-06-02 22:55:31,702 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB: change Leader from null to d359667a-5381-4980-9e71-849ae1684b39 at term 2 for becomeLeader, leader elected after 10633ms
2020-06-02 22:55:31,702 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 22:55:31,702 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 22:55:31,702 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB
2020-06-02 22:55:31,702 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 22:55:31,702 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 22:55:31,702 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 22:55:31,702 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 22:55:31,703 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 22:55:31,706 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-06-02 22:55:31,707 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 22:55:31,707 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2020-06-02 22:55:31,712 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:d359667a-5381-4980-9e71-849ae1684b39
2020-06-02 22:55:31,713 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: shutdown FollowerState
2020-06-02 22:55:31,713 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c: start FollowerState
2020-06-02 22:55:31,713 [Thread-211] INFO  impl.FollowerState (FollowerState.java:run(117)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-06-02 22:55:31,719 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2020-06-02 22:55:31,721 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 22:55:31,724 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 22:55:31,746 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-06-02 22:55:31,746 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 22:55:31,746 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2020-06-02 22:55:31,747 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2020-06-02 22:55:31,747 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 22:55:31,747 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 22:55:31,754 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d359667a-5381-4980-9e71-849ae1684b39: start LeaderState
2020-06-02 22:55:31,754 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 22:55:31,755 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-2/data/ratis/22adb0f4-24d2-408f-b2db-322c8c70d8ab/current/log_inprogress_0
2020-06-02 22:55:31,768 [d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB: set configuration 0: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null at 0
2020-06-02 22:55:31,780 [grpc-default-executor-1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-322C8C70D8AB with new leaderId: d359667a-5381-4980-9e71-849ae1684b39
2020-06-02 22:55:31,780 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB: change Leader from null to d359667a-5381-4980-9e71-849ae1684b39 at term 2 for appendEntries, leader elected after 10983ms
2020-06-02 22:55:31,815 [grpc-default-executor-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-322C8C70D8AB with new leaderId: d359667a-5381-4980-9e71-849ae1684b39
2020-06-02 22:55:31,815 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB: change Leader from null to d359667a-5381-4980-9e71-849ae1684b39 at term 2 for appendEntries, leader elected after 10813ms
2020-06-02 22:55:31,844 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB: set configuration 0: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null at 0
2020-06-02 22:55:31,846 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 22:55:31,858 [e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-0/data/ratis/22adb0f4-24d2-408f-b2db-322c8c70d8ab/current/log_inprogress_0
2020-06-02 22:55:31,859 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB: set configuration 0: [e3859357-2f16-4cf9-861f-4aa398f9f998:172.17.0.2:33361, d359667a-5381-4980-9e71-849ae1684b39:172.17.0.2:41663, 4c7e11ca-10b9-4e9c-a049-cdafb338d54c:172.17.0.2:46607], old=null at 0
2020-06-02 22:55:31,860 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 22:55:31,872 [4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-152e526f-8d0c-488e-ace5-edc4cdd7b7ee/datanode-1/data/ratis/22adb0f4-24d2-408f-b2db-322c8c70d8ab/current/log_inprogress_0
2020-06-02 22:55:31,965 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:31,965 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:32,965 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:32,965 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:33,965 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:33,966 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:34,966 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:34,966 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:35,966 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:35,966 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:36,967 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:36,967 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:37,967 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:37,968 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:38,968 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:38,968 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:39,968 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:39,968 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:40,968 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:40,969 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:41,969 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:41,969 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:42,969 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:42,969 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:43,969 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:43,970 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:44,970 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:44,970 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:45,970 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:45,970 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:46,971 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:46,971 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:47,971 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:47,971 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:48,972 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:48,972 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:49,972 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:49,973 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:50,973 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:50,973 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:51,973 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:51,973 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:52,973 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:52,974 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:53,974 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:53,974 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:54,974 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:54,974 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:55,974 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:55,975 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:56,975 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:56,975 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:57,975 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:57,975 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:58,982 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:58,982 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:55:59,983 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:55:59,983 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:56:00,983 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:56:00,983 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:56:01,983 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:56:01,983 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:56:02,986 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:56:02,987 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:56:03,987 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:56:03,987 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:56:04,987 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:56:04,987 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:56:05,988 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:56:05,988 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:56:06,988 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:56:06,988 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:56:07,988 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:56:07,989 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:56:08,989 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 22:56:08,989 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 22:56:09,944 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(387)) - Shutting down the Mini Ozone Cluster
2020-06-02 22:56:09,944 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(402)) - Stopping the Mini Ozone Cluster
2020-06-02 22:56:09,944 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(484)) - Stopping the OzoneManager
2020-06-02 22:56:09,945 [Listener at 127.0.0.1/42381] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42381
2020-06-02 22:56:09,955 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-06-02 22:56:09,955 [Listener at 127.0.0.1/42381] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(410)) - Stopping OMDoubleBuffer flush thread
2020-06-02 22:56:09,956 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(342)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2020-06-02 22:56:09,955 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-06-02 22:56:09,956 [Listener at 127.0.0.1/42381] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service KeyDeletingService
2020-06-02 22:56:09,959 [Listener at 127.0.0.1/42381] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@fabab4c{ozoneManager,/,null,UNAVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2020-06-02 22:56:09,975 [Listener at 127.0.0.1/42381] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@30502477{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-06-02 22:56:09,976 [Listener at 127.0.0.1/42381] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-06-02 22:56:09,988 [Listener at 127.0.0.1/42381] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@313098cb{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2020-06-02 22:56:09,988 [Listener at 127.0.0.1/42381] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@2dca5d2c{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-06-02 22:56:10,000 [Listener at 127.0.0.1/42381] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(461)) - Stopping the HddsDatanodes
====> TEST TIMED OUT. PRINTING THREAD DUMP. <====

Timestamp: 2020-06-02 10:56:09,975

"ChunkWriter-1-0" daemon prio=5 tid=227 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 18 on default port 34321" daemon prio=5 tid=74 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 14 on default port 34321" daemon prio=5 tid=70 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp609084279-209" daemon prio=5 tid=209 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Thread-195" daemon prio=5 tid=286 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"IPC Server handler 19 on default port 34535" daemon prio=5 tid=95 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-StateMachineUpdater" daemon prio=5 tid=257 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server Responder" daemon prio=5 tid=20 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=250 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 0 on default port 37781" daemon prio=5 tid=36 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 3 on default port 34535" daemon prio=5 tid=79 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 15 on default port 34321" daemon prio=5 tid=71 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"RatisPipelineUtilsThread"  prio=5 tid=16 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp751863605-164" daemon prio=5 tid=164 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Thread-208" daemon prio=5 tid=299 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@667c982a" daemon prio=5 tid=108 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=249 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"DataNode DiskChecker thread 0" daemon prio=5 tid=196 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp751863605-165" daemon prio=5 tid=165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"pool-10-thread-1"  prio=5 tid=105 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-StateMachineUpdater" daemon prio=5 tid=261 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 8 on default port 37781" daemon prio=5 tid=44 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-60-thread-1" daemon prio=5 tid=197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp751863605-160-acceptor-0@40a58692-ServerConnector@6732c808{HTTP/1.1,[http/1.1]}{0.0.0.0:40545}" daemon prio=3 tid=160 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-3-0" daemon prio=5 tid=229 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=200 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"grpc-nio-worker-ELG-3-2" daemon prio=5 tid=266 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:807)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=9 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readInt(DataInputStream.java:387)
        at org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:115)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:390)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=174 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-44-thread-1" daemon prio=5 tid=173 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=247 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"DataNode DiskChecker thread 0" daemon prio=5 tid=155 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=219 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=220 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 1 on default port 34321" daemon prio=5 tid=57 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 17 on default port 34535" daemon prio=5 tid=93 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp949101959-101" daemon prio=5 tid=101 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 17 on default port 37781" daemon prio=5 tid=53 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Parameter Sending Thread #0" daemon prio=5 tid=111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Thread-217" daemon prio=5 tid=308 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:243)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:97)
"IPC Server handler 4 on default port 34535" daemon prio=5 tid=80 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp147131923-187" daemon prio=5 tid=187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 6 on default port 37781" daemon prio=5 tid=42 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-40-thread-1"  prio=5 tid=168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp609084279-212" daemon prio=5 tid=212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=10 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp147131923-188" daemon prio=5 tid=188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Command processor thread" daemon prio=5 tid=222 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$171/2009319588.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 1 on default port 34535" daemon prio=5 tid=77 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=199 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 11 on default port 34321" daemon prio=5 tid=67 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=176 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp949101959-102" daemon prio=5 tid=102 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp949101959-98" daemon prio=5 tid=98 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server listener on 0" daemon prio=5 tid=17 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"IPC Server handler 2 on default port 34535" daemon prio=5 tid=78 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=221 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server idle connection scanner for port 34321" daemon prio=5 tid=23 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 15 on default port 37781" daemon prio=5 tid=51 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"EventQueue-Delayed safe mode statusForReplicationManager"  prio=5 tid=32 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-SegmentedRaftLogWorker"  prio=5 tid=273 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 4 on default port 34321" daemon prio=5 tid=60 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Periodic HDDS volume checker" daemon prio=5 tid=171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-6c384446-1"  prio=5 tid=104 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 0 on default port 34321" daemon prio=5 tid=56 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=175 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 10 on default port 34535" daemon prio=5 tid=86 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"EventQueue-Safe mode statusForSCMClientProtocolServer"  prio=5 tid=31 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server idle connection scanner for port 37781" daemon prio=5 tid=27 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"pool-72-thread-1"  prio=5 tid=216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"SCMBlockDeletingService#1" daemon prio=5 tid=109 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp751863605-163" daemon prio=5 tid=163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"BlockDeletingService#0" daemon prio=5 tid=231 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 16 on default port 37781" daemon prio=5 tid=52 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 19 on default port 34321" daemon prio=5 tid=75 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Socket Reader #1 for port 0"  prio=5 tid=18 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"ChunkWriter-0-0" daemon prio=5 tid=233 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 5 on default port 34535" daemon prio=5 tid=81 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=15 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@1afa59de" daemon prio=5 tid=203 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 12 on default port 34321" daemon prio=5 tid=68 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-0-0" daemon prio=5 tid=239 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode State Machine Thread - 0" daemon prio=5 tid=224 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp147131923-185" daemon prio=5 tid=185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Thread-216" daemon prio=5 tid=307 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"grpc-default-executor-1" daemon prio=5 tid=276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-3-0" daemon prio=5 tid=236 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"main"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1610)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:93)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:79)
        at org.apache.hadoop.test.TimedOutTestsListener.testFailure(TimedOutTestsListener.java:67)
        at org.junit.runner.notification.RunNotifier$4.notifyListener(RunNotifier.java:139)
        at org.junit.runner.notification.RunNotifier$SafeNotifier.run(RunNotifier.java:61)
        at org.junit.runner.notification.RunNotifier.fireTestFailures(RunNotifier.java:134)
        at org.junit.runner.notification.RunNotifier.fireTestFailure(RunNotifier.java:128)
        at org.apache.maven.surefire.common.junit4.Notifier.fireTestFailure(Notifier.java:114)
        at org.junit.internal.runners.model.EachTestNotifier.addFailure(EachTestNotifier.java:23)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:275)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
"IPC Server handler 4 on default port 37781" daemon prio=5 tid=40 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp609084279-210" daemon prio=5 tid=210 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-SegmentedRaftLogWorker"  prio=5 tid=267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-0-0" daemon prio=5 tid=226 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 1 on default port 37781" daemon prio=5 tid=37 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-2-0" daemon prio=5 tid=235 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp609084279-213" daemon prio=5 tid=213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=218 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 19 on default port 37781" daemon prio=5 tid=55 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp609084279-214" daemon prio=5 tid=214 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-322C8C70D8AB-StateMachineUpdater" daemon prio=5 tid=271 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"grpc-nio-boss-ELG-1-1" daemon prio=5 tid=230 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 11 on default port 34535" daemon prio=5 tid=87 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Command processor thread" daemon prio=5 tid=202 terminated
java.lang.Thread.State: TERMINATED
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$171/2009319588.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"qtp864247401-148" daemon prio=5 tid=148 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 13 on default port 37781" daemon prio=5 tid=49 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"e3859357-2f16-4cf9-861f-4aa398f9f998@group-322C8C70D8AB-SegmentedRaftLogWorker"  prio=5 tid=256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=245 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp609084279-208-acceptor-0@711af296-ServerConnector@3b9fc304{HTTP/1.1,[http/1.1]}{0.0.0.0:38519}" daemon prio=3 tid=208 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-SegmentedRaftLogWorker"  prio=5 tid=253 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"qtp949101959-96" daemon prio=5 tid=96 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/1129420551.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 14 on default port 34535" daemon prio=5 tid=90 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Session-HouseKeeper-d6a93b-1"  prio=5 tid=191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 7 on default port 34321" daemon prio=5 tid=63 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 11 on default port 37781" daemon prio=5 tid=47 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-2-0" daemon prio=5 tid=241 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-51-thread-1"  prio=5 tid=259 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@54919b12" daemon prio=5 tid=152 terminated
java.lang.Thread.State: TERMINATED
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 10 on default port 34321" daemon prio=5 tid=66 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 9 on default port 34535" daemon prio=5 tid=85 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"qtp147131923-184-acceptor-0@670e6b96-ServerConnector@1dfcb4eb{HTTP/1.1,[http/1.1]}{0.0.0.0:45283}" daemon prio=3 tid=184 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"qtp949101959-100" daemon prio=5 tid=100 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"BlockDeletingService#1" daemon prio=5 tid=232 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp864247401-144" daemon prio=5 tid=144 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp949101959-97-acceptor-0@2975b5cc-ServerConnector@16d9381c{HTTP/1.1,[http/1.1]}{0.0.0.0:40117}" daemon prio=3 tid=97 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 12 on default port 34535" daemon prio=5 tid=88 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 18 on default port 37781" daemon prio=5 tid=54 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Thread-215" daemon prio=5 tid=306 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:243)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:97)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=248 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-55-thread-1"  prio=5 tid=182 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp949101959-103" daemon prio=5 tid=103 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 18 on default port 34535" daemon prio=5 tid=94 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"EventQueue-Delayed safe mode statusForSCMPipelineManager"  prio=5 tid=33 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-StateMachineUpdater" daemon prio=5 tid=269 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"qtp147131923-186" daemon prio=5 tid=186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"prometheus" daemon prio=5 tid=106 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.metrics2.impl.SinkQueue.waitForData(SinkQueue.java:114)
        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:83)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:135)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:89)
"IPC Server handler 2 on default port 37781" daemon prio=5 tid=38 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 16 on default port 34535" daemon prio=5 tid=92 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"grpc-nio-worker-ELG-3-1" daemon prio=5 tid=264 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:807)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
"4c7e11ca-10b9-4e9c-a049-cdafb338d54c@group-76FFDCA17148-SegmentedRaftLogWorker"  prio=5 tid=260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"BlockDeletingService#1" daemon prio=5 tid=238 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-5306552a-1"  prio=5 tid=215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-6eb955fb-1"  prio=5 tid=167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"DataNode DiskChecker thread 0" daemon prio=5 tid=172 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"CommandWatcher-LeaseManager#LeaseMonitor" daemon prio=5 tid=35 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:234)
        at java.lang.Thread.run(Thread.java:748)
"SCMBlockDeletingService#0" daemon prio=5 tid=107 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp609084279-211" daemon prio=5 tid=211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 16 on default port 34321" daemon prio=5 tid=72 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"BlockDeletingService#0" daemon prio=5 tid=237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Command processor thread" daemon prio=5 tid=178 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$171/2009319588.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server idle connection scanner for port 34535" daemon prio=5 tid=19 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"pool-8-thread-1"  prio=5 tid=29 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-2-0" daemon prio=5 tid=228 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"grpc-default-executor-3" daemon prio=5 tid=314 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"d359667a-5381-4980-9e71-849ae1684b39@group-94C63DF86725-SegmentedRaftLogWorker"  prio=5 tid=268 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"d359667a-5381-4980-9e71-849ae1684b39@group-322C8C70D8AB-StateMachineUpdater" daemon prio=5 tid=274 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 17 on default port 34321" daemon prio=5 tid=73 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Datanode State Machine Thread - 0" daemon prio=5 tid=181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"grpc-default-executor-0" daemon prio=5 tid=265 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp864247401-145" daemon prio=5 tid=145 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Periodic HDDS volume checker" daemon prio=5 tid=195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp949101959-99" daemon prio=5 tid=99 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp864247401-146" daemon prio=5 tid=146 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Thread-205" daemon prio=5 tid=295 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"qtp751863605-159" daemon prio=5 tid=159 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/1129420551.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 9 on default port 34321" daemon prio=5 tid=65 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 8 on default port 34321" daemon prio=5 tid=64 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-56-thread-1"  prio=5 tid=192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"BlockDeletingService#0" daemon prio=5 tid=243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-1-0" daemon prio=5 tid=234 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp751863605-166" daemon prio=5 tid=166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 5 on default port 37781" daemon prio=5 tid=41 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server Responder" daemon prio=5 tid=24 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$451/587884151@59bc93f1" daemon prio=5 tid=309 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:151)
        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:105)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:77)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$451/587884151.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"java.util.concurrent.ThreadPoolExecutor$Worker@7c15f503[State = -1, empty queue]" daemon prio=5 tid=312 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode State Machine Thread - 0" daemon prio=5 tid=204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server listener on 0" daemon prio=5 tid=25 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"IPC Server handler 6 on default port 34535" daemon prio=5 tid=82 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Listener at 127.0.0.1/42381"  prio=5 tid=12 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.io.FileOutputStream.writeBytes(Native Method)
        at java.io.FileOutputStream.write(FileOutputStream.java:326)
        at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
        at java.io.PrintStream.write(PrintStream.java:480)
        at org.apache.maven.surefire.booter.ForkingRunListener.writeTestOutput(ForkingRunListener.java:208)
        at org.apache.maven.surefire.report.ConsoleOutputCapture$ForwardingPrintStream.write(ConsoleOutputCapture.java:60)
        at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:221)
        at sun.nio.cs.StreamEncoder.implFlushBuffer(StreamEncoder.java:291)
        at sun.nio.cs.StreamEncoder.implFlush(StreamEncoder.java:295)
        at sun.nio.cs.StreamEncoder.flush(StreamEncoder.java:141)
        at java.io.OutputStreamWriter.flush(OutputStreamWriter.java:229)
        at org.apache.log4j.helpers.QuietWriter.flush(QuietWriter.java:59)
        at org.apache.log4j.WriterAppender.subAppend(WriterAppender.java:324)
        at org.apache.log4j.WriterAppender.append(WriterAppender.java:162)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.log(Category.java:856)
        at org.slf4j.impl.Log4jLoggerAdapter.log(Log4jLoggerAdapter.java:581)
        at org.eclipse.jetty.util.log.JettyAwareLogger.log(JettyAwareLogger.java:625)
        at org.eclipse.jetty.util.log.JettyAwareLogger.info(JettyAwareLogger.java:314)
        at org.eclipse.jetty.util.log.Slf4jLog.info(Slf4jLog.java:77)
        at org.eclipse.jetty.server.session.HouseKeeper.stopScavenging(HouseKeeper.java:158)
        at org.eclipse.jetty.server.session.HouseKeeper.doStop(HouseKeeper.java:178)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:93)
        at org.eclipse.jetty.server.session.DefaultSessionIdManager.doStop(DefaultSessionIdManager.java:354)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:93)
        at org.eclipse.jetty.util.component.ContainerLifeCycle.stop(ContainerLifeCycle.java:180)
        at org.eclipse.jetty.util.component.ContainerLifeCycle.doStop(ContainerLifeCycle.java:201)
        at org.eclipse.jetty.server.handler.AbstractHandler.doStop(AbstractHandler.java:108)
        at org.eclipse.jetty.server.Server.doStop(Server.java:454)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:93)
        at org.apache.hadoop.hdds.server.http.HttpServer2.stop(HttpServer2.java:1338)
        at org.apache.hadoop.hdds.server.http.BaseHttpServer.stop(BaseHttpServer.java:310)
        at org.apache.hadoop.ozone.om.OzoneManager.stop(OzoneManager.java:1290)
        at org.apache.hadoop.ozone.MiniOzoneClusterImpl.stopOM(MiniOzoneClusterImpl.java:485)
        at org.apache.hadoop.ozone.MiniOzoneClusterImpl.stop(MiniOzoneClusterImpl.java:403)
        at org.apache.hadoop.ozone.MiniOzoneClusterImpl.shutdown(MiniOzoneClusterImpl.java:391)
        at org.apache.hadoop.ozone.om.TestOzoneManagerRocksDBLogging.shutdown(TestOzoneManagerRocksDBLogging.java:63)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
        at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
"qtp864247401-143" daemon prio=5 tid=143 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-6a45b97a-1"  prio=5 tid=150 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp609084279-207" daemon prio=5 tid=207 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/1129420551.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"e3859357-2f16-4cf9-861f-4aa398f9f998@group-662233E84282-StateMachineUpdater" daemon prio=5 tid=254 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"grpc-default-executor-2" daemon prio=5 tid=277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-39-thread-1"  prio=5 tid=158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"BlockDeletingService#1" daemon prio=5 tid=244 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 9 on default port 37781" daemon prio=5 tid=45 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-3-0" daemon prio=5 tid=242 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 15 on default port 34535" daemon prio=5 tid=91 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server Responder" daemon prio=5 tid=28 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"IPC Server handler 7 on default port 34535" daemon prio=5 tid=83 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-35-thread-1"  prio=5 tid=252 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-1-0" daemon prio=5 tid=240 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 5 on default port 34321" daemon prio=5 tid=61 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 10 on default port 37781" daemon prio=5 tid=46 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 8 on default port 34535" daemon prio=5 tid=84 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$451/587884151@1e4aa0c4" daemon prio=5 tid=310 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:151)
        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:105)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:77)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$451/587884151.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 13 on default port 34321" daemon prio=5 tid=69 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-67-thread-1"  prio=5 tid=263 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp751863605-162" daemon prio=5 tid=162 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@15f275fb" daemon prio=5 tid=179 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"qtp864247401-149" daemon prio=5 tid=149 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 12 on default port 37781" daemon prio=5 tid=48 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)
"IPC Server handler 13 on default port 34535" daemon prio=5 tid=89 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-71-thread-1"  prio=5 tid=206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp147131923-183" daemon prio=5 tid=183 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/1129420551.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"Periodic HDDS volume checker" da