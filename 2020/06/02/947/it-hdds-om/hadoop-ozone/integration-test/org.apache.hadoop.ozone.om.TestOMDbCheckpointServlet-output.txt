2020-06-02 21:30:30,287 [Thread-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 21:30:30,396 [Thread-1] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 21:30:30,533 [Thread-1] WARN  db.DBStoreBuilder (DBStoreBuilder.java:createDBStoreBuilder(277)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 21:30:30,690 [Thread-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(126)) - Loading file from sun.misc.CompoundEnumeration@5650d52f
2020-06-02 21:30:30,691 [Thread-1] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(172)) - Loading network topology layer schema file
2020-06-02 21:30:30,759 [Thread-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(73)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2020-06-02 21:30:30,760 [Thread-1] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(73)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2020-06-02 21:30:30,763 [Thread-1] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2020-06-02 21:30:30,877 [Thread-1] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(60)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2020-06-02 21:30:30,903 [Thread-1] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(158)) - No pipeline exists in current db
2020-06-02 21:30:30,969 [Thread-1] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:<init>(89)) - Total pipeline count is 0, healthy pipeline threshold count is 0
2020-06-02 21:30:30,972 [Thread-1] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:<init>(79)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2020-06-02 21:30:31,028 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2020-06-02 21:30:31,403 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 21:30:31,430 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 21:30:31,478 [Listener at 0.0.0.0/41783] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 21:30:31,479 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 21:30:31,494 [Listener at 0.0.0.0/38639] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 21:30:31,495 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 21:30:31,517 [Listener at 0.0.0.0/40443] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for scm at: http://0.0.0.0:0
2020-06-02 21:30:31,517 [Listener at 0.0.0.0/40443] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 21:30:31,543 [Listener at 0.0.0.0/40443] INFO  util.log (Log.java:initialized(169)) - Logging initialized @2321ms to org.eclipse.jetty.util.log.Slf4jLog
2020-06-02 21:30:31,682 [Listener at 0.0.0.0/40443] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:30:31,698 [Listener at 0.0.0.0/40443] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 21:30:31,704 [Listener at 0.0.0.0/40443] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 21:30:31,706 [Listener at 0.0.0.0/40443] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2020-06-02 21:30:31,706 [Listener at 0.0.0.0/40443] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 21:30:31,706 [Listener at 0.0.0.0/40443] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 21:30:31,761 [Listener at 0.0.0.0/40443] INFO  server.StorageContainerManager (StorageContainerManager.java:start(781)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:40443
2020-06-02 21:30:31,816 [Listener at 0.0.0.0/40443] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2020-06-02 21:30:31,832 [Listener at 0.0.0.0/40443] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-06-02 21:30:31,833 [Listener at 0.0.0.0/40443] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2020-06-02 21:30:32,077 [Listener at 0.0.0.0/40443] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(157)) - RPC server for Client  is listening at /0.0.0.0:40443
2020-06-02 21:30:32,079 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 21:30:32,080 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 21:30:32,082 [Listener at 0.0.0.0/40443] INFO  server.StorageContainerManager (StorageContainerManager.java:start(793)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:38639
2020-06-02 21:30:32,083 [Listener at 0.0.0.0/40443] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(149)) - RPC server for Block Protocol is listening at /0.0.0.0:38639
2020-06-02 21:30:32,084 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 21:30:32,085 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 21:30:32,087 [Listener at 0.0.0.0/40443] INFO  server.StorageContainerManager (StorageContainerManager.java:start(799)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:41783
2020-06-02 21:30:32,087 [Listener at 0.0.0.0/40443] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(172)) - RPC server for DataNodes is listening at /0.0.0.0:41783
2020-06-02 21:30:32,088 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 21:30:32,088 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 21:30:32,093 [Listener at 0.0.0.0/40443] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 41767
2020-06-02 21:30:32,094 [Listener at 0.0.0.0/40443] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 21:30:32,125 [Listener at 0.0.0.0/40443] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 21:30:32,126 [Listener at 0.0.0.0/40443] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 21:30:32,127 [Listener at 0.0.0.0/40443] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-06-02 21:30:32,141 [Listener at 0.0.0.0/40443] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:30:32,144 [Listener at 0.0.0.0/40443] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@26772240{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 21:30:32,144 [Listener at 0.0.0.0/40443] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@328d06d2{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2020-06-02 21:30:32,184 [Listener at 0.0.0.0/40443] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@223d5cbd{scm,/,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2020-06-02 21:30:32,192 [Listener at 0.0.0.0/40443] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@3dcdd0e0{HTTP/1.1,[http/1.1]}{0.0.0.0:41767}
2020-06-02 21:30:32,193 [Listener at 0.0.0.0/40443] INFO  server.Server (Server.java:doStart(399)) - Started @2970ms
2020-06-02 21:30:32,196 [Listener at 0.0.0.0/40443] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2020-06-02 21:30:32,196 [Listener at 0.0.0.0/40443] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(301)) - Registered sink prometheus
2020-06-02 21:30:32,200 [Listener at 0.0.0.0/40443] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of scm listening at http://0.0.0.0:41767
2020-06-02 21:30:32,209 [Listener at 0.0.0.0/40443] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 21:30:32,218 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@78b132d5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 21:30:32,312 [Listener at 0.0.0.0/40443] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(104)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2020-06-02 21:30:32,315 [Listener at 0.0.0.0/40443] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(207)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2020-06-02 21:30:32,315 [Listener at 0.0.0.0/40443] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(237)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2020-06-02 21:30:32,317 [Listener at 0.0.0.0/40443] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 21:30:32,318 [Listener at 0.0.0.0/40443] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 21:30:33,059 [Listener at 0.0.0.0/40443] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 21:30:33,193 [Listener at 0.0.0.0/40443] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 21:30:33,194 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 21:30:33,224 [Listener at 127.0.0.1/35123] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2020-06-02 21:30:33,226 [Listener at 127.0.0.1/35123] INFO  om.OzoneManager (OzoneManager.java:start(1097)) - OzoneManager RPC server is listening at localhost/127.0.0.1:35123
2020-06-02 21:30:33,247 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 21:30:33,247 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 21:30:33,257 [Listener at 127.0.0.1/35123] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2020-06-02 21:30:33,257 [Listener at 127.0.0.1/35123] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 21:30:33,258 [Listener at 127.0.0.1/35123] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:30:33,260 [Listener at 127.0.0.1/35123] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 21:30:33,261 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 21:30:33,262 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
2020-06-02 21:30:33,262 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 21:30:33,263 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 21:30:33,266 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 45367
2020-06-02 21:30:33,266 [Listener at 127.0.0.1/35123] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 21:30:33,268 [Listener at 127.0.0.1/35123] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 21:30:33,268 [Listener at 127.0.0.1/35123] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 21:30:33,268 [Listener at 127.0.0.1/35123] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-06-02 21:30:33,269 [Listener at 127.0.0.1/35123] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:30:33,270 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@73b0684c{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 21:30:33,270 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@63475b16{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2020-06-02 21:30:33,275 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@308a598f{ozoneManager,/,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2020-06-02 21:30:33,276 [Listener at 127.0.0.1/35123] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@5cee7e48{HTTP/1.1,[http/1.1]}{0.0.0.0:45367}
2020-06-02 21:30:33,276 [Listener at 127.0.0.1/35123] INFO  server.Server (Server.java:doStart(399)) - Started @4053ms
2020-06-02 21:30:33,276 [Listener at 127.0.0.1/35123] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 21:30:33,278 [Listener at 127.0.0.1/35123] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of ozoneManager listening at http://0.0.0.0:45367
2020-06-02 21:30:33,288 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@dc47fd2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 21:30:33,390 [Listener at 127.0.0.1/35123] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2020-06-02 21:30:33,391 [Listener at 127.0.0.1/35123] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-06-02 21:30:33,395 [Listener at 127.0.0.1/35123] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(205)) - HddsDatanodeService host:32d60ebb3871 ip:172.17.0.2
2020-06-02 21:30:33,436 [Listener at 127.0.0.1/35123] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-06-02 21:30:33,439 [Listener at 127.0.0.1/35123] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(181)) - Added Volume : /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data-0/containers/hdds to VolumeSet
2020-06-02 21:30:33,440 [Listener at 127.0.0.1/35123] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data-0/containers/hdds
2020-06-02 21:30:33,462 [Listener at 127.0.0.1/35123] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data-0/containers/hdds
2020-06-02 21:30:33,588 [Listener at 127.0.0.1/35123] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-06-02 21:30:33,648 [Listener at 127.0.0.1/35123] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-06-02 21:30:33,652 [Listener at 127.0.0.1/35123] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-06-02 21:30:33,653 [Listener at 127.0.0.1/35123] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-06-02 21:30:33,654 [Listener at 127.0.0.1/35123] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:30:33,654 [Listener at 127.0.0.1/35123] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-06-02 21:30:33,655 [Listener at 127.0.0.1/35123] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 21:30:33,818 [Listener at 127.0.0.1/35123] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis] (custom)
2020-06-02 21:30:33,898 [Listener at 127.0.0.1/35123] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-06-02 21:30:33,899 [Listener at 127.0.0.1/35123] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 21:30:33,900 [Listener at 127.0.0.1/35123] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:30:33,901 [Listener at 127.0.0.1/35123] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 21:30:33,901 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 21:30:33,902 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
2020-06-02 21:30:33,903 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 21:30:33,903 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 21:30:33,903 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 38005
2020-06-02 21:30:33,903 [Listener at 127.0.0.1/35123] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 21:30:33,915 [Listener at 127.0.0.1/35123] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 21:30:33,915 [Listener at 127.0.0.1/35123] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 21:30:33,915 [Listener at 127.0.0.1/35123] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-06-02 21:30:33,916 [Listener at 127.0.0.1/35123] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:30:33,917 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@9009af{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 21:30:33,917 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@1f44c3c2{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-06-02 21:30:33,963 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@3a2e0552{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-38005-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-5280477341996767842.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 21:30:33,965 [Listener at 127.0.0.1/35123] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@3fe1306f{HTTP/1.1,[http/1.1]}{0.0.0.0:38005}
2020-06-02 21:30:33,965 [Listener at 127.0.0.1/35123] INFO  server.Server (Server.java:doStart(399)) - Started @4742ms
2020-06-02 21:30:33,966 [Listener at 127.0.0.1/35123] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 21:30:33,972 [Listener at 127.0.0.1/35123] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of hddsDatanode listening at http://0.0.0.0:38005
2020-06-02 21:30:33,973 [Listener at 127.0.0.1/35123] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-06-02 21:30:33,974 [Listener at 127.0.0.1/35123] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(205)) - HddsDatanodeService host:32d60ebb3871 ip:172.17.0.2
2020-06-02 21:30:33,978 [Listener at 127.0.0.1/35123] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-06-02 21:30:33,978 [Listener at 127.0.0.1/35123] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(181)) - Added Volume : /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data-0/containers/hdds to VolumeSet
2020-06-02 21:30:33,978 [Listener at 127.0.0.1/35123] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data-0/containers/hdds
2020-06-02 21:30:33,979 [Listener at 127.0.0.1/35123] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data-0/containers/hdds
2020-06-02 21:30:34,036 [Listener at 127.0.0.1/35123] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-06-02 21:30:34,036 [Listener at 127.0.0.1/35123] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-06-02 21:30:34,037 [Listener at 127.0.0.1/35123] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-06-02 21:30:34,037 [Listener at 127.0.0.1/35123] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-06-02 21:30:34,037 [Listener at 127.0.0.1/35123] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:30:34,037 [Listener at 127.0.0.1/35123] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-06-02 21:30:34,037 [Listener at 127.0.0.1/35123] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 21:30:34,038 [Listener at 127.0.0.1/35123] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis] (custom)
2020-06-02 21:30:34,045 [Listener at 127.0.0.1/35123] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-06-02 21:30:34,045 [Listener at 127.0.0.1/35123] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 21:30:34,045 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d7ff8dc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 21:30:34,047 [Listener at 127.0.0.1/35123] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:30:34,056 [Listener at 127.0.0.1/35123] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 21:30:34,057 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 21:30:34,058 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
2020-06-02 21:30:34,060 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 21:30:34,060 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 21:30:34,060 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 36091
2020-06-02 21:30:34,060 [Listener at 127.0.0.1/35123] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 21:30:34,128 [Listener at 127.0.0.1/35123] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 21:30:34,128 [Listener at 127.0.0.1/35123] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 21:30:34,129 [Listener at 127.0.0.1/35123] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-06-02 21:30:34,137 [Listener at 127.0.0.1/35123] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:30:34,144 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@6e7262fb{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 21:30:34,145 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@537d30fe{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-06-02 21:30:34,180 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(145)) - DatanodeDetails is persisted to /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/meta/datanode.id
2020-06-02 21:30:34,190 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@24e3d1e9{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-36091-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-9034698646418515758.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 21:30:34,193 [Listener at 127.0.0.1/35123] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@3b201845{HTTP/1.1,[http/1.1]}{0.0.0.0:36091}
2020-06-02 21:30:34,193 [Listener at 127.0.0.1/35123] INFO  server.Server (Server.java:doStart(399)) - Started @4970ms
2020-06-02 21:30:34,193 [Listener at 127.0.0.1/35123] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 21:30:34,196 [Listener at 127.0.0.1/35123] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of hddsDatanode listening at http://0.0.0.0:36091
2020-06-02 21:30:34,197 [Listener at 127.0.0.1/35123] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-06-02 21:30:34,198 [Listener at 127.0.0.1/35123] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(205)) - HddsDatanodeService host:32d60ebb3871 ip:172.17.0.2
2020-06-02 21:30:34,204 [Listener at 127.0.0.1/35123] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-06-02 21:30:34,205 [Listener at 127.0.0.1/35123] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(181)) - Added Volume : /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data-0/containers/hdds to VolumeSet
2020-06-02 21:30:34,205 [Listener at 127.0.0.1/35123] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data-0/containers/hdds
2020-06-02 21:30:34,207 [Listener at 127.0.0.1/35123] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data-0/containers/hdds
2020-06-02 21:30:34,232 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@575fbced] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 21:30:34,244 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(145)) - DatanodeDetails is persisted to /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/meta/datanode.id
2020-06-02 21:30:34,247 [Listener at 127.0.0.1/35123] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-06-02 21:30:34,247 [Listener at 127.0.0.1/35123] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-06-02 21:30:34,247 [Listener at 127.0.0.1/35123] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-06-02 21:30:34,247 [Listener at 127.0.0.1/35123] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-06-02 21:30:34,247 [Listener at 127.0.0.1/35123] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:30:34,248 [Listener at 127.0.0.1/35123] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-06-02 21:30:34,248 [Listener at 127.0.0.1/35123] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 21:30:34,251 [Listener at 127.0.0.1/35123] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis] (custom)
2020-06-02 21:30:34,256 [Listener at 127.0.0.1/35123] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-06-02 21:30:34,256 [Listener at 127.0.0.1/35123] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 21:30:34,259 [Listener at 127.0.0.1/35123] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:30:34,260 [Listener at 127.0.0.1/35123] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 21:30:34,261 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 21:30:34,262 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
2020-06-02 21:30:34,262 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 21:30:34,262 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 21:30:34,263 [Listener at 127.0.0.1/35123] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 36711
2020-06-02 21:30:34,263 [Listener at 127.0.0.1/35123] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 21:30:34,265 [Listener at 127.0.0.1/35123] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 21:30:34,265 [Listener at 127.0.0.1/35123] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 21:30:34,266 [Listener at 127.0.0.1/35123] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-06-02 21:30:34,267 [Listener at 127.0.0.1/35123] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:30:34,268 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@408be914{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 21:30:34,268 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@2b4566d9{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-06-02 21:30:34,300 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@d088aa2{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-36711-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-6380681278497410068.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 21:30:34,302 [Listener at 127.0.0.1/35123] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@2e504073{HTTP/1.1,[http/1.1]}{0.0.0.0:36711}
2020-06-02 21:30:34,302 [Listener at 127.0.0.1/35123] INFO  server.Server (Server.java:doStart(399)) - Started @5080ms
2020-06-02 21:30:34,303 [Listener at 127.0.0.1/35123] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 21:30:34,308 [Listener at 127.0.0.1/35123] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of hddsDatanode listening at http://0.0.0.0:36711
2020-06-02 21:30:34,309 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 21:30:34,309 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:34,320 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@489f41d0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 21:30:34,322 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(145)) - DatanodeDetails is persisted to /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/meta/datanode.id
2020-06-02 21:30:35,309 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 21:30:35,309 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:36,103 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-06-02 21:30:36,105 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-06-02 21:30:36,105 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(425)) - Starting XceiverServerRatis 7bbd2402-c364-4868-9d2c-73c7d416b8c0 at port 0
2020-06-02 21:30:36,122 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: start RPC server
2020-06-02 21:30:36,175 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(159)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: GrpcService started, listening on 0.0.0.0/0.0.0.0:44277
2020-06-02 21:30:36,176 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(437)) - XceiverServerRatis 7bbd2402-c364-4868-9d2c-73c7d416b8c0 is started using port 44277
2020-06-02 21:30:36,180 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 7bbd2402-c364-4868-9d2c-73c7d416b8c0 is started using port 34401
2020-06-02 21:30:36,237 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-06-02 21:30:36,239 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-06-02 21:30:36,239 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(425)) - Starting XceiverServerRatis a6b41249-b273-4291-afb4-d06d350d4050 at port 0
2020-06-02 21:30:36,252 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - a6b41249-b273-4291-afb4-d06d350d4050: start RPC server
2020-06-02 21:30:36,256 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(159)) - a6b41249-b273-4291-afb4-d06d350d4050: GrpcService started, listening on 0.0.0.0/0.0.0.0:43235
2020-06-02 21:30:36,256 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(437)) - XceiverServerRatis a6b41249-b273-4291-afb4-d06d350d4050 is started using port 43235
2020-06-02 21:30:36,259 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc a6b41249-b273-4291-afb4-d06d350d4050 is started using port 44433
2020-06-02 21:30:36,310 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 21:30:36,310 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:36,323 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-06-02 21:30:36,324 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-06-02 21:30:36,324 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(425)) - Starting XceiverServerRatis 762fe7a3-380a-4155-b73e-ca6d55ceee4d at port 0
2020-06-02 21:30:36,325 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: start RPC server
2020-06-02 21:30:36,335 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(159)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: GrpcService started, listening on 0.0.0.0/0.0.0.0:35853
2020-06-02 21:30:36,335 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(437)) - XceiverServerRatis 762fe7a3-380a-4155-b73e-ca6d55ceee4d is started using port 35853
2020-06-02 21:30:36,336 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 762fe7a3-380a-4155-b73e-ca6d55ceee4d is started using port 40141
2020-06-02 21:30:37,310 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 21:30:37,311 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:38,056 [IPC Server handler 3 on default port 41783] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:30:38,057 [IPC Server handler 3 on default port 41783] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 7bbd2402-c364-4868-9d2c-73c7d416b8c0{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}
2020-06-02 21:30:38,062 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - ContainerSafeModeRule rule is successfully validated
2020-06-02 21:30:38,063 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2020-06-02 21:30:38,063 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - DataNodeSafeModeRule rule is successfully validated
2020-06-02 21:30:38,063 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(241)) - All SCM safe mode pre check rules have passed
2020-06-02 21:30:38,074 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=2082e97e-3c59-46f0-a902-371025157a39 to datanode:7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:30:38,088 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 2082e97e-3c59-46f0-a902-371025157a39, Nodes: 7bbd2402-c364-4868-9d2c-73c7d416b8c0{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T21:30:38.071Z]
2020-06-02 21:30:38,091 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 1 nodes. Healthy nodes 1
2020-06-02 21:30:38,091 [RatisPipelineUtilsThread] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(133)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2020-06-02 21:30:38,092 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2020-06-02 21:30:38,235 [IPC Server handler 1 on default port 41783] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/a6b41249-b273-4291-afb4-d06d350d4050
2020-06-02 21:30:38,235 [IPC Server handler 1 on default port 41783] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : a6b41249-b273-4291-afb4-d06d350d4050{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}
2020-06-02 21:30:38,235 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - DataNodeSafeModeRule rule is successfully validated
2020-06-02 21:30:38,236 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - ContainerSafeModeRule rule is successfully validated
2020-06-02 21:30:38,238 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=b4a2f779-cada-4ca2-a5b1-726dcb5b934a to datanode:a6b41249-b273-4291-afb4-d06d350d4050
2020-06-02 21:30:38,238 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: b4a2f779-cada-4ca2-a5b1-726dcb5b934a, Nodes: a6b41249-b273-4291-afb4-d06d350d4050{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T21:30:38.238Z]
2020-06-02 21:30:38,239 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
2020-06-02 21:30:38,239 [RatisPipelineUtilsThread] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(133)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2020-06-02 21:30:38,239 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2020-06-02 21:30:38,311 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 2 of 3 DN Heartbeats.
2020-06-02 21:30:38,311 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:38,322 [IPC Server handler 2 on default port 41783] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/762fe7a3-380a-4155-b73e-ca6d55ceee4d
2020-06-02 21:30:38,323 [IPC Server handler 2 on default port 41783] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 762fe7a3-380a-4155-b73e-ca6d55ceee4d{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}
2020-06-02 21:30:38,323 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=a484410b-1fcc-41d6-954e-633ccbac6965 to datanode:762fe7a3-380a-4155-b73e-ca6d55ceee4d
2020-06-02 21:30:38,323 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - ContainerSafeModeRule rule is successfully validated
2020-06-02 21:30:38,323 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - DataNodeSafeModeRule rule is successfully validated
2020-06-02 21:30:38,324 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: a484410b-1fcc-41d6-954e-633ccbac6965, Nodes: 762fe7a3-380a-4155-b73e-ca6d55ceee4d{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T21:30:38.323Z]
2020-06-02 21:30:38,324 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
2020-06-02 21:30:38,328 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=f211dd9d-3530-48da-b025-d9d1f22491bd to datanode:762fe7a3-380a-4155-b73e-ca6d55ceee4d
2020-06-02 21:30:38,328 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=f211dd9d-3530-48da-b025-d9d1f22491bd to datanode:a6b41249-b273-4291-afb4-d06d350d4050
2020-06-02 21:30:38,329 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=f211dd9d-3530-48da-b025-d9d1f22491bd to datanode:7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:30:38,329 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: f211dd9d-3530-48da-b025-d9d1f22491bd, Nodes: 762fe7a3-380a-4155-b73e-ca6d55ceee4d{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}a6b41249-b273-4291-afb4-d06d350d4050{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}7bbd2402-c364-4868-9d2c-73c7d416b8c0{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T21:30:38.328Z]
2020-06-02 21:30:38,329 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
2020-06-02 21:30:39,312 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:39,312 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:40,313 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:40,313 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:41,046 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: addNew group-371025157A39:[7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277] returns group-371025157A39:java.util.concurrent.CompletableFuture@37f13857[Not completed]
2020-06-02 21:30:41,058 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: new RaftServerImpl for group-371025157A39:[7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277] with ContainerStateMachine:uninitialized
2020-06-02 21:30:41,059 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 21:30:41,059 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 21:30:41,060 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 21:30:41,060 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 21:30:41,061 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:30:41,066 [pool-35-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39: ConfigurationManager, init=-1: [7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277], old=null, confs=<EMPTY_MAP>
2020-06-02 21:30:41,066 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis] (custom)
2020-06-02 21:30:41,070 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 21:30:41,071 [pool-35-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis/2082e97e-3c59-46f0-a902-371025157a39 does not exist. Creating ...
2020-06-02 21:30:41,075 [pool-35-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis/2082e97e-3c59-46f0-a902-371025157a39/in_use.lock acquired by nodename 4536@32d60ebb3871
2020-06-02 21:30:41,078 [pool-35-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis/2082e97e-3c59-46f0-a902-371025157a39 has been successfully formatted.
2020-06-02 21:30:41,081 [pool-35-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-371025157A39: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 21:30:41,081 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(378)) - Unable to start the DatanodeState Machine
java.io.IOException: Unable to finish the execution.
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:375)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:212)
	... 2 more
2020-06-02 21:30:41,082 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 21:30:41,084 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 21:30:41,089 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 21:30:41,089 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:30:41,091 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:30:41,096 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:30:41,106 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 21:30:41,111 [pool-35-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis/2082e97e-3c59-46f0-a902-371025157a39
2020-06-02 21:30:41,111 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 21:30:41,112 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 21:30:41,113 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:30:41,113 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 21:30:41,113 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 21:30:41,114 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 21:30:41,115 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 21:30:41,115 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 21:30:41,115 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 21:30:41,127 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 21:30:41,133 [pool-35-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 21:30:41,139 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 21:30:41,141 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 21:30:41,142 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 21:30:41,142 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 21:30:41,142 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 21:30:41,159 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39
2020-06-02 21:30:41,161 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39
2020-06-02 21:30:41,165 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39: start as a follower, conf=-1: [7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277], old=null
2020-06-02 21:30:41,171 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 21:30:41,172 [pool-35-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: start FollowerState
2020-06-02 21:30:41,174 [pool-35-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-371025157A39,id=7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:30:41,175 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39
2020-06-02 21:30:41,190 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS ONE #id: "2082e97e-3c59-46f0-a902-371025157a39"
.
2020-06-02 21:30:41,190 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: addNew group-D9D1F22491BD:[a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853] returns group-D9D1F22491BD:java.util.concurrent.CompletableFuture@4e453950[Not completed]
2020-06-02 21:30:41,191 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: new RaftServerImpl for group-D9D1F22491BD:[a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853] with ContainerStateMachine:uninitialized
2020-06-02 21:30:41,191 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 21:30:41,192 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 21:30:41,192 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 21:30:41,192 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 21:30:41,192 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:30:41,192 [pool-35-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD: ConfigurationManager, init=-1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null, confs=<EMPTY_MAP>
2020-06-02 21:30:41,192 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis] (custom)
2020-06-02 21:30:41,192 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 21:30:41,192 [pool-35-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd does not exist. Creating ...
2020-06-02 21:30:41,193 [pool-35-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd/in_use.lock acquired by nodename 4536@32d60ebb3871
2020-06-02 21:30:41,194 [pool-35-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd has been successfully formatted.
2020-06-02 21:30:41,195 [pool-35-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-D9D1F22491BD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 21:30:41,195 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 21:30:41,195 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 21:30:41,195 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 21:30:41,195 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:30:41,195 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:30:41,195 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 21:30:41,195 [pool-35-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd
2020-06-02 21:30:41,195 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 21:30:41,196 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 21:30:41,196 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:30:41,196 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 21:30:41,196 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 21:30:41,196 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 21:30:41,196 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 21:30:41,196 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 21:30:41,196 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 21:30:41,196 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 21:30:41,196 [pool-35-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 21:30:41,197 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 21:30:41,197 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 21:30:41,197 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 21:30:41,197 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 21:30:41,197 [pool-35-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 21:30:41,197 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD
2020-06-02 21:30:41,198 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD
2020-06-02 21:30:41,199 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD: start as a follower, conf=-1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null
2020-06-02 21:30:41,199 [pool-35-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 21:30:41,199 [pool-35-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: start FollowerState
2020-06-02 21:30:41,200 [pool-35-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D9D1F22491BD,id=7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:30:41,200 [pool-35-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD
2020-06-02 21:30:41,235 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - a6b41249-b273-4291-afb4-d06d350d4050: addNew group-726DCB5B934A:[a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235] returns group-726DCB5B934A:java.util.concurrent.CompletableFuture@357c20a4[Not completed]
2020-06-02 21:30:41,251 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - a6b41249-b273-4291-afb4-d06d350d4050: new RaftServerImpl for group-726DCB5B934A:[a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235] with ContainerStateMachine:uninitialized
2020-06-02 21:30:41,251 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 21:30:41,252 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 21:30:41,252 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 21:30:41,252 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 21:30:41,252 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:30:41,252 [pool-51-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A: ConfigurationManager, init=-1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235], old=null, confs=<EMPTY_MAP>
2020-06-02 21:30:41,252 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis] (custom)
2020-06-02 21:30:41,252 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 21:30:41,252 [pool-51-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis/b4a2f779-cada-4ca2-a5b1-726dcb5b934a does not exist. Creating ...
2020-06-02 21:30:41,263 [pool-51-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis/b4a2f779-cada-4ca2-a5b1-726dcb5b934a/in_use.lock acquired by nodename 4536@32d60ebb3871
2020-06-02 21:30:41,265 [pool-51-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis/b4a2f779-cada-4ca2-a5b1-726dcb5b934a has been successfully formatted.
2020-06-02 21:30:41,266 [pool-51-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-726DCB5B934A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 21:30:41,266 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(378)) - Unable to start the DatanodeState Machine
java.io.IOException: Unable to finish the execution.
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:375)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:212)
	... 2 more
2020-06-02 21:30:41,266 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 21:30:41,267 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 21:30:41,267 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 21:30:41,267 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:30:41,267 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:30:41,267 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.a6b41249-b273-4291-afb4-d06d350d4050
2020-06-02 21:30:41,268 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 21:30:41,268 [pool-51-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis/b4a2f779-cada-4ca2-a5b1-726dcb5b934a
2020-06-02 21:30:41,272 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 21:30:41,272 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 21:30:41,272 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:30:41,272 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 21:30:41,272 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 21:30:41,273 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 21:30:41,273 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 21:30:41,273 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 21:30:41,273 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 21:30:41,276 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 21:30:41,276 [pool-51-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 21:30:41,280 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 21:30:41,280 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 21:30:41,281 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 21:30:41,281 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 21:30:41,281 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 21:30:41,281 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A
2020-06-02 21:30:41,281 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A
2020-06-02 21:30:41,282 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A: start as a follower, conf=-1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235], old=null
2020-06-02 21:30:41,282 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 21:30:41,283 [pool-51-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a6b41249-b273-4291-afb4-d06d350d4050: start FollowerState
2020-06-02 21:30:41,292 [pool-51-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-726DCB5B934A,id=a6b41249-b273-4291-afb4-d06d350d4050
2020-06-02 21:30:41,293 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A
2020-06-02 21:30:41,296 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS ONE #id: "b4a2f779-cada-4ca2-a5b1-726dcb5b934a"
.
2020-06-02 21:30:41,297 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - a6b41249-b273-4291-afb4-d06d350d4050: addNew group-D9D1F22491BD:[a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853] returns group-D9D1F22491BD:java.util.concurrent.CompletableFuture@3143a2d3[Not completed]
2020-06-02 21:30:41,300 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - a6b41249-b273-4291-afb4-d06d350d4050: new RaftServerImpl for group-D9D1F22491BD:[a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853] with ContainerStateMachine:uninitialized
2020-06-02 21:30:41,300 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 21:30:41,300 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 21:30:41,300 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 21:30:41,300 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 21:30:41,300 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:30:41,300 [pool-51-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD: ConfigurationManager, init=-1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null, confs=<EMPTY_MAP>
2020-06-02 21:30:41,300 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis] (custom)
2020-06-02 21:30:41,301 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 21:30:41,301 [pool-51-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd does not exist. Creating ...
2020-06-02 21:30:41,303 [pool-51-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd/in_use.lock acquired by nodename 4536@32d60ebb3871
2020-06-02 21:30:41,304 [pool-51-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd has been successfully formatted.
2020-06-02 21:30:41,305 [pool-51-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-D9D1F22491BD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 21:30:41,305 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 21:30:41,305 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 21:30:41,305 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 21:30:41,305 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:30:41,305 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:30:41,305 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 21:30:41,305 [pool-51-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd
2020-06-02 21:30:41,305 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 21:30:41,305 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 21:30:41,305 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:30:41,306 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 21:30:41,306 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 21:30:41,306 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 21:30:41,306 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 21:30:41,306 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 21:30:41,306 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 21:30:41,307 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 21:30:41,307 [pool-51-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 21:30:41,313 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:41,313 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:41,314 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 21:30:41,314 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 21:30:41,314 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 21:30:41,314 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 21:30:41,314 [pool-51-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 21:30:41,314 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD
2020-06-02 21:30:41,317 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD
2020-06-02 21:30:41,317 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD: start as a follower, conf=-1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null
2020-06-02 21:30:41,318 [pool-51-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 21:30:41,318 [pool-51-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a6b41249-b273-4291-afb4-d06d350d4050: start FollowerState
2020-06-02 21:30:41,328 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: addNew group-633CCBAC6965:[762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853] returns group-633CCBAC6965:java.util.concurrent.CompletableFuture@3458c758[Not completed]
2020-06-02 21:30:41,328 [pool-51-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D9D1F22491BD,id=a6b41249-b273-4291-afb4-d06d350d4050
2020-06-02 21:30:41,329 [pool-51-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD
2020-06-02 21:30:41,344 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: new RaftServerImpl for group-633CCBAC6965:[762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853] with ContainerStateMachine:uninitialized
2020-06-02 21:30:41,348 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 21:30:41,348 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 21:30:41,348 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 21:30:41,348 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 21:30:41,348 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:30:41,348 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965: ConfigurationManager, init=-1: [762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null, confs=<EMPTY_MAP>
2020-06-02 21:30:41,348 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis] (custom)
2020-06-02 21:30:41,349 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 21:30:41,349 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis/a484410b-1fcc-41d6-954e-633ccbac6965 does not exist. Creating ...
2020-06-02 21:30:41,350 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis/a484410b-1fcc-41d6-954e-633ccbac6965/in_use.lock acquired by nodename 4536@32d60ebb3871
2020-06-02 21:30:41,352 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis/a484410b-1fcc-41d6-954e-633ccbac6965 has been successfully formatted.
2020-06-02 21:30:41,352 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(378)) - Unable to start the DatanodeState Machine
java.io.IOException: Unable to finish the execution.
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:375)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:212)
	... 2 more
2020-06-02 21:30:41,353 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-633CCBAC6965: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 21:30:41,353 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 21:30:41,353 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 21:30:41,353 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 21:30:41,353 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:30:41,353 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:30:41,353 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.762fe7a3-380a-4155-b73e-ca6d55ceee4d
2020-06-02 21:30:41,356 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 21:30:41,356 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis/a484410b-1fcc-41d6-954e-633ccbac6965
2020-06-02 21:30:41,356 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 21:30:41,356 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 21:30:41,356 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:30:41,356 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 21:30:41,356 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 21:30:41,356 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 21:30:41,356 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 21:30:41,357 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 21:30:41,357 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 21:30:41,360 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 21:30:41,360 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 21:30:41,361 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 21:30:41,361 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 21:30:41,361 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 21:30:41,361 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 21:30:41,361 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 21:30:41,362 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965
2020-06-02 21:30:41,362 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965
2020-06-02 21:30:41,363 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965: start as a follower, conf=-1: [762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null
2020-06-02 21:30:41,364 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 21:30:41,364 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: start FollowerState
2020-06-02 21:30:41,365 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-633CCBAC6965,id=762fe7a3-380a-4155-b73e-ca6d55ceee4d
2020-06-02 21:30:41,365 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965
2020-06-02 21:30:41,366 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS ONE #id: "a484410b-1fcc-41d6-954e-633ccbac6965"
.
2020-06-02 21:30:41,366 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: addNew group-D9D1F22491BD:[a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853] returns group-D9D1F22491BD:java.util.concurrent.CompletableFuture@3067550b[Not completed]
2020-06-02 21:30:41,368 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: new RaftServerImpl for group-D9D1F22491BD:[a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853] with ContainerStateMachine:uninitialized
2020-06-02 21:30:41,369 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 21:30:41,369 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 21:30:41,369 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 21:30:41,369 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 21:30:41,369 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:30:41,369 [pool-67-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD: ConfigurationManager, init=-1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null, confs=<EMPTY_MAP>
2020-06-02 21:30:41,369 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis] (custom)
2020-06-02 21:30:41,369 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 21:30:41,369 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd does not exist. Creating ...
2020-06-02 21:30:41,371 [pool-67-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd/in_use.lock acquired by nodename 4536@32d60ebb3871
2020-06-02 21:30:41,373 [pool-67-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd has been successfully formatted.
2020-06-02 21:30:41,373 [pool-67-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-D9D1F22491BD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 21:30:41,373 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 21:30:41,373 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 21:30:41,373 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 21:30:41,374 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:30:41,374 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:30:41,374 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 21:30:41,374 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd
2020-06-02 21:30:41,374 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 21:30:41,375 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 21:30:41,375 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:30:41,375 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 21:30:41,375 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 21:30:41,375 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 21:30:41,375 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 21:30:41,375 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 21:30:41,375 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 21:30:41,377 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 21:30:41,379 [pool-67-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 21:30:41,379 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 21:30:41,379 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 21:30:41,380 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 21:30:41,380 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 21:30:41,380 [pool-67-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 21:30:41,380 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD
2020-06-02 21:30:41,384 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD
2020-06-02 21:30:41,388 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD: start as a follower, conf=-1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null
2020-06-02 21:30:41,388 [pool-67-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 21:30:41,388 [pool-67-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: start FollowerState
2020-06-02 21:30:41,388 [pool-67-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D9D1F22491BD,id=762fe7a3-380a-4155-b73e-ca6d55ceee4d
2020-06-02 21:30:41,388 [pool-67-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD
2020-06-02 21:30:41,755 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS THREE #id: "f211dd9d-3530-48da-b025-d9d1f22491bd"
.
2020-06-02 21:30:41,761 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS THREE #id: "f211dd9d-3530-48da-b025-d9d1f22491bd"
.
2020-06-02 21:30:41,765 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS THREE #id: "f211dd9d-3530-48da-b025-d9d1f22491bd"
.
2020-06-02 21:30:42,314 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:42,314 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:43,314 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:43,314 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:44,314 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:44,315 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:45,315 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:45,315 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:46,266 [Thread-177] INFO  impl.FollowerState (FollowerState.java:run(108)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-FollowerState: change to CANDIDATE, lastRpcTime:5094ms, electionTimeout:5090ms
2020-06-02 21:30:46,273 [Thread-177] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: shutdown FollowerState
2020-06-02 21:30:46,280 [Thread-177] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 21:30:46,282 [Thread-177] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: start LeaderElection
2020-06-02 21:30:46,324 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:46,324 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:46,325 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1: begin an election at term 1 for -1: [7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277], old=null
2020-06-02 21:30:46,327 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: shutdown LeaderElection
2020-06-02 21:30:46,327 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 21:30:46,328 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-371025157A39 with new leaderId: 7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:30:46,328 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39: change Leader from null to 7bbd2402-c364-4868-9d2c-73c7d416b8c0 at term 1 for becomeLeader, leader elected after 5246ms
2020-06-02 21:30:46,331 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 21:30:46,332 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 21:30:46,334 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39
2020-06-02 21:30:46,343 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 21:30:46,343 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 21:30:46,367 [Thread-181] INFO  impl.FollowerState (FollowerState.java:run(108)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-FollowerState: change to CANDIDATE, lastRpcTime:5084ms, electionTimeout:5070ms
2020-06-02 21:30:46,373 [Thread-181] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a6b41249-b273-4291-afb4-d06d350d4050: shutdown FollowerState
2020-06-02 21:30:46,373 [Thread-181] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 21:30:46,373 [Thread-181] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a6b41249-b273-4291-afb4-d06d350d4050: start LeaderElection
2020-06-02 21:30:46,388 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 21:30:46,389 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 21:30:46,389 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 21:30:46,393 [Thread-179] INFO  impl.FollowerState (FollowerState.java:run(108)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-FollowerState: change to CANDIDATE, lastRpcTime:5193ms, electionTimeout:5192ms
2020-06-02 21:30:46,393 [Thread-179] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: shutdown FollowerState
2020-06-02 21:30:46,393 [Thread-179] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 21:30:46,393 [Thread-179] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: start LeaderElection
2020-06-02 21:30:46,425 [Thread-185] INFO  impl.FollowerState (FollowerState.java:run(108)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-FollowerState: change to CANDIDATE, lastRpcTime:5060ms, electionTimeout:5056ms
2020-06-02 21:30:46,425 [Thread-185] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: shutdown FollowerState
2020-06-02 21:30:46,426 [Thread-185] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 21:30:46,426 [Thread-185] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: start LeaderElection
2020-06-02 21:30:46,428 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: start LeaderState
2020-06-02 21:30:46,439 [Thread-183] INFO  impl.FollowerState (FollowerState.java:run(108)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-FollowerState: change to CANDIDATE, lastRpcTime:5121ms, electionTimeout:5111ms
2020-06-02 21:30:46,441 [Thread-183] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a6b41249-b273-4291-afb4-d06d350d4050: shutdown FollowerState
2020-06-02 21:30:46,441 [Thread-183] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 21:30:46,441 [Thread-183] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a6b41249-b273-4291-afb4-d06d350d4050: start LeaderElection
2020-06-02 21:30:46,457 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2: begin an election at term 1 for -1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235], old=null
2020-06-02 21:30:46,481 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - a6b41249-b273-4291-afb4-d06d350d4050: shutdown LeaderElection
2020-06-02 21:30:46,481 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 21:30:46,481 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-726DCB5B934A with new leaderId: a6b41249-b273-4291-afb4-d06d350d4050
2020-06-02 21:30:46,481 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A: change Leader from null to a6b41249-b273-4291-afb4-d06d350d4050 at term 1 for becomeLeader, leader elected after 5214ms
2020-06-02 21:30:46,481 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 21:30:46,481 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 21:30:46,481 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A
2020-06-02 21:30:46,482 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 21:30:46,482 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 21:30:46,482 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 21:30:46,482 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 21:30:46,482 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 21:30:46,482 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a6b41249-b273-4291-afb4-d06d350d4050: start LeaderState
2020-06-02 21:30:46,458 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection3: begin an election at term 1 for -1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null
2020-06-02 21:30:46,485 [Thread-187] INFO  impl.FollowerState (FollowerState.java:run(108)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-FollowerState: change to CANDIDATE, lastRpcTime:5097ms, electionTimeout:5093ms
2020-06-02 21:30:46,485 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: shutdown FollowerState
2020-06-02 21:30:46,485 [Thread-187] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 21:30:46,485 [Thread-187] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: start LeaderElection
2020-06-02 21:30:46,501 [a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-LeaderElection5: begin an election at term 1 for -1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null
2020-06-02 21:30:46,502 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4: begin an election at term 1 for -1: [762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null
2020-06-02 21:30:46,502 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: shutdown LeaderElection
2020-06-02 21:30:46,502 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 21:30:46,502 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-633CCBAC6965 with new leaderId: 762fe7a3-380a-4155-b73e-ca6d55ceee4d
2020-06-02 21:30:46,502 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 21:30:46,503 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 21:30:46,519 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965: change Leader from null to 762fe7a3-380a-4155-b73e-ca6d55ceee4d at term 1 for becomeLeader, leader elected after 5148ms
2020-06-02 21:30:46,520 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 21:30:46,520 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 21:30:46,520 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965
2020-06-02 21:30:46,520 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 21:30:46,520 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 21:30:46,521 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 21:30:46,521 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 21:30:46,521 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 21:30:46,521 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: start LeaderState
2020-06-02 21:30:46,521 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 21:30:46,541 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965: set configuration 0: [762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null at 0
2020-06-02 21:30:46,564 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39: set configuration 0: [7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277], old=null at 0
2020-06-02 21:30:46,566 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A: set configuration 0: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235], old=null at 0
2020-06-02 21:30:46,580 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-LeaderElection6: begin an election at term 1 for -1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null
2020-06-02 21:30:46,805 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis/2082e97e-3c59-46f0-a902-371025157a39/current/log_inprogress_0
2020-06-02 21:30:46,805 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis/a484410b-1fcc-41d6-954e-633ccbac6965/current/log_inprogress_0
2020-06-02 21:30:46,810 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis/b4a2f779-cada-4ca2-a5b1-726dcb5b934a/current/log_inprogress_0
2020-06-02 21:30:46,862 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection3: Election REJECTED; received 2 response(s) [7bbd2402-c364-4868-9d2c-73c7d416b8c0<-a6b41249-b273-4291-afb4-d06d350d4050#0:FAIL-t1, 7bbd2402-c364-4868-9d2c-73c7d416b8c0<-762fe7a3-380a-4155-b73e-ca6d55ceee4d#0:FAIL-t1] and 0 exception(s); 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD:t1, leader=null, voted=7bbd2402-c364-4868-9d2c-73c7d416b8c0, raftlog=7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null
2020-06-02 21:30:46,863 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2020-06-02 21:30:46,866 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: shutdown LeaderElection
2020-06-02 21:30:46,866 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: start FollowerState
2020-06-02 21:30:46,867 [a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-LeaderElection5: Election REJECTED; received 2 response(s) [a6b41249-b273-4291-afb4-d06d350d4050<-7bbd2402-c364-4868-9d2c-73c7d416b8c0#0:FAIL-t1, a6b41249-b273-4291-afb4-d06d350d4050<-762fe7a3-380a-4155-b73e-ca6d55ceee4d#0:FAIL-t1] and 0 exception(s); a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD:t1, leader=null, voted=a6b41249-b273-4291-afb4-d06d350d4050, raftlog=a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null
2020-06-02 21:30:46,890 [a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2020-06-02 21:30:46,890 [a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - a6b41249-b273-4291-afb4-d06d350d4050: shutdown LeaderElection
2020-06-02 21:30:46,890 [a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a6b41249-b273-4291-afb4-d06d350d4050: start FollowerState
2020-06-02 21:30:46,908 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-LeaderElection6: Election REJECTED; received 2 response(s) [762fe7a3-380a-4155-b73e-ca6d55ceee4d<-a6b41249-b273-4291-afb4-d06d350d4050#0:FAIL-t1, 762fe7a3-380a-4155-b73e-ca6d55ceee4d<-7bbd2402-c364-4868-9d2c-73c7d416b8c0#0:FAIL-t1] and 0 exception(s); 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD:t1, leader=null, voted=762fe7a3-380a-4155-b73e-ca6d55ceee4d, raftlog=762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null
2020-06-02 21:30:46,917 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2020-06-02 21:30:46,917 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: shutdown LeaderElection
2020-06-02 21:30:46,917 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: start FollowerState
2020-06-02 21:30:47,324 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:47,330 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:48,330 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:48,331 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:49,331 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:49,331 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:50,331 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:50,331 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:51,333 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:51,333 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:52,000 [Thread-209] INFO  impl.FollowerState (FollowerState.java:run(108)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-FollowerState: change to CANDIDATE, lastRpcTime:5134ms, electionTimeout:5104ms
2020-06-02 21:30:52,001 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: shutdown FollowerState
2020-06-02 21:30:52,001 [Thread-209] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2020-06-02 21:30:52,001 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: start LeaderElection
2020-06-02 21:30:52,025 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7: begin an election at term 2 for -1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null
2020-06-02 21:30:52,037 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:30:52,038 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a6b41249-b273-4291-afb4-d06d350d4050: shutdown FollowerState
2020-06-02 21:30:52,038 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - a6b41249-b273-4291-afb4-d06d350d4050: start FollowerState
2020-06-02 21:30:52,038 [Thread-210] INFO  impl.FollowerState (FollowerState.java:run(117)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-06-02 21:30:52,046 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7: Election PASSED; received 1 response(s) [7bbd2402-c364-4868-9d2c-73c7d416b8c0<-a6b41249-b273-4291-afb4-d06d350d4050#0:OK-t2] and 0 exception(s); 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD:t2, leader=null, voted=7bbd2402-c364-4868-9d2c-73c7d416b8c0, raftlog=7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null
2020-06-02 21:30:52,047 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: shutdown LeaderElection
2020-06-02 21:30:52,047 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2020-06-02 21:30:52,047 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-D9D1F22491BD with new leaderId: 7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:30:52,047 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD: change Leader from null to 7bbd2402-c364-4868-9d2c-73c7d416b8c0 at term 2 for becomeLeader, leader elected after 10851ms
2020-06-02 21:30:52,047 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 21:30:52,047 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 21:30:52,047 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD
2020-06-02 21:30:52,047 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 21:30:52,047 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 21:30:52,048 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 21:30:52,048 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 21:30:52,052 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 21:30:52,054 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-06-02 21:30:52,058 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:30:52,059 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: shutdown FollowerState
2020-06-02 21:30:52,059 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: start FollowerState
2020-06-02 21:30:52,059 [Thread-211] INFO  impl.FollowerState (FollowerState.java:run(117)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-06-02 21:30:52,068 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:30:52,069 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2020-06-02 21:30:52,074 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2020-06-02 21:30:52,075 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 21:30:52,075 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:30:52,080 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-06-02 21:30:52,084 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:30:52,084 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2020-06-02 21:30:52,084 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2020-06-02 21:30:52,084 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 21:30:52,085 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:30:52,086 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: start LeaderState
2020-06-02 21:30:52,092 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 21:30:52,093 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd/current/log_inprogress_0
2020-06-02 21:30:52,111 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD: set configuration 0: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null at 0
2020-06-02 21:30:52,147 [grpc-default-executor-2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-D9D1F22491BD with new leaderId: 7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:30:52,149 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD: change Leader from null to 7bbd2402-c364-4868-9d2c-73c7d416b8c0 at term 2 for appendEntries, leader elected after 10773ms
2020-06-02 21:30:52,152 [grpc-default-executor-3] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-D9D1F22491BD with new leaderId: 7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:30:52,152 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD: change Leader from null to 7bbd2402-c364-4868-9d2c-73c7d416b8c0 at term 2 for appendEntries, leader elected after 10847ms
2020-06-02 21:30:52,204 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD: set configuration 0: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null at 0
2020-06-02 21:30:52,205 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD: set configuration 0: [a6b41249-b273-4291-afb4-d06d350d4050:172.17.0.2:43235, 7bbd2402-c364-4868-9d2c-73c7d416b8c0:172.17.0.2:44277, 762fe7a3-380a-4155-b73e-ca6d55ceee4d:172.17.0.2:35853], old=null at 0
2020-06-02 21:30:52,205 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 21:30:52,205 [grpc-default-executor-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 21:30:52,207 [a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd/current/log_inprogress_0
2020-06-02 21:30:52,208 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd/current/log_inprogress_0
2020-06-02 21:30:52,333 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:52,333 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:53,333 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:53,333 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:54,334 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:54,334 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:55,334 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:55,334 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:56,334 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:56,335 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:57,335 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:57,335 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:58,335 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:58,335 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:30:59,335 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:30:59,336 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:00,336 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:00,336 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:01,336 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:01,336 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:02,336 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:02,337 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:03,337 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:03,337 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:04,337 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:04,337 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:05,338 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:05,338 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:06,338 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:06,338 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:07,338 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:07,338 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:08,339 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:08,339 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:09,339 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:09,339 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:10,339 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:10,340 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:11,340 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:11,340 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:12,340 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:12,340 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:13,341 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:13,341 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:14,341 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:14,341 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:15,341 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:15,341 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:16,342 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:16,342 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:17,342 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:17,342 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:18,342 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:18,342 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:19,343 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:19,343 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:20,343 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:20,343 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:21,343 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:21,344 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:22,344 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:22,344 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:23,344 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:23,344 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:24,344 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:24,345 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:25,345 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:25,345 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:26,345 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:26,345 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:27,346 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:27,346 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:28,346 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:28,346 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:29,346 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:29,346 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:29,955 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(387)) - Shutting down the Mini Ozone Cluster
2020-06-02 21:31:29,956 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(402)) - Stopping the Mini Ozone Cluster
2020-06-02 21:31:29,956 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(484)) - Stopping the OzoneManager
2020-06-02 21:31:29,956 [Listener at 127.0.0.1/35123] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35123
2020-06-02 21:31:29,961 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-06-02 21:31:29,961 [Listener at 127.0.0.1/35123] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(410)) - Stopping OMDoubleBuffer flush thread
2020-06-02 21:31:29,964 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(342)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2020-06-02 21:31:29,962 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-06-02 21:31:29,964 [Listener at 127.0.0.1/35123] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service KeyDeletingService
2020-06-02 21:31:29,968 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@308a598f{ozoneManager,/,null,UNAVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2020-06-02 21:31:29,996 [Listener at 127.0.0.1/35123] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@5cee7e48{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-06-02 21:31:29,996 [Listener at 127.0.0.1/35123] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-06-02 21:31:29,997 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@63475b16{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2020-06-02 21:31:30,015 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@73b0684c{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-06-02 21:31:30,056 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(461)) - Stopping the HddsDatanodes
====> TEST TIMED OUT. PRINTING THREAD DUMP. <====

Timestamp: 2020-06-02 09:31:29,974

"Datanode State Machine Thread - 0" daemon prio=5 tid=181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-35-thread-1"  prio=5 tid=252 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode State Machine Thread - 0" daemon prio=5 tid=224 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1344012241-188" daemon prio=5 tid=188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp1698308954-103" daemon prio=5 tid=103 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp324914188-145" daemon prio=5 tid=145 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-2-0" daemon prio=5 tid=241 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1698308954-97-acceptor-0@732ba490-ServerConnector@3dcdd0e0{HTTP/1.1,[http/1.1]}{0.0.0.0:41767}" daemon prio=3 tid=97 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server listener on 0" daemon prio=5 tid=21 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"IPC Server listener on 0" daemon prio=5 tid=25 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"ChunkWriter-1-0" daemon prio=5 tid=227 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Command processor thread" daemon prio=5 tid=222 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$171/825626209.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"Thread-216" daemon prio=5 tid=308 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"qtp200163889-161" daemon prio=5 tid=161 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"BlockDeletingService#1" daemon prio=5 tid=232 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-StateMachineUpdater" daemon prio=5 tid=264 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 6 on default port 38639" daemon prio=5 tid=62 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 1 on default port 41783" daemon prio=5 tid=77 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp2032299360-214" daemon prio=5 tid=214 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=201 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 17 on default port 41783" daemon prio=5 tid=93 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 4 on default port 41783" daemon prio=5 tid=80 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-SegmentedRaftLogWorker"  prio=5 tid=267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"grpc-default-executor-0" daemon prio=5 tid=276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp200163889-160-acceptor-0@5f8dffb-ServerConnector@3fe1306f{HTTP/1.1,[http/1.1]}{0.0.0.0:38005}" daemon prio=3 tid=160 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"qtp1344012241-189" daemon prio=5 tid=189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"SCMBlockDeletingService#1" daemon prio=5 tid=109 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp324914188-149" daemon prio=5 tid=149 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"pool-8-thread-1"  prio=5 tid=29 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 18 on default port 41783" daemon prio=5 tid=94 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server idle connection scanner for port 41783" daemon prio=5 tid=19 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1344012241-183" daemon prio=5 tid=183 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/1189801389.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 10 on default port 40443" daemon prio=5 tid=46 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 11 on default port 41783" daemon prio=5 tid=87 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 5 on default port 41783" daemon prio=5 tid=81 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Datanode State Machine Thread - 0" daemon prio=5 tid=204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Thread-217" daemon prio=5 tid=309 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:243)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:97)
"qtp1344012241-185" daemon prio=5 tid=185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"grpc-nio-worker-ELG-3-1" daemon prio=5 tid=274 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:807)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
"qtp200163889-166" daemon prio=5 tid=166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"grpc-nio-boss-ELG-1-1" daemon prio=5 tid=230 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
"qtp324914188-142" daemon prio=5 tid=142 terminated
java.lang.Thread.State: TERMINATED
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/1189801389.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"pool-10-thread-1"  prio=5 tid=105 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 15 on default port 41783" daemon prio=5 tid=91 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server Responder" daemon prio=5 tid=28 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"qtp1698308954-101" daemon prio=5 tid=101 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"DataNode DiskChecker thread 0" daemon prio=5 tid=172 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@489f41d0" daemon prio=5 tid=223 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=219 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 4 on default port 40443" daemon prio=5 tid=40 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$456/429341673@422795da" daemon prio=5 tid=311 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:151)
        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:105)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:77)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$456/429341673.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"Thread-205" daemon prio=5 tid=295 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"Thread-215" daemon prio=5 tid=307 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:243)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:97)
"Periodic HDDS volume checker" daemon prio=5 tid=195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 18 on default port 38639" daemon prio=5 tid=74 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=221 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 3 on default port 40443" daemon prio=5 tid=39 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"grpc-default-executor-1" daemon prio=5 tid=275 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp2032299360-208-acceptor-0@7c9654f5-ServerConnector@2e504073{HTTP/1.1,[http/1.1]}{0.0.0.0:36711}" daemon prio=3 tid=208 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-3-0" daemon prio=5 tid=229 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 7 on default port 40443" daemon prio=5 tid=43 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 12 on default port 41783" daemon prio=5 tid=88 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 2 on default port 38639" daemon prio=5 tid=58 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp1698308954-100" daemon prio=5 tid=100 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp1698308954-96" daemon prio=5 tid=96 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/1189801389.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 1 on default port 40443" daemon prio=5 tid=37 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Socket Reader #1 for port 0"  prio=5 tid=22 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"pool-71-thread-1"  prio=5 tid=206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"process reaper" daemon prio=10 tid=11 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 3 on default port 41783" daemon prio=5 tid=79 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Session-HouseKeeper-7c419b82-1"  prio=5 tid=191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp2032299360-212" daemon prio=5 tid=212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"pool-51-thread-1"  prio=5 tid=259 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1698308954-98" daemon prio=5 tid=98 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-SegmentedRaftLogWorker"  prio=5 tid=260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"pool-56-thread-1"  prio=5 tid=192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp324914188-148" daemon prio=5 tid=148 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-ContainerReportForContainerReportHandler" daemon prio=5 tid=246 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp2032299360-211" daemon prio=5 tid=211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 19 on default port 38639" daemon prio=5 tid=75 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-40-thread-1"  prio=5 tid=168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 8 on default port 40443" daemon prio=5 tid=44 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 9 on default port 38639" daemon prio=5 tid=65 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 8 on default port 38639" daemon prio=5 tid=64 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Socket Reader #1 for port 0"  prio=5 tid=26 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"Thread-200" daemon prio=5 tid=291 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"pool-67-thread-1"  prio=5 tid=266 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 17 on default port 40443" daemon prio=5 tid=53 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 15 on default port 38639" daemon prio=5 tid=71 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"BlockDeletingService#1" daemon prio=5 tid=238 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 2 on default port 40443" daemon prio=5 tid=38 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-28-thread-1" daemon prio=5 tid=156 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 14 on default port 38639" daemon prio=5 tid=70 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"pool-72-thread-1"  prio=5 tid=216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Listener at 127.0.0.1/35123"  prio=5 tid=12 runnable
java.lang.Thread.State: RUNNABLE
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
        at org.eclipse.jetty.io.ManagedSelector.doStop(ManagedSelector.java:150)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:93)
        at org.eclipse.jetty.util.component.ContainerLifeCycle.stop(ContainerLifeCycle.java:180)
        at org.eclipse.jetty.util.component.ContainerLifeCycle.doStop(ContainerLifeCycle.java:201)
        at org.eclipse.jetty.io.SelectorManager.doStop(SelectorManager.java:281)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:93)
        at org.eclipse.jetty.util.component.ContainerLifeCycle.stop(ContainerLifeCycle.java:180)
        at org.eclipse.jetty.util.component.ContainerLifeCycle.doStop(ContainerLifeCycle.java:201)
        at org.eclipse.jetty.server.AbstractConnector.doStop(AbstractConnector.java:373)
        at org.eclipse.jetty.server.AbstractNetworkConnector.doStop(AbstractNetworkConnector.java:88)
        at org.eclipse.jetty.server.ServerConnector.doStop(ServerConnector.java:243)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:93)
        at org.eclipse.jetty.server.Server.doStop(Server.java:443)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:93)
        at org.apache.hadoop.hdds.server.http.HttpServer2.stop(HttpServer2.java:1338)
        at org.apache.hadoop.hdds.server.http.BaseHttpServer.stop(BaseHttpServer.java:310)
        at org.apache.hadoop.ozone.om.OzoneManager.stop(OzoneManager.java:1290)
        at org.apache.hadoop.ozone.MiniOzoneClusterImpl.stopOM(MiniOzoneClusterImpl.java:485)
        at org.apache.hadoop.ozone.MiniOzoneClusterImpl.stop(MiniOzoneClusterImpl.java:403)
        at org.apache.hadoop.ozone.MiniOzoneClusterImpl.shutdown(MiniOzoneClusterImpl.java:391)
        at org.apache.hadoop.ozone.om.TestOMDbCheckpointServlet.shutdown(TestOMDbCheckpointServlet.java:107)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
        at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
"a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-StateMachineUpdater" daemon prio=5 tid=261 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-3f830e6d-1"  prio=5 tid=167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=15 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 10 on default port 38639" daemon prio=5 tid=66 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 7 on default port 38639" daemon prio=5 tid=63 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 9 on default port 40443" daemon prio=5 tid=45 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Parameter Sending Thread #0" daemon prio=5 tid=111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp324914188-144" daemon prio=5 tid=144 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"DataNode DiskChecker thread 0" daemon prio=5 tid=196 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"BlockDeletingService#1" daemon prio=5 tid=244 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@78b132d5" daemon prio=5 tid=108 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"Thread-195" daemon prio=5 tid=286 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"Periodic HDDS volume checker" daemon prio=5 tid=171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=245 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-1333e3d-1"  prio=5 tid=215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp200163889-159" daemon prio=5 tid=159 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/1189801389.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-StateMachineUpdater" daemon prio=5 tid=271 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"Timer for 'StorageContainerManager' metrics system" daemon prio=5 tid=34 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 9 on default port 41783" daemon prio=5 tid=85 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"EventQueue-Delayed safe mode statusForReplicationManager"  prio=5 tid=33 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp200163889-163" daemon prio=5 tid=163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 7 on default port 41783" daemon prio=5 tid=83 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=175 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 10 on default port 41783" daemon prio=5 tid=86 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 12 on default port 40443" daemon prio=5 tid=48 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-0-0" daemon prio=5 tid=239 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-60-thread-1" daemon prio=5 tid=197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server idle connection scanner for port 38639" daemon prio=5 tid=23 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ChunkWriter-0-0" daemon prio=5 tid=226 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp2032299360-207" daemon prio=5 tid=207 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/1189801389.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=174 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=176 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=220 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 18 on default port 40443" daemon prio=5 tid=54 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 0 on default port 41783" daemon prio=5 tid=76 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-2-0" daemon prio=5 tid=235 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 16 on default port 40443" daemon prio=5 tid=52 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 0 on default port 38639" daemon prio=5 tid=56 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server listener on 0" daemon prio=5 tid=17 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=177 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp324914188-147" daemon prio=5 tid=147 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=199 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 4 on default port 38639" daemon prio=5 tid=60 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 6 on default port 41783" daemon prio=5 tid=82 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"grpc-nio-worker-ELG-3-2" daemon prio=5 tid=273 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:807)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 16 on default port 38639" daemon prio=5 tid=72 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 6 on default port 40443" daemon prio=5 tid=42 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp2032299360-209" daemon prio=5 tid=209 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 16 on default port 41783" daemon prio=5 tid=92 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"EventQueue-Safe mode statusForSCMClientProtocolServer"  prio=5 tid=31 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp324914188-146" daemon prio=5 tid=146 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-StateMachineUpdater" daemon prio=5 tid=254 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 14 on default port 40443" daemon prio=5 tid=50 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 11 on default port 38639" daemon prio=5 tid=67 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-55-thread-1"  prio=5 tid=182 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-1-0" daemon prio=5 tid=240 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-3f35a601-1"  prio=5 tid=104 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Socket Reader #1 for port 0"  prio=5 tid=18 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"BlockDeletingService#0" daemon prio=5 tid=231 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp2032299360-213" daemon prio=5 tid=213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server Responder" daemon prio=5 tid=20 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-SegmentedRaftLogWorker"  prio=5 tid=253 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=200 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"CommandWatcher-LeaseManager#LeaseMonitor" daemon prio=5 tid=35 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:234)
        at java.lang.Thread.run(Thread.java:748)
"qtp324914188-143" daemon prio=5 tid=143 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-Delayed safe mode statusForSCMPipelineManager"  prio=5 tid=32 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"RatisPipelineUtilsThread"  prio=5 tid=16 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@575fbced" daemon prio=5 tid=203 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"pool-44-thread-1" daemon prio=5 tid=173 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-StateMachineUpdater" daemon prio=5 tid=257 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"main"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1610)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:93)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:79)
        at org.apache.hadoop.test.TimedOutTestsListener.testFailure(TimedOutTestsListener.java:67)
        at org.junit.runner.notification.RunNotifier$4.notifyListener(RunNotifier.java:139)
        at org.junit.runner.notification.RunNotifier$SafeNotifier.run(RunNotifier.java:61)
        at org.junit.runner.notification.RunNotifier.fireTestFailures(RunNotifier.java:134)
        at org.junit.runner.notification.RunNotifier.fireTestFailure(RunNotifier.java:128)
        at org.apache.maven.surefire.common.junit4.Notifier.fireTestFailure(Notifier.java:114)
        at org.junit.internal.runners.model.EachTestNotifier.addFailure(EachTestNotifier.java:23)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:275)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
"qtp1698308954-99" daemon prio=5 tid=99 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-3fa097c1-1"  prio=5 tid=150 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 15 on default port 40443" daemon prio=5 tid=51 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 13 on default port 41783" daemon prio=5 tid=89 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-3-0" daemon prio=5 tid=236 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 11 on default port 40443" daemon prio=5 tid=47 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-39-thread-1"  prio=5 tid=158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Periodic HDDS volume checker" daemon prio=5 tid=154 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp200163889-164" daemon prio=5 tid=164 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"grpc-default-executor-3" daemon prio=5 tid=300 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1344012241-184-acceptor-0@2f374ee9-ServerConnector@3b201845{HTTP/1.1,[http/1.1]}{0.0.0.0:36091}" daemon prio=3 tid=184 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 5 on default port 40443" daemon prio=5 tid=41 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-3-0" daemon prio=5 tid=242 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)
"IPC Server handler 0 on default port 40443" daemon prio=5 tid=36 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"BlockDeletingService#0" daemon prio=5 tid=237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server idle connection scanner for port 40443" daemon prio=5 tid=27 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-SegmentedRaftLogWorker"  prio=5 tid=263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"qtp1344012241-187" daemon prio=5 tid=187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"BlockDeletingService#0" daemon prio=5 tid=243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=9 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readInt(DataInputStream.java:387)
        at org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:115)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:390)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=250 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-StateMachineUpdater" daemon prio=5 tid=268 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-0-0" daemon prio=5 tid=233 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server Responder" daemon prio=5 tid=24 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d7ff8dc" daemon prio=5 tid=180 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 2 on default port 41783" daemon prio=5 tid=78 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"grpc-default-executor-2" daemon prio=5 tid=277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"SCMBlockDeletingService#0" daemon prio=5 tid=107 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 14 on default port 41783" daemon prio=5 tid=90 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 8 on default port 41783" daemon prio=5 tid=84 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp1344012241-186" daemon prio=5 tid=186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"java.util.concurrent.ThreadPoolExecutor$Worker@6392117b[State = -1, empty queue]" daemon prio=5 tid=314 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=249 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Command processor thread" daemon prio=5 tid=179 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$171/825626209.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 1 on default port 38639" daemon prio=5 tid=57 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-1-0" daemon prio=5 tid=234 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 17 on default port 38639" daemon prio=5 tid=73 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 5 on default port 38639" daemon prio=5 tid=61 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 13 on default port 38639" daemon prio=5 tid=69 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.ut2020-06-02 21:31:30,146 [Thread-255] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 21:31:30,149 [Thread-255] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 21:31:30,149 [Thread-255] WARN  db.DBStoreBuilder (DBStoreBuilder.java:createDBStoreBuilder(277)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 21:31:30,189 [Thread-255] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(126)) - Loading file from sun.misc.CompoundEnumeration@356e7d23
2020-06-02 21:31:30,189 [Thread-255] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(172)) - Loading network topology layer schema file
2020-06-02 21:31:30,192 [Thread-255] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(73)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2020-06-02 21:31:30,192 [Thread-255] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(73)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2020-06-02 21:31:30,193 [Thread-255] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(116)) - Entering startup safe mode.
2020-06-02 21:31:30,194 [Thread-255] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicy(60)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2020-06-02 21:31:30,195 [Thread-255] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(158)) - No pipeline exists in current db
2020-06-02 21:31:30,197 [Thread-255] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:<init>(89)) - Total pipeline count is 0, healthy pipeline threshold count is 0
2020-06-02 21:31:30,197 [Thread-255] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:<init>(79)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2020-06-02 21:31:30,201 [Thread-255] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 21:31:30,202 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 21:31:30,203 [Listener at 0.0.0.0/38913] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 21:31:30,212 [Listener at 0.0.0.0/38427] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 21:31:30,216 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 21:31:30,216 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 21:31:30,221 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
2020-06-02 21:31:30,223 [Listener at 0.0.0.0/33899] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for scm at: http://0.0.0.0:0
2020-06-02 21:31:30,223 [Listener at 0.0.0.0/33899] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 21:31:30,224 [Listener at 0.0.0.0/33899] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:31:30,232 [Listener at 0.0.0.0/33899] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 21:31:30,233 [Listener at 0.0.0.0/33899] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 21:31:30,234 [Listener at 0.0.0.0/33899] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2020-06-02 21:31:30,234 [Listener at 0.0.0.0/33899] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 21:31:30,234 [Listener at 0.0.0.0/33899] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 21:31:30,246 [Listener at 0.0.0.0/33899] INFO  server.StorageContainerManager (StorageContainerManager.java:start(781)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:33899
2020-06-02 21:31:30,246 [Listener at 0.0.0.0/33899] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2020-06-02 21:31:30,249 [Listener at 0.0.0.0/33899] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(157)) - RPC server for Client  is listening at /0.0.0.0:33899
2020-06-02 21:31:30,250 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 21:31:30,250 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 21:31:30,257 [Listener at 0.0.0.0/33899] INFO  server.StorageContainerManager (StorageContainerManager.java:start(793)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:38427
2020-06-02 21:31:30,257 [Listener at 0.0.0.0/33899] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(149)) - RPC server for Block Protocol is listening at /0.0.0.0:38427
2020-06-02 21:31:30,260 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 21:31:30,260 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 21:31:30,265 [Listener at 0.0.0.0/33899] INFO  server.StorageContainerManager (StorageContainerManager.java:start(799)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:38913
2020-06-02 21:31:30,265 [Listener at 0.0.0.0/33899] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(172)) - RPC server for DataNodes is listening at /0.0.0.0:38913
2020-06-02 21:31:30,268 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 21:31:30,268 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 21:31:30,274 [Listener at 0.0.0.0/33899] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 44557
2020-06-02 21:31:30,274 [Listener at 0.0.0.0/33899] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 21:31:30,276 [Listener at 0.0.0.0/33899] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 21:31:30,276 [Listener at 0.0.0.0/33899] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 21:31:30,276 [Listener at 0.0.0.0/33899] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 660000ms
2020-06-02 21:31:30,277 [Listener at 0.0.0.0/33899] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:31:30,277 [Listener at 0.0.0.0/33899] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@419f8c8e{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 21:31:30,278 [Listener at 0.0.0.0/33899] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@5b890b52{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2020-06-02 21:31:30,287 [Listener at 0.0.0.0/33899] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@6ac1caf0{scm,/,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2020-06-02 21:31:30,289 [Listener at 0.0.0.0/33899] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@37e85f63{HTTP/1.1,[http/1.1]}{0.0.0.0:44557}
2020-06-02 21:31:30,292 [Listener at 0.0.0.0/33899] INFO  server.Server (Server.java:doStart(399)) - Started @61069ms
2020-06-02 21:31:30,292 [Listener at 0.0.0.0/33899] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 21:31:30,295 [Listener at 0.0.0.0/33899] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of scm listening at http://0.0.0.0:44557
2020-06-02 21:31:30,296 [Listener at 0.0.0.0/33899] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 21:31:30,297 [Listener at 0.0.0.0/33899] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(104)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2020-06-02 21:31:30,297 [Listener at 0.0.0.0/33899] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(207)) - Configuration either no ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2020-06-02 21:31:30,297 [Listener at 0.0.0.0/33899] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetails(237)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2020-06-02 21:31:30,298 [Listener at 0.0.0.0/33899] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 21:31:30,298 [Listener at 0.0.0.0/33899] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 21:31:30,308 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d002e6b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 21:31:30,314 [Listener at 0.0.0.0/33899] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2020-06-02 21:31:30,376 [Listener at 0.0.0.0/33899] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-02 21:31:30,386 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-06-02 21:31:30,406 [Listener at 127.0.0.1/40631] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2020-06-02 21:31:30,408 [Listener at 127.0.0.1/40631] INFO  om.OzoneManager (OzoneManager.java:start(1097)) - OzoneManager RPC server is listening at localhost/127.0.0.1:40631
2020-06-02 21:31:30,409 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-06-02 21:31:30,409 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-06-02 21:31:30,445 [Listener at 127.0.0.1/40631] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2020-06-02 21:31:30,445 [Listener at 127.0.0.1/40631] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 21:31:30,447 [Listener at 127.0.0.1/40631] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:31:30,447 [Listener at 127.0.0.1/40631] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 21:31:30,448 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 21:31:30,449 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
2020-06-02 21:31:30,449 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 21:31:30,449 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 21:31:30,450 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 35275
2020-06-02 21:31:30,450 [Listener at 127.0.0.1/40631] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 21:31:30,453 [Listener at 127.0.0.1/40631] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 21:31:30,453 [Listener at 127.0.0.1/40631] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 21:31:30,453 [Listener at 127.0.0.1/40631] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-06-02 21:31:30,454 [Listener at 127.0.0.1/40631] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:31:30,454 [Listener at 127.0.0.1/40631] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@4fa0a2f5{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 21:31:30,455 [Listener at 127.0.0.1/40631] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@433de956{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2020-06-02 21:31:30,458 [Listener at 127.0.0.1/40631] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@53b5efa9{ozoneManager,/,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2020-06-02 21:31:30,461 [Listener at 127.0.0.1/40631] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@41fa0259{HTTP/1.1,[http/1.1]}{0.0.0.0:35275}
2020-06-02 21:31:30,461 [Listener at 127.0.0.1/40631] INFO  server.Server (Server.java:doStart(399)) - Started @61239ms
2020-06-02 21:31:30,461 [Listener at 127.0.0.1/40631] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 21:31:30,464 [Listener at 127.0.0.1/40631] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of ozoneManager listening at http://0.0.0.0:35275
2020-06-02 21:31:30,474 [Listener at 127.0.0.1/40631] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-06-02 21:31:30,476 [Listener at 127.0.0.1/40631] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(205)) - HddsDatanodeService host:32d60ebb3871 ip:172.17.0.2
2020-06-02 21:31:30,483 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@30bd0c07] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 21:31:30,489 [Listener at 127.0.0.1/40631] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-06-02 21:31:30,489 [Listener at 127.0.0.1/40631] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(181)) - Added Volume : /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data-0/containers/hdds to VolumeSet
2020-06-02 21:31:30,489 [Listener at 127.0.0.1/40631] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data-0/containers/hdds
2020-06-02 21:31:30,490 [Listener at 127.0.0.1/40631] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data-0/containers/hdds
2020-06-02 21:31:30,508 [Listener at 127.0.0.1/40631] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-06-02 21:31:30,509 [Listener at 127.0.0.1/40631] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-06-02 21:31:30,509 [Listener at 127.0.0.1/40631] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-06-02 21:31:30,510 [Listener at 127.0.0.1/40631] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-06-02 21:31:30,510 [Listener at 127.0.0.1/40631] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:31:30,510 [Listener at 127.0.0.1/40631] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-06-02 21:31:30,510 [Listener at 127.0.0.1/40631] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 21:31:30,511 [Listener at 127.0.0.1/40631] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data/ratis] (custom)
2020-06-02 21:31:30,515 [Listener at 127.0.0.1/40631] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-06-02 21:31:30,515 [Listener at 127.0.0.1/40631] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 21:31:30,517 [Listener at 127.0.0.1/40631] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:31:30,520 [Listener at 127.0.0.1/40631] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 21:31:30,521 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 21:31:30,522 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
2020-06-02 21:31:30,522 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 21:31:30,522 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 21:31:30,522 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 39325
2020-06-02 21:31:30,522 [Listener at 127.0.0.1/40631] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 21:31:30,529 [Listener at 127.0.0.1/40631] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 21:31:30,529 [Listener at 127.0.0.1/40631] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 21:31:30,529 [Listener at 127.0.0.1/40631] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-06-02 21:31:30,530 [Listener at 127.0.0.1/40631] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:31:30,530 [Listener at 127.0.0.1/40631] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@694a9bc3{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 21:31:30,531 [Listener at 127.0.0.1/40631] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@56aaed09{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-06-02 21:31:30,589 [Listener at 127.0.0.1/40631] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@685502e2{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-39325-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-1081981547511475410.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 21:31:30,594 [Listener at 127.0.0.1/40631] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@32fa4197{HTTP/1.1,[http/1.1]}{0.0.0.0:39325}
2020-06-02 21:31:30,594 [Listener at 127.0.0.1/40631] INFO  server.Server (Server.java:doStart(399)) - Started @61372ms
2020-06-02 21:31:30,595 [Listener at 127.0.0.1/40631] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 21:31:30,598 [Listener at 127.0.0.1/40631] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of hddsDatanode listening at http://0.0.0.0:39325
2020-06-02 21:31:30,598 [Listener at 127.0.0.1/40631] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-06-02 21:31:30,600 [Listener at 127.0.0.1/40631] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(205)) - HddsDatanodeService host:32d60ebb3871 ip:172.17.0.2
2020-06-02 21:31:30,601 [Listener at 127.0.0.1/40631] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-06-02 21:31:30,608 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@423bb09b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 21:31:30,608 [Listener at 127.0.0.1/40631] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(181)) - Added Volume : /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data-0/containers/hdds to VolumeSet
2020-06-02 21:31:30,609 [Listener at 127.0.0.1/40631] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data-0/containers/hdds
2020-06-02 21:31:30,621 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(145)) - DatanodeDetails is persisted to /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/meta/datanode.id
2020-06-02 21:31:30,624 [Listener at 127.0.0.1/40631] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data-0/containers/hdds
2020-06-02 21:31:30,645 [Listener at 127.0.0.1/40631] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-06-02 21:31:30,645 [Listener at 127.0.0.1/40631] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-06-02 21:31:30,645 [Listener at 127.0.0.1/40631] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-06-02 21:31:30,645 [Listener at 127.0.0.1/40631] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-06-02 21:31:30,645 [Listener at 127.0.0.1/40631] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:31:30,645 [Listener at 127.0.0.1/40631] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-06-02 21:31:30,646 [Listener at 127.0.0.1/40631] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 21:31:30,647 [Listener at 127.0.0.1/40631] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data/ratis] (custom)
2020-06-02 21:31:30,652 [Listener at 127.0.0.1/40631] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-06-02 21:31:30,653 [Listener at 127.0.0.1/40631] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 21:31:30,654 [Listener at 127.0.0.1/40631] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:31:30,655 [Listener at 127.0.0.1/40631] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 21:31:30,658 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 21:31:30,659 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
2020-06-02 21:31:30,659 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 21:31:30,659 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 21:31:30,659 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 44057
2020-06-02 21:31:30,660 [Listener at 127.0.0.1/40631] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 21:31:30,664 [Listener at 127.0.0.1/40631] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 21:31:30,665 [Listener at 127.0.0.1/40631] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 21:31:30,665 [Listener at 127.0.0.1/40631] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-06-02 21:31:30,666 [Listener at 127.0.0.1/40631] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:31:30,667 [Listener at 127.0.0.1/40631] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@5c7d25cd{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 21:31:30,667 [Listener at 127.0.0.1/40631] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@55925eb{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-06-02 21:31:30,713 [Listener at 127.0.0.1/40631] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@7d0881e0{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-44057-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-6503616269616930873.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 21:31:30,715 [Listener at 127.0.0.1/40631] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@6c784d9f{HTTP/1.1,[http/1.1]}{0.0.0.0:44057}
2020-06-02 21:31:30,715 [Listener at 127.0.0.1/40631] INFO  server.Server (Server.java:doStart(399)) - Started @61492ms
2020-06-02 21:31:30,715 [Listener at 127.0.0.1/40631] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 21:31:30,718 [Listener at 127.0.0.1/40631] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of hddsDatanode listening at http://0.0.0.0:44057
2020-06-02 21:31:30,718 [Listener at 127.0.0.1/40631] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2020-06-02 21:31:30,720 [Listener at 127.0.0.1/40631] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(205)) - HddsDatanodeService host:32d60ebb3871 ip:172.17.0.2
2020-06-02 21:31:30,721 [Listener at 127.0.0.1/40631] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data-0/containers/hdds of storage type : DISK and capacity : 9223372036854775807
2020-06-02 21:31:30,721 [Listener at 127.0.0.1/40631] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(181)) - Added Volume : /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data-0/containers/hdds to VolumeSet
2020-06-02 21:31:30,722 [Listener at 127.0.0.1/40631] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data-0/containers/hdds
2020-06-02 21:31:30,722 [Listener at 127.0.0.1/40631] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(200)) - Scheduled health check for volume /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data-0/containers/hdds
2020-06-02 21:31:30,732 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36a8b459] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 21:31:30,734 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(145)) - DatanodeDetails is persisted to /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/meta/datanode.id
2020-06-02 21:31:30,751 [Listener at 127.0.0.1/40631] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(44)) - raft.rpc.type = GRPC (default)
2020-06-02 21:31:30,751 [Listener at 127.0.0.1/40631] INFO  grpc.GrpcFactory (GrpcFactory.java:checkPooledByteBufAllocatorUseCacheForAllThreads(45)) - PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
2020-06-02 21:31:30,751 [Listener at 127.0.0.1/40631] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.port = 0 (default)
2020-06-02 21:31:30,751 [Listener at 127.0.0.1/40631] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2020-06-02 21:31:30,751 [Listener at 127.0.0.1/40631] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:31:30,751 [Listener at 127.0.0.1/40631] INFO  server.GrpcService (ConfUtils.java:logGet(44)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2020-06-02 21:31:30,751 [Listener at 127.0.0.1/40631] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 21:31:30,753 [Listener at 127.0.0.1/40631] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data/ratis] (custom)
2020-06-02 21:31:30,760 [Listener at 127.0.0.1/40631] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(205)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2020-06-02 21:31:30,760 [Listener at 127.0.0.1/40631] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(106)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2020-06-02 21:31:30,761 [Listener at 127.0.0.1/40631] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:31:30,766 [Listener at 127.0.0.1/40631] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2020-06-02 21:31:30,767 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(993)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2020-06-02 21:31:30,768 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addFilter(969)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
2020-06-02 21:31:30,768 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2020-06-02 21:31:30,768 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:addFilter(977)) - Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2020-06-02 21:31:30,769 [Listener at 127.0.0.1/40631] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1211)) - Jetty bound to port 33953
2020-06-02 21:31:30,769 [Listener at 127.0.0.1/40631] INFO  server.Server (Server.java:doStart(359)) - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 1.8.0_232-b09
2020-06-02 21:31:30,770 [Listener at 127.0.0.1/40631] INFO  server.session (DefaultSessionIdManager.java:doStart(333)) - DefaultSessionIdManager workerName=node0
2020-06-02 21:31:30,771 [Listener at 127.0.0.1/40631] INFO  server.session (DefaultSessionIdManager.java:doStart(338)) - No SessionScavenger set, using defaults
2020-06-02 21:31:30,771 [Listener at 127.0.0.1/40631] INFO  server.session (HouseKeeper.java:startScavenging(140)) - node0 Scavenging every 600000ms
2020-06-02 21:31:30,771 [Listener at 127.0.0.1/40631] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-02 21:31:30,772 [Listener at 127.0.0.1/40631] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@35e28642{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2020-06-02 21:31:30,772 [Listener at 127.0.0.1/40631] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.s.ServletContextHandler@358db46{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2020-06-02 21:31:30,802 [Listener at 127.0.0.1/40631] INFO  handler.ContextHandler (ContextHandler.java:doStart(825)) - Started o.e.j.w.WebAppContext@31a5dd4a{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-33953-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-3438335541464688531.dir/webapp/,AVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 21:31:30,804 [Listener at 127.0.0.1/40631] INFO  server.AbstractConnector (AbstractConnector.java:doStart(330)) - Started ServerConnector@66939798{HTTP/1.1,[http/1.1]}{0.0.0.0:33953}
2020-06-02 21:31:30,804 [Listener at 127.0.0.1/40631] INFO  server.Server (Server.java:doStart(399)) - Started @61581ms
2020-06-02 21:31:30,804 [Listener at 127.0.0.1/40631] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(276)) - Sink prometheus already exists!
2020-06-02 21:31:30,808 [Listener at 127.0.0.1/40631] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(325)) - HTTP server of hddsDatanode listening at http://0.0.0.0:33953
2020-06-02 21:31:30,811 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 21:31:30,812 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:30,832 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@71fdd28f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-06-02 21:31:30,835 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(145)) - DatanodeDetails is persisted to /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/meta/datanode.id
2020-06-02 21:31:31,812 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 21:31:31,812 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:32,621 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-06-02 21:31:32,621 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-06-02 21:31:32,621 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(425)) - Starting XceiverServerRatis d602985a-24b1-4fac-a391-54201d0c9032 at port 0
2020-06-02 21:31:32,622 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - d602985a-24b1-4fac-a391-54201d0c9032: start RPC server
2020-06-02 21:31:32,629 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(159)) - d602985a-24b1-4fac-a391-54201d0c9032: GrpcService started, listening on 0.0.0.0/0.0.0.0:41721
2020-06-02 21:31:32,629 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(437)) - XceiverServerRatis d602985a-24b1-4fac-a391-54201d0c9032 is started using port 41721
2020-06-02 21:31:32,630 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc d602985a-24b1-4fac-a391-54201d0c9032 is started using port 38915
2020-06-02 21:31:32,739 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-06-02 21:31:32,739 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-06-02 21:31:32,739 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(425)) - Starting XceiverServerRatis 165904ff-00de-48fd-9e56-43cbf105f57b at port 0
2020-06-02 21:31:32,744 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 165904ff-00de-48fd-9e56-43cbf105f57b: start RPC server
2020-06-02 21:31:32,746 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(159)) - 165904ff-00de-48fd-9e56-43cbf105f57b: GrpcService started, listening on 0.0.0.0/0.0.0.0:40593
2020-06-02 21:31:32,746 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(437)) - XceiverServerRatis 165904ff-00de-48fd-9e56-43cbf105f57b is started using port 40593
2020-06-02 21:31:32,747 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 165904ff-00de-48fd-9e56-43cbf105f57b is started using port 38409
2020-06-02 21:31:32,812 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 21:31:32,813 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:32,838 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(232)) - Attempting to start container services.
2020-06-02 21:31:32,838 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(196)) - Background container scanner has been disabled.
2020-06-02 21:31:32,838 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(425)) - Starting XceiverServerRatis 4cee6ed5-fd4a-4537-baa8-98df5210e899 at port 0
2020-06-02 21:31:32,847 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: start RPC server
2020-06-02 21:31:32,853 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(159)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: GrpcService started, listening on 0.0.0.0/0.0.0.0:32789
2020-06-02 21:31:32,853 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(437)) - XceiverServerRatis 4cee6ed5-fd4a-4537-baa8-98df5210e899 is started using port 32789
2020-06-02 21:31:32,854 [Datanode State Machine Thread - 0] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(145)) - XceiverServerGrpc 4cee6ed5-fd4a-4537-baa8-98df5210e899 is started using port 37047
2020-06-02 21:31:33,813 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 0 of 3 DN Heartbeats.
2020-06-02 21:31:33,813 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:34,612 [IPC Server handler 0 on default port 38913] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/d602985a-24b1-4fac-a391-54201d0c9032
2020-06-02 21:31:34,612 [IPC Server handler 0 on default port 38913] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : d602985a-24b1-4fac-a391-54201d0c9032{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}
2020-06-02 21:31:34,613 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2020-06-02 21:31:34,613 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - DataNodeSafeModeRule rule is successfully validated
2020-06-02 21:31:34,613 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(241)) - All SCM safe mode pre check rules have passed
2020-06-02 21:31:34,614 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - ContainerSafeModeRule rule is successfully validated
2020-06-02 21:31:34,615 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=3ff59c3b-467b-4556-8b45-68e42dffcbc4 to datanode:d602985a-24b1-4fac-a391-54201d0c9032
2020-06-02 21:31:34,616 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 3ff59c3b-467b-4556-8b45-68e42dffcbc4, Nodes: d602985a-24b1-4fac-a391-54201d0c9032{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T21:31:34.615Z]
2020-06-02 21:31:34,616 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 1 nodes. Healthy nodes 1
2020-06-02 21:31:34,616 [RatisPipelineUtilsThread] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(133)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2020-06-02 21:31:34,616 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2020-06-02 21:31:34,736 [IPC Server handler 1 on default port 38913] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/165904ff-00de-48fd-9e56-43cbf105f57b
2020-06-02 21:31:34,736 [IPC Server handler 1 on default port 38913] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 165904ff-00de-48fd-9e56-43cbf105f57b{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}
2020-06-02 21:31:34,736 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - DataNodeSafeModeRule rule is successfully validated
2020-06-02 21:31:34,737 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - ContainerSafeModeRule rule is successfully validated
2020-06-02 21:31:34,737 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=8b1f1230-5464-4e4f-ae6a-19af50b4b849 to datanode:165904ff-00de-48fd-9e56-43cbf105f57b
2020-06-02 21:31:34,738 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 8b1f1230-5464-4e4f-ae6a-19af50b4b849, Nodes: 165904ff-00de-48fd-9e56-43cbf105f57b{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T21:31:34.737Z]
2020-06-02 21:31:34,738 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
2020-06-02 21:31:34,738 [RatisPipelineUtilsThread] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(133)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2020-06-02 21:31:34,738 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2020-06-02 21:31:34,813 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Waiting for nodes to be ready. Got 2 of 3 DN Heartbeats.
2020-06-02 21:31:34,814 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:34,837 [IPC Server handler 2 on default port 38913] INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(111)) - Added a new node: /default-rack/4cee6ed5-fd4a-4537-baa8-98df5210e899
2020-06-02 21:31:34,837 [IPC Server handler 2 on default port 38913] INFO  node.SCMNodeManager (SCMNodeManager.java:register(268)) - Registered Data node : 4cee6ed5-fd4a-4537-baa8-98df5210e899{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}
2020-06-02 21:31:34,837 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - DataNodeSafeModeRule rule is successfully validated
2020-06-02 21:31:34,837 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(213)) - ContainerSafeModeRule rule is successfully validated
2020-06-02 21:31:34,838 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=4af8b8aa-419f-4392-bdff-130f7f42e658 to datanode:4cee6ed5-fd4a-4537-baa8-98df5210e899
2020-06-02 21:31:34,839 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: 4af8b8aa-419f-4392-bdff-130f7f42e658, Nodes: 4cee6ed5-fd4a-4537-baa8-98df5210e899{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T21:31:34.838Z]
2020-06-02 21:31:34,839 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
2020-06-02 21:31:34,839 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=b31d4ef4-1745-476e-a4da-f31aacb741a9 to datanode:165904ff-00de-48fd-9e56-43cbf105f57b
2020-06-02 21:31:34,839 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=b31d4ef4-1745-476e-a4da-f31aacb741a9 to datanode:4cee6ed5-fd4a-4537-baa8-98df5210e899
2020-06-02 21:31:34,839 [RatisPipelineUtilsThread] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(138)) - Sending CreatePipelineCommand for pipeline:PipelineID=b31d4ef4-1745-476e-a4da-f31aacb741a9 to datanode:d602985a-24b1-4fac-a391-54201d0c9032
2020-06-02 21:31:34,840 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(54)) - Created pipeline Pipeline[ Id: b31d4ef4-1745-476e-a4da-f31aacb741a9, Nodes: 165904ff-00de-48fd-9e56-43cbf105f57b{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}4cee6ed5-fd4a-4537-baa8-98df5210e899{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}d602985a-24b1-4fac-a391-54201d0c9032{ip: 172.17.0.2, host: 32d60ebb3871, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-02T21:31:34.839Z]
2020-06-02 21:31:34,843 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager (SCMPipelineManager.java:createPipeline(222)) - Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
2020-06-02 21:31:35,094 [Listener at 127.0.0.1/35123] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(246)) - Attempting to stop container services.
2020-06-02 21:31:35,095 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(246)) - Attempting to stop container services.
2020-06-02 21:31:35,096 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: close
2020-06-02 21:31:35,097 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39: shutdown
2020-06-02 21:31:35,098 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-371025157A39,id=7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:31:35,098 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: shutdown LeaderState
2020-06-02 21:31:35,098 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(242)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-PendingRequests: sendNotLeaderResponses
2020-06-02 21:31:35,099 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_appender.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39
2020-06-02 21:31:35,100 [Listener at 127.0.0.1/35123] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - a6b41249-b273-4291-afb4-d06d350d4050: close
2020-06-02 21:31:35,100 [Listener at 127.0.0.1/35123] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD: shutdown
2020-06-02 21:31:35,100 [Listener at 127.0.0.1/35123] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D9D1F22491BD,id=a6b41249-b273-4291-afb4-d06d350d4050
2020-06-02 21:31:35,100 [Listener at 127.0.0.1/35123] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - a6b41249-b273-4291-afb4-d06d350d4050: shutdown FollowerState
2020-06-02 21:31:35,101 [Thread-215] INFO  impl.FollowerState (FollowerState.java:run(117)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-06-02 21:31:35,101 [a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(288)) - group-D9D1F22491BD: Taking a snapshot at:(t:2, i:0) file /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd/sm/snapshot.2_0
2020-06-02 21:31:35,104 [Listener at 127.0.0.1/35123] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(142)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-StateMachineUpdater: set stopIndex = 0
2020-06-02 21:31:35,104 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(288)) - group-371025157A39: Taking a snapshot at:(t:1, i:0) file /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis/2082e97e-3c59-46f0-a902-371025157a39/sm/snapshot.1_0
2020-06-02 21:31:35,112 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(142)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-StateMachineUpdater: set stopIndex = 0
2020-06-02 21:31:35,403 [a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-D9D1F22491BD: Finished taking a snapshot at:(t:2, i:0) file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd/sm/snapshot.2_0 time:302
2020-06-02 21:31:35,404 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-371025157A39: Finished taking a snapshot at:(t:1, i:0) file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis/2082e97e-3c59-46f0-a902-371025157a39/sm/snapshot.1_0 time:300
2020-06-02 21:31:35,405 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(277)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-StateMachineUpdater: Took a snapshot at index 0
2020-06-02 21:31:35,405 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(87)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-06-02 21:31:35,405 [a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(277)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-StateMachineUpdater: Took a snapshot at index 0
2020-06-02 21:31:35,406 [a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(87)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-06-02 21:31:35,430 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39
2020-06-02 21:31:35,431 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39: closes. applyIndex: 0
2020-06-02 21:31:35,430 [a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD
2020-06-02 21:31:35,432 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-06-02 21:31:35,432 [Listener at 127.0.0.1/35123] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD: closes. applyIndex: 0
2020-06-02 21:31:35,432 [a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-06-02 21:31:35,441 [Listener at 127.0.0.1/35123] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD-SegmentedRaftLogWorker close()
2020-06-02 21:31:35,442 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39-SegmentedRaftLogWorker close()
2020-06-02 21:31:35,469 [Listener at 127.0.0.1/35123] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.a6b41249-b273-4291-afb4-d06d350d4050
2020-06-02 21:31:35,469 [Listener at 127.0.0.1/35123] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD
2020-06-02 21:31:35,469 [Listener at 127.0.0.1/35123] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.a6b41249-b273-4291-afb4-d06d350d4050@group-D9D1F22491BD
2020-06-02 21:31:35,469 [Listener at 127.0.0.1/35123] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A: shutdown
2020-06-02 21:31:35,469 [Listener at 127.0.0.1/35123] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-726DCB5B934A,id=a6b41249-b273-4291-afb4-d06d350d4050
2020-06-02 21:31:35,470 [Listener at 127.0.0.1/35123] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - a6b41249-b273-4291-afb4-d06d350d4050: shutdown LeaderState
2020-06-02 21:31:35,470 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:31:35,470 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39
2020-06-02 21:31:35,470 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-371025157A39
2020-06-02 21:31:35,470 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD: shutdown
2020-06-02 21:31:35,470 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D9D1F22491BD,id=7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:31:35,470 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: shutdown LeaderState
2020-06-02 21:31:35,470 [Listener at 127.0.0.1/35123] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(242)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-PendingRequests: sendNotLeaderResponses
2020-06-02 21:31:35,477 [Listener at 127.0.0.1/35123] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_appender.a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A
2020-06-02 21:31:35,477 [Listener at 127.0.0.1/35123] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(142)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-StateMachineUpdater: set stopIndex = 0
2020-06-02 21:31:35,477 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(288)) - group-726DCB5B934A: Taking a snapshot at:(t:1, i:0) file /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis/b4a2f779-cada-4ca2-a5b1-726dcb5b934a/sm/snapshot.1_0
2020-06-02 21:31:35,478 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$456/429341673@2ec93441] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(153)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD->a6b41249-b273-4291-afb4-d06d350d4050-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2020-06-02 21:31:35,480 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-726DCB5B934A: Finished taking a snapshot at:(t:1, i:0) file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-1/data/ratis/b4a2f779-cada-4ca2-a5b1-726dcb5b934a/sm/snapshot.1_0 time:3
2020-06-02 21:31:35,482 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(277)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-StateMachineUpdater: Took a snapshot at index 0
2020-06-02 21:31:35,482 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(87)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-06-02 21:31:35,482 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A
2020-06-02 21:31:35,483 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(137)) - a6b41249-b273-4291-afb4-d06d350d4050: Completed APPEND_ENTRIES, lastRequest: 7bbd2402-c364-4868-9d2c-73c7d416b8c0->a6b41249-b273-4291-afb4-d06d350d4050#1-t2, previous=(t:0, i:0), leaderCommit=0, initializing? false, entries: size=1, first=(t:2, i:0), CONFIGURATIONENTRY
2020-06-02 21:31:35,484 [Listener at 127.0.0.1/35123] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A: closes. applyIndex: 0
2020-06-02 21:31:35,484 [a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-06-02 21:31:35,481 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(242)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-PendingRequests: sendNotLeaderResponses
2020-06-02 21:31:35,484 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_appender.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD
2020-06-02 21:31:35,484 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(142)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-StateMachineUpdater: set stopIndex = 0
2020-06-02 21:31:35,485 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(288)) - group-D9D1F22491BD: Taking a snapshot at:(t:2, i:0) file /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd/sm/snapshot.2_0
2020-06-02 21:31:35,485 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-D9D1F22491BD: Finished taking a snapshot at:(t:2, i:0) file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-0/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd/sm/snapshot.2_0 time:0
2020-06-02 21:31:35,486 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(277)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-StateMachineUpdater: Took a snapshot at index 0
2020-06-02 21:31:35,486 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(87)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-06-02 21:31:35,486 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD
2020-06-02 21:31:35,486 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD: closes. applyIndex: 0
2020-06-02 21:31:35,486 [7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-06-02 21:31:35,481 [org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$456/429341673@422795da] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(153)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD->762fe7a3-380a-4155-b73e-ca6d55ceee4d-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2020-06-02 21:31:35,488 [Listener at 127.0.0.1/35123] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A-SegmentedRaftLogWorker close()
2020-06-02 21:31:35,486 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(309)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD->a6b41249-b273-4291-afb4-d06d350d4050-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2020-06-02 21:31:35,488 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-SegmentedRaftLogWorker close()
2020-06-02 21:31:35,488 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(137)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: Completed APPEND_ENTRIES, lastRequest: 7bbd2402-c364-4868-9d2c-73c7d416b8c0->762fe7a3-380a-4155-b73e-ca6d55ceee4d#1-t2, previous=(t:0, i:0), leaderCommit=0, initializing? false, entries: size=1, first=(t:2, i:0), CONFIGURATIONENTRY
2020-06-02 21:31:35,493 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(309)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD->762fe7a3-380a-4155-b73e-ca6d55ceee4d-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2020-06-02 21:31:35,500 [Listener at 127.0.0.1/35123] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.a6b41249-b273-4291-afb4-d06d350d4050
2020-06-02 21:31:35,501 [Listener at 127.0.0.1/35123] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A
2020-06-02 21:31:35,501 [Listener at 127.0.0.1/35123] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.a6b41249-b273-4291-afb4-d06d350d4050@group-726DCB5B934A
2020-06-02 21:31:35,501 [Listener at 127.0.0.1/35123] INFO  server.GrpcService (GrpcService.java:closeImpl(165)) - a6b41249-b273-4291-afb4-d06d350d4050: shutdown server with port 43235 now
2020-06-02 21:31:35,502 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.7bbd2402-c364-4868-9d2c-73c7d416b8c0
2020-06-02 21:31:35,502 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD
2020-06-02 21:31:35,502 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD
2020-06-02 21:31:35,502 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(165)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: shutdown server with port 44277 now
2020-06-02 21:31:35,507 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD->a6b41249-b273-4291-afb4-d06d350d4050: nextIndex: updateUnconditionally 1 -> 0
2020-06-02 21:31:35,520 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(173)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0: shutdown server with port 44277 successfully
2020-06-02 21:31:35,541 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service BlockDeletingService
2020-06-02 21:31:35,541 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD->762fe7a3-380a-4155-b73e-ca6d55ceee4d: nextIndex: updateUnconditionally 1 -> 0
2020-06-02 21:31:35,568 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(424)) - Ozone container server stopped.
2020-06-02 21:31:35,577 [Listener at 127.0.0.1/35123] INFO  server.GrpcService (GrpcService.java:closeImpl(173)) - a6b41249-b273-4291-afb4-d06d350d4050: shutdown server with port 43235 successfully
2020-06-02 21:31:35,579 [Listener at 127.0.0.1/35123] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service BlockDeletingService
2020-06-02 21:31:35,582 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@3a2e0552{hddsDatanode,/,null,UNAVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 21:31:35,582 [Listener at 127.0.0.1/35123] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(424)) - Ozone container server stopped.
2020-06-02 21:31:35,583 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@3fe1306f{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-06-02 21:31:35,583 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-06-02 21:31:35,584 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@24e3d1e9{hddsDatanode,/,null,UNAVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 21:31:35,585 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@1f44c3c2{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2020-06-02 21:31:35,586 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@9009af{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-06-02 21:31:35,588 [Listener at 127.0.0.1/35123] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@3b201845{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-06-02 21:31:35,588 [Listener at 127.0.0.1/35123] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-06-02 21:31:35,588 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@537d30fe{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2020-06-02 21:31:35,588 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@6e7262fb{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-06-02 21:31:35,814 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:35,814 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:36,814 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:36,814 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:37,610 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d602985a-24b1-4fac-a391-54201d0c9032: addNew group-68E42DFFCBC4:[d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721] returns group-68E42DFFCBC4:java.util.concurrent.CompletableFuture@7994edde[Not completed]
2020-06-02 21:31:37,613 [pool-106-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - d602985a-24b1-4fac-a391-54201d0c9032: new RaftServerImpl for group-68E42DFFCBC4:[d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721] with ContainerStateMachine:uninitialized
2020-06-02 21:31:37,614 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 21:31:37,614 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 21:31:37,614 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 21:31:37,614 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 21:31:37,614 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:31:37,614 [pool-106-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4: ConfigurationManager, init=-1: [d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721], old=null, confs=<EMPTY_MAP>
2020-06-02 21:31:37,614 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data/ratis] (custom)
2020-06-02 21:31:37,614 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 21:31:37,615 [pool-106-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data/ratis/3ff59c3b-467b-4556-8b45-68e42dffcbc4 does not exist. Creating ...
2020-06-02 21:31:37,616 [pool-106-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data/ratis/3ff59c3b-467b-4556-8b45-68e42dffcbc4/in_use.lock acquired by nodename 4536@32d60ebb3871
2020-06-02 21:31:37,617 [pool-106-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data/ratis/3ff59c3b-467b-4556-8b45-68e42dffcbc4 has been successfully formatted.
2020-06-02 21:31:37,618 [pool-106-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-68E42DFFCBC4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 21:31:37,618 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(378)) - Unable to start the DatanodeState Machine
java.io.IOException: Unable to finish the execution.
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:375)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:212)
	... 2 more
2020-06-02 21:31:37,618 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 21:31:37,624 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 21:31:37,624 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 21:31:37,624 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:31:37,624 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:31:37,624 [pool-106-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.d602985a-24b1-4fac-a391-54201d0c9032
2020-06-02 21:31:37,624 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 21:31:37,625 [pool-106-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data/ratis/3ff59c3b-467b-4556-8b45-68e42dffcbc4
2020-06-02 21:31:37,625 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 21:31:37,625 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 21:31:37,625 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:31:37,625 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 21:31:37,625 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 21:31:37,625 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 21:31:37,625 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 21:31:37,625 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 21:31:37,625 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 21:31:37,626 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 21:31:37,627 [pool-106-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 21:31:37,627 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 21:31:37,627 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 21:31:37,627 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 21:31:37,627 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 21:31:37,627 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 21:31:37,627 [pool-106-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4
2020-06-02 21:31:37,628 [pool-106-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4
2020-06-02 21:31:37,628 [pool-106-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4: start as a follower, conf=-1: [d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721], old=null
2020-06-02 21:31:37,628 [pool-106-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 21:31:37,629 [pool-106-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d602985a-24b1-4fac-a391-54201d0c9032: start FollowerState
2020-06-02 21:31:37,629 [pool-106-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-68E42DFFCBC4,id=d602985a-24b1-4fac-a391-54201d0c9032
2020-06-02 21:31:37,629 [pool-106-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4
2020-06-02 21:31:37,630 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS ONE #id: "3ff59c3b-467b-4556-8b45-68e42dffcbc4"
.
2020-06-02 21:31:37,630 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d602985a-24b1-4fac-a391-54201d0c9032: addNew group-F31AACB741A9:[165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789] returns group-F31AACB741A9:java.util.concurrent.CompletableFuture@7dab6634[Not completed]
2020-06-02 21:31:37,631 [pool-106-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - d602985a-24b1-4fac-a391-54201d0c9032: new RaftServerImpl for group-F31AACB741A9:[165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789] with ContainerStateMachine:uninitialized
2020-06-02 21:31:37,632 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 21:31:37,632 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 21:31:37,632 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 21:31:37,632 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 21:31:37,632 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:31:37,632 [pool-106-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9: ConfigurationManager, init=-1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null, confs=<EMPTY_MAP>
2020-06-02 21:31:37,632 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data/ratis] (custom)
2020-06-02 21:31:37,632 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 21:31:37,632 [pool-106-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data/ratis/b31d4ef4-1745-476e-a4da-f31aacb741a9 does not exist. Creating ...
2020-06-02 21:31:37,633 [pool-106-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data/ratis/b31d4ef4-1745-476e-a4da-f31aacb741a9/in_use.lock acquired by nodename 4536@32d60ebb3871
2020-06-02 21:31:37,634 [pool-106-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data/ratis/b31d4ef4-1745-476e-a4da-f31aacb741a9 has been successfully formatted.
2020-06-02 21:31:37,635 [pool-106-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-F31AACB741A9: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 21:31:37,635 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 21:31:37,635 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 21:31:37,635 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 21:31:37,635 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:31:37,635 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:31:37,635 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 21:31:37,635 [pool-106-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data/ratis/b31d4ef4-1745-476e-a4da-f31aacb741a9
2020-06-02 21:31:37,635 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 21:31:37,636 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 21:31:37,636 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:31:37,636 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 21:31:37,636 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 21:31:37,636 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 21:31:37,636 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 21:31:37,636 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 21:31:37,636 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 21:31:37,636 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 21:31:37,636 [pool-106-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 21:31:37,637 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 21:31:37,637 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 21:31:37,637 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 21:31:37,637 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 21:31:37,637 [pool-106-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 21:31:37,637 [pool-106-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9
2020-06-02 21:31:37,638 [pool-106-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9
2020-06-02 21:31:37,638 [pool-106-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9: start as a follower, conf=-1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null
2020-06-02 21:31:37,638 [pool-106-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 21:31:37,639 [pool-106-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d602985a-24b1-4fac-a391-54201d0c9032: start FollowerState
2020-06-02 21:31:37,639 [pool-106-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F31AACB741A9,id=d602985a-24b1-4fac-a391-54201d0c9032
2020-06-02 21:31:37,639 [pool-106-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9
2020-06-02 21:31:37,657 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 165904ff-00de-48fd-9e56-43cbf105f57b: addNew group-F31AACB741A9:[165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789] returns group-F31AACB741A9:java.util.concurrent.CompletableFuture@6377df9c[Not completed]
2020-06-02 21:31:37,660 [pool-122-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 165904ff-00de-48fd-9e56-43cbf105f57b: new RaftServerImpl for group-F31AACB741A9:[165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789] with ContainerStateMachine:uninitialized
2020-06-02 21:31:37,664 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 21:31:37,664 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 21:31:37,664 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 21:31:37,665 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 21:31:37,665 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:31:37,665 [pool-122-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9: ConfigurationManager, init=-1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null, confs=<EMPTY_MAP>
2020-06-02 21:31:37,665 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data/ratis] (custom)
2020-06-02 21:31:37,665 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 21:31:37,665 [pool-122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data/ratis/b31d4ef4-1745-476e-a4da-f31aacb741a9 does not exist. Creating ...
2020-06-02 21:31:37,666 [pool-122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data/ratis/b31d4ef4-1745-476e-a4da-f31aacb741a9/in_use.lock acquired by nodename 4536@32d60ebb3871
2020-06-02 21:31:37,667 [pool-122-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data/ratis/b31d4ef4-1745-476e-a4da-f31aacb741a9 has been successfully formatted.
2020-06-02 21:31:37,668 [pool-122-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-F31AACB741A9: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 21:31:37,668 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(378)) - Unable to start the DatanodeState Machine
java.io.IOException: Unable to finish the execution.
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:375)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:212)
	... 2 more
2020-06-02 21:31:37,668 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 21:31:37,668 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 21:31:37,668 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 21:31:37,668 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:31:37,669 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:31:37,669 [pool-122-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.165904ff-00de-48fd-9e56-43cbf105f57b
2020-06-02 21:31:37,669 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 21:31:37,669 [pool-122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data/ratis/b31d4ef4-1745-476e-a4da-f31aacb741a9
2020-06-02 21:31:37,669 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 21:31:37,669 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 21:31:37,669 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:31:37,669 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 21:31:37,669 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 21:31:37,669 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 21:31:37,669 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 21:31:37,669 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 21:31:37,670 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 21:31:37,671 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 21:31:37,671 [pool-122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 21:31:37,671 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 21:31:37,672 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 21:31:37,672 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 21:31:37,672 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 21:31:37,672 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 21:31:37,672 [pool-122-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9
2020-06-02 21:31:37,672 [pool-122-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9
2020-06-02 21:31:37,675 [pool-122-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9: start as a follower, conf=-1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null
2020-06-02 21:31:37,675 [pool-122-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 21:31:37,675 [pool-122-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 165904ff-00de-48fd-9e56-43cbf105f57b: start FollowerState
2020-06-02 21:31:37,676 [pool-122-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F31AACB741A9,id=165904ff-00de-48fd-9e56-43cbf105f57b
2020-06-02 21:31:37,676 [pool-122-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9
2020-06-02 21:31:37,701 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: addNew group-F31AACB741A9:[165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789] returns group-F31AACB741A9:java.util.concurrent.CompletableFuture@527a87a5[Not completed]
2020-06-02 21:31:37,703 [pool-138-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: new RaftServerImpl for group-F31AACB741A9:[165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789] with ContainerStateMachine:uninitialized
2020-06-02 21:31:37,704 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 21:31:37,704 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 21:31:37,704 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 21:31:37,704 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 21:31:37,704 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:31:37,704 [pool-138-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9: ConfigurationManager, init=-1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null, confs=<EMPTY_MAP>
2020-06-02 21:31:37,704 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data/ratis] (custom)
2020-06-02 21:31:37,705 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 21:31:37,705 [pool-138-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data/ratis/b31d4ef4-1745-476e-a4da-f31aacb741a9 does not exist. Creating ...
2020-06-02 21:31:37,706 [pool-138-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data/ratis/b31d4ef4-1745-476e-a4da-f31aacb741a9/in_use.lock acquired by nodename 4536@32d60ebb3871
2020-06-02 21:31:37,707 [pool-138-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data/ratis/b31d4ef4-1745-476e-a4da-f31aacb741a9 has been successfully formatted.
2020-06-02 21:31:37,707 [pool-138-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-F31AACB741A9: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 21:31:37,707 [Datanode State Machine Thread - 0] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(378)) - Unable to start the DatanodeState Machine
java.io.IOException: Unable to finish the execution.
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:219)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:375)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:212)
	... 2 more
2020-06-02 21:31:37,708 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 21:31:37,708 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 21:31:37,708 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 21:31:37,708 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:31:37,708 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:31:37,708 [pool-138-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_worker.4cee6ed5-fd4a-4537-baa8-98df5210e899
2020-06-02 21:31:37,708 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 21:31:37,709 [pool-138-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data/ratis/b31d4ef4-1745-476e-a4da-f31aacb741a9
2020-06-02 21:31:37,709 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 21:31:37,709 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 21:31:37,709 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:31:37,709 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 21:31:37,709 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 21:31:37,709 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 21:31:37,709 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 21:31:37,709 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 21:31:37,709 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 21:31:37,710 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 21:31:37,711 [pool-138-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 21:31:37,711 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 21:31:37,711 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 21:31:37,711 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 21:31:37,711 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 21:31:37,711 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 21:31:37,711 [pool-138-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9
2020-06-02 21:31:37,711 [pool-138-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9
2020-06-02 21:31:37,712 [pool-138-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9: start as a follower, conf=-1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null
2020-06-02 21:31:37,712 [pool-138-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 21:31:37,712 [pool-138-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: start FollowerState
2020-06-02 21:31:37,713 [pool-138-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F31AACB741A9,id=4cee6ed5-fd4a-4537-baa8-98df5210e899
2020-06-02 21:31:37,713 [pool-138-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9
2020-06-02 21:31:37,721 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS THREE #id: "b31d4ef4-1745-476e-a4da-f31aacb741a9"
.
2020-06-02 21:31:37,733 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 165904ff-00de-48fd-9e56-43cbf105f57b: addNew group-19AF50B4B849:[165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593] returns group-19AF50B4B849:java.util.concurrent.CompletableFuture@243293f0[Not completed]
2020-06-02 21:31:37,734 [pool-122-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 165904ff-00de-48fd-9e56-43cbf105f57b: new RaftServerImpl for group-19AF50B4B849:[165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593] with ContainerStateMachine:uninitialized
2020-06-02 21:31:37,734 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 21:31:37,734 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 21:31:37,734 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 21:31:37,734 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 21:31:37,734 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:31:37,734 [pool-122-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849: ConfigurationManager, init=-1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593], old=null, confs=<EMPTY_MAP>
2020-06-02 21:31:37,735 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data/ratis] (custom)
2020-06-02 21:31:37,735 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 21:31:37,735 [pool-122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data/ratis/8b1f1230-5464-4e4f-ae6a-19af50b4b849 does not exist. Creating ...
2020-06-02 21:31:37,736 [pool-122-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data/ratis/8b1f1230-5464-4e4f-ae6a-19af50b4b849/in_use.lock acquired by nodename 4536@32d60ebb3871
2020-06-02 21:31:37,737 [pool-122-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data/ratis/8b1f1230-5464-4e4f-ae6a-19af50b4b849 has been successfully formatted.
2020-06-02 21:31:37,738 [pool-122-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-19AF50B4B849: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 21:31:37,738 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 21:31:37,738 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 21:31:37,738 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 21:31:37,738 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:31:37,738 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:31:37,738 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 21:31:37,738 [pool-122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data/ratis/8b1f1230-5464-4e4f-ae6a-19af50b4b849
2020-06-02 21:31:37,738 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 21:31:37,738 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 21:31:37,738 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:31:37,738 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 21:31:37,738 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 21:31:37,739 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 21:31:37,739 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 21:31:37,739 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 21:31:37,739 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 21:31:37,739 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 21:31:37,740 [pool-122-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 21:31:37,741 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 21:31:37,741 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 21:31:37,741 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 21:31:37,741 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 21:31:37,741 [pool-122-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 21:31:37,741 [pool-122-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849
2020-06-02 21:31:37,742 [pool-122-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849
2020-06-02 21:31:37,742 [pool-122-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849: start as a follower, conf=-1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593], old=null
2020-06-02 21:31:37,743 [pool-122-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 21:31:37,743 [pool-122-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 165904ff-00de-48fd-9e56-43cbf105f57b: start FollowerState
2020-06-02 21:31:37,744 [pool-122-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-19AF50B4B849,id=165904ff-00de-48fd-9e56-43cbf105f57b
2020-06-02 21:31:37,744 [pool-122-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849
2020-06-02 21:31:37,744 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS ONE #id: "8b1f1230-5464-4e4f-ae6a-19af50b4b849"
.
2020-06-02 21:31:37,815 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:37,815 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:37,834 [Command processor thread] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: addNew group-130F7F42E658:[4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789] returns group-130F7F42E658:java.util.concurrent.CompletableFuture@bcc38e[Not completed]
2020-06-02 21:31:37,835 [pool-138-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(98)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: new RaftServerImpl for group-130F7F42E658:[4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789] with ContainerStateMachine:uninitialized
2020-06-02 21:31:37,835 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.min = 5s (custom)
2020-06-02 21:31:37,835 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.timeout.max = 5200ms (custom)
2020-06-02 21:31:37,835 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpcslowness.timeout = 300s (custom)
2020-06-02 21:31:37,835 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.sleep.deviation.threshold = 300 (default)
2020-06-02 21:31:37,835 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:31:37,835 [pool-138-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(103)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658: ConfigurationManager, init=-1: [4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null, confs=<EMPTY_MAP>
2020-06-02 21:31:37,835 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.storage.dir = [/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data/ratis] (custom)
2020-06-02 21:31:37,835 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.corruption.policy = EXCEPTION (default)
2020-06-02 21:31:37,836 [pool-138-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(261)) - The storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data/ratis/4af8b8aa-419f-4392-bdff-130f7f42e658 does not exist. Creating ...
2020-06-02 21:31:37,837 [pool-138-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(343)) - Lock on /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data/ratis/4af8b8aa-419f-4392-bdff-130f7f42e658/in_use.lock acquired by nodename 4536@32d60ebb3871
2020-06-02 21:31:37,838 [pool-138-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(84)) - Storage directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data/ratis/4af8b8aa-419f-4392-bdff-130f7f42e658 has been successfully formatted.
2020-06-02 21:31:37,839 [pool-138-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(226)) - group-130F7F42E658: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2020-06-02 21:31:37,840 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.notification.no-leader.timeout = 60s (default)
2020-06-02 21:31:37,840 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.use.memory = false (default)
2020-06-02 21:31:37,840 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.gap = 1000000 (custom)
2020-06-02 21:31:37,840 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:31:37,840 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:31:37,840 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.cache.num.max = 2 (custom)
2020-06-02 21:31:37,840 [pool-138-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(176)) - new 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-SegmentedRaftLogWorker for RaftStorage:Storage Directory /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data/ratis/4af8b8aa-419f-4392-bdff-130f7f42e658
2020-06-02 21:31:37,840 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2020-06-02 21:31:37,840 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.queue.element-limit = 1024 (custom)
2020-06-02 21:31:37,840 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.segment.size.max = 1048576 (custom)
2020-06-02 21:31:37,840 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.preallocated.size = 16384 (custom)
2020-06-02 21:31:37,840 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.write.buffer.size = 1048576 (custom)
2020-06-02 21:31:37,841 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.force.sync.num = 128 (default)
2020-06-02 21:31:37,841 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync = true (default)
2020-06-02 21:31:37,841 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2020-06-02 21:31:37,841 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2020-06-02 21:31:37,842 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2020-06-02 21:31:37,842 [pool-138-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(129)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2020-06-02 21:31:37,843 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2020-06-02 21:31:37,843 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2020-06-02 21:31:37,843 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.snapshot.retention.file.num = 5 (custom)
2020-06-02 21:31:37,843 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.purge.upto.snapshot.index = false (default)
2020-06-02 21:31:37,843 [pool-138-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.retrycache.expirytime = 600000ms (custom)
2020-06-02 21:31:37,843 [pool-138-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.leader_election.4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658
2020-06-02 21:31:37,844 [pool-138-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.server.4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658
2020-06-02 21:31:37,845 [pool-138-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(184)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658: start as a follower, conf=-1: [4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null
2020-06-02 21:31:37,845 [pool-138-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658: changes role from      null to FOLLOWER at term 0 for startAsFollower
2020-06-02 21:31:37,845 [pool-138-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: start FollowerState
2020-06-02 21:31:37,851 [pool-138-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-130F7F42E658,id=4cee6ed5-fd4a-4537-baa8-98df5210e899
2020-06-02 21:31:37,851 [pool-138-thread-1] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.state_machine.4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658
2020-06-02 21:31:37,855 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(109)) - Created Pipeline RATIS ONE #id: "4af8b8aa-419f-4392-bdff-130f7f42e658"
.
2020-06-02 21:31:38,815 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:38,815 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:39,815 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:39,816 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:40,591 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(246)) - Attempting to stop container services.
2020-06-02 21:31:40,591 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: close
2020-06-02 21:31:40,591 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD: shutdown
2020-06-02 21:31:40,591 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D9D1F22491BD,id=762fe7a3-380a-4155-b73e-ca6d55ceee4d
2020-06-02 21:31:40,592 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: shutdown FollowerState
2020-06-02 21:31:40,592 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(142)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-StateMachineUpdater: set stopIndex = 0
2020-06-02 21:31:40,592 [Thread-217] INFO  impl.FollowerState (FollowerState.java:run(117)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-06-02 21:31:40,592 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(288)) - group-D9D1F22491BD: Taking a snapshot at:(t:2, i:0) file /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd/sm/snapshot.2_0
2020-06-02 21:31:40,593 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-D9D1F22491BD: Finished taking a snapshot at:(t:2, i:0) file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis/f211dd9d-3530-48da-b025-d9d1f22491bd/sm/snapshot.2_0 time:1
2020-06-02 21:31:40,593 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(277)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-StateMachineUpdater: Took a snapshot at index 0
2020-06-02 21:31:40,593 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(87)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-06-02 21:31:40,594 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD
2020-06-02 21:31:40,594 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD: closes. applyIndex: 0
2020-06-02 21:31:40,594 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-06-02 21:31:40,597 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-SegmentedRaftLogWorker close()
2020-06-02 21:31:40,601 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.762fe7a3-380a-4155-b73e-ca6d55ceee4d
2020-06-02 21:31:40,601 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD
2020-06-02 21:31:40,601 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD
2020-06-02 21:31:40,601 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(250)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965: shutdown
2020-06-02 21:31:40,601 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-633CCBAC6965,id=762fe7a3-380a-4155-b73e-ca6d55ceee4d
2020-06-02 21:31:40,601 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: shutdown LeaderState
2020-06-02 21:31:40,602 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(242)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-PendingRequests: sendNotLeaderResponses
2020-06-02 21:31:40,602 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_appender.762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965
2020-06-02 21:31:40,602 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(142)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-StateMachineUpdater: set stopIndex = 0
2020-06-02 21:31:40,602 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(288)) - group-633CCBAC6965: Taking a snapshot at:(t:1, i:0) file /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis/a484410b-1fcc-41d6-954e-633ccbac6965/sm/snapshot.1_0
2020-06-02 21:31:40,603 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(299)) - group-633CCBAC6965: Finished taking a snapshot at:(t:1, i:0) file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f236d362-8fa3-4887-bed0-5caa5af079b0/datanode-2/data/ratis/a484410b-1fcc-41d6-954e-633ccbac6965/sm/snapshot.1_0 time:0
2020-06-02 21:31:40,603 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(277)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-StateMachineUpdater: Took a snapshot at index 0
2020-06-02 21:31:40,603 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(87)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2020-06-02 21:31:40,603 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-StateMachineUpdater] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.state_machine.762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965
2020-06-02 21:31:40,603 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(387)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965: closes. applyIndex: 0
2020-06-02 21:31:40,603 [762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(321)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2020-06-02 21:31:40,604 [ForkJoinPool.commonPool-worker-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(229)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965-SegmentedRaftLogWorker close()
2020-06-02 21:31:40,606 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.log_worker.762fe7a3-380a-4155-b73e-ca6d55ceee4d
2020-06-02 21:31:40,606 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.leader_election.762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965
2020-06-02 21:31:40,606 [ForkJoinPool.commonPool-worker-1] INFO  metrics.RatisMetrics (RatisMetrics.java:unregister(46)) - Unregistering Metrics Registry : ratis.server.762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-633CCBAC6965
2020-06-02 21:31:40,606 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(165)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: shutdown server with port 35853 now
2020-06-02 21:31:40,609 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(173)) - 762fe7a3-380a-4155-b73e-ca6d55ceee4d: shutdown server with port 35853 successfully
2020-06-02 21:31:40,611 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service BlockDeletingService
2020-06-02 21:31:40,624 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(424)) - Ozone container server stopped.
2020-06-02 21:31:40,652 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@d088aa2{hddsDatanode,/,null,UNAVAILABLE}{jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2020-06-02 21:31:40,665 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@2e504073{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-06-02 21:31:40,665 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-06-02 21:31:40,676 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@2b4566d9{static,/static,jar:file:/home/user/.m2/repository/org/apache/hadoop/hadoop-hdds-container-service/0.6.0-SNAPSHOT/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,UNAVAILABLE}
2020-06-02 21:31:40,697 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@408be914{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-06-02 21:31:40,710 [Listener at 127.0.0.1/35123] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(476)) - Stopping the StorageContainerManager
2020-06-02 21:31:40,710 [Listener at 127.0.0.1/35123] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(824)) - Stopping Replication Manager Service.
2020-06-02 21:31:40,710 [Listener at 127.0.0.1/35123] INFO  container.ReplicationManager (ReplicationManager.java:stop(215)) - Replication Monitor Thread is not running.
2020-06-02 21:31:40,710 [Listener at 127.0.0.1/35123] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(831)) - Stopping Lease Manager of the command watchers
2020-06-02 21:31:40,710 [Listener at 127.0.0.1/35123] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(838)) - Stopping datanode service RPC server
2020-06-02 21:31:40,710 [Listener at 127.0.0.1/35123] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(361)) - Stopping the RPC server for DataNodes
2020-06-02 21:31:40,710 [Listener at 127.0.0.1/35123] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41783
2020-06-02 21:31:40,710 [CommandWatcher-LeaseManager#LeaseMonitor] ERROR lease.LeaseManager (LeaseManager.java:run(238)) - Execution was interrupted 
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:234)
	at java.lang.Thread.run(Thread.java:748)
2020-06-02 21:31:40,713 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-06-02 21:31:40,713 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-06-02 21:31:40,737 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(661)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2020-06-02 21:31:40,737 [Listener at 127.0.0.1/35123] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(846)) - Stopping block service RPC server
2020-06-02 21:31:40,737 [Listener at 127.0.0.1/35123] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(158)) - Stopping the RPC server for Block Protocol
2020-06-02 21:31:40,737 [Listener at 127.0.0.1/35123] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38639
2020-06-02 21:31:40,741 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-06-02 21:31:40,741 [Listener at 127.0.0.1/35123] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(853)) - Stopping the StorageContainerLocationProtocol RPC server
2020-06-02 21:31:40,741 [Listener at 127.0.0.1/35123] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(166)) - Stopping the RPC server for Client Protocol
2020-06-02 21:31:40,741 [Listener at 127.0.0.1/35123] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40443
2020-06-02 21:31:40,741 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-06-02 21:31:40,743 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-06-02 21:31:40,743 [Listener at 127.0.0.1/35123] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(860)) - Stopping Storage Container Manager HTTP server.
2020-06-02 21:31:40,744 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@223d5cbd{scm,/,null,UNAVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2020-06-02 21:31:40,744 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-06-02 21:31:40,745 [Listener at 127.0.0.1/35123] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@3dcdd0e0{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-06-02 21:31:40,745 [Listener at 127.0.0.1/35123] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-06-02 21:31:40,745 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@328d06d2{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2020-06-02 21:31:40,745 [Listener at 127.0.0.1/35123] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@26772240{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-06-02 21:31:40,747 [Listener at 127.0.0.1/35123] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(871)) - Stopping Block Manager Service.
2020-06-02 21:31:40,747 [Listener at 127.0.0.1/35123] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service SCMBlockDeletingService
2020-06-02 21:31:40,747 [Listener at 127.0.0.1/35123] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service SCMBlockDeletingService
2020-06-02 21:31:40,748 [Listener at 127.0.0.1/35123] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(896)) - Stopping SCM Event Queue.
2020-06-02 21:31:40,761 [Listener at 127.0.0.1/35123] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2020-06-02 21:31:40,800 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2020-06-02 21:31:40,804 [Listener at 127.0.0.1/35123] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2020-06-02 21:31:40,816 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:40,816 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:41,816 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:41,816 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:42,704 [Thread-431] INFO  impl.FollowerState (FollowerState.java:run(108)) - d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-FollowerState: change to CANDIDATE, lastRpcTime:5075ms, electionTimeout:5074ms
2020-06-02 21:31:42,704 [Thread-431] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d602985a-24b1-4fac-a391-54201d0c9032: shutdown FollowerState
2020-06-02 21:31:42,704 [Thread-431] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 21:31:42,704 [Thread-431] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d602985a-24b1-4fac-a391-54201d0c9032: start LeaderElection
2020-06-02 21:31:42,734 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8: begin an election at term 1 for -1: [d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721], old=null
2020-06-02 21:31:42,734 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d602985a-24b1-4fac-a391-54201d0c9032: shutdown LeaderElection
2020-06-02 21:31:42,735 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 21:31:42,735 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-68E42DFFCBC4 with new leaderId: d602985a-24b1-4fac-a391-54201d0c9032
2020-06-02 21:31:42,735 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4: change Leader from null to d602985a-24b1-4fac-a391-54201d0c9032 at term 1 for becomeLeader, leader elected after 5116ms
2020-06-02 21:31:42,735 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 21:31:42,735 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 21:31:42,735 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4
2020-06-02 21:31:42,735 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 21:31:42,735 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 21:31:42,736 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 21:31:42,736 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 21:31:42,736 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 21:31:42,737 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d602985a-24b1-4fac-a391-54201d0c9032: start LeaderState
2020-06-02 21:31:42,737 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 21:31:42,738 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4: set configuration 0: [d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721], old=null at 0
2020-06-02 21:31:42,738 [d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data/ratis/3ff59c3b-467b-4556-8b45-68e42dffcbc4/current/log_inprogress_0
2020-06-02 21:31:42,775 [Thread-433] INFO  impl.FollowerState (FollowerState.java:run(108)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-FollowerState: change to CANDIDATE, lastRpcTime:5136ms, electionTimeout:5136ms
2020-06-02 21:31:42,775 [Thread-433] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d602985a-24b1-4fac-a391-54201d0c9032: shutdown FollowerState
2020-06-02 21:31:42,775 [Thread-433] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 21:31:42,775 [Thread-433] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d602985a-24b1-4fac-a391-54201d0c9032: start LeaderElection
2020-06-02 21:31:42,797 [Thread-438] INFO  impl.FollowerState (FollowerState.java:run(108)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-FollowerState: change to CANDIDATE, lastRpcTime:5084ms, electionTimeout:5071ms
2020-06-02 21:31:42,797 [Thread-438] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: shutdown FollowerState
2020-06-02 21:31:42,797 [Thread-438] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 21:31:42,797 [Thread-438] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: start LeaderElection
2020-06-02 21:31:42,803 [d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-LeaderElection9: begin an election at term 1 for -1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null
2020-06-02 21:31:42,817 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:42,817 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:42,819 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection10: begin an election at term 1 for -1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null
2020-06-02 21:31:42,828 [Thread-435] INFO  impl.FollowerState (FollowerState.java:run(108)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-FollowerState: change to CANDIDATE, lastRpcTime:5153ms, electionTimeout:5151ms
2020-06-02 21:31:42,833 [Thread-435] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 165904ff-00de-48fd-9e56-43cbf105f57b: shutdown FollowerState
2020-06-02 21:31:42,833 [Thread-435] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 21:31:42,834 [Thread-435] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 165904ff-00de-48fd-9e56-43cbf105f57b: start LeaderElection
2020-06-02 21:31:42,872 [165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-LeaderElection11: begin an election at term 1 for -1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null
2020-06-02 21:31:42,901 [Thread-441] INFO  impl.FollowerState (FollowerState.java:run(108)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-FollowerState: change to CANDIDATE, lastRpcTime:5158ms, electionTimeout:5148ms
2020-06-02 21:31:42,901 [Thread-441] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 165904ff-00de-48fd-9e56-43cbf105f57b: shutdown FollowerState
2020-06-02 21:31:42,901 [Thread-441] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 21:31:42,901 [Thread-441] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 165904ff-00de-48fd-9e56-43cbf105f57b: start LeaderElection
2020-06-02 21:31:42,941 [d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-LeaderElection9: Election REJECTED; received 2 response(s) [d602985a-24b1-4fac-a391-54201d0c9032<-165904ff-00de-48fd-9e56-43cbf105f57b#0:FAIL-t1, d602985a-24b1-4fac-a391-54201d0c9032<-4cee6ed5-fd4a-4537-baa8-98df5210e899#0:FAIL-t1] and 0 exception(s); d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9:t1, leader=null, voted=d602985a-24b1-4fac-a391-54201d0c9032, raftlog=d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null
2020-06-02 21:31:42,941 [d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2020-06-02 21:31:42,941 [d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d602985a-24b1-4fac-a391-54201d0c9032: shutdown LeaderElection
2020-06-02 21:31:42,942 [d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d602985a-24b1-4fac-a391-54201d0c9032: start FollowerState
2020-06-02 21:31:42,948 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12: begin an election at term 1 for -1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593], old=null
2020-06-02 21:31:42,965 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 165904ff-00de-48fd-9e56-43cbf105f57b: shutdown LeaderElection
2020-06-02 21:31:42,965 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 21:31:42,965 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-19AF50B4B849 with new leaderId: 165904ff-00de-48fd-9e56-43cbf105f57b
2020-06-02 21:31:42,965 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849: change Leader from null to 165904ff-00de-48fd-9e56-43cbf105f57b at term 1 for becomeLeader, leader elected after 5227ms
2020-06-02 21:31:42,965 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 21:31:42,965 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 21:31:42,965 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849
2020-06-02 21:31:42,966 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 21:31:42,966 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 21:31:42,966 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection10: Election REJECTED; received 2 response(s) [4cee6ed5-fd4a-4537-baa8-98df5210e899<-165904ff-00de-48fd-9e56-43cbf105f57b#0:FAIL-t1, 4cee6ed5-fd4a-4537-baa8-98df5210e899<-d602985a-24b1-4fac-a391-54201d0c9032#0:FAIL-t1] and 0 exception(s); 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9:t1, leader=null, voted=4cee6ed5-fd4a-4537-baa8-98df5210e899, raftlog=4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null
2020-06-02 21:31:42,966 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection10] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2020-06-02 21:31:42,966 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 21:31:42,966 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 21:31:42,966 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: shutdown LeaderElection
2020-06-02 21:31:42,967 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 21:31:42,967 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: start FollowerState
2020-06-02 21:31:42,967 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 165904ff-00de-48fd-9e56-43cbf105f57b: start LeaderState
2020-06-02 21:31:42,967 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 21:31:42,981 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-LeaderElection12] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849: set configuration 0: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593], old=null at 0
2020-06-02 21:31:42,997 [165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-LeaderElection11: Election REJECTED; received 2 response(s) [165904ff-00de-48fd-9e56-43cbf105f57b<-d602985a-24b1-4fac-a391-54201d0c9032#0:FAIL-t1, 165904ff-00de-48fd-9e56-43cbf105f57b<-4cee6ed5-fd4a-4537-baa8-98df5210e899#0:FAIL-t1] and 0 exception(s); 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9:t1, leader=null, voted=165904ff-00de-48fd-9e56-43cbf105f57b, raftlog=165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null
2020-06-02 21:31:42,997 [165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-LeaderElection11] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2020-06-02 21:31:42,997 [165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 165904ff-00de-48fd-9e56-43cbf105f57b: shutdown LeaderElection
2020-06-02 21:31:42,997 [165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 165904ff-00de-48fd-9e56-43cbf105f57b: start FollowerState
2020-06-02 21:31:42,997 [165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data/ratis/8b1f1230-5464-4e4f-ae6a-19af50b4b849/current/log_inprogress_0
2020-06-02 21:31:43,016 [Thread-443] INFO  impl.FollowerState (FollowerState.java:run(108)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-FollowerState: change to CANDIDATE, lastRpcTime:5170ms, electionTimeout:5161ms
2020-06-02 21:31:43,016 [Thread-443] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: shutdown FollowerState
2020-06-02 21:31:43,016 [Thread-443] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2020-06-02 21:31:43,016 [Thread-443] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: start LeaderElection
2020-06-02 21:31:43,042 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13: begin an election at term 1 for -1: [4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null
2020-06-02 21:31:43,042 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: shutdown LeaderElection
2020-06-02 21:31:43,042 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2020-06-02 21:31:43,042 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-130F7F42E658 with new leaderId: 4cee6ed5-fd4a-4537-baa8-98df5210e899
2020-06-02 21:31:43,042 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658: change Leader from null to 4cee6ed5-fd4a-4537-baa8-98df5210e899 at term 1 for becomeLeader, leader elected after 5202ms
2020-06-02 21:31:43,042 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 21:31:43,042 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 21:31:43,042 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658
2020-06-02 21:31:43,043 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 21:31:43,043 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 21:31:43,043 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 21:31:43,043 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 21:31:43,043 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 21:31:43,043 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: start LeaderState
2020-06-02 21:31:43,043 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 21:31:43,045 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data/ratis/4af8b8aa-419f-4392-bdff-130f7f42e658/current/log_inprogress_0
2020-06-02 21:31:43,052 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-LeaderElection13] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658: set configuration 0: [4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null at 0
2020-06-02 21:31:43,817 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:43,817 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:44,817 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:44,817 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:45,819 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:45,819 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:46,819 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:46,819 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:47,820 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:47,820 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:48,064 [Thread-458] INFO  impl.FollowerState (FollowerState.java:run(108)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-FollowerState: change to CANDIDATE, lastRpcTime:5097ms, electionTimeout:5072ms
2020-06-02 21:31:48,064 [Thread-458] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: shutdown FollowerState
2020-06-02 21:31:48,064 [Thread-458] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2020-06-02 21:31:48,064 [Thread-458] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: start LeaderElection
2020-06-02 21:31:48,090 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(206)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14: begin an election at term 2 for -1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null
2020-06-02 21:31:48,100 [Thread-456] INFO  impl.FollowerState (FollowerState.java:run(108)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-FollowerState: change to CANDIDATE, lastRpcTime:5158ms, electionTimeout:5135ms
2020-06-02 21:31:48,100 [Thread-456] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d602985a-24b1-4fac-a391-54201d0c9032: shutdown FollowerState
2020-06-02 21:31:48,100 [Thread-456] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2020-06-02 21:31:48,110 [Thread-456] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d602985a-24b1-4fac-a391-54201d0c9032: start LeaderElection
2020-06-02 21:31:48,129 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:4cee6ed5-fd4a-4537-baa8-98df5210e899
2020-06-02 21:31:48,129 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 165904ff-00de-48fd-9e56-43cbf105f57b: shutdown FollowerState
2020-06-02 21:31:48,129 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 165904ff-00de-48fd-9e56-43cbf105f57b: start FollowerState
2020-06-02 21:31:48,130 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9: changes role from CANDIDATE to FOLLOWER at term 2 for recognizeCandidate:4cee6ed5-fd4a-4537-baa8-98df5210e899
2020-06-02 21:31:48,130 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d602985a-24b1-4fac-a391-54201d0c9032: shutdown LeaderElection
2020-06-02 21:31:48,130 [Thread-459] INFO  impl.FollowerState (FollowerState.java:run(117)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2020-06-02 21:31:48,133 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(61)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14: Election PASSED; received 1 response(s) [4cee6ed5-fd4a-4537-baa8-98df5210e899<-165904ff-00de-48fd-9e56-43cbf105f57b#0:OK-t2] and 0 exception(s); 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9:t2, leader=null, voted=4cee6ed5-fd4a-4537-baa8-98df5210e899, raftlog=4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null
2020-06-02 21:31:48,134 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: shutdown LeaderElection
2020-06-02 21:31:48,134 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(173)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2020-06-02 21:31:48,134 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-F31AACB741A9 with new leaderId: 4cee6ed5-fd4a-4537-baa8-98df5210e899
2020-06-02 21:31:48,134 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9: change Leader from null to 4cee6ed5-fd4a-4537-baa8-98df5210e899 at term 2 for becomeLeader, leader elected after 10426ms
2020-06-02 21:31:48,134 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.staging.catchup.gap = 1000 (default)
2020-06-02 21:31:48,134 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.sleep.time = 25ms (default)
2020-06-02 21:31:48,134 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  metrics.RatisMetrics (RatisMetrics.java:lambda$create$0(39)) - Creating Metrics Registry : ratis.log_appender.4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9
2020-06-02 21:31:48,134 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.element-limit = 1024 (custom)
2020-06-02 21:31:48,134 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.write.byte-limit = 1073741824 (custom)
2020-06-02 21:31:48,134 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout = 180s (custom)
2020-06-02 21:31:48,135 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.timeout.denomination = 1s (default)
2020-06-02 21:31:48,135 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.watch.element-limit = 65536 (default)
2020-06-02 21:31:48,135 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-06-02 21:31:48,135 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:31:48,135 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2020-06-02 21:31:48,135 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2020-06-02 21:31:48,135 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 21:31:48,135 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:31:48,136 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2020-06-02 21:31:48,136 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2020-06-02 21:31:48,145 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2020-06-02 21:31:48,145 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(44)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2020-06-02 21:31:48,145 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.rpc.request.timeout = 60s (custom)
2020-06-02 21:31:48,145 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(44)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2020-06-02 21:31:48,146 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899: start LeaderState
2020-06-02 21:31:48,146 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 21:31:48,146 [d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:run(155)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-LeaderElection15: skip running since this is already CLOSING
2020-06-02 21:31:48,168 [grpc-default-executor-2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-F31AACB741A9 with new leaderId: 4cee6ed5-fd4a-4537-baa8-98df5210e899
2020-06-02 21:31:48,180 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9: change Leader from null to 4cee6ed5-fd4a-4537-baa8-98df5210e899 at term 2 for appendEntries, leader elected after 10499ms
2020-06-02 21:31:48,165 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d602985a-24b1-4fac-a391-54201d0c9032: start FollowerState
2020-06-02 21:31:48,161 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-LeaderElection14] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9: set configuration 0: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null at 0
2020-06-02 21:31:48,147 [4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-2/data/ratis/b31d4ef4-1745-476e-a4da-f31aacb741a9/current/log_inprogress_0
2020-06-02 21:31:48,215 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9: set configuration 0: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null at 0
2020-06-02 21:31:48,215 [grpc-default-executor-2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 21:31:48,216 [grpc-default-executor-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(762)) - Leader change notification received for group: group-F31AACB741A9 with new leaderId: 4cee6ed5-fd4a-4537-baa8-98df5210e899
2020-06-02 21:31:48,216 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(255)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9: change Leader from null to 4cee6ed5-fd4a-4537-baa8-98df5210e899 at term 2 for appendEntries, leader elected after 10580ms
2020-06-02 21:31:48,219 [165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - 165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-1/data/ratis/b31d4ef4-1745-476e-a4da-f31aacb741a9/current/log_inprogress_0
2020-06-02 21:31:48,228 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(356)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9: set configuration 0: [165904ff-00de-48fd-9e56-43cbf105f57b:172.17.0.2:40593, d602985a-24b1-4fac-a391-54201d0c9032:172.17.0.2:41721, 4cee6ed5-fd4a-4537-baa8-98df5210e899:172.17.0.2:32789], old=null at 0
2020-06-02 21:31:48,229 [grpc-default-executor-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(391)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-SegmentedRaftLogWorker: Starting segment from index:0
2020-06-02 21:31:48,240 [d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(583)) - d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-SegmentedRaftLogWorker: created new log segment /github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-b88fb71c-b2b9-4799-9372-430bb3cba9f9/datanode-0/data/ratis/b31d4ef4-1745-476e-a4da-f31aacb741a9/current/log_inprogress_0
2020-06-02 21:31:48,820 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:48,820 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:49,820 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:49,821 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:50,821 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:50,821 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:51,821 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:51,821 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:52,822 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:52,822 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:53,822 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:53,822 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:54,822 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:54,822 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:55,823 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:55,823 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:56,823 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:56,823 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:57,823 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:57,824 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:58,824 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:58,824 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:31:59,824 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:31:59,824 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:00,824 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:00,825 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:01,825 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:01,825 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:02,825 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:02,825 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:03,825 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:03,826 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:04,826 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:04,826 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:05,826 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:05,826 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:06,826 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:06,827 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:07,827 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:07,827 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:08,827 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:08,827 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:09,827 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:09,828 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:10,828 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:10,828 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:11,828 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:11,829 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:12,829 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:12,829 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:13,829 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:13,829 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:14,829 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:14,830 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:15,830 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:15,830 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:16,830 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:16,830 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:17,831 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:17,831 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:18,831 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:18,831 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:19,831 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:19,831 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:20,832 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:20,832 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:21,832 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:21,832 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:22,832 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:22,833 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:23,833 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:23,833 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:24,833 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:24,833 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:25,833 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:25,834 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:26,834 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:26,834 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:27,834 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:27,834 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:28,835 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:28,835 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:29,835 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(177)) - Nodes are ready. Got 3 of 3 DN Heartbeats.
2020-06-02 21:32:29,835 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(180)) - Waiting for cluster to exit safe mode
2020-06-02 21:32:30,097 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(387)) - Shutting down the Mini Ozone Cluster
2020-06-02 21:32:30,097 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(402)) - Stopping the Mini Ozone Cluster
2020-06-02 21:32:30,097 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(484)) - Stopping the OzoneManager
2020-06-02 21:32:30,097 [Listener at 127.0.0.1/40631] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40631
2020-06-02 21:32:30,106 [Listener at 127.0.0.1/40631] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(410)) - Stopping OMDoubleBuffer flush thread
2020-06-02 21:32:30,106 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(342)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit. OMDoubleBufferFlushThread
2020-06-02 21:32:30,106 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-06-02 21:32:30,106 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-06-02 21:32:30,108 [Listener at 127.0.0.1/40631] INFO  utils.BackgroundService (BackgroundService.java:shutdown(157)) - Shutting down service KeyDeletingService
2020-06-02 21:32:30,109 [Listener at 127.0.0.1/40631] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.w.WebAppContext@53b5efa9{ozoneManager,/,null,UNAVAILABLE}{file:/github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2020-06-02 21:32:30,111 [Listener at 127.0.0.1/40631] INFO  server.AbstractConnector (AbstractConnector.java:doStop(380)) - Stopped ServerConnector@41fa0259{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-06-02 21:32:30,111 [Listener at 127.0.0.1/40631] INFO  server.session (HouseKeeper.java:stopScavenging(158)) - node0 Stopped scavenging
2020-06-02 21:32:30,111 [Listener at 127.0.0.1/40631] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@433de956{static,/static,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,UNAVAILABLE}
2020-06-02 21:32:30,111 [Listener at 127.0.0.1/40631] INFO  handler.ContextHandler (ContextHandler.java:doStop(1016)) - Stopped o.e.j.s.ServletContextHandler@4fa0a2f5{logs,/logs,file:///github/workspace/mnt/ozone/hadoop-ozone/integration-test/target/log,UNAVAILABLE}
2020-06-02 21:32:30,118 [Listener at 127.0.0.1/40631] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(461)) - Stopping the HddsDatanodes
il.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Command processor thread" daemon prio=5 tid=202 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$171/825626209.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"qtp1698308954-102" daemon prio=5 tid=102 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"7bbd2402-c364-4868-9d2c-73c7d416b8c0@group-D9D1F22491BD-SegmentedRaftLogWorker"  prio=5 tid=256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 3 on default port 38639" daemon prio=5 tid=59 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp200163889-162" daemon prio=5 tid=162 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp200163889-165" daemon prio=5 tid=165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@dc47fd2" daemon prio=5 tid=152 terminated
java.lang.Thread.State: TERMINATED
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-Safe mode statusForBlockManagerImpl"  prio=5 tid=30 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=247 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"prometheus" daemon prio=5 tid=106 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.metrics2.impl.SinkQueue.waitForData(SinkQueue.java:114)
        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:83)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:135)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:89)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=218 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=10 runnable
java.lang.Thread.State: RUNNABLE
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp2032299360-210" daemon prio=5 tid=210 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp1344012241-190" daemon prio=5 tid=190 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 19 on default port 41783" daemon prio=5 tid=95 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-2-0" daemon prio=5 tid=228 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$456/429341673@2ec93441" daemon prio=5 tid=310 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:151)
        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:105)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:77)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$456/429341673.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"762fe7a3-380a-4155-b73e-ca6d55ceee4d@group-D9D1F22491BD-SegmentedRaftLogWorker"  prio=5 tid=270 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"DataNode DiskChecker thread 0" daemon prio=5 tid=155 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 12 on default port 38639" daemon prio=5 tid=68 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=248 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 13 on default port 40443" daemon prio=5 tid=49 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 19 on default port 40443" daemon prio=5 tid=55 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)

====> TEST TIMED OUT. PRINTING THREAD DUMP. <====

Timestamp: 2020-06-02 09:32:30,100

"SCMBlockDeletingService#1" daemon prio=5 tid=441 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-Delayed safe mode statusForReplicationManager"  prio=5 tid=366 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server idle connection scanner for port 33899" daemon prio=5 tid=361 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$456/429341673@36d4a115" daemon prio=5 tid=632 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:151)
        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:105)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:77)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$456/429341673.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-StateMachineUpdater" daemon prio=5 tid=606 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 18 on default port 33899" daemon prio=5 tid=387 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-126-thread-1"  prio=5 tid=512 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"BlockDeletingService#0" daemon prio=5 tid=568 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"CommandWatcher-LeaseManager#LeaseMonitor" daemon prio=5 tid=368 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:234)
        at java.lang.Thread.run(Thread.java:748)
"Command processor thread" daemon prio=5 tid=506 terminated
java.lang.Thread.State: TERMINATED
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$171/825626209.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 2 on default port 33899" daemon prio=5 tid=371 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-81-thread-1"  prio=5 tid=363 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=550 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 1 on default port 38427" daemon prio=5 tid=390 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=505 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 4 on default port 38913" daemon prio=5 tid=413 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp1664721333-435" daemon prio=5 tid=435 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server Responder" daemon prio=5 tid=358 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"DataNode DiskChecker thread 0" daemon prio=5 tid=526 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-2-0" daemon prio=5 tid=572 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 5 on default port 38913" daemon prio=5 tid=414 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-106-thread-1"  prio=5 tid=585 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=578 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Socket Reader #1 for port 0"  prio=5 tid=445 terminated
java.lang.Thread.State: TERMINATED
        at sun.nio.ch.FileDispatcherImpl.closeIntFD(Native Method)
        at sun.nio.ch.EPollSelectorImpl.implClose(EPollSelectorImpl.java:151)
        at sun.nio.ch.SelectorImpl.implCloseSelector(SelectorImpl.java:113)
        at java.nio.channels.spi.AbstractSelector.close(AbstractSelector.java:111)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1224)
"IPC Server handler 8 on default port 38913" daemon prio=5 tid=417 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Thread-467" daemon prio=5 tid=634 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:243)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:97)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=529 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"grpc-default-executor-0" daemon prio=5 tid=276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 15 on default port 38427" daemon prio=5 tid=404 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 14 on default port 38427" daemon prio=5 tid=403 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=503 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 7 on default port 38427" daemon prio=5 tid=396 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Listener at 127.0.0.1/40631"  prio=5 tid=348 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.lang.Thread.join(Thread.java:1252)
        at java.lang.Thread.join(Thread.java:1326)
        at org.apache.hadoop.ipc.Server$Listener$Reader.shutdown(Server.java:1289)
        at org.apache.hadoop.ipc.Server$Listener.doStop(Server.java:1430)
        at org.apache.hadoop.ipc.Server.stop(Server.java:3369)
        at org.apache.hadoop.ozone.om.OzoneManager.stop(OzoneManager.java:1276)
        at org.apache.hadoop.ozone.MiniOzoneClusterImpl.stopOM(MiniOzoneClusterImpl.java:485)
        at org.apache.hadoop.ozone.MiniOzoneClusterImpl.stop(MiniOzoneClusterImpl.java:403)
        at org.apache.hadoop.ozone.MiniOzoneClusterImpl.shutdown(MiniOzoneClusterImpl.java:391)
        at org.apache.hadoop.ozone.om.TestOMDbCheckpointServlet.shutdown(TestOMDbCheckpointServlet.java:107)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
        at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
"165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-StateMachineUpdater" daemon prio=5 tid=603 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 17 on default port 38913" daemon prio=5 tid=426 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-3-0" daemon prio=5 tid=561 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 18 on default port 38913" daemon prio=5 tid=427 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp1701467136-514-acceptor-0@16bcf70e-ServerConnector@6c784d9f{HTTP/1.1,[http/1.1]}{0.0.0.0:44057}" daemon prio=3 tid=514 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"qtp905556896-494" daemon prio=5 tid=494 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 16 on default port 33899" daemon prio=5 tid=385 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-StateMachineUpdater" daemon prio=5 tid=587 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"grpc-nio-worker-ELG-3-1" daemon prio=5 tid=274 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:807)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 3 on default port 38427" daemon prio=5 tid=392 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"grpc-nio-boss-ELG-1-1" daemon prio=5 tid=230 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
"165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-StateMachineUpdater" daemon prio=5 tid=594 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"Command processor thread" daemon prio=5 tid=552 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$171/825626209.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 3 on default port 33899" daemon prio=5 tid=372 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp520431307-473" daemon prio=5 tid=473 terminated
java.lang.Thread.State: TERMINATED
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/1189801389.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"pool-122-thread-1"  prio=5 tid=592 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=219 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp800882060-540" daemon prio=5 tid=540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 11 on default port 38427" daemon prio=5 tid=400 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-0-0" daemon prio=5 tid=564 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-StateMachineUpdater" daemon prio=5 tid=590 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-7a11fcdc-1"  prio=5 tid=437 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 0 on default port 33899" daemon prio=5 tid=369 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 7 on default port 38913" daemon prio=5 tid=416 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-138-thread-1"  prio=5 tid=597 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"BlockDeletingService#0" daemon prio=5 tid=562 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1701467136-517" daemon prio=5 tid=517 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp520431307-472" daemon prio=5 tid=472 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Socket Reader #1 for port 0"  prio=5 tid=356 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"qtp1701467136-519" daemon prio=5 tid=519 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"d602985a-24b1-4fac-a391-54201d0c9032@group-F31AACB741A9-SegmentedRaftLogWorker"  prio=5 tid=589 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 17 on default port 38427" daemon prio=5 tid=406 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server Responder" daemon prio=5 tid=362 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"IPC Server handler 1 on default port 33899" daemon prio=5 tid=370 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=221 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 19 on default port 38913" daemon prio=5 tid=428 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"grpc-default-executor-1" daemon prio=5 tid=275 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode State Machine Thread - 0" daemon prio=5 tid=534 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Thread-468" daemon prio=5 tid=631 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"IPC Server handler 12 on default port 38427" daemon prio=5 tid=401 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 19 on default port 33899" daemon prio=5 tid=388 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 16 on default port 38427" daemon prio=5 tid=405 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 9 on default port 33899" daemon prio=5 tid=378 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 15 on default port 38913" daemon prio=5 tid=424 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp1701467136-518" daemon prio=5 tid=518 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 2 on default port 38427" daemon prio=5 tid=391 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"process reaper" daemon prio=10 tid=11 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"KeyDeletingService#0" daemon prio=5 tid=449 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp905556896-496" daemon prio=5 tid=496 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp1664721333-432" daemon prio=5 tid=432 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-Delayed safe mode statusForSCMPipelineManager"  prio=5 tid=367 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$456/429341673@329aa636" daemon prio=5 tid=633 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:151)
        at org.apache.ratis.grpc.server.GrpcLogAppender.runAppenderImpl(GrpcLogAppender.java:105)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon.run(LogAppender.java:77)
        at org.apache.ratis.server.impl.LogAppender$AppenderDaemon$$Lambda$456/429341673.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"qtp520431307-478" daemon prio=5 tid=478 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server listener on 0" daemon prio=5 tid=444 terminated
java.lang.Thread.State: TERMINATED
        at org.apache.hadoop.ipc.Server$Listener.getSelector(Server.java:1434)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1305)
"IPC Server handler 4 on default port 33899" daemon prio=5 tid=373 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 11 on default port 38913" daemon prio=5 tid=420 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server idle connection scanner for port 38427" daemon prio=5 tid=357 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp520431307-477" daemon prio=5 tid=477 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Periodic HDDS volume checker" daemon prio=5 tid=484 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"SCMBlockDeletingService#0" daemon prio=5 tid=439 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@71fdd28f" daemon prio=5 tid=553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-5cd9d5ea-1"  prio=5 tid=545 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-596c7f17-1"  prio=5 tid=480 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1701467136-515" daemon prio=5 tid=515 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=530 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d002e6b" daemon prio=5 tid=440 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"qtp905556896-493" daemon prio=5 tid=493 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"pool-95-thread-1"  prio=5 tid=471 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 16 on default port 38913" daemon prio=5 tid=425 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@36a8b459" daemon prio=5 tid=533 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=579 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1664721333-434" daemon prio=5 tid=434 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"IPC Server idle connection scanner for port 40631" daemon prio=5 tid=446 terminated
java.lang.Thread.State: TERMINATED
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 10 on default port 33899" daemon prio=5 tid=379 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 10 on default port 38913" daemon prio=5 tid=419 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-115-thread-1" daemon prio=5 tid=510 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Periodic HDDS volume checker" daemon prio=5 tid=501 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1664721333-429" daemon prio=5 tid=429 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/1189801389.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"Datanode State Machine Thread - 0" daemon prio=5 tid=508 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Parameter Sending Thread #0" daemon prio=5 tid=111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp905556896-495" daemon prio=5 tid=495 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"165904ff-00de-48fd-9e56-43cbf105f57b@group-F31AACB741A9-SegmentedRaftLogWorker"  prio=5 tid=593 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 13 on default port 33899" daemon prio=5 tid=382 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 1 on default port 38913" daemon prio=5 tid=410 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp905556896-490-acceptor-0@59651654-ServerConnector@32fa4197{HTTP/1.1,[http/1.1]}{0.0.0.0:39325}" daemon prio=3 tid=490 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=349 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-99-thread-1" daemon prio=5 tid=486 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-1b25d066-1"  prio=5 tid=521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 5 on default port 38427" daemon prio=5 tid=394 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server idle connection scanner for port 38913" daemon prio=5 tid=353 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp800882060-541" daemon prio=5 tid=541 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 8 on default port 33899" daemon prio=5 tid=377 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"4cee6ed5-fd4a-4537-baa8-98df5210e899@group-130F7F42E658-SegmentedRaftLogWorker"  prio=5 tid=605 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server Responder" daemon prio=5 tid=447 terminated
java.lang.Thread.State: TERMINATED
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"EventQueue-ContainerReportForContainerReportHandler" daemon prio=5 tid=577 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 11 on default port 33899" daemon prio=5 tid=380 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-1-0" daemon prio=5 tid=565 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1664721333-431" daemon prio=5 tid=431 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=551 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=504 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 0 on default port 38913" daemon prio=5 tid=409 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 17 on default port 33899" daemon prio=5 tid=386 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Command processor thread" daemon prio=5 tid=532 terminated
java.lang.Thread.State: TERMINATED
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:472)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$171/825626209.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server listener on 0" daemon prio=5 tid=355 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"IPC Server handler 15 on default port 33899" daemon prio=5 tid=384 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-131-thread-1" daemon prio=5 tid=527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-127-thread-1"  prio=5 tid=522 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=175 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@30bd0c07" daemon prio=5 tid=482 terminated
java.lang.Thread.State: TERMINATED
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 14 on default port 38913" daemon prio=5 tid=423 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Thread-457" daemon prio=5 tid=621 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"IPC Server handler 10 on default port 38427" daemon prio=5 tid=399 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 13 on default port 38427" daemon prio=5 tid=402 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp905556896-489" daemon prio=5 tid=489 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/1189801389.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"Thread-461" daemon prio=5 tid=625 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"ChunkWriter-0-0" daemon prio=5 tid=570 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 0 on default port 38427" daemon prio=5 tid=389 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"EventQueue-Safe mode statusForSCMClientProtocolServer"  prio=5 tid=364 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-96-thread-1"  prio=5 tid=481 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp520431307-474" daemon prio=5 tid=474 terminated
java.lang.Thread.State: TERMINATED
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 19 on default port 38427" daemon prio=5 tid=408 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-StateMachineUpdater" daemon prio=5 tid=599 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:200)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:165)
        at java.lang.Thread.run(Thread.java:748)
"OMDoubleBufferFlushThread" daemon prio=5 tid=443 terminated
java.lang.Thread.State: TERMINATED
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:482)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:232)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$80/1718363529.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=581 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-2-0" daemon prio=5 tid=560 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=531 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=174 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-142-thread-1"  prio=5 tid=536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-Safe mode statusForBlockManagerImpl"  prio=5 tid=365 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=176 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server listener on 0" daemon prio=5 tid=351 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=220 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-3-0" daemon prio=5 tid=567 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 3 on default port 38913" daemon prio=5 tid=412 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"java.util.concurrent.ThreadPoolExecutor$Worker@5ba33ad3[State = -1, empty queue]" daemon prio=5 tid=635 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=177 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=549 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp800882060-543" daemon prio=5 tid=543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp800882060-539" daemon prio=5 tid=539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-3-0" daemon prio=5 tid=573 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"BlockDeletingService#1" daemon prio=5 tid=575 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"grpc-nio-worker-ELG-3-2" daemon prio=5 tid=273 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:807)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:748)
"Socket Reader #1 for port 0"  prio=5 tid=352 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"RatisPipelineUtilsThread"  prio=5 tid=350 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 2 on default port 38913" daemon prio=5 tid=411 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp905556896-492" daemon prio=5 tid=492 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"qtp1701467136-520" daemon prio=5 tid=520 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"Session-HouseKeeper-4140480a-1"  prio=5 tid=497 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"KeyDeletingService#1" daemon prio=5 tid=470 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1664721333-433" daemon prio=5 tid=433 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=576 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Datanode State Machine Thread - 0" daemon prio=5 tid=554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Thread-466" daemon prio=5 tid=630 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:243)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:97)
"qtp905556896-491" daemon prio=5 tid=491 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"ChunkWriter-1-0" daemon prio=5 tid=559 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Thread-445" daemon prio=5 tid=609 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderState$EventQueue.poll(LeaderState.java:121)
        at org.apache.ratis.server.impl.LeaderState$EventProcessor.run(LeaderState.java:496)
"d602985a-24b1-4fac-a391-54201d0c9032@group-68E42DFFCBC4-SegmentedRaftLogWorker"  prio=5 tid=586 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"qtp520431307-479" daemon prio=5 tid=479 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 12 on default port 38913" daemon prio=5 tid=421 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 5 on default port 33899" daemon prio=5 tid=374 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"BlockDeletingService#1" daemon prio=5 tid=563 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 4 on default port 38427" daemon prio=5 tid=393 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"DataNode DiskChecker thread 0" daemon prio=5 tid=509 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-143-thread-1"  prio=5 tid=546 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 9 on default port 38427" daemon prio=5 tid=398 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-111-thread-1"  prio=5 tid=498 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-110-thread-1"  prio=5 tid=488 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 14 on default port 33899" daemon prio=5 tid=383 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 6 on default port 33899" daemon prio=5 tid=375 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@423bb09b" daemon prio=5 tid=507 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"qtp1701467136-513" daemon prio=5 tid=513 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/1189801389.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"main"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1610)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:93)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:79)
        at org.apache.hadoop.test.TimedOutTestsListener.testFailure(TimedOutTestsListener.java:67)
        at org.junit.runner.notification.RunNotifier$4.notifyListener(RunNotifier.java:139)
        at org.junit.runner.notification.RunNotifier$SafeNotifier.run(RunNotifier.java:61)
        at org.junit.runner.notification.RunNotifier.fireTestFailures(RunNotifier.java:134)
        at org.junit.runner.notification.RunNotifier.fireTestFailure(RunNotifier.java:128)
        at org.apache.maven.surefire.common.junit4.Notifier.fireTestFailure(Notifier.java:114)
        at org.junit.internal.runners.model.EachTestNotifier.addFailure(EachTestNotifier.java:23)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:275)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
"qtp1664721333-436" daemon prio=5 tid=436 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 6 on default port 38913" daemon prio=5 tid=415 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"DataNode DiskChecker thread 0" daemon prio=5 tid=485 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"165904ff-00de-48fd-9e56-43cbf105f57b@group-19AF50B4B849-SegmentedRaftLogWorker"  prio=5 tid=602 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"qtp800882060-544" daemon prio=5 tid=544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 7 on default port 33899" daemon prio=5 tid=376 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ChunkWriter-0-0" daemon prio=5 tid=558 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Socket Reader #1 for port 0"  prio=5 tid=360 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"Periodic HDDS volume checker" daemon prio=5 tid=525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"grpc-default-executor-3" daemon prio=5 tid=300 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp520431307-476" daemon prio=5 tid=476 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"4cee6ed5-fd4a-4537-baa8-98df5210e899@group-F31AACB741A9-SegmentedRaftLogWorker"  prio=5 tid=598 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:137)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:287)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server Responder" daemon prio=5 tid=354 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)
"BlockDeletingService#1" daemon prio=5 tid=569 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 12 on default port 33899" daemon prio=5 tid=381 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 13 on default port 38913" daemon prio=5 tid=422 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp1664721333-430-acceptor-0@24f6d469-ServerConnector@37e85f63{HTTP/1.1,[http/1.1]}{0.0.0.0:44557}" daemon prio=3 tid=430 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:385)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:701)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 6 on default port 38427" daemon prio=5 tid=395 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp800882060-537" daemon prio=5 tid=537 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:472)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:409)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:135)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$72/1189801389.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
        at java.lang.Thread.run(Thread.java:748)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=9 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readInt(DataInputStream.java:387)
        at org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:115)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:390)
        at java.lang.Thread.run(Thread.java:748)
"BlockDeletingService#0" daemon prio=5 tid=574 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"grpc-default-executor-2" daemon prio=5 tid=277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp520431307-475" daemon prio=5 tid=475 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:875)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:925)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 9 on default port 38913" daemon prio=5 tid=418 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java