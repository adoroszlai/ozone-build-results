Attaching to ozone-topology_datanode_3_1, ozone-topology_datanode_5_1, ozone-topology_om_1, ozone-topology_datanode_6_1, ozone-topology_datanode_1_1, ozone-topology_datanode_4_1, ozone-topology_scm_1, ozone-topology_datanode_2_1
datanode_2_1  | Enabled profiling in kernel
datanode_2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2_1  | 2020-06-19 01:07:30,167 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2_1  | /************************************************************
datanode_2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2_1  | STARTUP_MSG:   host = ce5ff476a058/10.5.0.5
datanode_2_1  | STARTUP_MSG:   args = []
datanode_2_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/5ebb065848a63b211bcfce646fbe395c2eab042a ; compiled by 'jenkins1001' on 2020-06-19T00:46Z
datanode_2_1  | STARTUP_MSG:   java = 11.0.6
datanode_2_1  | ************************************************************/
datanode_2_1  | 2020-06-19 01:07:30,229 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2_1  | 2020-06-19 01:07:32,505 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2_1  | 2020-06-19 01:07:33,173 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2_1  | 2020-06-19 01:07:34,522 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2_1  | 2020-06-19 01:07:34,523 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2_1  | 2020-06-19 01:07:35,131 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:ce5ff476a058 ip:10.5.0.5
datanode_2_1  | 2020-06-19 01:07:35,389 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2_1  | 2020-06-19 01:07:35,412 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2_1  | 2020-06-19 01:07:35,420 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2_1  | 2020-06-19 01:07:35,456 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2_1  | 2020-06-19 01:07:35,632 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2_1  | 2020-06-19 01:07:41,696 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2_1  | 2020-06-19 01:07:42,011 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2_1  | 2020-06-19 01:07:42,362 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2_1  | 2020-06-19 01:07:42,364 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2_1  | 2020-06-19 01:07:42,369 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-19 01:07:42,370 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2_1  | 2020-06-19 01:07:42,383 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-06-19 01:07:43,674 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-06-19 01:07:45,073 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2_1  | 2020-06-19 01:07:45,218 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2_1  | 2020-06-19 01:07:45,419 [main] INFO util.log: Logging initialized @21392ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2_1  | 2020-06-19 01:07:46,393 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2_1  | 2020-06-19 01:07:46,408 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2_1  | 2020-06-19 01:07:46,438 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2_1  | 2020-06-19 01:07:46,440 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_2_1  | 2020-06-19 01:07:46,440 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_2_1  | 2020-06-19 01:07:46,440 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_2_1  | 2020-06-19 01:07:46,835 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2_1  | 2020-06-19 01:07:46,890 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2_1  | 2020-06-19 01:07:46,907 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2_1  | 2020-06-19 01:07:47,066 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2_1  | 2020-06-19 01:07:47,072 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2_1  | 2020-06-19 01:07:47,073 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_2_1  | 2020-06-19 01:07:47,121 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2_1  | 2020-06-19 01:07:47,128 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@52d97ab6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2_1  | 2020-06-19 01:07:47,129 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b5e7036{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2_1  | 2020-06-19 01:07:47,450 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@806996{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-9252512492379550644.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2_1  | 2020-06-19 01:07:47,489 [main] INFO server.AbstractConnector: Started ServerConnector@44f24a20{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2_1  | 2020-06-19 01:07:47,491 [main] INFO server.Server: Started @23463ms
datanode_1_1  | Enabled profiling in kernel
datanode_1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1_1  | 2020-06-19 01:07:30,842 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1_1  | /************************************************************
datanode_1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1_1  | STARTUP_MSG:   host = a9b36bc5a21b/10.5.0.4
datanode_1_1  | STARTUP_MSG:   args = []
datanode_1_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2_1  | 2020-06-19 01:07:47,502 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2_1  | 2020-06-19 01:07:47,503 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2_1  | 2020-06-19 01:07:47,510 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2_1  | 2020-06-19 01:07:47,593 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1cc78c64] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2_1  | 2020-06-19 01:07:48,229 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2_1  | 2020-06-19 01:07:50,674 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2_1  | 2020-06-19 01:07:50,676 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2_1  | 2020-06-19 01:07:50,681 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 1fe601f2-329a-46b5-8003-e31a11712904 at port 9858
datanode_2_1  | 2020-06-19 01:07:50,729 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 1fe601f2-329a-46b5-8003-e31a11712904: start RPC server
datanode_2_1  | 2020-06-19 01:07:51,023 [Datanode State Machine Thread - 0] INFO server.GrpcService: 1fe601f2-329a-46b5-8003-e31a11712904: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/5ebb065848a63b211bcfce646fbe395c2eab042a ; compiled by 'jenkins1001' on 2020-06-19T00:46Z
datanode_1_1  | STARTUP_MSG:   java = 11.0.6
datanode_1_1  | ************************************************************/
datanode_1_1  | 2020-06-19 01:07:30,892 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1_1  | 2020-06-19 01:07:33,252 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1_1  | 2020-06-19 01:07:33,968 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1_1  | 2020-06-19 01:07:35,263 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1_1  | 2020-06-19 01:07:35,264 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1_1  | 2020-06-19 01:07:35,842 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:a9b36bc5a21b ip:10.5.0.4
datanode_1_1  | 2020-06-19 01:07:36,203 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1_1  | 2020-06-19 01:07:36,214 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1_1  | 2020-06-19 01:07:36,216 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1_1  | 2020-06-19 01:07:36,257 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1_1  | 2020-06-19 01:07:36,305 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1_1  | 2020-06-19 01:07:41,924 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1_1  | 2020-06-19 01:07:42,215 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1_1  | 2020-06-19 01:07:42,536 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1_1  | 2020-06-19 01:07:42,553 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1_1  | 2020-06-19 01:07:42,553 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-06-19 01:07:42,554 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1_1  | 2020-06-19 01:07:42,587 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-06-19 01:07:43,413 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-06-19 01:07:44,829 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1_1  | 2020-06-19 01:07:45,024 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1_1  | 2020-06-19 01:07:45,248 [main] INFO util.log: Logging initialized @19959ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1_1  | 2020-06-19 01:07:46,218 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1_1  | 2020-06-19 01:07:46,244 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1_1  | 2020-06-19 01:07:46,266 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1_1  | 2020-06-19 01:07:46,268 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_1_1  | 2020-06-19 01:07:46,275 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_1_1  | 2020-06-19 01:07:46,284 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_1_1  | 2020-06-19 01:07:46,454 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1_1  | 2020-06-19 01:07:46,644 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1_1  | 2020-06-19 01:07:46,654 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1_1  | 2020-06-19 01:07:46,802 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1_1  | 2020-06-19 01:07:46,805 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1_1  | 2020-06-19 01:07:46,807 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1_1  | 2020-06-19 01:07:46,866 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1_1  | 2020-06-19 01:07:46,871 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@337bbfdf{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1_1  | 2020-06-19 01:07:46,872 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@524a076e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1_1  | 2020-06-19 01:07:47,203 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@38e7ed69{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-11766896959756792680.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1_1  | 2020-06-19 01:07:47,248 [main] INFO server.AbstractConnector: Started ServerConnector@73844119{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2_1  | 2020-06-19 01:07:54,657 [Command processor thread] INFO impl.RaftServerProxy: 1fe601f2-329a-46b5-8003-e31a11712904: addNew group-3764FF5BA268:[1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858] returns group-3764FF5BA268:java.util.concurrent.CompletableFuture@4029fef7[Not completed]
datanode_2_1  | 2020-06-19 01:07:54,773 [pool-19-thread-1] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904: new RaftServerImpl for group-3764FF5BA268:[1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-06-19 01:07:54,777 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-06-19 01:07:54,778 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-06-19 01:07:54,784 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-06-19 01:07:54,785 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-06-19 01:07:54,790 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-06-19 01:07:54,809 [pool-19-thread-1] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268: ConfigurationManager, init=-1: [1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-06-19 01:07:54,819 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-06-19 01:07:54,842 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-06-19 01:07:54,857 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/3ed600d5-9c82-4b23-a409-3764ff5ba268 does not exist. Creating ...
datanode_2_1  | 2020-06-19 01:07:54,883 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/3ed600d5-9c82-4b23-a409-3764ff5ba268/in_use.lock acquired by nodename 6@ce5ff476a058
datanode_2_1  | 2020-06-19 01:07:54,894 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/3ed600d5-9c82-4b23-a409-3764ff5ba268 has been successfully formatted.
datanode_2_1  | 2020-06-19 01:07:54,924 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-3764FF5BA268: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-06-19 01:07:54,924 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-06-19 01:07:54,961 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-06-19 01:07:54,991 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-06-19 01:07:54,993 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-19 01:07:54,997 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-19 01:07:55,016 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268
datanode_2_1  | 2020-06-19 01:07:55,141 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-06-19 01:07:55,184 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/3ed600d5-9c82-4b23-a409-3764ff5ba268
datanode_2_1  | 2020-06-19 01:07:55,193 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-06-19 01:07:55,196 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-06-19 01:07:55,203 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-19 01:07:55,206 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-06-19 01:07:55,213 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-06-19 01:07:55,214 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-06-19 01:07:55,219 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-06-19 01:07:55,220 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-06-19 01:07:55,222 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-06-19 01:07:55,297 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-06-19 01:07:55,345 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-19 01:07:55,360 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-19 01:07:55,481 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-06-19 01:07:55,482 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-06-19 01:07:55,482 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-06-19 01:07:55,489 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-06-19 01:07:55,490 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-06-19 01:07:55,606 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268
datanode_2_1  | 2020-06-19 01:07:55,616 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268
datanode_2_1  | 2020-06-19 01:07:55,640 [pool-19-thread-1] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268: start as a follower, conf=-1: [1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858], old=null
datanode_2_1  | 2020-06-19 01:07:55,655 [pool-19-thread-1] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-06-19 01:07:55,657 [pool-19-thread-1] INFO impl.RoleInfo: 1fe601f2-329a-46b5-8003-e31a11712904: start FollowerState
datanode_2_1  | 2020-06-19 01:07:55,689 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3764FF5BA268,id=1fe601f2-329a-46b5-8003-e31a11712904
datanode_2_1  | 2020-06-19 01:07:55,691 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268
datanode_2_1  | 2020-06-19 01:07:55,752 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "3ed600d5-9c82-4b23-a409-3764ff5ba268"
datanode_2_1  | .
datanode_1_1  | 2020-06-19 01:07:47,254 [main] INFO server.Server: Started @21966ms
datanode_1_1  | 2020-06-19 01:07:47,266 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1_1  | 2020-06-19 01:07:47,267 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1_1  | 2020-06-19 01:07:47,273 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1_1  | 2020-06-19 01:07:47,392 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5ca16d7a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1_1  | 2020-06-19 01:07:47,965 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1_1  | 2020-06-19 01:07:50,459 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_1_1  | java.net.SocketTimeoutException: Call From a9b36bc5a21b/10.5.0.4 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.4:58690 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2_1  | 2020-06-19 01:07:55,753 [Command processor thread] INFO impl.RaftServerProxy: 1fe601f2-329a-46b5-8003-e31a11712904: addNew group-0E2EB5F51AAD:[1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858] returns group-0E2EB5F51AAD:java.util.concurrent.CompletableFuture@53588709[Not completed]
datanode_2_1  | 2020-06-19 01:07:55,760 [pool-19-thread-1] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904: new RaftServerImpl for group-0E2EB5F51AAD:[1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-06-19 01:07:55,764 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-06-19 01:07:55,765 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-06-19 01:07:55,765 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-06-19 01:07:55,765 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-06-19 01:07:55,768 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-06-19 01:07:55,769 [pool-19-thread-1] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD: ConfigurationManager, init=-1: [1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-06-19 01:07:55,769 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-06-19 01:07:55,770 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-06-19 01:07:55,771 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/eaaeea6c-49fd-4c41-b247-0e2eb5f51aad does not exist. Creating ...
datanode_2_1  | 2020-06-19 01:07:55,780 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/eaaeea6c-49fd-4c41-b247-0e2eb5f51aad/in_use.lock acquired by nodename 6@ce5ff476a058
datanode_2_1  | 2020-06-19 01:07:55,783 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/eaaeea6c-49fd-4c41-b247-0e2eb5f51aad has been successfully formatted.
datanode_2_1  | 2020-06-19 01:07:55,783 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-0E2EB5F51AAD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-06-19 01:07:55,783 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-06-19 01:07:55,784 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-06-19 01:07:55,784 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-06-19 01:07:55,785 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-19 01:07:55,785 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-19 01:07:55,786 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD
datanode_2_1  | 2020-06-19 01:07:55,786 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-06-19 01:07:55,794 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/eaaeea6c-49fd-4c41-b247-0e2eb5f51aad
datanode_2_1  | 2020-06-19 01:07:55,794 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-06-19 01:07:55,795 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-06-19 01:07:55,795 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-19 01:07:55,795 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-06-19 01:07:55,795 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-06-19 01:07:55,796 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-06-19 01:07:55,796 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-06-19 01:07:55,797 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-06-19 01:07:55,797 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-06-19 01:07:55,798 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-06-19 01:07:55,804 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-19 01:07:55,806 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-19 01:07:55,807 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-06-19 01:07:55,807 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-06-19 01:07:55,810 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-06-19 01:07:55,810 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-06-19 01:07:55,810 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-06-19 01:07:55,810 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD
datanode_2_1  | 2020-06-19 01:07:55,811 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD
datanode_2_1  | 2020-06-19 01:07:55,817 [pool-19-thread-1] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD: start as a follower, conf=-1: [1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858], old=null
datanode_2_1  | 2020-06-19 01:07:55,820 [pool-19-thread-1] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-06-19 01:07:55,820 [pool-19-thread-1] INFO impl.RoleInfo: 1fe601f2-329a-46b5-8003-e31a11712904: start FollowerState
datanode_2_1  | 2020-06-19 01:07:55,826 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0E2EB5F51AAD,id=1fe601f2-329a-46b5-8003-e31a11712904
datanode_2_1  | 2020-06-19 01:07:55,827 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD
datanode_1_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_1_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_1_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_1_1  | 	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
datanode_1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_1_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.4:58690 remote=scm/10.5.0.71:9861]
datanode_1_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_1_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_1_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_1_1  | 2020-06-19 01:07:51,420 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1_1  | 2020-06-19 01:07:51,421 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1_1  | 2020-06-19 01:07:51,421 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis bad929e1-92e9-4f9a-b8b4-4f52cb0ead89 at port 9858
datanode_1_1  | 2020-06-19 01:07:51,472 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89: start RPC server
datanode_1_1  | 2020-06-19 01:07:51,625 [Datanode State Machine Thread - 0] INFO server.GrpcService: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1_1  | 2020-06-19 01:07:56,414 [Command processor thread] INFO impl.RaftServerProxy: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89: addNew group-3B67E3CF1029:[bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858] returns group-3B67E3CF1029:java.util.concurrent.CompletableFuture@2bddb428[Not completed]
datanode_1_1  | 2020-06-19 01:07:56,541 [pool-19-thread-1] INFO impl.RaftServerImpl: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89: new RaftServerImpl for group-3B67E3CF1029:[bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-06-19 01:07:56,544 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-06-19 01:07:56,553 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-06-19 01:07:56,555 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-06-19 01:07:56,556 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-06-19 01:07:56,557 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-06-19 01:07:56,582 [pool-19-thread-1] INFO impl.RaftServerImpl: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029: ConfigurationManager, init=-1: [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-06-19 01:07:56,583 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-06-19 01:07:56,595 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-06-19 01:07:56,607 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e5232efc-6eb4-4532-a52f-3b67e3cf1029 does not exist. Creating ...
datanode_1_1  | 2020-06-19 01:07:56,625 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e5232efc-6eb4-4532-a52f-3b67e3cf1029/in_use.lock acquired by nodename 6@a9b36bc5a21b
datanode_1_1  | 2020-06-19 01:07:56,634 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e5232efc-6eb4-4532-a52f-3b67e3cf1029 has been successfully formatted.
datanode_1_1  | 2020-06-19 01:07:56,637 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-3B67E3CF1029: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-06-19 01:07:56,669 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-06-19 01:07:56,697 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-06-19 01:07:56,740 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-06-19 01:07:56,749 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-06-19 01:07:56,760 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-06-19 01:07:56,780 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029
datanode_1_1  | 2020-06-19 01:07:56,918 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-06-19 01:07:56,967 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/e5232efc-6eb4-4532-a52f-3b67e3cf1029
datanode_1_1  | 2020-06-19 01:07:56,973 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-06-19 01:07:56,974 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-06-19 01:07:56,977 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-06-19 01:07:56,977 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-06-19 01:07:56,978 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-06-19 01:07:56,979 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-06-19 01:07:56,980 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-06-19 01:07:56,985 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-06-19 01:07:56,986 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-06-19 01:07:57,090 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-06-19 01:07:57,117 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-06-19 01:07:57,120 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-06-19 01:07:57,137 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-06-19 01:07:57,189 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-06-19 01:07:57,190 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-06-19 01:07:57,219 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-06-19 01:07:57,219 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-06-19 01:07:57,320 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029
datanode_1_1  | 2020-06-19 01:07:57,355 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029
datanode_1_1  | 2020-06-19 01:07:57,420 [pool-19-thread-1] INFO impl.RaftServerImpl: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029: start as a follower, conf=-1: [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858], old=null
datanode_1_1  | 2020-06-19 01:07:57,423 [pool-19-thread-1] INFO impl.RaftServerImpl: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-06-19 01:07:57,425 [pool-19-thread-1] INFO impl.RoleInfo: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89: start FollowerState
datanode_1_1  | 2020-06-19 01:07:57,452 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3B67E3CF1029,id=bad929e1-92e9-4f9a-b8b4-4f52cb0ead89
datanode_1_1  | 2020-06-19 01:07:57,454 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029
datanode_1_1  | 2020-06-19 01:07:57,527 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "e5232efc-6eb4-4532-a52f-3b67e3cf1029"
datanode_1_1  | .
datanode_1_1  | 2020-06-19 01:07:57,533 [Command processor thread] INFO impl.RaftServerProxy: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89: addNew group-0E2EB5F51AAD:[1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858] returns group-0E2EB5F51AAD:java.util.concurrent.CompletableFuture@525b8f4e[Not completed]
datanode_1_1  | 2020-06-19 01:07:57,536 [pool-19-thread-1] INFO impl.RaftServerImpl: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89: new RaftServerImpl for group-0E2EB5F51AAD:[1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-06-19 01:07:57,551 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-06-19 01:07:57,559 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-06-19 01:07:57,568 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-06-19 01:07:57,568 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-06-19 01:07:57,568 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-06-19 01:07:57,568 [pool-19-thread-1] INFO impl.RaftServerImpl: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD: ConfigurationManager, init=-1: [1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-06-19 01:07:57,569 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-06-19 01:07:57,569 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-06-19 01:07:57,569 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/eaaeea6c-49fd-4c41-b247-0e2eb5f51aad does not exist. Creating ...
datanode_1_1  | 2020-06-19 01:07:57,573 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/eaaeea6c-49fd-4c41-b247-0e2eb5f51aad/in_use.lock acquired by nodename 6@a9b36bc5a21b
datanode_1_1  | 2020-06-19 01:07:57,574 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/eaaeea6c-49fd-4c41-b247-0e2eb5f51aad has been successfully formatted.
datanode_1_1  | 2020-06-19 01:07:57,575 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-0E2EB5F51AAD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-06-19 01:07:57,575 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-06-19 01:07:57,604 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-06-19 01:07:57,604 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-06-19 01:07:57,604 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-06-19 01:07:57,604 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-06-19 01:07:57,604 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD
datanode_1_1  | 2020-06-19 01:07:57,604 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-06-19 01:07:57,604 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/eaaeea6c-49fd-4c41-b247-0e2eb5f51aad
datanode_1_1  | 2020-06-19 01:07:57,604 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-06-19 01:07:57,604 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-06-19 01:07:57,604 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-06-19 01:07:57,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-06-19 01:07:57,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-06-19 01:07:57,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-06-19 01:07:57,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-06-19 01:07:57,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-06-19 01:07:57,605 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-06-19 01:07:57,618 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-06-19 01:07:57,622 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-06-19 01:07:57,622 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-06-19 01:07:57,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-06-19 01:07:57,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-06-19 01:07:57,625 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-06-19 01:07:57,626 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-06-19 01:07:57,627 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-06-19 01:07:57,627 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD
datanode_1_1  | 2020-06-19 01:07:57,628 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD
datanode_1_1  | 2020-06-19 01:07:57,634 [pool-19-thread-1] INFO impl.RaftServerImpl: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD: start as a follower, conf=-1: [1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858], old=null
datanode_1_1  | 2020-06-19 01:07:57,638 [pool-19-thread-1] INFO impl.RaftServerImpl: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-06-19 01:07:57,638 [pool-19-thread-1] INFO impl.RoleInfo: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89: start FollowerState
datanode_1_1  | 2020-06-19 01:07:57,642 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0E2EB5F51AAD,id=bad929e1-92e9-4f9a-b8b4-4f52cb0ead89
datanode_1_1  | 2020-06-19 01:07:57,643 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD
datanode_1_1  | 2020-06-19 01:07:59,403 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "eaaeea6c-49fd-4c41-b247-0e2eb5f51aad"
datanode_1_1  | .
datanode_1_1  | 2020-06-19 01:08:01,160 [grpc-default-executor-0] INFO impl.RaftServerImpl: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:1fe601f2-329a-46b5-8003-e31a11712904
datanode_1_1  | 2020-06-19 01:08:01,161 [grpc-default-executor-0] INFO impl.RoleInfo: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89: shutdown FollowerState
datanode_1_1  | 2020-06-19 01:08:01,162 [grpc-default-executor-0] INFO impl.RoleInfo: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89: start FollowerState
datanode_1_1  | 2020-06-19 01:08:01,162 [Thread-23] INFO impl.FollowerState: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1_1  | 2020-06-19 01:08:01,506 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0E2EB5F51AAD with new leaderId: 1fe601f2-329a-46b5-8003-e31a11712904
datanode_1_1  | 2020-06-19 01:08:01,507 [grpc-default-executor-0] INFO impl.RaftServerImpl: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD: change Leader from null to 1fe601f2-329a-46b5-8003-e31a11712904 at term 1 for appendEntries, leader elected after 3931ms
datanode_1_1  | 2020-06-19 01:08:01,680 [grpc-default-executor-0] INFO impl.RaftServerImpl: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD: set configuration 0: [1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858], old=null at 0
datanode_1_1  | 2020-06-19 01:08:01,685 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-06-19 01:08:02,016 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-0E2EB5F51AAD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/eaaeea6c-49fd-4c41-b247-0e2eb5f51aad/current/log_inprogress_0
datanode_1_1  | 2020-06-19 01:08:02,564 [Thread-21] INFO impl.FollowerState: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-FollowerState: change to CANDIDATE, lastRpcTime:5139ms, electionTimeout:5112ms
datanode_1_1  | 2020-06-19 01:08:02,564 [Thread-21] INFO impl.RoleInfo: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89: shutdown FollowerState
datanode_1_1  | 2020-06-19 01:08:02,564 [Thread-21] INFO impl.RaftServerImpl: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1_1  | 2020-06-19 01:08:02,578 [Thread-21] INFO impl.RoleInfo: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89: start LeaderElection
datanode_1_1  | 2020-06-19 01:08:02,594 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO impl.LeaderElection: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1: begin an election at term 1 for -1: [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858], old=null
datanode_1_1  | 2020-06-19 01:08:02,595 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO impl.RoleInfo: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89: shutdown LeaderElection
datanode_1_1  | 2020-06-19 01:08:02,595 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO impl.RaftServerImpl: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1_1  | 2020-06-19 01:08:02,596 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-3B67E3CF1029 with new leaderId: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89
datanode_1_1  | 2020-06-19 01:08:02,596 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO impl.RaftServerImpl: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029: change Leader from null to bad929e1-92e9-4f9a-b8b4-4f52cb0ead89 at term 1 for becomeLeader, leader elected after 5926ms
datanode_1_1  | 2020-06-19 01:08:02,600 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1_1  | 2020-06-19 01:08:02,600 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1_1  | 2020-06-19 01:08:02,603 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029
datanode_1_1  | 2020-06-19 01:08:02,612 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1_1  | 2020-06-19 01:08:02,618 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1_1  | 2020-06-19 01:08:02,624 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1_1  | 2020-06-19 01:08:02,624 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1_1  | 2020-06-19 01:08:02,627 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1_1  | 2020-06-19 01:08:02,639 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO impl.RoleInfo: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89: start LeaderState
datanode_1_1  | 2020-06-19 01:08:02,645 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-06-19 01:08:02,652 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-LeaderElection1] INFO impl.RaftServerImpl: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029: set configuration 0: [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858], old=null at 0
datanode_1_1  | 2020-06-19 01:08:02,666 [bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89@group-3B67E3CF1029-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e5232efc-6eb4-4532-a52f-3b67e3cf1029/current/log_inprogress_0
datanode_1_1  | 2020-06-19 01:13:05,983 [RatisApplyTransactionExecutor 2] INFO interfaces.Container: Container 2 is synced with bcsId 111.
datanode_1_1  | 2020-06-19 01:13:05,983 [RatisApplyTransactionExecutor 2] INFO interfaces.Container: Container 2 is synced with bcsId 111.
datanode_1_1  | 2020-06-19 01:13:05,996 [RatisApplyTransactionExecutor 2] INFO interfaces.Container: Container 2 is closed with bcsId 111.
datanode_1_1  | 2020-06-19 01:13:06,057 [RatisApplyTransactionExecutor 4] INFO interfaces.Container: Container 4 is synced with bcsId 131.
datanode_1_1  | 2020-06-19 01:13:06,059 [RatisApplyTransactionExecutor 4] INFO interfaces.Container: Container 4 is synced with bcsId 131.
datanode_1_1  | 2020-06-19 01:13:06,070 [RatisApplyTransactionExecutor 4] INFO interfaces.Container: Container 4 is closed with bcsId 131.
datanode_1_1  | 2020-06-19 01:13:06,114 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is synced with bcsId 142.
datanode_1_1  | 2020-06-19 01:13:06,115 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is synced with bcsId 142.
datanode_1_1  | 2020-06-19 01:13:06,117 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is closed with bcsId 142.
datanode_1_1  | 2020-06-19 01:13:06,158 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is synced with bcsId 153.
datanode_2_1  | 2020-06-19 01:07:59,252 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "eaaeea6c-49fd-4c41-b247-0e2eb5f51aad"
datanode_2_1  | .
datanode_2_1  | 2020-06-19 01:08:00,691 [Thread-20] INFO impl.FollowerState: 1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-FollowerState: change to CANDIDATE, lastRpcTime:5034ms, electionTimeout:5008ms
datanode_2_1  | 2020-06-19 01:08:00,693 [Thread-20] INFO impl.RoleInfo: 1fe601f2-329a-46b5-8003-e31a11712904: shutdown FollowerState
datanode_2_1  | 2020-06-19 01:08:00,693 [Thread-20] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2_1  | 2020-06-19 01:08:00,695 [Thread-20] INFO impl.RoleInfo: 1fe601f2-329a-46b5-8003-e31a11712904: start LeaderElection
datanode_2_1  | 2020-06-19 01:08:00,711 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO impl.LeaderElection: 1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1: begin an election at term 1 for -1: [1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858], old=null
datanode_2_1  | 2020-06-19 01:08:00,718 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO impl.RoleInfo: 1fe601f2-329a-46b5-8003-e31a11712904: shutdown LeaderElection
datanode_2_1  | 2020-06-19 01:08:00,720 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2_1  | 2020-06-19 01:08:00,720 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-3764FF5BA268 with new leaderId: 1fe601f2-329a-46b5-8003-e31a11712904
datanode_2_1  | 2020-06-19 01:08:00,721 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268: change Leader from null to 1fe601f2-329a-46b5-8003-e31a11712904 at term 1 for becomeLeader, leader elected after 5796ms
datanode_2_1  | 2020-06-19 01:08:00,765 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2_1  | 2020-06-19 01:08:00,767 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2_1  | 2020-06-19 01:08:00,776 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268
datanode_2_1  | 2020-06-19 01:08:00,798 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2_1  | 2020-06-19 01:08:00,802 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2_1  | 2020-06-19 01:08:00,849 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2_1  | 2020-06-19 01:08:00,849 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2_1  | 2020-06-19 01:08:00,850 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2_1  | 2020-06-19 01:08:00,899 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO impl.RoleInfo: 1fe601f2-329a-46b5-8003-e31a11712904: start LeaderState
datanode_2_1  | 2020-06-19 01:08:00,964 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-06-19 01:08:00,968 [Thread-22] INFO impl.FollowerState: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-FollowerState: change to CANDIDATE, lastRpcTime:5147ms, electionTimeout:5141ms
datanode_2_1  | 2020-06-19 01:08:00,973 [Thread-22] INFO impl.RoleInfo: 1fe601f2-329a-46b5-8003-e31a11712904: shutdown FollowerState
datanode_2_1  | 2020-06-19 01:08:00,974 [Thread-22] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2_1  | 2020-06-19 01:08:00,974 [Thread-22] INFO impl.RoleInfo: 1fe601f2-329a-46b5-8003-e31a11712904: start LeaderElection
datanode_2_1  | 2020-06-19 01:08:01,037 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO impl.LeaderElection: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2: begin an election at term 1 for -1: [1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858], old=null
datanode_2_1  | 2020-06-19 01:08:01,076 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-LeaderElection1] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268: set configuration 0: [1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-06-19 01:08:01,238 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO impl.LeaderElection: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2: Election PASSED; received 1 response(s) [1fe601f2-329a-46b5-8003-e31a11712904<-e16193af-992b-449b-a054-1b4385464923#0:OK-t1] and 0 exception(s); 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD:t1, leader=null, voted=1fe601f2-329a-46b5-8003-e31a11712904, raftlog=1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858], old=null
datanode_2_1  | 2020-06-19 01:08:01,239 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO impl.RoleInfo: 1fe601f2-329a-46b5-8003-e31a11712904: shutdown LeaderElection
datanode_2_1  | 2020-06-19 01:08:01,256 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2_1  | 2020-06-19 01:08:01,257 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0E2EB5F51AAD with new leaderId: 1fe601f2-329a-46b5-8003-e31a11712904
datanode_2_1  | 2020-06-19 01:08:01,257 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD: change Leader from null to 1fe601f2-329a-46b5-8003-e31a11712904 at term 1 for becomeLeader, leader elected after 5473ms
datanode_2_1  | 2020-06-19 01:08:01,259 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2_1  | 2020-06-19 01:08:01,259 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2_1  | 2020-06-19 01:08:01,260 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD
datanode_1_1  | 2020-06-19 01:13:06,158 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is synced with bcsId 153.
datanode_1_1  | 2020-06-19 01:13:06,173 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is closed with bcsId 153.
datanode_1_1  | 2020-06-19 01:13:06,194 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is synced with bcsId 164.
datanode_1_1  | 2020-06-19 01:13:06,194 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is synced with bcsId 164.
datanode_1_1  | 2020-06-19 01:13:06,198 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is closed with bcsId 164.
datanode_1_1  | 2020-06-19 01:13:06,242 [RatisApplyTransactionExecutor 1] INFO interfaces.Container: Container 11 is synced with bcsId 175.
datanode_1_1  | 2020-06-19 01:13:06,242 [RatisApplyTransactionExecutor 1] INFO interfaces.Container: Container 11 is synced with bcsId 175.
datanode_1_1  | 2020-06-19 01:13:06,252 [RatisApplyTransactionExecutor 1] INFO interfaces.Container: Container 11 is closed with bcsId 175.
datanode_2_1  | 2020-06-19 01:08:01,260 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2_1  | 2020-06-19 01:08:01,261 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2_1  | 2020-06-19 01:08:01,261 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2_1  | 2020-06-19 01:08:01,266 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2_1  | 2020-06-19 01:08:01,267 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2_1  | 2020-06-19 01:08:01,282 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2_1  | 2020-06-19 01:08:01,284 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-19 01:08:01,285 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2_1  | 2020-06-19 01:08:01,310 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2_1  | 2020-06-19 01:08:01,319 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-06-19 01:08:01,320 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-06-19 01:08:01,320 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD
datanode_2_1  | 2020-06-19 01:08:01,345 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2_1  | 2020-06-19 01:08:01,363 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-19 01:08:01,370 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2_1  | 2020-06-19 01:08:01,374 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2_1  | 2020-06-19 01:08:01,374 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-06-19 01:08:01,376 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-06-19 01:08:01,387 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO impl.RoleInfo: 1fe601f2-329a-46b5-8003-e31a11712904: start LeaderState
datanode_2_1  | 2020-06-19 01:08:01,391 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-06-19 01:08:01,438 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-LeaderElection2] INFO impl.RaftServerImpl: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD: set configuration 0: [1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858], old=null at 0
datanode_2_1  | 2020-06-19 01:08:01,908 [1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1fe601f2-329a-46b5-8003-e31a11712904@group-3764FF5BA268-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/3ed600d5-9c82-4b23-a409-3764ff5ba268/current/log_inprogress_0
datanode_2_1  | 2020-06-19 01:08:01,943 [1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/eaaeea6c-49fd-4c41-b247-0e2eb5f51aad/current/log_inprogress_0
datanode_2_1  | 2020-06-19 01:09:01,671 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1,entriesCount=1,lastEntry=(t:1, i:0)
datanode_2_1  | 2020-06-19 01:09:08,830 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4,entriesCount=1,lastEntry=(t:1, i:1)
datanode_2_1  | 2020-06-19 01:09:08,907 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5,entriesCount=1,lastEntry=(t:1, i:2)
datanode_2_1  | 2020-06-19 01:09:09,809 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6,entriesCount=1,lastEntry=(t:1, i:3)
datanode_2_1  | 2020-06-19 01:09:09,823 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=7,entriesCount=1,lastEntry=(t:1, i:4)
datanode_2_1  | 2020-06-19 01:09:12,582 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=9,entriesCount=1,lastEntry=(t:1, i:5)
datanode_2_1  | 2020-06-19 01:09:12,598 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=10,entriesCount=1,lastEntry=(t:1, i:6)
datanode_2_1  | 2020-06-19 01:09:12,616 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=11,entriesCount=1,lastEntry=(t:1, i:7)
datanode_4_1  | Enabled profiling in kernel
datanode_4_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_4_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_4_1  | 2020-06-19 01:07:29,236 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_4_1  | /************************************************************
datanode_4_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_4_1  | STARTUP_MSG:   host = 76a4c07cdf4d/10.5.0.7
datanode_4_1  | STARTUP_MSG:   args = []
datanode_4_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3_1  | Enabled profiling in kernel
datanode_3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3_1  | 2020-06-19 01:07:28,383 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3_1  | /************************************************************
datanode_3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3_1  | STARTUP_MSG:   host = cb48fc6b9da0/10.5.0.6
datanode_3_1  | STARTUP_MSG:   args = []
datanode_3_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_4_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_4_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/5ebb065848a63b211bcfce646fbe395c2eab042a ; compiled by 'jenkins1001' on 2020-06-19T00:46Z
datanode_4_1  | STARTUP_MSG:   java = 11.0.6
datanode_4_1  | ************************************************************/
datanode_4_1  | 2020-06-19 01:07:29,317 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_4_1  | 2020-06-19 01:07:31,273 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_4_1  | 2020-06-19 01:07:32,008 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_4_1  | 2020-06-19 01:07:33,368 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_4_1  | 2020-06-19 01:07:33,370 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_4_1  | 2020-06-19 01:07:33,778 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:76a4c07cdf4d ip:10.5.0.7
datanode_4_1  | 2020-06-19 01:07:34,157 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_4_1  | 2020-06-19 01:07:34,168 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_4_1  | 2020-06-19 01:07:34,173 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_4_1  | 2020-06-19 01:07:34,237 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_4_1  | 2020-06-19 01:07:34,417 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_4_1  | 2020-06-19 01:07:40,611 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4_1  | 2020-06-19 01:07:40,862 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_4_1  | 2020-06-19 01:07:41,260 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_4_1  | 2020-06-19 01:07:41,261 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_4_1  | 2020-06-19 01:07:41,277 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-06-19 01:07:41,278 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_4_1  | 2020-06-19 01:07:41,282 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 2020-06-19 01:07:42,435 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-06-19 01:07:43,807 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_4_1  | 2020-06-19 01:07:43,983 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_4_1  | 2020-06-19 01:07:44,201 [main] INFO util.log: Logging initialized @20965ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_4_1  | 2020-06-19 01:07:45,240 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_4_1  | 2020-06-19 01:07:45,259 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_4_1  | 2020-06-19 01:07:45,287 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_4_1  | 2020-06-19 01:07:45,320 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_4_1  | 2020-06-19 01:07:45,322 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_4_1  | 2020-06-19 01:07:45,323 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_4_1  | 2020-06-19 01:07:45,474 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_4_1  | 2020-06-19 01:07:45,532 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_4_1  | 2020-06-19 01:07:45,540 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_4_1  | 2020-06-19 01:07:45,628 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_4_1  | 2020-06-19 01:07:45,628 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_4_1  | 2020-06-19 01:07:45,635 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_4_1  | 2020-06-19 01:07:45,704 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_4_1  | 2020-06-19 01:07:45,716 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@52d97ab6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_4_1  | 2020-06-19 01:07:45,729 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b5e7036{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_4_1  | 2020-06-19 01:07:46,148 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@806996{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-5863348143302147693.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_4_1  | 2020-06-19 01:07:46,189 [main] INFO server.AbstractConnector: Started ServerConnector@44f24a20{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_4_1  | 2020-06-19 01:07:46,190 [main] INFO server.Server: Started @22954ms
datanode_4_1  | 2020-06-19 01:07:46,201 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_4_1  | 2020-06-19 01:07:46,201 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_4_1  | 2020-06-19 01:07:46,205 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_4_1  | 2020-06-19 01:07:46,271 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7eacf866] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_4_1  | 2020-06-19 01:07:47,384 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_4_1  | 2020-06-19 01:07:49,419 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-06-19 01:07:50,441 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_4_1  | java.net.SocketTimeoutException: Call From 76a4c07cdf4d/10.5.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:45200 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/5ebb065848a63b211bcfce646fbe395c2eab042a ; compiled by 'jenkins1001' on 2020-06-19T00:46Z
datanode_3_1  | STARTUP_MSG:   java = 11.0.6
datanode_3_1  | ************************************************************/
datanode_3_1  | 2020-06-19 01:07:28,458 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3_1  | 2020-06-19 01:07:30,595 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3_1  | 2020-06-19 01:07:31,303 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3_1  | 2020-06-19 01:07:32,672 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3_1  | 2020-06-19 01:07:32,673 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3_1  | 2020-06-19 01:07:33,082 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:cb48fc6b9da0 ip:10.5.0.6
datanode_3_1  | 2020-06-19 01:07:33,436 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3_1  | 2020-06-19 01:07:33,450 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3_1  | 2020-06-19 01:07:33,451 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3_1  | 2020-06-19 01:07:33,477 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3_1  | 2020-06-19 01:07:33,557 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3_1  | 2020-06-19 01:07:39,284 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3_1  | 2020-06-19 01:07:39,574 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3_1  | 2020-06-19 01:07:39,965 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3_1  | 2020-06-19 01:07:39,982 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3_1  | 2020-06-19 01:07:39,984 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-19 01:07:39,995 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3_1  | 2020-06-19 01:07:39,999 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-06-19 01:07:40,896 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-06-19 01:07:42,253 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3_1  | 2020-06-19 01:07:42,456 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3_1  | 2020-06-19 01:07:42,721 [main] INFO util.log: Logging initialized @19810ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3_1  | 2020-06-19 01:07:43,623 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3_1  | 2020-06-19 01:07:43,663 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3_1  | 2020-06-19 01:07:43,715 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3_1  | 2020-06-19 01:07:43,754 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_3_1  | 2020-06-19 01:07:43,758 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_3_1  | 2020-06-19 01:07:43,758 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_3_1  | 2020-06-19 01:07:44,001 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_3_1  | 2020-06-19 01:07:44,065 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3_1  | 2020-06-19 01:07:44,075 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3_1  | 2020-06-19 01:07:44,284 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3_1  | 2020-06-19 01:07:44,285 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3_1  | 2020-06-19 01:07:44,297 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_3_1  | 2020-06-19 01:07:44,391 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3_1  | 2020-06-19 01:07:44,410 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@30b131b2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3_1  | 2020-06-19 01:07:44,419 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6e0c6a7a{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3_1  | 2020-06-19 01:07:45,070 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@22752544{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-17346122355616808064.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3_1  | 2020-06-19 01:07:45,151 [main] INFO server.AbstractConnector: Started ServerConnector@176996c3{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3_1  | 2020-06-19 01:07:45,162 [main] INFO server.Server: Started @22286ms
datanode_3_1  | 2020-06-19 01:07:45,169 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3_1  | 2020-06-19 01:07:45,169 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3_1  | 2020-06-19 01:07:45,210 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3_1  | 2020-06-19 01:07:45,367 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@716ea67e] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3_1  | 2020-06-19 01:07:46,877 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3_1  | 2020-06-19 01:07:48,481 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-06-19 01:07:49,482 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-06-19 01:07:50,496 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_4_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_4_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_4_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_4_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_4_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_4_1  | 	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_4_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_4_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_4_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_4_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_4_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_4_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.7:45200 remote=scm/10.5.0.71:9861]
datanode_4_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_4_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_4_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_4_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_4_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_4_1  | 2020-06-19 01:07:50,681 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_4_1  | 2020-06-19 01:07:50,685 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_4_1  | 2020-06-19 01:07:50,686 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 849d5c96-9fa8-47f6-a4f1-8034e5e21574 at port 9858
datanode_4_1  | 2020-06-19 01:07:50,732 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 849d5c96-9fa8-47f6-a4f1-8034e5e21574: start RPC server
datanode_4_1  | 2020-06-19 01:07:51,042 [Datanode State Machine Thread - 1] INFO server.GrpcService: 849d5c96-9fa8-47f6-a4f1-8034e5e21574: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_4_1  | 2020-06-19 01:07:55,368 [Command processor thread] INFO impl.RaftServerProxy: 849d5c96-9fa8-47f6-a4f1-8034e5e21574: addNew group-5A67F50BBD6B:[849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858] returns group-5A67F50BBD6B:java.util.concurrent.CompletableFuture@57fbf302[Not completed]
datanode_4_1  | 2020-06-19 01:07:55,447 [pool-19-thread-1] INFO impl.RaftServerImpl: 849d5c96-9fa8-47f6-a4f1-8034e5e21574: new RaftServerImpl for group-5A67F50BBD6B:[849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-06-19 01:07:55,456 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-06-19 01:07:55,460 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-06-19 01:07:55,460 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-06-19 01:07:55,461 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-06-19 01:07:55,463 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-06-19 01:07:55,488 [pool-19-thread-1] INFO impl.RaftServerImpl: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B: ConfigurationManager, init=-1: [849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-06-19 01:07:55,495 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-06-19 01:07:55,501 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-06-19 01:07:55,513 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/cec7efc5-1764-4106-bcb0-5a67f50bbd6b does not exist. Creating ...
datanode_4_1  | 2020-06-19 01:07:55,532 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/cec7efc5-1764-4106-bcb0-5a67f50bbd6b/in_use.lock acquired by nodename 6@76a4c07cdf4d
datanode_4_1  | 2020-06-19 01:07:55,540 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/cec7efc5-1764-4106-bcb0-5a67f50bbd6b has been successfully formatted.
datanode_4_1  | 2020-06-19 01:07:55,549 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-5A67F50BBD6B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-06-19 01:07:55,550 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-06-19 01:07:55,571 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-06-19 01:07:55,588 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-06-19 01:07:55,590 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-06-19 01:07:55,592 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-06-19 01:07:55,601 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B
datanode_4_1  | 2020-06-19 01:07:55,711 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | java.net.SocketTimeoutException: Call From cb48fc6b9da0/10.5.0.6 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:52964 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_3_1  | 	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:52964 remote=scm/10.5.0.71:9861]
datanode_3_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_3_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_3_1  | 2020-06-19 01:07:50,648 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3_1  | 2020-06-19 01:07:50,650 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3_1  | 2020-06-19 01:07:50,650 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis f4253cac-8b23-4603-baf9-9d0335b1f337 at port 9858
datanode_3_1  | 2020-06-19 01:07:50,683 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: f4253cac-8b23-4603-baf9-9d0335b1f337: start RPC server
datanode_3_1  | 2020-06-19 01:07:50,998 [Datanode State Machine Thread - 1] INFO server.GrpcService: f4253cac-8b23-4603-baf9-9d0335b1f337: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3_1  | 2020-06-19 01:07:54,426 [Command processor thread] INFO impl.RaftServerProxy: f4253cac-8b23-4603-baf9-9d0335b1f337: addNew group-9B0DAEFCE644:[f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858] returns group-9B0DAEFCE644:java.util.concurrent.CompletableFuture@ad83b4c[Not completed]
datanode_3_1  | 2020-06-19 01:07:54,482 [pool-19-thread-1] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337: new RaftServerImpl for group-9B0DAEFCE644:[f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-06-19 01:07:54,496 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-06-19 01:07:54,499 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-06-19 01:07:54,499 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-06-19 01:07:54,502 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-06-19 01:07:54,510 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-06-19 01:07:54,520 [pool-19-thread-1] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644: ConfigurationManager, init=-1: [f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-06-19 01:07:54,521 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-06-19 01:07:54,551 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-06-19 01:07:54,562 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6c4a8402-d6b3-4216-ba1e-9b0daefce644 does not exist. Creating ...
datanode_3_1  | 2020-06-19 01:07:54,573 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6c4a8402-d6b3-4216-ba1e-9b0daefce644/in_use.lock acquired by nodename 6@cb48fc6b9da0
datanode_3_1  | 2020-06-19 01:07:54,578 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6c4a8402-d6b3-4216-ba1e-9b0daefce644 has been successfully formatted.
datanode_3_1  | 2020-06-19 01:07:54,581 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-9B0DAEFCE644: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-06-19 01:07:54,608 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-06-19 01:07:54,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-06-19 01:07:54,661 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-06-19 01:07:54,664 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-19 01:07:54,730 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-06-19 01:07:54,760 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644
datanode_3_1  | 2020-06-19 01:07:54,854 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-06-19 01:07:54,950 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/6c4a8402-d6b3-4216-ba1e-9b0daefce644
datanode_3_1  | 2020-06-19 01:07:54,951 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-06-19 01:07:54,951 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-19 01:07:54,952 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-06-19 01:07:54,953 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-06-19 01:07:54,958 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-06-19 01:07:54,971 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-06-19 01:07:54,973 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-06-19 01:07:54,975 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-06-19 01:07:54,978 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-06-19 01:07:55,049 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-06-19 01:07:55,111 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-19 01:07:55,111 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-19 01:07:55,135 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-06-19 01:07:55,138 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-06-19 01:07:55,142 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-06-19 01:07:55,144 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-06-19 01:07:55,144 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-06-19 01:07:55,281 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644
datanode_3_1  | 2020-06-19 01:07:55,298 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644
datanode_3_1  | 2020-06-19 01:07:55,335 [pool-19-thread-1] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644: start as a follower, conf=-1: [f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858], old=null
datanode_3_1  | 2020-06-19 01:07:55,343 [pool-19-thread-1] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-06-19 01:07:55,350 [pool-19-thread-1] INFO impl.RoleInfo: f4253cac-8b23-4603-baf9-9d0335b1f337: start FollowerState
datanode_3_1  | 2020-06-19 01:07:55,376 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9B0DAEFCE644,id=f4253cac-8b23-4603-baf9-9d0335b1f337
datanode_3_1  | 2020-06-19 01:07:55,389 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644
datanode_3_1  | 2020-06-19 01:07:55,468 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "6c4a8402-d6b3-4216-ba1e-9b0daefce644"
datanode_3_1  | .
datanode_3_1  | 2020-06-19 01:07:55,471 [Command processor thread] INFO impl.RaftServerProxy: f4253cac-8b23-4603-baf9-9d0335b1f337: addNew group-43CE517B6ECA:[f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858] returns group-43CE517B6ECA:java.util.concurrent.CompletableFuture@784b4ed0[Not completed]
datanode_3_1  | 2020-06-19 01:07:55,473 [pool-19-thread-1] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337: new RaftServerImpl for group-43CE517B6ECA:[f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-06-19 01:07:55,484 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-06-19 01:07:55,484 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-06-19 01:07:55,485 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-06-19 01:07:55,485 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-06-19 01:07:55,485 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-06-19 01:09:12,627 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=12,entriesCount=1,lastEntry=(t:1, i:8)
datanode_2_1  | 2020-06-19 01:09:15,183 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=14,entriesCount=1,lastEntry=(t:1, i:9)
datanode_2_1  | 2020-06-19 01:09:15,201 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=15,entriesCount=1,lastEntry=(t:1, i:10)
datanode_2_1  | 2020-06-19 01:09:15,213 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=16,entriesCount=1,lastEntry=(t:1, i:11)
datanode_2_1  | 2020-06-19 01:09:15,236 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=17,entriesCount=1,lastEntry=(t:1, i:12)
datanode_2_1  | 2020-06-19 01:09:17,797 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=19,entriesCount=1,lastEntry=(t:1, i:13)
datanode_2_1  | 2020-06-19 01:09:17,803 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=20,entriesCount=1,lastEntry=(t:1, i:14)
datanode_2_1  | 2020-06-19 01:09:17,814 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=21,entriesCount=1,lastEntry=(t:1, i:15)
datanode_2_1  | 2020-06-19 01:09:17,829 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=22,entriesCount=1,lastEntry=(t:1, i:16)
datanode_2_1  | 2020-06-19 01:09:20,377 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=24,entriesCount=1,lastEntry=(t:1, i:17)
datanode_2_1  | 2020-06-19 01:09:20,389 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=25,entriesCount=1,lastEntry=(t:1, i:18)
datanode_2_1  | 2020-06-19 01:09:20,441 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=26,entriesCount=1,lastEntry=(t:1, i:19)
datanode_2_1  | 2020-06-19 01:09:20,453 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=27,entriesCount=1,lastEntry=(t:1, i:20)
datanode_2_1  | 2020-06-19 01:09:23,123 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=29,entriesCount=1,lastEntry=(t:1, i:21)
datanode_2_1  | 2020-06-19 01:09:23,133 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=30,entriesCount=1,lastEntry=(t:1, i:22)
datanode_2_1  | 2020-06-19 01:09:23,140 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=31,entriesCount=1,lastEntry=(t:1, i:23)
datanode_2_1  | 2020-06-19 01:09:23,154 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=32,entriesCount=1,lastEntry=(t:1, i:24)
datanode_2_1  | 2020-06-19 01:09:25,863 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=34,entriesCount=1,lastEntry=(t:1, i:25)
datanode_2_1  | 2020-06-19 01:09:25,874 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=35,entriesCount=1,lastEntry=(t:1, i:26)
datanode_2_1  | 2020-06-19 01:09:25,877 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=36,entriesCount=1,lastEntry=(t:1, i:27)
datanode_2_1  | 2020-06-19 01:09:28,599 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=38,entriesCount=1,lastEntry=(t:1, i:28)
datanode_2_1  | 2020-06-19 01:09:28,608 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=39,entriesCount=1,lastEntry=(t:1, i:29)
datanode_2_1  | 2020-06-19 01:09:28,609 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=40,entriesCount=1,lastEntry=(t:1, i:30)
datanode_4_1  | 2020-06-19 01:07:55,742 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/cec7efc5-1764-4106-bcb0-5a67f50bbd6b
datanode_4_1  | 2020-06-19 01:07:55,751 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-06-19 01:07:55,751 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-06-19 01:07:55,758 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-06-19 01:07:55,762 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-06-19 01:07:55,763 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-06-19 01:07:55,765 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-06-19 01:07:55,769 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-06-19 01:07:55,779 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-06-19 01:07:55,780 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-06-19 01:07:55,853 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-06-19 01:07:55,893 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-06-19 01:07:55,893 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-06-19 01:07:55,937 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-06-19 01:07:55,951 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-06-19 01:07:55,952 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-06-19 01:07:55,958 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-06-19 01:07:55,961 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-06-19 01:07:56,074 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B
datanode_4_1  | 2020-06-19 01:07:56,091 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B
datanode_4_1  | 2020-06-19 01:07:56,097 [pool-19-thread-1] INFO impl.RaftServerImpl: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B: start as a follower, conf=-1: [849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858], old=null
datanode_4_1  | 2020-06-19 01:07:56,126 [pool-19-thread-1] INFO impl.RaftServerImpl: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-06-19 01:07:56,127 [pool-19-thread-1] INFO impl.RoleInfo: 849d5c96-9fa8-47f6-a4f1-8034e5e21574: start FollowerState
datanode_4_1  | 2020-06-19 01:07:56,195 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5A67F50BBD6B,id=849d5c96-9fa8-47f6-a4f1-8034e5e21574
datanode_4_1  | 2020-06-19 01:07:56,196 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B
datanode_4_1  | 2020-06-19 01:07:56,289 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "cec7efc5-1764-4106-bcb0-5a67f50bbd6b"
datanode_4_1  | .
datanode_4_1  | 2020-06-19 01:07:56,289 [Command processor thread] INFO impl.RaftServerProxy: 849d5c96-9fa8-47f6-a4f1-8034e5e21574: addNew group-43CE517B6ECA:[f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858] returns group-43CE517B6ECA:java.util.concurrent.CompletableFuture@50275ae7[Not completed]
datanode_4_1  | 2020-06-19 01:07:56,350 [pool-19-thread-1] INFO impl.RaftServerImpl: 849d5c96-9fa8-47f6-a4f1-8034e5e21574: new RaftServerImpl for group-43CE517B6ECA:[f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-06-19 01:07:56,355 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-06-19 01:07:56,355 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-06-19 01:07:56,356 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-06-19 01:07:56,356 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-06-19 01:07:56,356 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-06-19 01:07:56,357 [pool-19-thread-1] INFO impl.RaftServerImpl: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA: ConfigurationManager, init=-1: [f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-06-19 01:07:56,357 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-06-19 01:07:56,357 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-06-19 01:07:56,357 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/3c154b4e-35c3-468d-a70d-43ce517b6eca does not exist. Creating ...
datanode_4_1  | 2020-06-19 01:07:56,369 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/3c154b4e-35c3-468d-a70d-43ce517b6eca/in_use.lock acquired by nodename 6@76a4c07cdf4d
datanode_4_1  | 2020-06-19 01:07:56,374 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/3c154b4e-35c3-468d-a70d-43ce517b6eca has been successfully formatted.
datanode_4_1  | 2020-06-19 01:07:56,375 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-43CE517B6ECA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-06-19 01:07:56,393 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-06-19 01:07:56,399 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-06-19 01:07:56,399 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-06-19 01:07:56,400 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-06-19 01:07:56,402 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-06-19 01:07:56,402 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA
datanode_3_1  | 2020-06-19 01:07:55,485 [pool-19-thread-1] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA: ConfigurationManager, init=-1: [f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-06-19 01:07:55,485 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-06-19 01:07:55,486 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-06-19 01:07:55,486 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/3c154b4e-35c3-468d-a70d-43ce517b6eca does not exist. Creating ...
datanode_3_1  | 2020-06-19 01:07:55,490 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/3c154b4e-35c3-468d-a70d-43ce517b6eca/in_use.lock acquired by nodename 6@cb48fc6b9da0
datanode_3_1  | 2020-06-19 01:07:55,495 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/3c154b4e-35c3-468d-a70d-43ce517b6eca has been successfully formatted.
datanode_3_1  | 2020-06-19 01:07:55,497 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-43CE517B6ECA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-06-19 01:07:55,506 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-06-19 01:07:55,507 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-06-19 01:07:55,507 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-06-19 01:07:55,507 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-19 01:07:55,508 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-06-19 01:07:55,513 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA
datanode_3_1  | 2020-06-19 01:07:55,517 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-06-19 01:07:55,517 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/3c154b4e-35c3-468d-a70d-43ce517b6eca
datanode_3_1  | 2020-06-19 01:07:55,517 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-06-19 01:07:55,517 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-19 01:07:55,518 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-06-19 01:07:55,518 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-06-19 01:07:55,522 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-06-19 01:07:55,522 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-06-19 01:07:55,523 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-06-19 01:07:55,523 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-06-19 01:07:55,523 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-06-19 01:07:55,525 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-06-19 01:07:55,540 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-19 01:07:55,540 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-19 01:07:55,546 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-06-19 01:07:55,546 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-06-19 01:07:55,547 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-06-19 01:07:55,547 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-06-19 01:07:55,554 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-06-19 01:07:55,557 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA
datanode_3_1  | 2020-06-19 01:07:55,558 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA
datanode_3_1  | 2020-06-19 01:07:55,558 [pool-19-thread-1] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA: start as a follower, conf=-1: [f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858], old=null
datanode_3_1  | 2020-06-19 01:07:55,558 [pool-19-thread-1] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-06-19 01:07:55,558 [pool-19-thread-1] INFO impl.RoleInfo: f4253cac-8b23-4603-baf9-9d0335b1f337: start FollowerState
datanode_3_1  | 2020-06-19 01:07:55,560 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-43CE517B6ECA,id=f4253cac-8b23-4603-baf9-9d0335b1f337
datanode_3_1  | 2020-06-19 01:07:55,560 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA
datanode_3_1  | 2020-06-19 01:07:59,140 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "3c154b4e-35c3-468d-a70d-43ce517b6eca"
datanode_3_1  | .
datanode_3_1  | 2020-06-19 01:08:00,522 [Thread-21] INFO impl.FollowerState: f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-FollowerState: change to CANDIDATE, lastRpcTime:5172ms, electionTimeout:5157ms
datanode_3_1  | 2020-06-19 01:08:00,523 [Thread-21] INFO impl.RoleInfo: f4253cac-8b23-4603-baf9-9d0335b1f337: shutdown FollowerState
datanode_3_1  | 2020-06-19 01:08:00,523 [Thread-21] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3_1  | 2020-06-19 01:08:00,525 [Thread-21] INFO impl.RoleInfo: f4253cac-8b23-4603-baf9-9d0335b1f337: start LeaderElection
datanode_3_1  | 2020-06-19 01:08:00,530 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO impl.LeaderElection: f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1: begin an election at term 1 for -1: [f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858], old=null
datanode_3_1  | 2020-06-19 01:08:00,531 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO impl.RoleInfo: f4253cac-8b23-4603-baf9-9d0335b1f337: shutdown LeaderElection
datanode_3_1  | 2020-06-19 01:08:00,531 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3_1  | 2020-06-19 01:08:00,531 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-9B0DAEFCE644 with new leaderId: f4253cac-8b23-4603-baf9-9d0335b1f337
datanode_3_1  | 2020-06-19 01:08:00,533 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644: change Leader from null to f4253cac-8b23-4603-baf9-9d0335b1f337 at term 1 for becomeLeader, leader elected after 5929ms
datanode_3_1  | 2020-06-19 01:08:00,537 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-06-19 01:08:00,538 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 2020-06-19 01:08:00,540 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644
datanode_3_1  | 2020-06-19 01:08:00,548 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-19 01:08:00,548 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-06-19 01:08:00,561 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3_1  | 2020-06-19 01:08:00,561 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-06-19 01:08:00,567 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-06-19 01:08:00,581 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO impl.RoleInfo: f4253cac-8b23-4603-baf9-9d0335b1f337: start LeaderState
datanode_3_1  | 2020-06-19 01:08:00,606 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-06-19 01:08:00,671 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-LeaderElection1] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644: set configuration 0: [f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858], old=null at 0
datanode_3_1  | 2020-06-19 01:08:00,738 [Thread-23] INFO impl.FollowerState: f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-FollowerState: change to CANDIDATE, lastRpcTime:5179ms, electionTimeout:5179ms
datanode_3_1  | 2020-06-19 01:08:00,739 [Thread-23] INFO impl.RoleInfo: f4253cac-8b23-4603-baf9-9d0335b1f337: shutdown FollowerState
datanode_3_1  | 2020-06-19 01:08:00,739 [Thread-23] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3_1  | 2020-06-19 01:08:00,739 [Thread-23] INFO impl.RoleInfo: f4253cac-8b23-4603-baf9-9d0335b1f337: start LeaderElection
datanode_3_1  | 2020-06-19 01:08:00,776 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO impl.LeaderElection: f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2: begin an election at term 1 for -1: [f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858], old=null
datanode_3_1  | 2020-06-19 01:08:00,917 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO impl.LeaderElection: f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2: Election PASSED; received 1 response(s) [f4253cac-8b23-4603-baf9-9d0335b1f337<-64b3d39f-3fe5-4249-9316-ebaafc2d6305#0:OK-t1] and 0 exception(s); f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA:t1, leader=null, voted=f4253cac-8b23-4603-baf9-9d0335b1f337, raftlog=f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858], old=null
datanode_3_1  | 2020-06-19 01:08:00,917 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO impl.RoleInfo: f4253cac-8b23-4603-baf9-9d0335b1f337: shutdown LeaderElection
datanode_3_1  | 2020-06-19 01:08:00,917 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3_1  | 2020-06-19 01:08:00,917 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-43CE517B6ECA with new leaderId: f4253cac-8b23-4603-baf9-9d0335b1f337
datanode_3_1  | 2020-06-19 01:08:00,918 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA: change Leader from null to f4253cac-8b23-4603-baf9-9d0335b1f337 at term 1 for becomeLeader, leader elected after 5420ms
datanode_3_1  | 2020-06-19 01:08:00,918 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-06-19 01:08:00,918 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 2020-06-19 01:08:00,918 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA
datanode_3_1  | 2020-06-19 01:08:00,942 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-19 01:08:00,942 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-06-19 01:08:00,949 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3_1  | 2020-06-19 01:08:00,964 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-06-19 01:08:00,964 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-06-19 01:08:00,950 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f4253cac-8b23-4603-baf9-9d0335b1f337@group-9B0DAEFCE644-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6c4a8402-d6b3-4216-ba1e-9b0daefce644/current/log_inprogress_0
datanode_3_1  | 2020-06-19 01:08:00,974 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3_1  | 2020-06-19 01:08:00,988 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-19 01:08:00,988 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3_1  | 2020-06-19 01:08:01,007 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3_1  | 2020-06-19 01:08:01,020 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-06-19 01:08:01,024 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-06-19 01:08:01,025 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA
datanode_3_1  | 2020-06-19 01:08:01,040 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3_1  | 2020-06-19 01:08:01,048 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-19 01:08:01,070 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2_1  | 2020-06-19 01:09:28,636 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=41,entriesCount=1,lastEntry=(t:1, i:31)
datanode_2_1  | 2020-06-19 01:09:31,174 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=43,entriesCount=1,lastEntry=(t:1, i:32)
datanode_2_1  | 2020-06-19 01:09:31,185 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=44,entriesCount=1,lastEntry=(t:1, i:33)
datanode_2_1  | 2020-06-19 01:09:31,197 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=45,entriesCount=1,lastEntry=(t:1, i:34)
datanode_2_1  | 2020-06-19 01:09:31,215 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=46,entriesCount=1,lastEntry=(t:1, i:35)
datanode_2_1  | 2020-06-19 01:09:38,905 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=50,entriesCount=1,lastEntry=(t:1, i:36)
datanode_2_1  | 2020-06-19 01:09:38,910 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=51,entriesCount=1,lastEntry=(t:1, i:37)
datanode_2_1  | 2020-06-19 01:09:38,913 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=52,entriesCount=1,lastEntry=(t:1, i:38)
datanode_2_1  | 2020-06-19 01:09:38,932 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=53,entriesCount=1,lastEntry=(t:1, i:39)
datanode_2_1  | 2020-06-19 01:09:41,464 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=55,entriesCount=1,lastEntry=(t:1, i:40)
datanode_2_1  | 2020-06-19 01:09:41,471 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=56,entriesCount=1,lastEntry=(t:1, i:41)
datanode_2_1  | 2020-06-19 01:09:41,476 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=57,entriesCount=1,lastEntry=(t:1, i:42)
datanode_2_1  | 2020-06-19 01:09:41,489 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=58,entriesCount=1,lastEntry=(t:1, i:43)
datanode_2_1  | 2020-06-19 01:09:44,018 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=60,entriesCount=1,lastEntry=(t:1, i:44)
datanode_2_1  | 2020-06-19 01:09:44,018 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=61,entriesCount=1,lastEntry=(t:1, i:45)
datanode_2_1  | 2020-06-19 01:09:44,051 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=62,entriesCount=1,lastEntry=(t:1, i:46)
datanode_2_1  | 2020-06-19 01:09:44,051 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=63,entriesCount=1,lastEntry=(t:1, i:47)
datanode_2_1  | 2020-06-19 01:09:46,577 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=65,entriesCount=1,lastEntry=(t:1, i:48)
datanode_2_1  | 2020-06-19 01:09:46,592 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=66,entriesCount=1,lastEntry=(t:1, i:49)
datanode_2_1  | 2020-06-19 01:09:46,618 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=67,entriesCount=1,lastEntry=(t:1, i:50)
datanode_2_1  | 2020-06-19 01:09:46,634 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=68,entriesCount=1,lastEntry=(t:1, i:51)
datanode_2_1  | 2020-06-19 01:09:49,175 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=70,entriesCount=1,lastEntry=(t:1, i:52)
datanode_2_1  | 2020-06-19 01:09:49,185 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=71,entriesCount=1,lastEntry=(t:1, i:53)
datanode_4_1  | 2020-06-19 01:07:56,403 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-06-19 01:07:56,403 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/3c154b4e-35c3-468d-a70d-43ce517b6eca
datanode_4_1  | 2020-06-19 01:07:56,403 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-06-19 01:07:56,404 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-06-19 01:07:56,405 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-06-19 01:07:56,405 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-06-19 01:07:56,423 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-06-19 01:07:56,423 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-06-19 01:07:56,424 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-06-19 01:07:56,424 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-06-19 01:07:56,428 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-06-19 01:07:56,444 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-06-19 01:07:56,448 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-06-19 01:07:56,448 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-06-19 01:07:56,449 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-06-19 01:07:56,450 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-06-19 01:07:56,450 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-06-19 01:07:56,450 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-06-19 01:07:56,450 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-06-19 01:07:56,452 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA
datanode_4_1  | 2020-06-19 01:07:56,457 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA
datanode_4_1  | 2020-06-19 01:07:56,458 [pool-19-thread-1] INFO impl.RaftServerImpl: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA: start as a follower, conf=-1: [f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858], old=null
datanode_4_1  | 2020-06-19 01:07:56,458 [pool-19-thread-1] INFO impl.RaftServerImpl: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-06-19 01:07:56,459 [pool-19-thread-1] INFO impl.RoleInfo: 849d5c96-9fa8-47f6-a4f1-8034e5e21574: start FollowerState
datanode_4_1  | 2020-06-19 01:07:56,460 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-43CE517B6ECA,id=849d5c96-9fa8-47f6-a4f1-8034e5e21574
datanode_4_1  | 2020-06-19 01:07:56,461 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA
datanode_4_1  | 2020-06-19 01:07:58,996 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "3c154b4e-35c3-468d-a70d-43ce517b6eca"
datanode_4_1  | .
datanode_4_1  | 2020-06-19 01:08:00,856 [grpc-default-executor-1] INFO impl.RaftServerImpl: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:f4253cac-8b23-4603-baf9-9d0335b1f337
datanode_4_1  | 2020-06-19 01:08:00,866 [grpc-default-executor-1] INFO impl.RoleInfo: 849d5c96-9fa8-47f6-a4f1-8034e5e21574: shutdown FollowerState
datanode_4_1  | 2020-06-19 01:08:00,866 [Thread-23] INFO impl.FollowerState: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_4_1  | 2020-06-19 01:08:00,866 [grpc-default-executor-1] INFO impl.RoleInfo: 849d5c96-9fa8-47f6-a4f1-8034e5e21574: start FollowerState
datanode_4_1  | 2020-06-19 01:08:01,191 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-43CE517B6ECA with new leaderId: f4253cac-8b23-4603-baf9-9d0335b1f337
datanode_4_1  | 2020-06-19 01:08:01,191 [grpc-default-executor-1] INFO impl.RaftServerImpl: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA: change Leader from null to f4253cac-8b23-4603-baf9-9d0335b1f337 at term 1 for appendEntries, leader elected after 4797ms
datanode_4_1  | 2020-06-19 01:08:01,285 [grpc-default-executor-1] INFO impl.RaftServerImpl: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA: set configuration 0: [f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858], old=null at 0
datanode_4_1  | 2020-06-19 01:08:01,339 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-06-19 01:08:01,372 [Thread-21] INFO impl.FollowerState: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-FollowerState: change to CANDIDATE, lastRpcTime:5245ms, electionTimeout:5186ms
datanode_4_1  | 2020-06-19 01:08:01,377 [Thread-21] INFO impl.RoleInfo: 849d5c96-9fa8-47f6-a4f1-8034e5e21574: shutdown FollowerState
datanode_4_1  | 2020-06-19 01:08:01,377 [Thread-21] INFO impl.RaftServerImpl: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4_1  | 2020-06-19 01:08:01,381 [Thread-21] INFO impl.RoleInfo: 849d5c96-9fa8-47f6-a4f1-8034e5e21574: start LeaderElection
datanode_4_1  | 2020-06-19 01:08:01,408 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO impl.LeaderElection: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1: begin an election at term 1 for -1: [849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858], old=null
datanode_4_1  | 2020-06-19 01:08:01,409 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO impl.RoleInfo: 849d5c96-9fa8-47f6-a4f1-8034e5e21574: shutdown LeaderElection
datanode_4_1  | 2020-06-19 01:08:01,417 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO impl.RaftServerImpl: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_4_1  | 2020-06-19 01:08:01,422 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-5A67F50BBD6B with new leaderId: 849d5c96-9fa8-47f6-a4f1-8034e5e21574
datanode_3_1  | 2020-06-19 01:08:01,070 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3_1  | 2020-06-19 01:08:01,070 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-06-19 01:08:01,071 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-06-19 01:08:01,078 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO impl.RoleInfo: f4253cac-8b23-4603-baf9-9d0335b1f337: start LeaderState
datanode_3_1  | 2020-06-19 01:08:01,084 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-06-19 01:08:01,086 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/3c154b4e-35c3-468d-a70d-43ce517b6eca/current/log_inprogress_0
datanode_3_1  | 2020-06-19 01:08:01,106 [f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA-LeaderElection2] INFO impl.RaftServerImpl: f4253cac-8b23-4603-baf9-9d0335b1f337@group-43CE517B6ECA: set configuration 0: [f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858], old=null at 0
datanode_5_1  | Enabled profiling in kernel
datanode_5_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_5_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_5_1  | 2020-06-19 01:07:27,904 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_5_1  | /************************************************************
datanode_5_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_5_1  | STARTUP_MSG:   host = e334a8247672/10.5.0.8
datanode_5_1  | STARTUP_MSG:   args = []
datanode_5_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_4_1  | 2020-06-19 01:08:01,423 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO impl.RaftServerImpl: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B: change Leader from null to 849d5c96-9fa8-47f6-a4f1-8034e5e21574 at term 1 for becomeLeader, leader elected after 5872ms
datanode_4_1  | 2020-06-19 01:08:01,463 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4_1  | 2020-06-19 01:08:01,463 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4_1  | 2020-06-19 01:08:01,497 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B
datanode_4_1  | 2020-06-19 01:08:01,509 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4_1  | 2020-06-19 01:08:01,510 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_4_1  | 2020-06-19 01:08:01,524 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4_1  | 2020-06-19 01:08:01,525 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4_1  | 2020-06-19 01:08:01,525 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4_1  | 2020-06-19 01:08:01,536 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO impl.RoleInfo: 849d5c96-9fa8-47f6-a4f1-8034e5e21574: start LeaderState
datanode_4_1  | 2020-06-19 01:08:01,545 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-06-19 01:08:01,549 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-LeaderElection1] INFO impl.RaftServerImpl: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B: set configuration 0: [849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858], old=null at 0
datanode_4_1  | 2020-06-19 01:08:01,637 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-5A67F50BBD6B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/cec7efc5-1764-4106-bcb0-5a67f50bbd6b/current/log_inprogress_0
datanode_4_1  | 2020-06-19 01:08:01,639 [849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 849d5c96-9fa8-47f6-a4f1-8034e5e21574@group-43CE517B6ECA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/3c154b4e-35c3-468d-a70d-43ce517b6eca/current/log_inprogress_0
datanode_5_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_5_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/5ebb065848a63b211bcfce646fbe395c2eab042a ; compiled by 'jenkins1001' on 2020-06-19T00:46Z
datanode_5_1  | STARTUP_MSG:   java = 11.0.6
datanode_5_1  | ************************************************************/
datanode_5_1  | 2020-06-19 01:07:27,964 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2_1  | 2020-06-19 01:09:49,199 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=72,entriesCount=1,lastEntry=(t:1, i:54)
datanode_2_1  | 2020-06-19 01:09:49,220 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=73,entriesCount=1,lastEntry=(t:1, i:55)
datanode_2_1  | 2020-06-19 01:09:51,757 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=75,entriesCount=1,lastEntry=(t:1, i:56)
datanode_2_1  | 2020-06-19 01:09:51,768 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=76,entriesCount=1,lastEntry=(t:1, i:57)
datanode_2_1  | 2020-06-19 01:09:51,779 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=77,entriesCount=1,lastEntry=(t:1, i:58)
datanode_2_1  | 2020-06-19 01:09:51,794 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=78,entriesCount=1,lastEntry=(t:1, i:59)
datanode_2_1  | 2020-06-19 01:09:54,588 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=80,entriesCount=1,lastEntry=(t:1, i:60)
datanode_2_1  | 2020-06-19 01:09:54,596 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=81,entriesCount=1,lastEntry=(t:1, i:61)
datanode_2_1  | 2020-06-19 01:09:54,618 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=82,entriesCount=1,lastEntry=(t:1, i:62)
datanode_2_1  | 2020-06-19 01:09:54,619 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=83,entriesCount=1,lastEntry=(t:1, i:63)
datanode_2_1  | 2020-06-19 01:09:57,223 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=85,entriesCount=1,lastEntry=(t:1, i:64)
datanode_2_1  | 2020-06-19 01:09:57,228 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=86,entriesCount=1,lastEntry=(t:1, i:65)
datanode_2_1  | 2020-06-19 01:09:57,231 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=87,entriesCount=1,lastEntry=(t:1, i:66)
datanode_2_1  | 2020-06-19 01:09:57,251 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=88,entriesCount=1,lastEntry=(t:1, i:67)
datanode_2_1  | 2020-06-19 01:09:59,942 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=90,entriesCount=1,lastEntry=(t:1, i:68)
datanode_2_1  | 2020-06-19 01:09:59,952 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=91,entriesCount=1,lastEntry=(t:1, i:69)
datanode_2_1  | 2020-06-19 01:09:59,957 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=92,entriesCount=1,lastEntry=(t:1, i:70)
datanode_2_1  | 2020-06-19 01:09:59,969 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=93,entriesCount=1,lastEntry=(t:1, i:71)
datanode_2_1  | 2020-06-19 01:10:02,809 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=95,entriesCount=1,lastEntry=(t:1, i:72)
datanode_2_1  | 2020-06-19 01:10:02,815 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=96,entriesCount=1,lastEntry=(t:1, i:73)
datanode_2_1  | 2020-06-19 01:10:02,822 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=97,entriesCount=1,lastEntry=(t:1, i:74)
datanode_2_1  | 2020-06-19 01:10:02,827 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=98,entriesCount=1,lastEntry=(t:1, i:75)
datanode_2_1  | 2020-06-19 01:10:05,465 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=100,entriesCount=1,lastEntry=(t:1, i:76)
datanode_5_1  | 2020-06-19 01:07:29,905 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_5_1  | 2020-06-19 01:07:30,596 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_5_1  | 2020-06-19 01:07:31,991 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_5_1  | 2020-06-19 01:07:31,991 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_5_1  | 2020-06-19 01:07:32,457 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:e334a8247672 ip:10.5.0.8
datanode_5_1  | 2020-06-19 01:07:32,815 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_5_1  | 2020-06-19 01:07:32,842 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_5_1  | 2020-06-19 01:07:32,887 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_5_1  | 2020-06-19 01:07:32,970 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_5_1  | 2020-06-19 01:07:33,091 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_5_1  | 2020-06-19 01:07:39,302 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5_1  | 2020-06-19 01:07:39,583 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_5_1  | 2020-06-19 01:07:40,099 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_5_1  | 2020-06-19 01:07:40,100 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_5_1  | 2020-06-19 01:07:40,100 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-06-19 01:07:40,101 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_5_1  | 2020-06-19 01:07:40,133 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-06-19 01:07:41,839 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-06-19 01:07:43,326 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_5_1  | 2020-06-19 01:07:43,476 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_5_1  | 2020-06-19 01:07:43,699 [main] INFO util.log: Logging initialized @21212ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_5_1  | 2020-06-19 01:07:44,803 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_5_1  | 2020-06-19 01:07:44,856 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_5_1  | 2020-06-19 01:07:44,861 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_5_1  | 2020-06-19 01:07:44,873 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_5_1  | 2020-06-19 01:07:44,896 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_5_1  | 2020-06-19 01:07:44,898 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_5_1  | 2020-06-19 01:07:45,098 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_5_1  | 2020-06-19 01:07:45,147 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_5_1  | 2020-06-19 01:07:45,152 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_5_1  | 2020-06-19 01:07:45,305 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_5_1  | 2020-06-19 01:07:45,305 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_5_1  | 2020-06-19 01:07:45,319 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_5_1  | 2020-06-19 01:07:45,426 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_5_1  | 2020-06-19 01:07:45,428 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@52d97ab6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_5_1  | 2020-06-19 01:07:45,443 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b5e7036{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_5_1  | 2020-06-19 01:07:45,839 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@806996{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-17385202105678227718.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_5_1  | 2020-06-19 01:07:45,911 [main] INFO server.AbstractConnector: Started ServerConnector@44f24a20{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_5_1  | 2020-06-19 01:07:45,914 [main] INFO server.Server: Started @23428ms
datanode_5_1  | 2020-06-19 01:07:45,962 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_5_1  | 2020-06-19 01:07:45,962 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_5_1  | 2020-06-19 01:07:45,967 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_5_1  | 2020-06-19 01:07:46,120 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7740cf7] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_5_1  | 2020-06-19 01:07:47,271 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_5_1  | 2020-06-19 01:07:49,334 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-06-19 01:07:50,346 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_5_1  | java.net.SocketTimeoutException: Call From e334a8247672/10.5.0.8 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.8:57830 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_5_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_5_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_5_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_5_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_5_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_5_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_5_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_5_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_5_1  | 	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
datanode_5_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_5_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_5_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.8:57830 remote=scm/10.5.0.71:9861]
datanode_5_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_5_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_5_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_5_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_5_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_5_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_5_1  | 2020-06-19 01:07:50,660 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_5_1  | 2020-06-19 01:07:50,667 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_5_1  | 2020-06-19 01:07:50,667 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 64b3d39f-3fe5-4249-9316-ebaafc2d6305 at port 9858
datanode_5_1  | 2020-06-19 01:07:50,705 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 64b3d39f-3fe5-4249-9316-ebaafc2d6305: start RPC server
datanode_5_1  | 2020-06-19 01:07:50,962 [Datanode State Machine Thread - 1] INFO server.GrpcService: 64b3d39f-3fe5-4249-9316-ebaafc2d6305: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_5_1  | 2020-06-19 01:07:55,213 [Command processor thread] INFO impl.RaftServerProxy: 64b3d39f-3fe5-4249-9316-ebaafc2d6305: addNew group-4FB43BC732F7:[64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858] returns group-4FB43BC732F7:java.util.concurrent.CompletableFuture@32d38db2[Not completed]
datanode_5_1  | 2020-06-19 01:07:55,266 [pool-19-thread-1] INFO impl.RaftServerImpl: 64b3d39f-3fe5-4249-9316-ebaafc2d6305: new RaftServerImpl for group-4FB43BC732F7:[64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-06-19 01:07:55,278 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-06-19 01:07:55,287 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-06-19 01:07:55,288 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-06-19 01:07:55,291 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-06-19 01:07:55,293 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-06-19 01:07:55,306 [pool-19-thread-1] INFO impl.RaftServerImpl: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7: ConfigurationManager, init=-1: [64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-06-19 01:07:55,319 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-06-19 01:07:55,345 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-06-19 01:07:55,347 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/3b462c0b-ea51-4a3a-a3c6-4fb43bc732f7 does not exist. Creating ...
datanode_5_1  | 2020-06-19 01:07:55,374 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/3b462c0b-ea51-4a3a-a3c6-4fb43bc732f7/in_use.lock acquired by nodename 6@e334a8247672
datanode_5_1  | 2020-06-19 01:07:55,403 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/3b462c0b-ea51-4a3a-a3c6-4fb43bc732f7 has been successfully formatted.
datanode_5_1  | 2020-06-19 01:07:55,433 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-4FB43BC732F7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-06-19 01:07:55,439 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-06-19 01:07:55,482 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-06-19 01:07:55,530 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-06-19 01:07:55,532 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-06-19 01:07:55,539 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-06-19 01:07:55,581 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7
datanode_5_1  | 2020-06-19 01:07:55,740 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-06-19 01:07:55,808 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/3b462c0b-ea51-4a3a-a3c6-4fb43bc732f7
datanode_5_1  | 2020-06-19 01:07:55,814 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-06-19 01:07:55,821 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-06-19 01:07:55,822 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-06-19 01:07:55,828 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-06-19 01:07:55,829 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | Enabled profiling in kernel
datanode_6_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_6_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_6_1  | 2020-06-19 01:07:28,048 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_6_1  | /************************************************************
datanode_6_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_6_1  | STARTUP_MSG:   host = a2efdf678ebb/10.5.0.9
datanode_6_1  | STARTUP_MSG:   args = []
datanode_6_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_6_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_6_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/5ebb065848a63b211bcfce646fbe395c2eab042a ; compiled by 'jenkins1001' on 2020-06-19T00:46Z
datanode_6_1  | STARTUP_MSG:   java = 11.0.6
datanode_6_1  | ************************************************************/
datanode_6_1  | 2020-06-19 01:07:28,104 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_6_1  | 2020-06-19 01:07:30,347 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_6_1  | 2020-06-19 01:07:30,974 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_6_1  | 2020-06-19 01:07:32,378 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_6_1  | 2020-06-19 01:07:32,379 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_6_1  | 2020-06-19 01:07:32,865 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:a2efdf678ebb ip:10.5.0.9
datanode_6_1  | 2020-06-19 01:07:33,211 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_6_1  | 2020-06-19 01:07:33,242 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_6_1  | 2020-06-19 01:07:33,253 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_6_1  | 2020-06-19 01:07:33,302 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_6_1  | 2020-06-19 01:07:33,449 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_6_1  | 2020-06-19 01:07:39,681 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_6_1  | 2020-06-19 01:07:39,963 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_6_1  | 2020-06-19 01:07:40,306 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_6_1  | 2020-06-19 01:07:40,312 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_6_1  | 2020-06-19 01:07:40,317 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-06-19 01:07:40,322 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_6_1  | 2020-06-19 01:07:40,327 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 2020-06-19 01:07:41,379 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-06-19 01:07:42,345 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_6_1  | 2020-06-19 01:07:42,510 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_6_1  | 2020-06-19 01:07:42,701 [main] INFO util.log: Logging initialized @20012ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_6_1  | 2020-06-19 01:07:43,478 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_6_1  | 2020-06-19 01:07:43,504 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_6_1  | 2020-06-19 01:07:43,584 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_6_1  | 2020-06-19 01:07:43,607 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_6_1  | 2020-06-19 01:07:43,607 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_6_1  | 2020-06-19 01:07:43,607 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_6_1  | 2020-06-19 01:07:43,949 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_6_1  | 2020-06-19 01:07:43,988 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_6_1  | 2020-06-19 01:07:44,002 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_6_1  | 2020-06-19 01:07:44,261 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_6_1  | 2020-06-19 01:07:44,263 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_6_1  | 2020-06-19 01:07:44,267 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_6_1  | 2020-06-19 01:07:44,348 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_6_1  | 2020-06-19 01:07:44,381 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@337bbfdf{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_6_1  | 2020-06-19 01:07:44,385 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@524a076e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_6_1  | 2020-06-19 01:07:44,937 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@38e7ed69{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-5838726591177897451.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_6_1  | 2020-06-19 01:07:44,993 [main] INFO server.AbstractConnector: Started ServerConnector@73844119{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_6_1  | 2020-06-19 01:07:45,006 [main] INFO server.Server: Started @22317ms
datanode_6_1  | 2020-06-19 01:07:45,028 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_6_1  | 2020-06-19 01:07:45,028 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_6_1  | 2020-06-19 01:07:45,040 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_6_1  | 2020-06-19 01:07:45,174 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@12e9ebc7] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_6_1  | 2020-06-19 01:07:46,861 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_6_1  | 2020-06-19 01:07:48,380 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-06-19 01:07:49,380 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-06-19 01:07:50,404 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-06-19 01:07:31,891 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = d3f9a140b6c4/10.5.0.71
scm_1         | STARTUP_MSG:   args = [--init]
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_5_1  | 2020-06-19 01:07:55,830 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-06-19 01:07:55,838 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-06-19 01:07:55,844 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-06-19 01:07:55,851 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-06-19 01:07:55,922 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-06-19 01:07:55,952 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-19 01:07:55,952 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-19 01:07:56,003 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-06-19 01:07:56,014 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-06-19 01:07:56,022 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-06-19 01:07:56,026 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-06-19 01:07:56,028 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-06-19 01:07:56,150 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7
datanode_5_1  | 2020-06-19 01:07:56,165 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7
datanode_5_1  | 2020-06-19 01:07:56,177 [pool-19-thread-1] INFO impl.RaftServerImpl: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7: start as a follower, conf=-1: [64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858], old=null
datanode_5_1  | 2020-06-19 01:07:56,193 [pool-19-thread-1] INFO impl.RaftServerImpl: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-06-19 01:07:56,199 [pool-19-thread-1] INFO impl.RoleInfo: 64b3d39f-3fe5-4249-9316-ebaafc2d6305: start FollowerState
datanode_5_1  | 2020-06-19 01:07:56,235 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4FB43BC732F7,id=64b3d39f-3fe5-4249-9316-ebaafc2d6305
datanode_5_1  | 2020-06-19 01:07:56,246 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7
datanode_5_1  | 2020-06-19 01:07:56,296 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "3b462c0b-ea51-4a3a-a3c6-4fb43bc732f7"
datanode_5_1  | .
datanode_5_1  | 2020-06-19 01:07:56,307 [Command processor thread] INFO impl.RaftServerProxy: 64b3d39f-3fe5-4249-9316-ebaafc2d6305: addNew group-43CE517B6ECA:[f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858] returns group-43CE517B6ECA:java.util.concurrent.CompletableFuture@615023bd[Not completed]
datanode_5_1  | 2020-06-19 01:07:56,344 [pool-19-thread-1] INFO impl.RaftServerImpl: 64b3d39f-3fe5-4249-9316-ebaafc2d6305: new RaftServerImpl for group-43CE517B6ECA:[f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-06-19 01:07:56,373 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-06-19 01:07:56,373 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-06-19 01:07:56,373 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-06-19 01:07:56,374 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-06-19 01:07:56,374 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-06-19 01:07:56,375 [pool-19-thread-1] INFO impl.RaftServerImpl: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA: ConfigurationManager, init=-1: [f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-06-19 01:07:56,375 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-06-19 01:07:56,394 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-06-19 01:07:56,394 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/3c154b4e-35c3-468d-a70d-43ce517b6eca does not exist. Creating ...
datanode_5_1  | 2020-06-19 01:07:56,395 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/3c154b4e-35c3-468d-a70d-43ce517b6eca/in_use.lock acquired by nodename 6@e334a8247672
datanode_5_1  | 2020-06-19 01:07:56,410 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/3c154b4e-35c3-468d-a70d-43ce517b6eca has been successfully formatted.
datanode_5_1  | 2020-06-19 01:07:56,414 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-43CE517B6ECA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-06-19 01:07:56,418 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-06-19 01:07:56,421 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-06-19 01:07:56,421 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-06-19 01:07:56,421 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-06-19 01:07:56,421 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-06-19 01:07:56,421 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA
datanode_5_1  | 2020-06-19 01:07:56,421 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-06-19 01:07:56,422 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/3c154b4e-35c3-468d-a70d-43ce517b6eca
datanode_5_1  | 2020-06-19 01:07:56,422 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-06-19 01:07:56,422 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-06-19 01:07:56,422 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-06-19 01:07:56,422 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | java.net.SocketTimeoutException: Call From a2efdf678ebb/10.5.0.9 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:45142 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_6_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_6_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_6_1  | 	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_6_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:45142 remote=scm/10.5.0.71:9861]
datanode_6_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_6_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_6_1  | 2020-06-19 01:07:50,628 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_6_1  | 2020-06-19 01:07:50,629 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_6_1  | 2020-06-19 01:07:50,633 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis e16193af-992b-449b-a054-1b4385464923 at port 9858
datanode_6_1  | 2020-06-19 01:07:50,678 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: e16193af-992b-449b-a054-1b4385464923: start RPC server
datanode_6_1  | 2020-06-19 01:07:50,982 [Datanode State Machine Thread - 1] INFO server.GrpcService: e16193af-992b-449b-a054-1b4385464923: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_6_1  | 2020-06-19 01:07:54,288 [Command processor thread] INFO impl.RaftServerProxy: e16193af-992b-449b-a054-1b4385464923: addNew group-73E9E68DBB60:[e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858] returns group-73E9E68DBB60:java.util.concurrent.CompletableFuture@5b00dac1[Not completed]
datanode_6_1  | 2020-06-19 01:07:54,354 [pool-19-thread-1] INFO impl.RaftServerImpl: e16193af-992b-449b-a054-1b4385464923: new RaftServerImpl for group-73E9E68DBB60:[e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-06-19 01:07:54,365 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-06-19 01:07:54,366 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-06-19 01:07:54,368 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-06-19 01:07:54,371 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-06-19 01:07:54,373 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-06-19 01:07:54,385 [pool-19-thread-1] INFO impl.RaftServerImpl: e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60: ConfigurationManager, init=-1: [e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-06-19 01:07:54,385 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-06-19 01:07:54,398 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-06-19 01:07:54,404 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f879c4ce-2d93-4c9c-b88e-73e9e68dbb60 does not exist. Creating ...
datanode_6_1  | 2020-06-19 01:07:54,422 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f879c4ce-2d93-4c9c-b88e-73e9e68dbb60/in_use.lock acquired by nodename 7@a2efdf678ebb
datanode_6_1  | 2020-06-19 01:07:54,426 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f879c4ce-2d93-4c9c-b88e-73e9e68dbb60 has been successfully formatted.
datanode_6_1  | 2020-06-19 01:07:54,433 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-73E9E68DBB60: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-06-19 01:07:54,433 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_6_1  | 2020-06-19 01:07:54,448 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-06-19 01:07:54,504 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-06-19 01:07:54,514 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-06-19 01:07:54,515 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-06-19 01:07:54,537 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-06-19 01:07:30,358 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 98f1b89d2358/10.5.0.70
om_1          | STARTUP_MSG:   args = [--init]
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/5ebb065848a63b211bcfce646fbe395c2eab042a ; compiled by 'jenkins1001' on 2020-06-19T00:46Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-06-19 01:07:31,957 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-06-19 01:07:33,011 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-06-19 01:07:33,282 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-42d3c8af-0ae4-4f29-88f4-b7069808259c
scm_1         | 2020-06-19 01:07:33,386 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1         | /************************************************************
scm_1         | SHUTDOWN_MSG: Shutting down StorageContainerManager at d3f9a140b6c4/10.5.0.71
scm_1         | ************************************************************/
scm_1         | Enabled profiling in kernel
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-06-19 01:07:46,478 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = d3f9a140b6c4/10.5.0.71
scm_1         | STARTUP_MSG:   args = []
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_5_1  | 2020-06-19 01:07:56,422 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-06-19 01:07:56,422 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-06-19 01:07:56,423 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-06-19 01:07:56,423 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-06-19 01:07:56,423 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-06-19 01:07:56,425 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-06-19 01:07:56,435 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-19 01:07:56,441 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-19 01:07:56,441 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-06-19 01:07:56,442 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-06-19 01:07:56,442 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-06-19 01:07:56,442 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-06-19 01:07:56,442 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-06-19 01:07:56,443 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA
datanode_5_1  | 2020-06-19 01:07:56,476 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA
datanode_5_1  | 2020-06-19 01:07:56,477 [pool-19-thread-1] INFO impl.RaftServerImpl: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA: start as a follower, conf=-1: [f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858], old=null
datanode_5_1  | 2020-06-19 01:07:56,478 [pool-19-thread-1] INFO impl.RaftServerImpl: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-06-19 01:07:56,478 [pool-19-thread-1] INFO impl.RoleInfo: 64b3d39f-3fe5-4249-9316-ebaafc2d6305: start FollowerState
datanode_5_1  | 2020-06-19 01:07:56,478 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-43CE517B6ECA,id=64b3d39f-3fe5-4249-9316-ebaafc2d6305
datanode_5_1  | 2020-06-19 01:07:56,478 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA
datanode_5_1  | 2020-06-19 01:07:59,131 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "3c154b4e-35c3-468d-a70d-43ce517b6eca"
datanode_5_1  | .
datanode_5_1  | 2020-06-19 01:08:00,845 [grpc-default-executor-0] INFO impl.RaftServerImpl: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:f4253cac-8b23-4603-baf9-9d0335b1f337
datanode_5_1  | 2020-06-19 01:08:00,846 [grpc-default-executor-0] INFO impl.RoleInfo: 64b3d39f-3fe5-4249-9316-ebaafc2d6305: shutdown FollowerState
datanode_5_1  | 2020-06-19 01:08:00,846 [grpc-default-executor-0] INFO impl.RoleInfo: 64b3d39f-3fe5-4249-9316-ebaafc2d6305: start FollowerState
datanode_5_1  | 2020-06-19 01:08:00,846 [Thread-23] INFO impl.FollowerState: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_5_1  | 2020-06-19 01:08:01,149 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-43CE517B6ECA with new leaderId: f4253cac-8b23-4603-baf9-9d0335b1f337
datanode_5_1  | 2020-06-19 01:08:01,150 [grpc-default-executor-0] INFO impl.RaftServerImpl: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA: change Leader from null to f4253cac-8b23-4603-baf9-9d0335b1f337 at term 1 for appendEntries, leader elected after 4731ms
datanode_5_1  | 2020-06-19 01:08:01,236 [grpc-default-executor-0] INFO impl.RaftServerImpl: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA: set configuration 0: [f4253cac-8b23-4603-baf9-9d0335b1f337:10.5.0.6:9858, 64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858, 849d5c96-9fa8-47f6-a4f1-8034e5e21574:10.5.0.7:9858], old=null at 0
datanode_5_1  | 2020-06-19 01:08:01,248 [Thread-21] INFO impl.FollowerState: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-FollowerState: change to CANDIDATE, lastRpcTime:5049ms, electionTimeout:5006ms
datanode_5_1  | 2020-06-19 01:08:01,251 [Thread-21] INFO impl.RoleInfo: 64b3d39f-3fe5-4249-9316-ebaafc2d6305: shutdown FollowerState
datanode_5_1  | 2020-06-19 01:08:01,251 [Thread-21] INFO impl.RaftServerImpl: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-06-19 01:08:01,258 [Thread-21] INFO impl.RoleInfo: 64b3d39f-3fe5-4249-9316-ebaafc2d6305: start LeaderElection
datanode_5_1  | 2020-06-19 01:08:01,298 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO impl.LeaderElection: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1: begin an election at term 1 for -1: [64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858], old=null
datanode_5_1  | 2020-06-19 01:08:01,341 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO impl.RoleInfo: 64b3d39f-3fe5-4249-9316-ebaafc2d6305: shutdown LeaderElection
datanode_5_1  | 2020-06-19 01:08:01,345 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO impl.RaftServerImpl: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-06-19 01:08:01,342 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-06-19 01:08:01,345 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4FB43BC732F7 with new leaderId: 64b3d39f-3fe5-4249-9316-ebaafc2d6305
datanode_5_1  | 2020-06-19 01:08:01,346 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO impl.RaftServerImpl: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7: change Leader from null to 64b3d39f-3fe5-4249-9316-ebaafc2d6305 at term 1 for becomeLeader, leader elected after 5907ms
datanode_5_1  | 2020-06-19 01:08:01,353 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | 2020-06-19 01:08:01,354 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5_1  | 2020-06-19 01:08:01,357 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7
datanode_2_1  | 2020-06-19 01:10:05,467 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=101,entriesCount=1,lastEntry=(t:1, i:77)
datanode_2_1  | 2020-06-19 01:10:05,480 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=102,entriesCount=1,lastEntry=(t:1, i:78)
datanode_2_1  | 2020-06-19 01:10:05,509 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=103,entriesCount=1,lastEntry=(t:1, i:79)
datanode_2_1  | 2020-06-19 01:10:08,250 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=105,entriesCount=1,lastEntry=(t:1, i:80)
datanode_2_1  | 2020-06-19 01:10:08,259 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=106,entriesCount=1,lastEntry=(t:1, i:81)
datanode_2_1  | 2020-06-19 01:10:08,276 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=107,entriesCount=1,lastEntry=(t:1, i:82)
datanode_2_1  | 2020-06-19 01:10:08,296 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=108,entriesCount=1,lastEntry=(t:1, i:83)
datanode_2_1  | 2020-06-19 01:10:10,832 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=110,entriesCount=1,lastEntry=(t:1, i:84)
datanode_2_1  | 2020-06-19 01:10:10,839 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=111,entriesCount=1,lastEntry=(t:1, i:85)
datanode_2_1  | 2020-06-19 01:10:10,846 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=112,entriesCount=1,lastEntry=(t:1, i:86)
datanode_2_1  | 2020-06-19 01:10:10,860 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=113,entriesCount=1,lastEntry=(t:1, i:87)
datanode_2_1  | 2020-06-19 01:10:16,073 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=116,entriesCount=1,lastEntry=(t:1, i:88)
datanode_2_1  | 2020-06-19 01:10:16,075 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=117,entriesCount=1,lastEntry=(t:1, i:89)
datanode_2_1  | 2020-06-19 01:10:16,087 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=118,entriesCount=1,lastEntry=(t:1, i:90)
datanode_2_1  | 2020-06-19 01:10:16,090 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=119,entriesCount=1,lastEntry=(t:1, i:91)
datanode_2_1  | 2020-06-19 01:10:18,641 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=121,entriesCount=1,lastEntry=(t:1, i:92)
datanode_2_1  | 2020-06-19 01:10:18,647 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=122,entriesCount=1,lastEntry=(t:1, i:93)
datanode_2_1  | 2020-06-19 01:10:18,665 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=123,entriesCount=1,lastEntry=(t:1, i:94)
datanode_2_1  | 2020-06-19 01:10:18,671 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=124,entriesCount=1,lastEntry=(t:1, i:95)
datanode_2_1  | 2020-06-19 01:10:21,278 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=126,entriesCount=1,lastEntry=(t:1, i:96)
datanode_2_1  | 2020-06-19 01:10:21,291 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=127,entriesCount=1,lastEntry=(t:1, i:97)
datanode_2_1  | 2020-06-19 01:10:21,292 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=128,entriesCount=1,lastEntry=(t:1, i:98)
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/5ebb065848a63b211bcfce646fbe395c2eab042a ; compiled by 'jenkins1001' on 2020-06-19T00:46Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-06-19 01:07:46,553 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-06-19 01:07:47,300 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-06-19 01:07:48,028 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-06-19 01:07:48,396 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@20b2475a
scm_1         | 2020-06-19 01:07:48,397 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1         | 2020-06-19 01:07:48,571 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1         | 2020-06-19 01:07:48,720 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
scm_1         | 2020-06-19 01:07:48,734 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1         | 2020-06-19 01:07:48,771 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1         | 2020-06-19 01:07:48,772 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1         | 2020-06-19 01:07:48,858 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1         | 2020-06-19 01:07:49,248 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-06-19 01:07:49,270 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1         | 2020-06-19 01:07:49,301 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-06-19 01:07:49,307 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1         | 2020-06-19 01:07:49,323 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-06-19 01:07:49,324 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1         | 2020-06-19 01:07:49,345 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1         | 2020-06-19 01:07:49,346 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1         | 2020-06-19 01:07:49,364 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @13974ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1         | 2020-06-19 01:07:49,495 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | 2020-06-19 01:07:49,508 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1         | 2020-06-19 01:07:49,512 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1         | 2020-06-19 01:07:49,513 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm_1         | 2020-06-19 01:07:49,514 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm_1         | 2020-06-19 01:07:49,514 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm_1         | 2020-06-19 01:07:49,643 [Listener at 0.0.0.0/9860] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
scm_1         | 2020-06-19 01:07:49,685 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1         | 2020-06-19 01:07:49,796 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1         | 2020-06-19 01:07:49,847 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1         | 2020-06-19 01:07:49,847 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1         | 2020-06-19 01:07:50,036 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1         | 2020-06-19 01:07:50,037 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-06-19 01:07:50,122 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1         | 2020-06-19 01:07:50,130 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1         | 2020-06-19 01:07:50,132 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1         | 2020-06-19 01:07:50,133 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/5ebb065848a63b211bcfce646fbe395c2eab042a ; compiled by 'jenkins1001' on 2020-06-19T00:46Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-06-19 01:07:30,380 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-06-19 01:07:35,147 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-06-19 01:07:35,425 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-06-19 01:07:35,442 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-06-19 01:07:35,488 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-19 01:07:38,122 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-19 01:07:39,123 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-19 01:07:40,124 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-19 01:07:41,124 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-19 01:07:42,125 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-19 01:07:43,130 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-19 01:07:44,131 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-19 01:07:45,132 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-19 01:07:46,133 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-19 01:07:47,133 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-19 01:07:47,135 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1          | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-42d3c8af-0ae4-4f29-88f4-b7069808259c
om_1          | 2020-06-19 01:07:52,238 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1          | /************************************************************
om_1          | SHUTDOWN_MSG: Shutting down OzoneManager at 98f1b89d2358/10.5.0.70
om_1          | ************************************************************/
om_1          | Enabled profiling in kernel
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-06-19 01:07:53,247 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 98f1b89d2358/10.5.0.70
om_1          | STARTUP_MSG:   args = []
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/5ebb065848a63b211bcfce646fbe395c2eab042a ; compiled by 'jenkins1001' on 2020-06-19T00:46Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-06-19 01:07:53,270 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-06-19 01:07:55,232 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-06-19 01:07:55,479 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-06-19 01:07:55,480 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-06-19 01:07:55,523 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-19 01:07:55,574 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-19 01:07:59,428 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-19 01:08:00,116 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1          | 2020-06-19 01:08:00,161 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1          | 2020-06-19 01:08:00,534 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1          | 2020-06-19 01:08:00,736 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1          | 2020-06-19 01:08:00,736 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1          | 2020-06-19 01:08:01,046 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/10.5.0.70:9862
om_1          | 2020-06-19 01:08:01,149 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1          | 2020-06-19 01:08:01,216 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1          | 2020-06-19 01:08:02,074 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1          | 2020-06-19 01:08:02,075 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1          | 2020-06-19 01:08:02,135 [Listener at om/9862] INFO util.log: Logging initialized @9705ms to org.eclipse.jetty.util.log.Slf4jLog
om_1          | 2020-06-19 01:08:02,408 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1          | 2020-06-19 01:08:02,413 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1          | 2020-06-19 01:08:02,431 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_5_1  | 2020-06-19 01:08:01,403 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5_1  | 2020-06-19 01:08:01,442 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_5_1  | 2020-06-19 01:08:01,456 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5_1  | 2020-06-19 01:08:01,456 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5_1  | 2020-06-19 01:08:01,456 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5_1  | 2020-06-19 01:08:01,606 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO impl.RoleInfo: 64b3d39f-3fe5-4249-9316-ebaafc2d6305: start LeaderState
datanode_5_1  | 2020-06-19 01:08:01,632 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-06-19 01:08:01,635 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-LeaderElection1] INFO impl.RaftServerImpl: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7: set configuration 0: [64b3d39f-3fe5-4249-9316-ebaafc2d6305:10.5.0.8:9858], old=null at 0
datanode_5_1  | 2020-06-19 01:08:01,795 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-4FB43BC732F7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/3b462c0b-ea51-4a3a-a3c6-4fb43bc732f7/current/log_inprogress_0
datanode_5_1  | 2020-06-19 01:08:01,798 [64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 64b3d39f-3fe5-4249-9316-ebaafc2d6305@group-43CE517B6ECA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/3c154b4e-35c3-468d-a70d-43ce517b6eca/current/log_inprogress_0
datanode_2_1  | 2020-06-19 01:10:24,106 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=130,entriesCount=1,lastEntry=(t:1, i:99)
datanode_2_1  | 2020-06-19 01:10:24,112 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=131,entriesCount=1,lastEntry=(t:1, i:100)
datanode_2_1  | 2020-06-19 01:10:24,126 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=132,entriesCount=1,lastEntry=(t:1, i:101)
datanode_2_1  | 2020-06-19 01:10:26,660 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=134,entriesCount=1,lastEntry=(t:1, i:102)
datanode_2_1  | 2020-06-19 01:10:26,668 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=135,entriesCount=1,lastEntry=(t:1, i:103)
datanode_2_1  | 2020-06-19 01:10:26,672 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=136,entriesCount=1,lastEntry=(t:1, i:104)
datanode_2_1  | 2020-06-19 01:10:26,685 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=137,entriesCount=1,lastEntry=(t:1, i:105)
datanode_2_1  | 2020-06-19 01:10:29,375 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=139,entriesCount=1,lastEntry=(t:1, i:106)
datanode_2_1  | 2020-06-19 01:10:29,383 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=140,entriesCount=1,lastEntry=(t:1, i:107)
datanode_2_1  | 2020-06-19 01:10:29,385 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=141,entriesCount=1,lastEntry=(t:1, i:108)
datanode_2_1  | 2020-06-19 01:10:29,403 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=142,entriesCount=1,lastEntry=(t:1, i:109)
datanode_2_1  | 2020-06-19 01:10:34,705 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=145,entriesCount=1,lastEntry=(t:1, i:110)
datanode_2_1  | 2020-06-19 01:10:34,705 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=146,entriesCount=1,lastEntry=(t:1, i:111)
datanode_2_1  | 2020-06-19 01:10:34,718 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=147,entriesCount=1,lastEntry=(t:1, i:112)
datanode_2_1  | 2020-06-19 01:10:34,718 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=148,entriesCount=1,lastEntry=(t:1, i:113)
datanode_2_1  | 2020-06-19 01:10:39,953 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=151,entriesCount=1,lastEntry=(t:1, i:114)
datanode_2_1  | 2020-06-19 01:10:39,961 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=152,entriesCount=1,lastEntry=(t:1, i:115)
datanode_2_1  | 2020-06-19 01:10:40,012 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=153,entriesCount=1,lastEntry=(t:1, i:116)
datanode_2_1  | 2020-06-19 01:10:40,015 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=154,entriesCount=1,lastEntry=(t:1, i:117)
datanode_2_1  | 2020-06-19 01:10:42,537 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=156,entriesCount=1,lastEntry=(t:1, i:118)
datanode_2_1  | 2020-06-19 01:10:42,543 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=157,entriesCount=1,lastEntry=(t:1, i:119)
datanode_2_1  | 2020-06-19 01:10:42,549 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=158,entriesCount=1,lastEntry=(t:1, i:120)
datanode_2_1  | 2020-06-19 01:10:42,555 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=159,entriesCount=1,lastEntry=(t:1, i:121)
datanode_6_1  | 2020-06-19 01:07:54,565 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-06-19 01:07:54,589 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/f879c4ce-2d93-4c9c-b88e-73e9e68dbb60
datanode_6_1  | 2020-06-19 01:07:54,594 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-06-19 01:07:54,597 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-06-19 01:07:54,597 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-06-19 01:07:54,600 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-06-19 01:07:54,601 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-06-19 01:07:54,602 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-06-19 01:07:54,603 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-06-19 01:07:54,603 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-06-19 01:07:54,608 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-06-19 01:07:54,697 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-06-19 01:07:54,716 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-19 01:07:54,717 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-19 01:07:54,739 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-06-19 01:07:54,739 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-06-19 01:07:54,740 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-06-19 01:07:54,742 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-06-19 01:07:54,747 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-06-19 01:07:54,836 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60
datanode_6_1  | 2020-06-19 01:07:54,850 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60
datanode_6_1  | 2020-06-19 01:07:54,861 [pool-19-thread-1] INFO impl.RaftServerImpl: e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60: start as a follower, conf=-1: [e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858], old=null
datanode_6_1  | 2020-06-19 01:07:54,867 [pool-19-thread-1] INFO impl.RaftServerImpl: e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-06-19 01:07:54,868 [pool-19-thread-1] INFO impl.RoleInfo: e16193af-992b-449b-a054-1b4385464923: start FollowerState
datanode_6_1  | 2020-06-19 01:07:54,973 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-73E9E68DBB60,id=e16193af-992b-449b-a054-1b4385464923
datanode_6_1  | 2020-06-19 01:07:54,979 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60
datanode_6_1  | 2020-06-19 01:07:55,085 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "f879c4ce-2d93-4c9c-b88e-73e9e68dbb60"
datanode_6_1  | .
datanode_6_1  | 2020-06-19 01:07:57,812 [grpc-default-executor-0] INFO impl.RaftServerProxy: e16193af-992b-449b-a054-1b4385464923: addNew group-0E2EB5F51AAD:[1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858] returns group-0E2EB5F51AAD:java.util.concurrent.CompletableFuture@7c27b3d4[Not completed]
datanode_6_1  | 2020-06-19 01:07:57,827 [pool-19-thread-1] INFO impl.RaftServerImpl: e16193af-992b-449b-a054-1b4385464923: new RaftServerImpl for group-0E2EB5F51AAD:[1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-06-19 01:07:57,835 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-06-19 01:07:57,836 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-06-19 01:07:57,836 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-06-19 01:07:57,836 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-06-19 01:07:57,845 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-06-19 01:07:57,850 [pool-19-thread-1] INFO impl.RaftServerImpl: e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD: ConfigurationManager, init=-1: [1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-06-19 01:07:57,850 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-06-19 01:07:57,852 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-06-19 01:07:57,852 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/eaaeea6c-49fd-4c41-b247-0e2eb5f51aad does not exist. Creating ...
datanode_6_1  | 2020-06-19 01:07:57,865 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/eaaeea6c-49fd-4c41-b247-0e2eb5f51aad/in_use.lock acquired by nodename 7@a2efdf678ebb
datanode_6_1  | 2020-06-19 01:07:57,867 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/eaaeea6c-49fd-4c41-b247-0e2eb5f51aad has been successfully formatted.
datanode_6_1  | 2020-06-19 01:07:57,870 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-0E2EB5F51AAD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-06-19 01:07:57,870 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_6_1  | 2020-06-19 01:07:57,880 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-06-19 01:07:57,880 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-06-19 01:07:57,881 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-19 01:10:45,084 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=161,entriesCount=1,lastEntry=(t:1, i:122)
datanode_2_1  | 2020-06-19 01:10:45,086 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=162,entriesCount=1,lastEntry=(t:1, i:123)
datanode_2_1  | 2020-06-19 01:10:45,093 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=163,entriesCount=1,lastEntry=(t:1, i:124)
datanode_2_1  | 2020-06-19 01:10:45,099 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=164,entriesCount=1,lastEntry=(t:1, i:125)
datanode_2_1  | 2020-06-19 01:10:47,802 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=166,entriesCount=1,lastEntry=(t:1, i:126)
datanode_2_1  | 2020-06-19 01:10:47,818 [java.util.concurrent.ThreadPoolExecutor$Worker@7d2db76c[State = -1, empty queue]] WARN server.GrpcLogAppender: 1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD->e16193af-992b-449b-a054-1b4385464923-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=167,entriesCount=1,lastEntry=(t:1, i:127)
datanode_2_1  | 2020-06-19 01:12:47,985 [Thread-197] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-BD3DFE818F63->1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD, cid=228, seq=0, Watch-ALL_COMMITTED(128), Message:<EMPTY>, reply=RaftClientReply:client-BD3DFE818F63->1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD, cid=228, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 228 and log index 128 is not yet replicated to ALL_COMMITTED, logIndex=128, commits[1fe601f2-329a-46b5-8003-e31a11712904:c170, e16193af-992b-449b-a054-1b4385464923:c127, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:c170]
datanode_2_1  | 2020-06-19 01:13:03,982 [Thread-203] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-2559280D2B4C->1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD, cid=240, seq=0, Watch-ALL_COMMITTED(131), Message:<EMPTY>, reply=RaftClientReply:client-2559280D2B4C->1fe601f2-329a-46b5-8003-e31a11712904@group-0E2EB5F51AAD, cid=240, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 240 and log index 131 is not yet replicated to ALL_COMMITTED, logIndex=131, commits[1fe601f2-329a-46b5-8003-e31a11712904:c173, e16193af-992b-449b-a054-1b4385464923:c127, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:c173]
datanode_2_1  | 2020-06-19 01:13:05,948 [RatisApplyTransactionExecutor 2] INFO interfaces.Container: Container 2 is synced with bcsId 111.
datanode_2_1  | 2020-06-19 01:13:05,949 [RatisApplyTransactionExecutor 2] INFO interfaces.Container: Container 2 is synced with bcsId 111.
datanode_2_1  | 2020-06-19 01:13:05,963 [RatisApplyTransactionExecutor 2] INFO interfaces.Container: Container 2 is closed with bcsId 111.
datanode_2_1  | 2020-06-19 01:13:06,046 [RatisApplyTransactionExecutor 4] INFO interfaces.Container: Container 4 is synced with bcsId 131.
datanode_2_1  | 2020-06-19 01:13:06,046 [RatisApplyTransactionExecutor 4] INFO interfaces.Container: Container 4 is synced with bcsId 131.
datanode_2_1  | 2020-06-19 01:13:06,057 [RatisApplyTransactionExecutor 4] INFO interfaces.Container: Container 4 is closed with bcsId 131.
datanode_2_1  | 2020-06-19 01:13:06,097 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is synced with bcsId 142.
datanode_2_1  | 2020-06-19 01:13:06,097 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is synced with bcsId 142.
datanode_2_1  | 2020-06-19 01:13:06,105 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is closed with bcsId 142.
datanode_2_1  | 2020-06-19 01:13:06,153 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is synced with bcsId 153.
datanode_2_1  | 2020-06-19 01:13:06,153 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is synced with bcsId 153.
datanode_2_1  | 2020-06-19 01:13:06,168 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is closed with bcsId 153.
datanode_2_1  | 2020-06-19 01:13:06,184 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is synced with bcsId 164.
datanode_2_1  | 2020-06-19 01:13:06,184 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is synced with bcsId 164.
datanode_2_1  | 2020-06-19 01:13:06,188 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is closed with bcsId 164.
datanode_2_1  | 2020-06-19 01:13:06,229 [RatisApplyTransactionExecutor 1] INFO interfaces.Container: Container 11 is synced with bcsId 175.
datanode_2_1  | 2020-06-19 01:13:06,230 [RatisApplyTransactionExecutor 1] INFO interfaces.Container: Container 11 is synced with bcsId 175.
datanode_2_1  | 2020-06-19 01:13:06,235 [RatisApplyTransactionExecutor 1] INFO interfaces.Container: Container 11 is closed with bcsId 175.
scm_1         | 2020-06-19 01:07:50,134 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1         | 2020-06-19 01:07:50,165 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1         | 2020-06-19 01:07:50,165 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1         | 2020-06-19 01:07:50,170 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-06-19 01:07:50,171 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1         | 2020-06-19 01:07:50,237 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1         | 2020-06-19 01:07:50,239 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1         | 2020-06-19 01:07:50,335 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1         | 2020-06-19 01:07:50,336 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1         | 2020-06-19 01:07:50,339 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1         | 2020-06-19 01:07:50,364 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | 2020-06-19 01:07:50,376 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3e7dfd44{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1         | 2020-06-19 01:07:50,377 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@d8948cd{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1         | 2020-06-19 01:07:50,528 [IPC Server handler 0 on default port 9861] WARN ipc.Server: IPC Server handler 0 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.9:45142: output error
scm_1         | 2020-06-19 01:07:50,534 [IPC Server handler 4 on default port 9861] WARN ipc.Server: IPC Server handler 4 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.8:57830: output error
scm_1         | 2020-06-19 01:07:50,538 [IPC Server handler 3 on default port 9861] WARN ipc.Server: IPC Server handler 3 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.4:58690: output error
scm_1         | 2020-06-19 01:07:50,538 [IPC Server handler 2 on default port 9861] WARN ipc.Server: IPC Server handler 2 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.7:45200: output error
scm_1         | 2020-06-19 01:07:50,571 [IPC Server handler 5 on default port 9861] WARN ipc.Server: IPC Server handler 5 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.6:52964: output error
scm_1         | 2020-06-19 01:07:50,575 [IPC Server handler 4 on default port 9861] INFO ipc.Server: IPC Server handler 4 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-19 01:07:50,576 [IPC Server handler 5 on default port 9861] INFO ipc.Server: IPC Server handler 5 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-19 01:07:50,582 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-19 01:07:50,591 [IPC Server handler 3 on default port 9861] INFO ipc.Server: IPC Server handler 3 on default port 9861 caught an exception
om_1          | 2020-06-19 01:08:02,444 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om_1          | 2020-06-19 01:08:02,444 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om_1          | 2020-06-19 01:08:02,444 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om_1          | 2020-06-19 01:08:02,480 [Listener at om/9862] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1          | 2020-06-19 01:08:02,484 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1          | 2020-06-19 01:08:02,488 [Listener at om/9862] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1          | 2020-06-19 01:08:02,537 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1          | 2020-06-19 01:08:02,537 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1          | 2020-06-19 01:08:02,538 [Listener at om/9862] INFO server.session: node0 Scavenging every 600000ms
om_1          | 2020-06-19 01:08:02,569 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1          | 2020-06-19 01:08:02,583 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1352434e{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1          | 2020-06-19 01:08:02,584 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3d96fa9e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1          | 2020-06-19 01:08:03,002 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5399f6c5{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-4214383454563402202.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1          | 2020-06-19 01:08:03,023 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@46aa712c{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1          | 2020-06-19 01:08:03,024 [Listener at om/9862] INFO server.Server: Started @10594ms
om_1          | 2020-06-19 01:08:03,030 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1          | 2020-06-19 01:08:03,030 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1          | 2020-06-19 01:08:03,070 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1          | 2020-06-19 01:08:03,089 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@a22c4d8] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1          | 2020-06-19 01:08:05,825 [IPC Server handler 57 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-74610 for user:hadoop
om_1          | 2020-06-19 01:08:05,847 [IPC Server handler 17 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-93117 for user:hadoop
om_1          | 2020-06-19 01:08:05,853 [IPC Server handler 7 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-43076 for user:hadoop
om_1          | 2020-06-19 01:08:05,859 [IPC Server handler 9 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-46976 for user:hadoop
om_1          | 2020-06-19 01:08:05,865 [IPC Server handler 11 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-22775 for user:hadoop
datanode_6_1  | 2020-06-19 01:07:57,881 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-06-19 01:07:57,881 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD
datanode_6_1  | 2020-06-19 01:07:57,881 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-06-19 01:07:57,881 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/eaaeea6c-49fd-4c41-b247-0e2eb5f51aad
datanode_6_1  | 2020-06-19 01:07:57,881 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-06-19 01:07:57,882 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-06-19 01:07:57,882 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-06-19 01:07:57,882 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-06-19 01:07:57,882 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-06-19 01:07:57,882 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-06-19 01:07:57,883 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-06-19 01:07:57,883 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-06-19 01:07:57,883 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-06-19 01:07:57,884 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-06-19 01:07:57,909 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-19 01:07:57,909 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-19 01:07:57,910 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-06-19 01:07:57,911 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-06-19 01:07:57,911 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-06-19 01:07:57,911 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-06-19 01:07:57,911 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-06-19 01:07:57,912 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD
datanode_6_1  | 2020-06-19 01:07:57,913 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD
datanode_6_1  | 2020-06-19 01:07:57,917 [pool-19-thread-1] INFO impl.RaftServerImpl: e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD: start as a follower, conf=-1: [1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858], old=null
datanode_6_1  | 2020-06-19 01:07:57,918 [pool-19-thread-1] INFO impl.RaftServerImpl: e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-06-19 01:07:57,922 [pool-19-thread-1] INFO impl.RoleInfo: e16193af-992b-449b-a054-1b4385464923: start FollowerState
datanode_6_1  | 2020-06-19 01:07:57,942 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0E2EB5F51AAD,id=e16193af-992b-449b-a054-1b4385464923
datanode_6_1  | 2020-06-19 01:07:57,943 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD
datanode_6_1  | 2020-06-19 01:07:59,908 [Thread-21] INFO impl.FollowerState: e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-FollowerState: change to CANDIDATE, lastRpcTime:5040ms, electionTimeout:5035ms
datanode_6_1  | 2020-06-19 01:07:59,910 [Thread-21] INFO impl.RoleInfo: e16193af-992b-449b-a054-1b4385464923: shutdown FollowerState
datanode_6_1  | 2020-06-19 01:07:59,910 [Thread-21] INFO impl.RaftServerImpl: e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_6_1  | 2020-06-19 01:07:59,912 [Thread-21] INFO impl.RoleInfo: e16193af-992b-449b-a054-1b4385464923: start LeaderElection
datanode_6_1  | 2020-06-19 01:07:59,922 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO impl.LeaderElection: e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1: begin an election at term 1 for -1: [e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858], old=null
datanode_6_1  | 2020-06-19 01:07:59,923 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO impl.RoleInfo: e16193af-992b-449b-a054-1b4385464923: shutdown LeaderElection
datanode_6_1  | 2020-06-19 01:07:59,924 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO impl.RaftServerImpl: e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_6_1  | 2020-06-19 01:07:59,924 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-73E9E68DBB60 with new leaderId: e16193af-992b-449b-a054-1b4385464923
datanode_6_1  | 2020-06-19 01:07:59,925 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO impl.RaftServerImpl: e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60: change Leader from null to e16193af-992b-449b-a054-1b4385464923 at term 1 for becomeLeader, leader elected after 5491ms
datanode_6_1  | 2020-06-19 01:07:59,955 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_6_1  | 2020-06-19 01:07:59,955 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_6_1  | 2020-06-19 01:07:59,962 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60
datanode_6_1  | 2020-06-19 01:07:59,965 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_6_1  | 2020-06-19 01:07:59,970 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_6_1  | 2020-06-19 01:07:59,981 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_6_1  | 2020-06-19 01:07:59,981 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_6_1  | 2020-06-19 01:07:59,982 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_6_1  | 2020-06-19 01:07:59,993 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO impl.RoleInfo: e16193af-992b-449b-a054-1b4385464923: start LeaderState
datanode_6_1  | 2020-06-19 01:08:00,028 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-06-19 01:08:00,082 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-LeaderElection1] INFO impl.RaftServerImpl: e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60: set configuration 0: [e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858], old=null at 0
datanode_6_1  | 2020-06-19 01:08:00,195 [e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e16193af-992b-449b-a054-1b4385464923@group-73E9E68DBB60-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f879c4ce-2d93-4c9c-b88e-73e9e68dbb60/current/log_inprogress_0
datanode_6_1  | 2020-06-19 01:08:01,177 [grpc-default-executor-0] INFO impl.RaftServerImpl: e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:1fe601f2-329a-46b5-8003-e31a11712904
datanode_6_1  | 2020-06-19 01:08:01,177 [grpc-default-executor-0] INFO impl.RoleInfo: e16193af-992b-449b-a054-1b4385464923: shutdown FollowerState
datanode_6_1  | 2020-06-19 01:08:01,177 [Thread-23] INFO impl.FollowerState: e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_6_1  | 2020-06-19 01:08:01,178 [grpc-default-executor-0] INFO impl.RoleInfo: e16193af-992b-449b-a054-1b4385464923: start FollowerState
datanode_6_1  | 2020-06-19 01:08:01,596 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-0E2EB5F51AAD with new leaderId: 1fe601f2-329a-46b5-8003-e31a11712904
datanode_6_1  | 2020-06-19 01:08:01,602 [grpc-default-executor-0] INFO impl.RaftServerImpl: e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD: change Leader from null to 1fe601f2-329a-46b5-8003-e31a11712904 at term 1 for appendEntries, leader elected after 3726ms
datanode_6_1  | 2020-06-19 01:08:01,753 [grpc-default-executor-0] INFO impl.RaftServerImpl: e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD: set configuration 0: [1fe601f2-329a-46b5-8003-e31a11712904:10.5.0.5:9858, e16193af-992b-449b-a054-1b4385464923:10.5.0.9:9858, bad929e1-92e9-4f9a-b8b4-4f52cb0ead89:10.5.0.4:9858], old=null at 0
datanode_6_1  | 2020-06-19 01:08:01,754 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-06-19 01:08:01,763 [e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e16193af-992b-449b-a054-1b4385464923@group-0E2EB5F51AAD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/eaaeea6c-49fd-4c41-b247-0e2eb5f51aad/current/log_inprogress_0
datanode_6_1  | 2020-06-19 01:10:13,195 [grpc-default-executor-0] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 131 .Container 4 bcsId is 123. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 131 .Container 4 bcsId is 123.
datanode_6_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-06-19 01:10:48,625 [grpc-default-executor-0] INFO impl.HddsDispatcher: Operation: GetBlock , Trace ID:  , Message: ContainerID 6 does not exist , Result: CONTAINER_NOT_FOUND , StorageContainerException Occurred.
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 6 does not exist
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:275)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-19 01:07:50,591 [IPC Server handler 2 on default port 9861] INFO ipc.Server: IPC Server handler 2 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-19 01:07:51,350 [IPC Server handler 8 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/e16193af-992b-449b-a054-1b4385464923
scm_1         | 2020-06-19 01:07:51,351 [IPC Server handler 8 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e16193af-992b-449b-a054-1b4385464923{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-06-19 01:07:51,423 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 4 required.
scm_1         | 2020-06-19 01:07:51,431 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-19 01:07:51,484 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f879c4ce-2d93-4c9c-b88e-73e9e68dbb60 to datanode:e16193af-992b-449b-a054-1b4385464923
scm_1         | 2020-06-19 01:07:51,507 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: f879c4ce-2d93-4c9c-b88e-73e9e68dbb60, Nodes: e16193af-992b-449b-a054-1b4385464923{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-19T01:07:51.482184Z]
scm_1         | 2020-06-19 01:07:51,509 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/f4253cac-8b23-4603-baf9-9d0335b1f337
scm_1         | 2020-06-19 01:07:51,511 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered Data node : f4253cac-8b23-4603-baf9-9d0335b1f337{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-06-19 01:07:51,511 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 4 required.
scm_1         | 2020-06-19 01:07:51,512 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-19 01:07:51,529 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=6c4a8402-d6b3-4216-ba1e-9b0daefce644 to datanode:f4253cac-8b23-4603-baf9-9d0335b1f337
scm_1         | 2020-06-19 01:07:51,530 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 6c4a8402-d6b3-4216-ba1e-9b0daefce644, Nodes: f4253cac-8b23-4603-baf9-9d0335b1f337{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-19T01:07:51.529680Z]
scm_1         | 2020-06-19 01:07:51,533 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
scm_1         | 2020-06-19 01:07:51,561 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@146dcfe6{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-5553642953217968781.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
scm_1         | 2020-06-19 01:07:51,580 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@f72203{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1         | 2020-06-19 01:07:51,580 [Listener at 0.0.0.0/9860] INFO server.Server: Started @16191ms
scm_1         | 2020-06-19 01:07:51,592 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1         | 2020-06-19 01:07:51,592 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1         | 2020-06-19 01:07:51,600 [IPC Server handler 4 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/1fe601f2-329a-46b5-8003-e31a11712904
scm_1         | 2020-06-19 01:07:51,600 [IPC Server handler 4 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 1fe601f2-329a-46b5-8003-e31a11712904{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-06-19 01:07:51,600 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 4 required.
scm_1         | 2020-06-19 01:07:51,600 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-19 01:07:51,602 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3ed600d5-9c82-4b23-a409-3764ff5ba268 to datanode:1fe601f2-329a-46b5-8003-e31a11712904
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-06-19 01:12:44,952 [grpc-default-executor-0] INFO impl.HddsDispatcher: Operation: GetBlock , Trace ID:  , Message: ContainerID 11 does not exist , Result: CONTAINER_NOT_FOUND , StorageContainerException Occurred.
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 11 does not exist
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:275)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-06-19 01:07:51,604 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 3ed600d5-9c82-4b23-a409-3764ff5ba268, Nodes: 1fe601f2-329a-46b5-8003-e31a11712904{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-19T01:07:51.602818Z]
scm_1         | 2020-06-19 01:07:51,605 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1         | 2020-06-19 01:07:51,609 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1         | 2020-06-19 01:07:51,635 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@255eaa6b] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1         | 2020-06-19 01:07:52,183 [IPC Server handler 15 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/64b3d39f-3fe5-4249-9316-ebaafc2d6305
scm_1         | 2020-06-19 01:07:52,184 [IPC Server handler 15 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 64b3d39f-3fe5-4249-9316-ebaafc2d6305{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-06-19 01:07:52,184 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3b462c0b-ea51-4a3a-a3c6-4fb43bc732f7 to datanode:64b3d39f-3fe5-4249-9316-ebaafc2d6305
scm_1         | 2020-06-19 01:07:52,185 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 3b462c0b-ea51-4a3a-a3c6-4fb43bc732f7, Nodes: 64b3d39f-3fe5-4249-9316-ebaafc2d6305{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-19T01:07:52.184490Z]
scm_1         | 2020-06-19 01:07:52,185 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 4 required.
scm_1         | 2020-06-19 01:07:52,185 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-19 01:07:52,189 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 4 nodes. Healthy nodes 4
scm_1         | 2020-06-19 01:07:52,189 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-06-19 01:07:52,190 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1         | 2020-06-19 01:07:52,328 [IPC Server handler 6 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/849d5c96-9fa8-47f6-a4f1-8034e5e21574
scm_1         | 2020-06-19 01:07:52,329 [IPC Server handler 6 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 849d5c96-9fa8-47f6-a4f1-8034e5e21574{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-06-19 01:07:52,329 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-06-19 01:07:52,329 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-19 01:07:52,332 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cec7efc5-1764-4106-bcb0-5a67f50bbd6b to datanode:849d5c96-9fa8-47f6-a4f1-8034e5e21574
scm_1         | 2020-06-19 01:07:52,332 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: cec7efc5-1764-4106-bcb0-5a67f50bbd6b, Nodes: 849d5c96-9fa8-47f6-a4f1-8034e5e21574{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-19T01:07:52.331991Z]
scm_1         | 2020-06-19 01:07:52,334 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 5 nodes. Healthy nodes 5
scm_1         | 2020-06-19 01:07:52,342 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3c154b4e-35c3-468d-a70d-43ce517b6eca to datanode:64b3d39f-3fe5-4249-9316-ebaafc2d6305
scm_1         | 2020-06-19 01:07:52,342 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3c154b4e-35c3-468d-a70d-43ce517b6eca to datanode:f4253cac-8b23-4603-baf9-9d0335b1f337
scm_1         | 2020-06-19 01:07:52,342 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3c154b4e-35c3-468d-a70d-43ce517b6eca to datanode:849d5c96-9fa8-47f6-a4f1-8034e5e21574
scm_1         | 2020-06-19 01:07:52,342 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 3c154b4e-35c3-468d-a70d-43ce517b6eca, Nodes: 64b3d39f-3fe5-4249-9316-ebaafc2d6305{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}f4253cac-8b23-4603-baf9-9d0335b1f337{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}849d5c96-9fa8-47f6-a4f1-8034e5e21574{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-19T01:07:52.342041Z]
scm_1         | 2020-06-19 01:07:52,343 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 2
scm_1         | 2020-06-19 01:07:53,388 [IPC Server handler 8 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/bad929e1-92e9-4f9a-b8b4-4f52cb0ead89
scm_1         | 2020-06-19 01:07:53,389 [IPC Server handler 8 on default port 9861] INFO node.SCMNodeManager: Registered Data node : bad929e1-92e9-4f9a-b8b4-4f52cb0ead89{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-06-19 01:07:53,389 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-06-19 01:07:53,390 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-19 01:07:53,392 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e5232efc-6eb4-4532-a52f-3b67e3cf1029 to datanode:bad929e1-92e9-4f9a-b8b4-4f52cb0ead89
scm_1         | 2020-06-19 01:07:53,392 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e5232efc-6eb4-4532-a52f-3b67e3cf1029, Nodes: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-19T01:07:53.392250Z]
scm_1         | 2020-06-19 01:07:53,412 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-06-19 01:07:53,412 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=eaaeea6c-49fd-4c41-b247-0e2eb5f51aad to datanode:1fe601f2-329a-46b5-8003-e31a11712904
scm_1         | 2020-06-19 01:07:53,413 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=eaaeea6c-49fd-4c41-b247-0e2eb5f51aad to datanode:e16193af-992b-449b-a054-1b4385464923
scm_1         | 2020-06-19 01:07:53,413 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=eaaeea6c-49fd-4c41-b247-0e2eb5f51aad to datanode:bad929e1-92e9-4f9a-b8b4-4f52cb0ead89
scm_1         | 2020-06-19 01:07:53,415 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: eaaeea6c-49fd-4c41-b247-0e2eb5f51aad, Nodes: 1fe601f2-329a-46b5-8003-e31a11712904{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}e16193af-992b-449b-a054-1b4385464923{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}bad929e1-92e9-4f9a-b8b4-4f52cb0ead89{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-19T01:07:53.412763Z]
scm_1         | 2020-06-19 01:07:53,416 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-06-19 01:07:55,130 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: f879c4ce-2d93-4c9c-b88e-73e9e68dbb60, Nodes: e16193af-992b-449b-a054-1b4385464923{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:e16193af-992b-449b-a054-1b4385464923, CreationTimestamp2020-06-19T01:07:51.482184Z] moved to OPEN state
scm_1         | 2020-06-19 01:07:55,134 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-19 01:07:55,150 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-19 01:07:55,175 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 6c4a8402-d6b3-4216-ba1e-9b0daefce644, Nodes: f4253cac-8b23-4603-baf9-9d0335b1f337{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:f4253cac-8b23-4603-baf9-9d0335b1f337, CreationTimestamp2020-06-19T01:07:51.529680Z] moved to OPEN state
scm_1         | 2020-06-19 01:07:55,176 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-19 01:07:55,176 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-19 01:07:55,652 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 3ed600d5-9c82-4b23-a409-3764ff5ba268, Nodes: 1fe601f2-329a-46b5-8003-e31a11712904{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:1fe601f2-329a-46b5-8003-e31a11712904, CreationTimestamp2020-06-19T01:07:51.602818Z] moved to OPEN state
scm_1         | 2020-06-19 01:07:55,659 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-19 01:07:55,661 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-19 01:07:56,147 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 3b462c0b-ea51-4a3a-a3c6-4fb43bc732f7, Nodes: 64b3d39f-3fe5-4249-9316-ebaafc2d6305{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:64b3d39f-3fe5-4249-9316-ebaafc2d6305, CreationTimestamp2020-06-19T01:07:52.184490Z] moved to OPEN state
scm_1         | 2020-06-19 01:07:56,148 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-19 01:07:56,150 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-19 01:07:56,327 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: cec7efc5-1764-4106-bcb0-5a67f50bbd6b, Nodes: 849d5c96-9fa8-47f6-a4f1-8034e5e21574{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:849d5c96-9fa8-47f6-a4f1-8034e5e21574, CreationTimestamp2020-06-19T01:07:52.331991Z] moved to OPEN state
scm_1         | 2020-06-19 01:07:56,334 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-19 01:07:56,334 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-19 01:07:57,308 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: e5232efc-6eb4-4532-a52f-3b67e3cf1029, Nodes: bad929e1-92e9-4f9a-b8b4-4f52cb0ead89{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:bad929e1-92e9-4f9a-b8b4-4f52cb0ead89, CreationTimestamp2020-06-19T01:07:53.392250Z] moved to OPEN state
scm_1         | 2020-06-19 01:07:57,314 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-19 01:07:57,314 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-19 01:08:00,956 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 3c154b4e-35c3-468d-a70d-43ce517b6eca, Nodes: 64b3d39f-3fe5-4249-9316-ebaafc2d6305{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}f4253cac-8b23-4603-baf9-9d0335b1f337{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}849d5c96-9fa8-47f6-a4f1-8034e5e21574{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:f4253cac-8b23-4603-baf9-9d0335b1f337, CreationTimestamp2020-06-19T01:07:52.342041Z] moved to OPEN state
scm_1         | 2020-06-19 01:08:00,973 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-19 01:08:00,974 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1         | 2020-06-19 01:08:00,982 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1         | 2020-06-19 01:08:00,982 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1         | 2020-06-19 01:08:00,982 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1         | 2020-06-19 01:08:01,267 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: eaaeea6c-49fd-4c41-b247-0e2eb5f51aad, Nodes: 1fe601f2-329a-46b5-8003-e31a11712904{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}e16193af-992b-449b-a054-1b4385464923{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}bad929e1-92e9-4f9a-b8b4-4f52cb0ead89{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:1fe601f2-329a-46b5-8003-e31a11712904, CreationTimestamp2020-06-19T01:07:53.412763Z] moved to OPEN state
scm_1         | 2020-06-19 01:08:08,461 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:12,366 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:12,569 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:15,172 [IPC Server handler 55 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:17,764 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:20,361 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:22,975 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:23,108 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:25,672 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:25,754 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:25,839 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:28,410 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:28,495 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:28,570 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:31,167 [IPC Server handler 53 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:33,737 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:36,346 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:38,903 [IPC Server handler 10 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:41,447 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:44,006 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:46,573 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:49,169 [IPC Server handler 42 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:51,739 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:54,315 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:54,412 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:54,490 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:54,570 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:57,135 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:57,238 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:59,776 [IPC Server handler 10 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:59,847 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:08:59,937 [IPC Server handler 14 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:02,483 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:02,570 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:02,652 [IPC Server handler 10 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:02,721 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:02,794 [IPC Server handler 14 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:05,381 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:05,450 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:08,028 [IPC Server handler 38 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:08,096 [IPC Server handler 32 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:08,156 [IPC Server handler 29 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:08,243 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:10,824 [IPC Server handler 38 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:13,392 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:13,494 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:16,057 [IPC Server handler 32 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:18,603 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:21,201 [IPC Server handler 72 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:21,268 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:23,828 [IPC Server handler 32 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:23,898 [IPC Server handler 48 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:23,983 [IPC Server handler 43 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:24,037 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:24,098 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:26,645 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:29,201 [IPC Server handler 59 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:29,262 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:29,318 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:29,370 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:31,927 [IPC Server handler 43 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:32,003 [IPC Server handler 23 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:32,079 [IPC Server handler 46 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:34,629 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:34,712 [IPC Server handler 14 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:37,232 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:37,296 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:37,360 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:39,924 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:42,530 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:45,069 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:47,619 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:47,734 [IPC Server handler 38 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:47,795 [IPC Server handler 32 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:48,868 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-06-19 01:09:48,868 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-06-19 01:09:57,902 [IPC Server handler 48 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:58,017 [IPC Server handler 46 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:09:58,079 [IPC Server handler 22 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:10:13,174 [IPC Server handler 51 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:10:13,290 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:10:28,389 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:10:28,498 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:10:43,604 [IPC Server handler 18 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:10:58,708 [IPC Server handler 52 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:11:13,854 [IPC Server handler 48 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:11:13,976 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:11:14,046 [IPC Server handler 53 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:11:14,100 [IPC Server handler 51 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:11:29,204 [IPC Server handler 7 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:11:29,292 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:11:44,398 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:11:48,869 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-06-19 01:11:48,870 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-06-19 01:11:59,509 [IPC Server handler 13 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:12:14,622 [IPC Server handler 52 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:12:29,708 [IPC Server handler 28 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:12:29,826 [IPC Server handler 48 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:12:44,937 [IPC Server handler 27 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:12:45,055 [IPC Server handler 22 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:13:00,129 [IPC Server handler 35 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:13:00,255 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:13:00,315 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-19 01:13:00,994 [EventQueue-Delayed safe mode statusForReplicationManager] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1         | 2020-06-19 01:13:01,008 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1
scm_1         | 2020-06-19 01:13:01,016 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2
scm_1         | 2020-06-19 01:13:01,017 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #3
scm_1         | 2020-06-19 01:13:01,017 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #4
scm_1         | 2020-06-19 01:13:01,018 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #5
scm_1         | 2020-06-19 01:13:01,019 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #6
scm_1         | 2020-06-19 01:13:01,026 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 30 milliseconds for processing 12 containers.
scm_1         | 2020-06-19 01:13:01,027 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #7
scm_1         | 2020-06-19 01:13:01,027 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #8
scm_1         | 2020-06-19 01:13:01,027 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #9
scm_1         | 2020-06-19 01:13:01,028 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #10
scm_1         | 2020-06-19 01:13:01,028 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #11
scm_1         | 2020-06-19 01:13:01,028 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #12
scm_1         | 2020-06-19 01:13:05,964 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode 1fe601f2-329a-46b5-8003-e31a11712904{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-06-19 01:13:06,063 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #4 to CLOSED state, datanode 1fe601f2-329a-46b5-8003-e31a11712904{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-06-19 01:13:06,106 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #6 to CLOSED state, datanode 1fe601f2-329a-46b5-8003-e31a11712904{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-06-19 01:13:06,172 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #7 to CLOSED state, datanode 1fe601f2-329a-46b5-8003-e31a11712904{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-06-19 01:13:06,193 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #9 to CLOSED state, datanode 1fe601f2-329a-46b5-8003-e31a11712904{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-06-19 01:13:06,237 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #11 to CLOSED state, datanode 1fe601f2-329a-46b5-8003-e31a11712904{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null} reported CLOSED replica.
