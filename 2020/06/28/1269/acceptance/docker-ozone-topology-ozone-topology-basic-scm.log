Attaching to ozone-topology_datanode_5_1, ozone-topology_datanode_3_1, ozone-topology_datanode_2_1, ozone-topology_datanode_4_1, ozone-topology_datanode_6_1, ozone-topology_om_1, ozone-topology_datanode_1_1, ozone-topology_scm_1
datanode_2_1  | Enabled profiling in kernel
datanode_2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2_1  | 2020-06-28 04:48:20,477 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2_1  | /************************************************************
datanode_2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2_1  | STARTUP_MSG:   host = afca4a6bd46c/10.5.0.5
datanode_2_1  | STARTUP_MSG:   args = []
datanode_2_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/04f8e6a7cb48fec22990dc37bb33bf5daefde5fa ; compiled by 'runner' on 2020-06-28T04:22Z
datanode_2_1  | STARTUP_MSG:   java = 11.0.6
datanode_2_1  | ************************************************************/
datanode_2_1  | 2020-06-28 04:48:20,526 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2_1  | 2020-06-28 04:48:22,493 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2_1  | 2020-06-28 04:48:23,506 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2_1  | 2020-06-28 04:48:25,107 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2_1  | 2020-06-28 04:48:25,111 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2_1  | 2020-06-28 04:48:25,925 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:afca4a6bd46c ip:10.5.0.5
datanode_2_1  | 2020-06-28 04:48:26,976 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2_1  | 2020-06-28 04:48:26,981 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2_1  | 2020-06-28 04:48:27,072 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2_1  | 2020-06-28 04:48:27,114 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2_1  | 2020-06-28 04:48:27,450 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2_1  | 2020-06-28 04:48:34,278 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2_1  | 2020-06-28 04:48:34,634 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2_1  | 2020-06-28 04:48:35,728 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2_1  | 2020-06-28 04:48:35,735 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2_1  | 2020-06-28 04:48:35,740 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-28 04:48:35,747 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2_1  | 2020-06-28 04:48:35,748 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2_1  | 2020-06-28 04:48:36,889 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-06-28 04:48:38,448 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2_1  | 2020-06-28 04:48:38,656 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2_1  | 2020-06-28 04:48:38,887 [main] INFO util.log: Logging initialized @26640ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2_1  | 2020-06-28 04:48:39,622 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2_1  | 2020-06-28 04:48:39,645 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2_1  | 2020-06-28 04:48:39,704 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2_1  | 2020-06-28 04:48:39,725 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2_1  | 2020-06-28 04:48:39,727 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2_1  | 2020-06-28 04:48:39,731 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2_1  | 2020-06-28 04:48:39,989 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2_1  | 2020-06-28 04:48:40,059 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2_1  | 2020-06-28 04:48:40,083 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2_1  | 2020-06-28 04:48:40,338 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2_1  | 2020-06-28 04:48:40,338 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2_1  | 2020-06-28 04:48:40,340 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2_1  | 2020-06-28 04:48:40,436 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b4954b2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2_1  | 2020-06-28 04:48:40,442 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57416e49{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2_1  | 2020-06-28 04:48:40,985 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c27f72{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-2653936505141226061.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2_1  | 2020-06-28 04:48:41,029 [main] INFO server.AbstractConnector: Started ServerConnector@25cde5bb{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2_1  | 2020-06-28 04:48:41,029 [main] INFO server.Server: Started @28782ms
datanode_2_1  | 2020-06-28 04:48:41,067 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2_1  | 2020-06-28 04:48:41,067 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2_1  | 2020-06-28 04:48:41,083 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2_1  | 2020-06-28 04:48:41,216 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2e75307] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2_1  | 2020-06-28 04:48:42,652 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2_1  | 2020-06-28 04:48:44,612 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-06-28 04:48:45,613 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-06-28 04:48:46,614 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-06-28 04:48:47,615 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2_1  | 2020-06-28 04:48:48,646 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2_1  | java.net.SocketTimeoutException: Call From afca4a6bd46c/10.5.0.5 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:44498 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_2_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_2_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_2_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_2_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_2_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.5:44498 remote=scm/10.5.0.71:9861]
datanode_2_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_2_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_2_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_2_1  | 2020-06-28 04:48:49,378 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2_1  | 2020-06-28 04:48:49,380 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2_1  | 2020-06-28 04:48:49,395 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 33c58236-2210-4e24-acad-e8ad1ad12aba at port 9858
datanode_2_1  | 2020-06-28 04:48:49,533 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 33c58236-2210-4e24-acad-e8ad1ad12aba: start RPC server
datanode_2_1  | 2020-06-28 04:48:49,909 [Datanode State Machine Thread - 1] INFO server.GrpcService: 33c58236-2210-4e24-acad-e8ad1ad12aba: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2_1  | 2020-06-28 04:48:54,651 [Command processor thread] INFO impl.RaftServerProxy: 33c58236-2210-4e24-acad-e8ad1ad12aba: addNew group-F6BE55194031:[33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858] returns group-F6BE55194031:java.util.concurrent.CompletableFuture@64476b8f[Not completed]
datanode_2_1  | 2020-06-28 04:48:54,873 [pool-19-thread-1] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba: new RaftServerImpl for group-F6BE55194031:[33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-06-28 04:48:54,874 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-06-28 04:48:54,919 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-06-28 04:48:54,919 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-06-28 04:48:54,943 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-06-28 04:48:54,951 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-06-28 04:48:55,011 [pool-19-thread-1] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031: ConfigurationManager, init=-1: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-06-28 04:48:55,012 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-06-28 04:48:55,161 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-06-28 04:48:55,173 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/89434bcf-f0f0-4ce9-b210-f6be55194031 does not exist. Creating ...
datanode_2_1  | 2020-06-28 04:48:55,389 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/89434bcf-f0f0-4ce9-b210-f6be55194031/in_use.lock acquired by nodename 6@afca4a6bd46c
datanode_2_1  | 2020-06-28 04:48:55,424 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/89434bcf-f0f0-4ce9-b210-f6be55194031 has been successfully formatted.
datanode_2_1  | 2020-06-28 04:48:55,492 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-F6BE55194031: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-06-28 04:48:55,544 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-06-28 04:48:55,559 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-06-28 04:48:55,636 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2_1  | 2020-06-28 04:48:55,647 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-28 04:48:55,671 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-28 04:48:55,729 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031
datanode_2_1  | 2020-06-28 04:48:55,837 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-06-28 04:48:55,890 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/89434bcf-f0f0-4ce9-b210-f6be55194031
datanode_2_1  | 2020-06-28 04:48:55,947 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-06-28 04:48:55,948 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-06-28 04:48:55,976 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-28 04:48:55,986 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-06-28 04:48:55,987 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-06-28 04:48:55,992 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-06-28 04:48:55,994 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-06-28 04:48:55,998 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-06-28 04:48:56,004 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-06-28 04:48:56,213 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-06-28 04:48:56,322 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-28 04:48:56,322 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-28 04:48:56,404 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-06-28 04:48:56,419 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-06-28 04:48:56,433 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-06-28 04:48:56,436 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-06-28 04:48:56,440 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-06-28 04:48:56,611 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031
datanode_2_1  | 2020-06-28 04:48:56,624 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031
datanode_2_1  | 2020-06-28 04:48:56,636 [pool-19-thread-1] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031: start as a follower, conf=-1: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858], old=null
datanode_2_1  | 2020-06-28 04:48:56,651 [pool-19-thread-1] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-06-28 04:48:56,654 [pool-19-thread-1] INFO impl.RoleInfo: 33c58236-2210-4e24-acad-e8ad1ad12aba: start FollowerState
datanode_2_1  | 2020-06-28 04:48:56,683 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F6BE55194031,id=33c58236-2210-4e24-acad-e8ad1ad12aba
datanode_2_1  | 2020-06-28 04:48:56,685 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031
datanode_2_1  | 2020-06-28 04:48:56,817 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "89434bcf-f0f0-4ce9-b210-f6be55194031"
datanode_2_1  | .
datanode_2_1  | 2020-06-28 04:48:56,824 [Command processor thread] INFO impl.RaftServerProxy: 33c58236-2210-4e24-acad-e8ad1ad12aba: addNew group-DB6904F15B83:[33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858] returns group-DB6904F15B83:java.util.concurrent.CompletableFuture@37bfb6ee[Not completed]
datanode_2_1  | 2020-06-28 04:48:56,838 [pool-19-thread-1] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba: new RaftServerImpl for group-DB6904F15B83:[33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_2_1  | 2020-06-28 04:48:56,883 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2_1  | 2020-06-28 04:48:56,883 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2_1  | 2020-06-28 04:48:56,883 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2_1  | 2020-06-28 04:48:56,884 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2_1  | 2020-06-28 04:48:56,884 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2_1  | 2020-06-28 04:48:56,884 [pool-19-thread-1] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83: ConfigurationManager, init=-1: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_2_1  | 2020-06-28 04:48:56,887 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2_1  | 2020-06-28 04:48:56,887 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2_1  | 2020-06-28 04:48:56,889 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7a741092-4377-4624-abe5-db6904f15b83 does not exist. Creating ...
datanode_2_1  | 2020-06-28 04:48:56,898 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7a741092-4377-4624-abe5-db6904f15b83/in_use.lock acquired by nodename 6@afca4a6bd46c
datanode_2_1  | 2020-06-28 04:48:56,908 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7a741092-4377-4624-abe5-db6904f15b83 has been successfully formatted.
datanode_2_1  | 2020-06-28 04:48:56,909 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-DB6904F15B83: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2_1  | 2020-06-28 04:48:56,909 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2_1  | 2020-06-28 04:48:56,920 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2_1  | 2020-06-28 04:48:56,921 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | Enabled profiling in kernel
datanode_1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1_1  | 2020-06-28 04:48:17,004 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1_1  | /************************************************************
datanode_1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1_1  | STARTUP_MSG:   host = d9a4a2bff95d/10.5.0.4
datanode_1_1  | STARTUP_MSG:   args = []
datanode_1_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2_1  | 2020-06-28 04:48:56,921 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2_1  | 2020-06-28 04:48:56,921 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-28 04:48:56,921 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83
datanode_2_1  | 2020-06-28 04:48:56,922 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2_1  | 2020-06-28 04:48:56,922 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/7a741092-4377-4624-abe5-db6904f15b83
datanode_2_1  | 2020-06-28 04:48:56,923 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2_1  | 2020-06-28 04:48:56,924 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2_1  | 2020-06-28 04:48:56,924 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2_1  | 2020-06-28 04:48:56,925 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2_1  | 2020-06-28 04:48:56,927 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2_1  | 2020-06-28 04:48:56,927 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2_1  | 2020-06-28 04:48:56,929 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2_1  | 2020-06-28 04:48:56,930 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2_1  | 2020-06-28 04:48:56,930 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2_1  | 2020-06-28 04:48:56,936 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2_1  | 2020-06-28 04:48:56,944 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-28 04:48:56,944 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2_1  | 2020-06-28 04:48:56,957 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2_1  | 2020-06-28 04:48:56,963 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2_1  | 2020-06-28 04:48:56,963 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2_1  | 2020-06-28 04:48:56,963 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2_1  | 2020-06-28 04:48:56,964 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2_1  | 2020-06-28 04:48:56,967 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83
datanode_2_1  | 2020-06-28 04:48:56,968 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83
datanode_2_1  | 2020-06-28 04:48:56,976 [pool-19-thread-1] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83: start as a follower, conf=-1: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null
datanode_2_1  | 2020-06-28 04:48:56,981 [pool-19-thread-1] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2_1  | 2020-06-28 04:48:56,981 [pool-19-thread-1] INFO impl.RoleInfo: 33c58236-2210-4e24-acad-e8ad1ad12aba: start FollowerState
datanode_2_1  | 2020-06-28 04:48:56,996 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DB6904F15B83,id=33c58236-2210-4e24-acad-e8ad1ad12aba
datanode_2_1  | 2020-06-28 04:48:56,996 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83
datanode_2_1  | 2020-06-28 04:49:01,670 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "7a741092-4377-4624-abe5-db6904f15b83"
datanode_2_1  | .
datanode_2_1  | 2020-06-28 04:49:01,731 [Thread-23] INFO impl.FollowerState: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-FollowerState: change to CANDIDATE, lastRpcTime:5077ms, electionTimeout:5046ms
datanode_2_1  | 2020-06-28 04:49:01,743 [Thread-23] INFO impl.RoleInfo: 33c58236-2210-4e24-acad-e8ad1ad12aba: shutdown FollowerState
datanode_2_1  | 2020-06-28 04:49:01,743 [Thread-23] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2_1  | 2020-06-28 04:49:01,766 [Thread-23] INFO impl.RoleInfo: 33c58236-2210-4e24-acad-e8ad1ad12aba: start LeaderElection
datanode_2_1  | 2020-06-28 04:49:01,804 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO impl.LeaderElection: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1: begin an election at term 1 for -1: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858], old=null
datanode_2_1  | 2020-06-28 04:49:01,808 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO impl.RoleInfo: 33c58236-2210-4e24-acad-e8ad1ad12aba: shutdown LeaderElection
datanode_2_1  | 2020-06-28 04:49:01,817 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2_1  | 2020-06-28 04:49:01,881 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F6BE55194031 with new leaderId: 33c58236-2210-4e24-acad-e8ad1ad12aba
datanode_2_1  | 2020-06-28 04:49:01,914 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031: change Leader from null to 33c58236-2210-4e24-acad-e8ad1ad12aba at term 1 for becomeLeader, leader elected after 6387ms
datanode_2_1  | 2020-06-28 04:49:01,957 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2_1  | 2020-06-28 04:49:01,959 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2_1  | 2020-06-28 04:49:02,002 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031
datanode_2_1  | 2020-06-28 04:49:02,032 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2_1  | 2020-06-28 04:49:02,036 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2_1  | 2020-06-28 04:49:02,053 [Thread-25] INFO impl.FollowerState: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83-FollowerState: change to CANDIDATE, lastRpcTime:5071ms, electionTimeout:5055ms
datanode_2_1  | 2020-06-28 04:49:02,065 [Thread-25] INFO impl.RoleInfo: 33c58236-2210-4e24-acad-e8ad1ad12aba: shutdown FollowerState
datanode_2_1  | 2020-06-28 04:49:02,067 [Thread-25] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2_1  | 2020-06-28 04:49:02,067 [Thread-25] INFO impl.RoleInfo: 33c58236-2210-4e24-acad-e8ad1ad12aba: start LeaderElection
datanode_2_1  | 2020-06-28 04:49:02,081 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83-LeaderElection2] INFO impl.LeaderElection: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83-LeaderElection2: begin an election at term 1 for -1: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null
datanode_2_1  | 2020-06-28 04:49:02,138 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2_1  | 2020-06-28 04:49:02,162 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2_1  | 2020-06-28 04:49:02,172 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2_1  | 2020-06-28 04:49:02,297 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO impl.RoleInfo: 33c58236-2210-4e24-acad-e8ad1ad12aba: start LeaderState
datanode_2_1  | 2020-06-28 04:49:02,638 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-06-28 04:49:02,703 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83-LeaderElection2] INFO impl.LeaderElection: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83-LeaderElection2: Election REJECTED; received 2 response(s) [33c58236-2210-4e24-acad-e8ad1ad12aba<-7112676b-d549-48b4-b648-8def29c22825#0:FAIL-t1, 33c58236-2210-4e24-acad-e8ad1ad12aba<-a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9#0:FAIL-t1] and 0 exception(s); 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83:t1, leader=null, voted=33c58236-2210-4e24-acad-e8ad1ad12aba, raftlog=33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null
datanode_2_1  | 2020-06-28 04:49:02,708 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83-LeaderElection2] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83: changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
datanode_2_1  | 2020-06-28 04:49:02,708 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83-LeaderElection2] INFO impl.RoleInfo: 33c58236-2210-4e24-acad-e8ad1ad12aba: shutdown LeaderElection
datanode_2_1  | 2020-06-28 04:49:02,708 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83-LeaderElection2] INFO impl.RoleInfo: 33c58236-2210-4e24-acad-e8ad1ad12aba: start FollowerState
datanode_2_1  | 2020-06-28 04:49:02,807 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-LeaderElection1] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031: set configuration 0: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858], old=null at 0
datanode_2_1  | 2020-06-28 04:49:03,282 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-DB6904F15B83 with new leaderId: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9
datanode_2_1  | 2020-06-28 04:49:03,282 [grpc-default-executor-0] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83: change Leader from null to a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9 at term 1 for appendEntries, leader elected after 6372ms
datanode_2_1  | 2020-06-28 04:49:03,414 [grpc-default-executor-0] INFO impl.RaftServerImpl: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83: set configuration 0: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null at 0
datanode_2_1  | 2020-06-28 04:49:03,433 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2_1  | 2020-06-28 04:49:03,751 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-DB6904F15B83-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7a741092-4377-4624-abe5-db6904f15b83/current/log_inprogress_0
datanode_2_1  | 2020-06-28 04:49:03,773 [33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 33c58236-2210-4e24-acad-e8ad1ad12aba@group-F6BE55194031-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/89434bcf-f0f0-4ce9-b210-f6be55194031/current/log_inprogress_0
datanode_2_1  | 2020-06-28 04:54:10,132 [RatisApplyTransactionExecutor 5] INFO interfaces.Container: Container 5 is synced with bcsId 137.
datanode_2_1  | 2020-06-28 04:54:10,132 [RatisApplyTransactionExecutor 5] INFO interfaces.Container: Container 5 is synced with bcsId 137.
datanode_2_1  | 2020-06-28 04:54:10,159 [RatisApplyTransactionExecutor 5] INFO interfaces.Container: Container 5 is closed with bcsId 137.
datanode_2_1  | 2020-06-28 04:54:10,199 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is synced with bcsId 140.
datanode_2_1  | 2020-06-28 04:54:10,199 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is synced with bcsId 140.
datanode_2_1  | 2020-06-28 04:54:10,229 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is closed with bcsId 140.
datanode_2_1  | 2020-06-28 04:54:10,257 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is synced with bcsId 155.
datanode_2_1  | 2020-06-28 04:54:10,257 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is synced with bcsId 155.
datanode_2_1  | 2020-06-28 04:54:10,262 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is closed with bcsId 155.
datanode_2_1  | 2020-06-28 04:54:10,296 [RatisApplyTransactionExecutor 1] INFO interfaces.Container: Container 1 is synced with bcsId 50.
datanode_2_1  | 2020-06-28 04:54:10,299 [RatisApplyTransactionExecutor 1] INFO interfaces.Container: Container 1 is synced with bcsId 50.
datanode_2_1  | 2020-06-28 04:54:10,309 [RatisApplyTransactionExecutor 1] INFO interfaces.Container: Container 1 is closed with bcsId 50.
datanode_2_1  | 2020-06-28 04:54:10,342 [RatisApplyTransactionExecutor 3] INFO interfaces.Container: Container 3 is synced with bcsId 105.
datanode_2_1  | 2020-06-28 04:54:10,342 [RatisApplyTransactionExecutor 3] INFO interfaces.Container: Container 3 is synced with bcsId 105.
datanode_2_1  | 2020-06-28 04:54:10,350 [RatisApplyTransactionExecutor 3] INFO interfaces.Container: Container 3 is closed with bcsId 105.
datanode_1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/04f8e6a7cb48fec22990dc37bb33bf5daefde5fa ; compiled by 'runner' on 2020-06-28T04:22Z
datanode_1_1  | STARTUP_MSG:   java = 11.0.6
datanode_1_1  | ************************************************************/
datanode_1_1  | 2020-06-28 04:48:17,092 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1_1  | 2020-06-28 04:48:18,905 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1_1  | 2020-06-28 04:48:19,837 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1_1  | 2020-06-28 04:48:21,243 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1_1  | 2020-06-28 04:48:21,244 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1_1  | 2020-06-28 04:48:21,933 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:d9a4a2bff95d ip:10.5.0.4
datanode_1_1  | 2020-06-28 04:48:22,910 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1_1  | 2020-06-28 04:48:22,996 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1_1  | 2020-06-28 04:48:23,040 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1_1  | 2020-06-28 04:48:23,118 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1_1  | 2020-06-28 04:48:23,600 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1_1  | 2020-06-28 04:48:31,196 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1_1  | 2020-06-28 04:48:31,714 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1_1  | 2020-06-28 04:48:32,830 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1_1  | 2020-06-28 04:48:32,830 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1_1  | 2020-06-28 04:48:32,876 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-06-28 04:48:32,876 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1_1  | 2020-06-28 04:48:32,877 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-06-28 04:48:34,863 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-06-28 04:48:36,598 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1_1  | 2020-06-28 04:48:36,795 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1_1  | 2020-06-28 04:48:36,998 [main] INFO util.log: Logging initialized @26122ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1_1  | 2020-06-28 04:48:37,730 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1_1  | 2020-06-28 04:48:37,773 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1_1  | 2020-06-28 04:48:37,799 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1_1  | 2020-06-28 04:48:37,801 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1_1  | 2020-06-28 04:48:37,801 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1_1  | 2020-06-28 04:48:37,810 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1_1  | 2020-06-28 04:48:38,035 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1_1  | 2020-06-28 04:48:38,111 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1_1  | 2020-06-28 04:48:38,112 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1_1  | 2020-06-28 04:48:38,355 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1_1  | 2020-06-28 04:48:38,355 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1_1  | 2020-06-28 04:48:38,356 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1_1  | 2020-06-28 04:48:38,556 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b4954b2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1_1  | 2020-06-28 04:48:38,557 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57416e49{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1_1  | 2020-06-28 04:48:39,108 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c27f72{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-3298197506325847257.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1_1  | 2020-06-28 04:48:39,180 [main] INFO server.AbstractConnector: Started ServerConnector@25cde5bb{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1_1  | 2020-06-28 04:48:39,180 [main] INFO server.Server: Started @28304ms
datanode_1_1  | 2020-06-28 04:48:39,213 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1_1  | 2020-06-28 04:48:39,213 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1_1  | 2020-06-28 04:48:39,230 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1_1  | 2020-06-28 04:48:39,413 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4b4bb535] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1_1  | 2020-06-28 04:48:40,703 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1_1  | 2020-06-28 04:48:42,978 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-06-28 04:48:43,979 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-06-28 04:48:44,980 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-06-28 04:48:45,981 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-06-28 04:48:46,981 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-06-28 04:48:47,982 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1_1  | 2020-06-28 04:48:49,297 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1_1  | 2020-06-28 04:48:49,300 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1_1  | 2020-06-28 04:48:49,305 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9 at port 9858
datanode_1_1  | 2020-06-28 04:48:49,400 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: start RPC server
datanode_1_1  | 2020-06-28 04:48:49,954 [Datanode State Machine Thread - 0] INFO server.GrpcService: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1_1  | 2020-06-28 04:48:54,751 [Command processor thread] INFO impl.RaftServerProxy: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: addNew group-31D93A00EB7A:[a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858] returns group-31D93A00EB7A:java.util.concurrent.CompletableFuture@68d1d475[Not completed]
datanode_1_1  | 2020-06-28 04:48:54,947 [pool-19-thread-1] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: new RaftServerImpl for group-31D93A00EB7A:[a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-06-28 04:48:55,023 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-06-28 04:48:55,050 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-06-28 04:48:55,050 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-06-28 04:48:55,051 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-06-28 04:48:55,067 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-06-28 04:48:55,145 [pool-19-thread-1] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A: ConfigurationManager, init=-1: [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-06-28 04:48:55,174 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-06-28 04:48:55,249 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-06-28 04:48:55,296 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/02c2667e-f50b-4f03-ae5c-31d93a00eb7a does not exist. Creating ...
datanode_1_1  | 2020-06-28 04:48:55,355 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/02c2667e-f50b-4f03-ae5c-31d93a00eb7a/in_use.lock acquired by nodename 6@d9a4a2bff95d
datanode_1_1  | 2020-06-28 04:48:55,383 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/02c2667e-f50b-4f03-ae5c-31d93a00eb7a has been successfully formatted.
datanode_1_1  | 2020-06-28 04:48:55,543 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-31D93A00EB7A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-06-28 04:48:55,545 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-06-28 04:48:55,607 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-06-28 04:48:55,673 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-06-28 04:48:55,693 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-06-28 04:48:55,704 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-06-28 04:48:55,736 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A
datanode_1_1  | 2020-06-28 04:48:55,849 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-06-28 04:48:55,933 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/02c2667e-f50b-4f03-ae5c-31d93a00eb7a
datanode_1_1  | 2020-06-28 04:48:55,934 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-06-28 04:48:55,934 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-06-28 04:48:55,936 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-06-28 04:48:55,939 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-06-28 04:48:55,940 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-06-28 04:48:55,948 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-06-28 04:48:55,974 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-06-28 04:48:55,976 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-06-28 04:48:55,976 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-06-28 04:48:56,112 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-06-28 04:48:56,156 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-06-28 04:48:56,183 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-06-28 04:48:56,190 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-06-28 04:48:56,216 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-06-28 04:48:56,231 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-06-28 04:48:56,235 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-06-28 04:48:56,239 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-06-28 04:48:56,415 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A
datanode_1_1  | 2020-06-28 04:48:56,438 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A
datanode_1_1  | 2020-06-28 04:48:56,545 [pool-19-thread-1] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A: start as a follower, conf=-1: [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null
datanode_1_1  | 2020-06-28 04:48:56,546 [pool-19-thread-1] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-06-28 04:48:56,560 [pool-19-thread-1] INFO impl.RoleInfo: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: start FollowerState
datanode_1_1  | 2020-06-28 04:48:56,617 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-31D93A00EB7A,id=a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9
datanode_1_1  | 2020-06-28 04:48:56,625 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A
datanode_1_1  | 2020-06-28 04:48:56,737 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "02c2667e-f50b-4f03-ae5c-31d93a00eb7a"
datanode_1_1  | .
datanode_1_1  | 2020-06-28 04:48:56,746 [Command processor thread] INFO impl.RaftServerProxy: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: addNew group-DB6904F15B83:[33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858] returns group-DB6904F15B83:java.util.concurrent.CompletableFuture@1507b188[Not completed]
datanode_1_1  | 2020-06-28 04:48:56,781 [pool-19-thread-1] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: new RaftServerImpl for group-DB6904F15B83:[33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_1_1  | 2020-06-28 04:48:56,786 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1_1  | 2020-06-28 04:48:56,795 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1_1  | 2020-06-28 04:48:56,799 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1_1  | 2020-06-28 04:48:56,799 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1_1  | 2020-06-28 04:48:56,799 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-06-28 04:48:56,800 [pool-19-thread-1] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83: ConfigurationManager, init=-1: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_1_1  | 2020-06-28 04:48:56,800 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1_1  | 2020-06-28 04:48:56,800 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1_1  | 2020-06-28 04:48:56,801 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7a741092-4377-4624-abe5-db6904f15b83 does not exist. Creating ...
datanode_1_1  | 2020-06-28 04:48:56,831 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7a741092-4377-4624-abe5-db6904f15b83/in_use.lock acquired by nodename 6@d9a4a2bff95d
datanode_1_1  | 2020-06-28 04:48:56,835 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7a741092-4377-4624-abe5-db6904f15b83 has been successfully formatted.
datanode_1_1  | 2020-06-28 04:48:56,840 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-DB6904F15B83: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1_1  | 2020-06-28 04:48:56,843 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1_1  | 2020-06-28 04:48:56,848 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1_1  | 2020-06-28 04:48:56,855 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1_1  | 2020-06-28 04:48:56,855 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-06-28 04:48:56,855 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-06-28 04:48:56,855 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83
datanode_1_1  | 2020-06-28 04:48:56,856 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1_1  | 2020-06-28 04:48:56,857 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/7a741092-4377-4624-abe5-db6904f15b83
datanode_1_1  | 2020-06-28 04:48:56,857 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1_1  | 2020-06-28 04:48:56,858 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1_1  | 2020-06-28 04:48:56,858 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1_1  | 2020-06-28 04:48:56,858 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1_1  | 2020-06-28 04:48:56,859 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1_1  | 2020-06-28 04:48:56,859 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1_1  | 2020-06-28 04:48:56,863 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1_1  | 2020-06-28 04:48:56,863 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1_1  | 2020-06-28 04:48:56,871 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1_1  | 2020-06-28 04:48:56,872 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1_1  | 2020-06-28 04:48:56,875 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-06-28 04:48:56,877 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1_1  | 2020-06-28 04:48:56,879 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1_1  | 2020-06-28 04:48:56,883 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1_1  | 2020-06-28 04:48:56,883 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1_1  | 2020-06-28 04:48:56,886 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1_1  | 2020-06-28 04:48:56,887 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1_1  | 2020-06-28 04:48:56,887 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83
datanode_1_1  | 2020-06-28 04:48:56,888 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83
datanode_1_1  | 2020-06-28 04:48:56,889 [pool-19-thread-1] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83: start as a follower, conf=-1: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null
datanode_1_1  | 2020-06-28 04:48:56,891 [pool-19-thread-1] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1_1  | 2020-06-28 04:48:56,891 [pool-19-thread-1] INFO impl.RoleInfo: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: start FollowerState
datanode_1_1  | 2020-06-28 04:48:56,892 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DB6904F15B83,id=a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9
datanode_1_1  | 2020-06-28 04:48:56,898 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83
datanode_1_1  | 2020-06-28 04:49:00,920 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 7112676b-d549-48b4-b648-8def29c22825{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
datanode_1_1  | org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2.861012630s. [buffered_nanos=2777031858, remote_addr=/10.5.0.7:9858]
datanode_1_1  | 	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
datanode_1_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:86)
datanode_1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:187)
datanode_1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:156)
datanode_1_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:95)
datanode_1_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:337)
datanode_1_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:249)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:102)
datanode_1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode_1_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode_1_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654)
datanode_1_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode_1_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode_1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode_1_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode_1_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode_1_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:99)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:465)
datanode_1_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.861012630s. [buffered_nanos=2777031858, remote_addr=/10.5.0.7:9858]
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
datanode_1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
datanode_1_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:284)
datanode_1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:158)
datanode_1_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:185)
datanode_1_1  | 	... 18 more
datanode_1_1  | 2020-06-28 04:49:01,777 [Thread-22] INFO impl.FollowerState: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-FollowerState: change to CANDIDATE, lastRpcTime:5218ms, electionTimeout:5173ms
datanode_1_1  | 2020-06-28 04:49:01,785 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "7a741092-4377-4624-abe5-db6904f15b83"
datanode_1_1  | .
datanode_1_1  | 2020-06-28 04:49:01,786 [Thread-22] INFO impl.RoleInfo: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: shutdown FollowerState
datanode_1_1  | 2020-06-28 04:49:01,788 [Thread-22] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1_1  | 2020-06-28 04:49:01,792 [Thread-22] INFO impl.RoleInfo: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: start LeaderElection
datanode_1_1  | 2020-06-28 04:49:01,836 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO impl.LeaderElection: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1: begin an election at term 1 for -1: [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null
datanode_1_1  | 2020-06-28 04:49:01,893 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO impl.RoleInfo: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: shutdown LeaderElection
datanode_1_1  | 2020-06-28 04:49:01,907 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1_1  | 2020-06-28 04:49:01,907 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-31D93A00EB7A with new leaderId: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9
datanode_1_1  | 2020-06-28 04:49:01,927 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A: change Leader from null to a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9 at term 1 for becomeLeader, leader elected after 6363ms
datanode_1_1  | 2020-06-28 04:49:01,974 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1_1  | 2020-06-28 04:49:02,022 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1_1  | 2020-06-28 04:49:02,003 [Thread-24] INFO impl.FollowerState: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-FollowerState: change to CANDIDATE, lastRpcTime:5111ms, electionTimeout:5101ms
datanode_1_1  | 2020-06-28 04:49:02,035 [Thread-24] INFO impl.RoleInfo: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: shutdown FollowerState
datanode_3_1  | Enabled profiling in kernel
datanode_3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3_1  | 2020-06-28 04:48:21,168 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3_1  | /************************************************************
datanode_3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3_1  | STARTUP_MSG:   host = 1383bfed402e/10.5.0.6
datanode_3_1  | STARTUP_MSG:   args = []
datanode_3_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1_1  | 2020-06-28 04:49:02,035 [Thread-24] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1_1  | 2020-06-28 04:49:02,036 [Thread-24] INFO impl.RoleInfo: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: start LeaderElection
datanode_1_1  | 2020-06-28 04:49:02,068 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A
datanode_1_1  | 2020-06-28 04:49:02,105 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1_1  | 2020-06-28 04:49:02,111 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1_1  | 2020-06-28 04:49:02,105 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO impl.LeaderElection: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2: begin an election at term 1 for -1: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null
datanode_1_1  | 2020-06-28 04:49:02,205 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1_1  | 2020-06-28 04:49:02,248 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1_1  | 2020-06-28 04:49:02,251 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1_1  | 2020-06-28 04:49:02,453 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO impl.RoleInfo: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: start LeaderState
datanode_1_1  | 2020-06-28 04:49:02,656 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO impl.LeaderElection: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2: Election PASSED; received 1 response(s) [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9<-7112676b-d549-48b4-b648-8def29c22825#0:OK-t1] and 0 exception(s); a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83:t1, leader=null, voted=a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9, raftlog=a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null
datanode_1_1  | 2020-06-28 04:49:02,659 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO impl.RoleInfo: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: shutdown LeaderElection
datanode_1_1  | 2020-06-28 04:49:02,660 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1_1  | 2020-06-28 04:49:02,663 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-DB6904F15B83 with new leaderId: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9
datanode_1_1  | 2020-06-28 04:49:02,664 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83: change Leader from null to a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9 at term 1 for becomeLeader, leader elected after 5820ms
datanode_1_1  | 2020-06-28 04:49:02,664 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1_1  | 2020-06-28 04:49:02,669 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1_1  | 2020-06-28 04:49:02,669 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83
datanode_1_1  | 2020-06-28 04:49:02,670 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1_1  | 2020-06-28 04:49:02,675 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1_1  | 2020-06-28 04:49:02,675 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1_1  | 2020-06-28 04:49:02,676 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1_1  | 2020-06-28 04:49:02,677 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1_1  | 2020-06-28 04:49:02,707 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1_1  | 2020-06-28 04:49:02,722 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-06-28 04:49:02,726 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1_1  | 2020-06-28 04:49:02,732 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-06-28 04:49:02,827 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1_1  | 2020-06-28 04:49:02,843 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-06-28 04:49:02,850 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-06-28 04:49:02,895 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83
datanode_1_1  | 2020-06-28 04:49:02,965 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1_1  | 2020-06-28 04:49:02,985 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1_1  | 2020-06-28 04:49:02,976 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-LeaderElection1] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A: set configuration 0: [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null at 0
datanode_1_1  | 2020-06-28 04:49:02,986 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_5_1  | Enabled profiling in kernel
datanode_5_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_5_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_5_1  | 2020-06-28 04:48:22,584 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_5_1  | /************************************************************
datanode_5_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_5_1  | STARTUP_MSG:   host = 1256b0818dea/10.5.0.8
datanode_5_1  | STARTUP_MSG:   args = []
datanode_4_1  | Enabled profiling in kernel
datanode_4_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_4_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_4_1  | 2020-06-28 04:48:22,329 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_4_1  | /************************************************************
datanode_4_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_4_1  | STARTUP_MSG:   host = e7894b308847/10.5.0.7
datanode_4_1  | STARTUP_MSG:   args = []
datanode_4_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1_1  | 2020-06-28 04:49:02,986 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1_1  | 2020-06-28 04:49:02,987 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1_1  | 2020-06-28 04:49:02,993 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1_1  | 2020-06-28 04:49:03,036 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO impl.RoleInfo: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9: start LeaderState
datanode_1_1  | 2020-06-28 04:49:03,046 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1_1  | 2020-06-28 04:49:03,066 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-LeaderElection2] INFO impl.RaftServerImpl: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83: set configuration 0: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null at 0
datanode_1_1  | 2020-06-28 04:49:03,573 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-DB6904F15B83-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7a741092-4377-4624-abe5-db6904f15b83/current/log_inprogress_0
datanode_1_1  | 2020-06-28 04:49:03,599 [a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9@group-31D93A00EB7A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/02c2667e-f50b-4f03-ae5c-31d93a00eb7a/current/log_inprogress_0
datanode_1_1  | 2020-06-28 04:54:10,085 [RatisApplyTransactionExecutor 5] INFO interfaces.Container: Container 5 is synced with bcsId 137.
datanode_1_1  | 2020-06-28 04:54:10,085 [RatisApplyTransactionExecutor 5] INFO interfaces.Container: Container 5 is synced with bcsId 137.
datanode_1_1  | 2020-06-28 04:54:10,091 [RatisApplyTransactionExecutor 5] INFO interfaces.Container: Container 5 is closed with bcsId 137.
datanode_1_1  | 2020-06-28 04:54:10,177 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is synced with bcsId 140.
datanode_1_1  | 2020-06-28 04:54:10,180 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is synced with bcsId 140.
datanode_1_1  | 2020-06-28 04:54:10,186 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is closed with bcsId 140.
datanode_1_1  | 2020-06-28 04:54:10,235 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is synced with bcsId 155.
datanode_1_1  | 2020-06-28 04:54:10,235 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is synced with bcsId 155.
datanode_1_1  | 2020-06-28 04:54:10,250 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is closed with bcsId 155.
datanode_1_1  | 2020-06-28 04:54:10,291 [RatisApplyTransactionExecutor 1] INFO interfaces.Container: Container 1 is synced with bcsId 50.
datanode_1_1  | 2020-06-28 04:54:10,291 [RatisApplyTransactionExecutor 1] INFO interfaces.Container: Container 1 is synced with bcsId 50.
datanode_1_1  | 2020-06-28 04:54:10,311 [RatisApplyTransactionExecutor 1] INFO interfaces.Container: Container 1 is closed with bcsId 50.
datanode_1_1  | 2020-06-28 04:54:10,340 [RatisApplyTransactionExecutor 3] INFO interfaces.Container: Container 3 is synced with bcsId 105.
datanode_1_1  | 2020-06-28 04:54:10,340 [RatisApplyTransactionExecutor 3] INFO interfaces.Container: Container 3 is synced with bcsId 105.
datanode_1_1  | 2020-06-28 04:54:10,347 [RatisApplyTransactionExecutor 3] INFO interfaces.Container: Container 3 is closed with bcsId 105.
datanode_3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/04f8e6a7cb48fec22990dc37bb33bf5daefde5fa ; compiled by 'runner' on 2020-06-28T04:22Z
datanode_3_1  | STARTUP_MSG:   java = 11.0.6
datanode_3_1  | ************************************************************/
datanode_3_1  | 2020-06-28 04:48:21,274 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3_1  | 2020-06-28 04:48:23,197 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3_1  | 2020-06-28 04:48:24,155 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3_1  | 2020-06-28 04:48:25,271 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3_1  | 2020-06-28 04:48:25,271 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3_1  | 2020-06-28 04:48:25,964 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:1383bfed402e ip:10.5.0.6
datanode_3_1  | 2020-06-28 04:48:26,979 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3_1  | 2020-06-28 04:48:27,016 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3_1  | 2020-06-28 04:48:27,065 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3_1  | 2020-06-28 04:48:27,122 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3_1  | 2020-06-28 04:48:27,548 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3_1  | 2020-06-28 04:48:34,949 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3_1  | 2020-06-28 04:48:35,469 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3_1  | 2020-06-28 04:48:36,439 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3_1  | 2020-06-28 04:48:36,462 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3_1  | 2020-06-28 04:48:36,475 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-28 04:48:36,476 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3_1  | 2020-06-28 04:48:36,478 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-06-28 04:48:37,848 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-06-28 04:48:39,511 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3_1  | 2020-06-28 04:48:39,702 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3_1  | 2020-06-28 04:48:39,882 [main] INFO util.log: Logging initialized @27282ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3_1  | 2020-06-28 04:48:40,675 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3_1  | 2020-06-28 04:48:40,692 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3_1  | 2020-06-28 04:48:40,715 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3_1  | 2020-06-28 04:48:40,723 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3_1  | 2020-06-28 04:48:40,730 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3_1  | 2020-06-28 04:48:40,731 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3_1  | 2020-06-28 04:48:40,903 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_3_1  | 2020-06-28 04:48:40,965 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3_1  | 2020-06-28 04:48:40,968 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3_1  | 2020-06-28 04:48:41,257 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3_1  | 2020-06-28 04:48:41,271 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3_1  | 2020-06-28 04:48:41,273 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_3_1  | 2020-06-28 04:48:41,321 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6003220a{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3_1  | 2020-06-28 04:48:41,348 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@726a8729{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3_1  | 2020-06-28 04:48:42,002 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2807cf3{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-2379599905286311036.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3_1  | 2020-06-28 04:48:42,140 [main] INFO server.AbstractConnector: Started ServerConnector@52b32b70{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3_1  | 2020-06-28 04:48:42,141 [main] INFO server.Server: Started @29541ms
datanode_3_1  | 2020-06-28 04:48:42,156 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3_1  | 2020-06-28 04:48:42,156 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3_1  | 2020-06-28 04:48:42,160 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3_1  | 2020-06-28 04:48:42,258 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4983b164] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3_1  | 2020-06-28 04:48:43,739 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3_1  | 2020-06-28 04:48:45,705 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-06-28 04:48:46,706 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-06-28 04:48:47,707 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3_1  | 2020-06-28 04:48:48,752 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_3_1  | java.net.SocketTimeoutException: Call From 1383bfed402e/10.5.0.6 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:60742 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_3_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_3_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_3_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.6:60742 remote=scm/10.5.0.71:9861]
datanode_3_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_3_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_3_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_3_1  | 2020-06-28 04:48:49,391 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3_1  | 2020-06-28 04:48:49,393 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3_1  | 2020-06-28 04:48:49,411 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3 at port 9858
datanode_3_1  | 2020-06-28 04:48:49,545 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: start RPC server
datanode_3_1  | 2020-06-28 04:48:49,993 [Datanode State Machine Thread - 1] INFO server.GrpcService: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3_1  | 2020-06-28 04:48:53,602 [Command processor thread] INFO impl.RaftServerProxy: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: addNew group-6155B05AAEDB:[cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858] returns group-6155B05AAEDB:java.util.concurrent.CompletableFuture@68d2e620[Not completed]
datanode_3_1  | 2020-06-28 04:48:53,755 [pool-19-thread-1] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: new RaftServerImpl for group-6155B05AAEDB:[cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-06-28 04:48:53,782 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-06-28 04:48:53,787 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-06-28 04:48:53,787 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-06-28 04:48:53,788 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-06-28 04:48:53,793 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-06-28 04:48:53,811 [pool-19-thread-1] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB: ConfigurationManager, init=-1: [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-06-28 04:48:53,827 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-06-28 04:48:53,846 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-06-28 04:48:53,855 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/005d03de-8143-41d6-b8da-6155b05aaedb does not exist. Creating ...
datanode_3_1  | 2020-06-28 04:48:53,876 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/005d03de-8143-41d6-b8da-6155b05aaedb/in_use.lock acquired by nodename 6@1383bfed402e
datanode_3_1  | 2020-06-28 04:48:53,891 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/005d03de-8143-41d6-b8da-6155b05aaedb has been successfully formatted.
datanode_3_1  | 2020-06-28 04:48:53,945 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-6155B05AAEDB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-06-28 04:48:53,947 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-06-28 04:48:53,949 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-06-28 04:48:54,003 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-06-28 04:48:54,005 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-28 04:48:54,026 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_4_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/04f8e6a7cb48fec22990dc37bb33bf5daefde5fa ; compiled by 'runner' on 2020-06-28T04:22Z
datanode_4_1  | STARTUP_MSG:   java = 11.0.6
datanode_4_1  | ************************************************************/
datanode_4_1  | 2020-06-28 04:48:22,443 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_4_1  | 2020-06-28 04:48:24,651 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_4_1  | 2020-06-28 04:48:25,663 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_4_1  | 2020-06-28 04:48:26,815 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_4_1  | 2020-06-28 04:48:26,815 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_4_1  | 2020-06-28 04:48:27,481 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:e7894b308847 ip:10.5.0.7
datanode_4_1  | 2020-06-28 04:48:28,627 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_4_1  | 2020-06-28 04:48:28,629 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_4_1  | 2020-06-28 04:48:28,638 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_4_1  | 2020-06-28 04:48:28,787 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_4_1  | 2020-06-28 04:48:29,271 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_4_1  | 2020-06-28 04:48:36,585 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_4_1  | 2020-06-28 04:48:37,017 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_4_1  | 2020-06-28 04:48:38,348 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_4_1  | 2020-06-28 04:48:38,357 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_4_1  | 2020-06-28 04:48:38,363 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-06-28 04:48:38,367 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_4_1  | 2020-06-28 04:48:38,368 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_4_1  | 2020-06-28 04:48:39,723 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-06-28 04:48:41,253 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_4_1  | 2020-06-28 04:48:41,429 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_4_1  | 2020-06-28 04:48:41,758 [main] INFO util.log: Logging initialized @27374ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_4_1  | 2020-06-28 04:48:42,628 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_4_1  | 2020-06-28 04:48:42,663 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_4_1  | 2020-06-28 04:48:42,692 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_4_1  | 2020-06-28 04:48:42,703 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_4_1  | 2020-06-28 04:48:42,715 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_4_1  | 2020-06-28 04:48:42,717 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_4_1  | 2020-06-28 04:48:43,004 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_4_1  | 2020-06-28 04:48:43,068 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_4_1  | 2020-06-28 04:48:43,076 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_4_1  | 2020-06-28 04:48:43,292 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_4_1  | 2020-06-28 04:48:43,292 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_4_1  | 2020-06-28 04:48:43,299 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_4_1  | 2020-06-28 04:48:43,383 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@9205c0a{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_4_1  | 2020-06-28 04:48:43,384 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@283d3628{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_4_1  | 2020-06-28 04:48:43,833 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4aab7195{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-13037277839523736379.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_4_1  | 2020-06-28 04:48:43,899 [main] INFO server.AbstractConnector: Started ServerConnector@30d15e4a{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_4_1  | 2020-06-28 04:48:43,900 [main] INFO server.Server: Started @29517ms
datanode_4_1  | 2020-06-28 04:48:43,909 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_4_1  | 2020-06-28 04:48:43,909 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_4_1  | 2020-06-28 04:48:43,921 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_4_1  | 2020-06-28 04:48:44,036 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@27bbc121] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_4_1  | 2020-06-28 04:48:45,042 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_4_1  | 2020-06-28 04:48:47,123 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-06-28 04:48:48,124 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_4_1  | 2020-06-28 04:48:49,538 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_4_1  | 2020-06-28 04:48:49,544 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_4_1  | 2020-06-28 04:48:49,547 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 7112676b-d549-48b4-b648-8def29c22825 at port 9858
datanode_4_1  | 2020-06-28 04:48:49,669 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 7112676b-d549-48b4-b648-8def29c22825: start RPC server
datanode_4_1  | 2020-06-28 04:48:50,135 [Datanode State Machine Thread - 0] INFO server.GrpcService: 7112676b-d549-48b4-b648-8def29c22825: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_4_1  | 2020-06-28 04:48:55,635 [Command processor thread] INFO impl.RaftServerProxy: 7112676b-d549-48b4-b648-8def29c22825: addNew group-FCF718F41080:[7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858] returns group-FCF718F41080:java.util.concurrent.CompletableFuture@3f3dcdce[Not completed]
datanode_4_1  | 2020-06-28 04:48:55,775 [pool-19-thread-1] INFO impl.RaftServerImpl: 7112676b-d549-48b4-b648-8def29c22825: new RaftServerImpl for group-FCF718F41080:[7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-06-28 04:48:55,782 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-06-28 04:48:55,787 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-06-28 04:48:55,791 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-06-28 04:48:55,799 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-06-28 04:48:55,801 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-06-28 04:48:55,840 [pool-19-thread-1] INFO impl.RaftServerImpl: 7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080: ConfigurationManager, init=-1: [7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-06-28 04:48:55,867 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-06-28 04:48:55,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-06-28 04:48:55,916 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a84ba09c-c17f-4d14-a5de-fcf718f41080 does not exist. Creating ...
datanode_4_1  | 2020-06-28 04:48:55,984 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a84ba09c-c17f-4d14-a5de-fcf718f41080/in_use.lock acquired by nodename 6@e7894b308847
datanode_4_1  | 2020-06-28 04:48:56,010 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a84ba09c-c17f-4d14-a5de-fcf718f41080 has been successfully formatted.
datanode_4_1  | 2020-06-28 04:48:56,072 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-FCF718F41080: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-06-28 04:48:56,079 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-06-28 04:48:56,141 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-06-28 04:48:56,207 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-06-28 04:48:56,214 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-06-28 04:48:56,240 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_5_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_5_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/04f8e6a7cb48fec22990dc37bb33bf5daefde5fa ; compiled by 'runner' on 2020-06-28T04:22Z
datanode_5_1  | STARTUP_MSG:   java = 11.0.6
datanode_5_1  | ************************************************************/
datanode_5_1  | 2020-06-28 04:48:22,675 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3_1  | 2020-06-28 04:48:54,040 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB
datanode_3_1  | 2020-06-28 04:48:54,164 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-06-28 04:48:54,205 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/005d03de-8143-41d6-b8da-6155b05aaedb
datanode_3_1  | 2020-06-28 04:48:54,220 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-06-28 04:48:54,231 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-28 04:48:54,232 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-06-28 04:48:54,234 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-06-28 04:48:54,237 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-06-28 04:48:54,240 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-06-28 04:48:54,242 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-06-28 04:48:54,255 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-06-28 04:48:54,255 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-06-28 04:48:54,357 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-06-28 04:48:54,418 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-28 04:48:54,418 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-28 04:48:54,443 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-06-28 04:48:54,455 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-06-28 04:48:54,455 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-06-28 04:48:54,476 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-06-28 04:48:54,478 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-06-28 04:48:54,658 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB
datanode_3_1  | 2020-06-28 04:48:54,721 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB
datanode_3_1  | 2020-06-28 04:48:54,762 [pool-19-thread-1] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB: start as a follower, conf=-1: [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858], old=null
datanode_3_1  | 2020-06-28 04:48:54,806 [pool-19-thread-1] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-06-28 04:48:54,828 [pool-19-thread-1] INFO impl.RoleInfo: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: start FollowerState
datanode_3_1  | 2020-06-28 04:48:54,927 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6155B05AAEDB,id=cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3
datanode_3_1  | 2020-06-28 04:48:54,938 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB
datanode_3_1  | 2020-06-28 04:48:55,237 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "005d03de-8143-41d6-b8da-6155b05aaedb"
datanode_3_1  | .
datanode_3_1  | 2020-06-28 04:48:55,250 [Command processor thread] INFO impl.RaftServerProxy: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: addNew group-F277262A3CA5:[cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858] returns group-F277262A3CA5:java.util.concurrent.CompletableFuture@51900621[Not completed]
datanode_3_1  | 2020-06-28 04:48:55,345 [pool-19-thread-1] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: new RaftServerImpl for group-F277262A3CA5:[cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_3_1  | 2020-06-28 04:48:55,348 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3_1  | 2020-06-28 04:48:55,351 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3_1  | 2020-06-28 04:48:55,355 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-06-28 04:48:55,356 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3_1  | 2020-06-28 04:48:55,360 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-06-28 04:48:55,369 [pool-19-thread-1] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5: ConfigurationManager, init=-1: [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_3_1  | 2020-06-28 04:48:55,370 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3_1  | 2020-06-28 04:48:55,375 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3_1  | 2020-06-28 04:48:55,379 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/843592c9-09f2-4b01-86b3-f277262a3ca5 does not exist. Creating ...
datanode_3_1  | 2020-06-28 04:48:55,454 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/843592c9-09f2-4b01-86b3-f277262a3ca5/in_use.lock acquired by nodename 6@1383bfed402e
datanode_3_1  | 2020-06-28 04:48:55,500 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/843592c9-09f2-4b01-86b3-f277262a3ca5 has been successfully formatted.
datanode_3_1  | 2020-06-28 04:48:55,508 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-F277262A3CA5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3_1  | 2020-06-28 04:48:55,508 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3_1  | 2020-06-28 04:48:55,508 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3_1  | 2020-06-28 04:48:55,508 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-06-28 04:48:55,508 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-06-28 04:48:56,281 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080
datanode_4_1  | 2020-06-28 04:48:56,485 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-06-28 04:48:56,569 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/a84ba09c-c17f-4d14-a5de-fcf718f41080
datanode_4_1  | 2020-06-28 04:48:56,575 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-06-28 04:48:56,576 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-06-28 04:48:56,656 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-06-28 04:48:56,664 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-06-28 04:48:56,671 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-06-28 04:48:56,675 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-06-28 04:48:56,698 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-06-28 04:48:56,698 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-06-28 04:48:56,699 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-06-28 04:48:56,940 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-06-28 04:48:57,036 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-06-28 04:48:57,036 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-06-28 04:48:57,074 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-06-28 04:48:57,099 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-06-28 04:48:57,110 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-06-28 04:48:57,110 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-06-28 04:48:57,129 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-06-28 04:48:57,339 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080
datanode_4_1  | 2020-06-28 04:48:57,371 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080
datanode_4_1  | 2020-06-28 04:48:57,428 [pool-19-thread-1] INFO impl.RaftServerImpl: 7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080: start as a follower, conf=-1: [7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858], old=null
datanode_4_1  | 2020-06-28 04:48:57,432 [pool-19-thread-1] INFO impl.RaftServerImpl: 7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-06-28 04:48:57,440 [pool-19-thread-1] INFO impl.RoleInfo: 7112676b-d549-48b4-b648-8def29c22825: start FollowerState
datanode_4_1  | 2020-06-28 04:48:57,488 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FCF718F41080,id=7112676b-d549-48b4-b648-8def29c22825
datanode_4_1  | 2020-06-28 04:48:57,490 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080
datanode_5_1  | 2020-06-28 04:48:24,745 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_5_1  | 2020-06-28 04:48:25,657 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_5_1  | 2020-06-28 04:48:27,208 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_5_1  | 2020-06-28 04:48:27,209 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_5_1  | 2020-06-28 04:48:27,953 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:1256b0818dea ip:10.5.0.8
datanode_5_1  | 2020-06-28 04:48:28,883 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_5_1  | 2020-06-28 04:48:28,955 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_5_1  | 2020-06-28 04:48:28,958 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_5_1  | 2020-06-28 04:48:29,052 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_5_1  | 2020-06-28 04:48:29,299 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_5_1  | 2020-06-28 04:48:36,183 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_5_1  | 2020-06-28 04:48:36,550 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_5_1  | 2020-06-28 04:48:37,909 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_5_1  | 2020-06-28 04:48:37,910 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_5_1  | 2020-06-28 04:48:37,911 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-06-28 04:48:37,917 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_5_1  | 2020-06-28 04:48:37,919 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_5_1  | 2020-06-28 04:48:39,114 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-06-28 04:48:40,711 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_5_1  | 2020-06-28 04:48:40,823 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_5_1  | 2020-06-28 04:48:41,007 [main] INFO util.log: Logging initialized @26487ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_5_1  | 2020-06-28 04:48:41,757 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_5_1  | 2020-06-28 04:48:41,782 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_5_1  | 2020-06-28 04:48:41,851 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_5_1  | 2020-06-28 04:48:41,855 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_5_1  | 2020-06-28 04:48:41,855 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_5_1  | 2020-06-28 04:48:41,869 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_5_1  | 2020-06-28 04:48:42,108 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_5_1  | 2020-06-28 04:48:42,199 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_5_1  | 2020-06-28 04:48:42,211 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_5_1  | 2020-06-28 04:48:42,431 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_5_1  | 2020-06-28 04:48:42,435 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_5_1  | 2020-06-28 04:48:42,436 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_5_1  | 2020-06-28 04:48:42,532 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b4954b2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_5_1  | 2020-06-28 04:48:42,554 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57416e49{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_5_1  | 2020-06-28 04:48:43,120 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c27f72{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-6585449092108375580.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_5_1  | 2020-06-28 04:48:43,223 [main] INFO server.AbstractConnector: Started ServerConnector@25cde5bb{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_5_1  | 2020-06-28 04:48:43,224 [main] INFO server.Server: Started @28710ms
datanode_5_1  | 2020-06-28 04:48:43,229 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_5_1  | 2020-06-28 04:48:43,229 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_5_1  | 2020-06-28 04:48:43,235 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_5_1  | 2020-06-28 04:48:43,454 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@482d8abe] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_4_1  | 2020-06-28 04:48:57,666 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "a84ba09c-c17f-4d14-a5de-fcf718f41080"
datanode_4_1  | .
datanode_4_1  | 2020-06-28 04:48:57,683 [Command processor thread] INFO impl.RaftServerProxy: 7112676b-d549-48b4-b648-8def29c22825: addNew group-DB6904F15B83:[33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858] returns group-DB6904F15B83:java.util.concurrent.CompletableFuture@7e0dad78[Not completed]
datanode_4_1  | 2020-06-28 04:48:57,689 [pool-19-thread-1] INFO impl.RaftServerImpl: 7112676b-d549-48b4-b648-8def29c22825: new RaftServerImpl for group-DB6904F15B83:[33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858] with ContainerStateMachine:uninitialized
datanode_4_1  | 2020-06-28 04:48:57,705 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_4_1  | 2020-06-28 04:48:57,713 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_4_1  | 2020-06-28 04:48:57,719 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_4_1  | 2020-06-28 04:48:57,719 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_4_1  | 2020-06-28 04:48:57,719 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_4_1  | 2020-06-28 04:48:57,719 [pool-19-thread-1] INFO impl.RaftServerImpl: 7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83: ConfigurationManager, init=-1: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_4_1  | 2020-06-28 04:48:57,720 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_4_1  | 2020-06-28 04:48:57,720 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_4_1  | 2020-06-28 04:48:57,723 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7a741092-4377-4624-abe5-db6904f15b83 does not exist. Creating ...
datanode_4_1  | 2020-06-28 04:48:57,725 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7a741092-4377-4624-abe5-db6904f15b83/in_use.lock acquired by nodename 6@e7894b308847
datanode_4_1  | 2020-06-28 04:48:57,731 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7a741092-4377-4624-abe5-db6904f15b83 has been successfully formatted.
datanode_4_1  | 2020-06-28 04:48:57,732 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-DB6904F15B83: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_4_1  | 2020-06-28 04:48:57,732 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_4_1  | 2020-06-28 04:48:57,732 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_4_1  | 2020-06-28 04:48:57,733 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_4_1  | 2020-06-28 04:48:57,733 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_4_1  | 2020-06-28 04:48:57,733 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-06-28 04:48:57,733 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83
datanode_4_1  | 2020-06-28 04:48:57,734 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_4_1  | 2020-06-28 04:48:57,739 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/7a741092-4377-4624-abe5-db6904f15b83
datanode_4_1  | 2020-06-28 04:48:57,739 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_4_1  | 2020-06-28 04:48:57,739 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_4_1  | 2020-06-28 04:48:57,739 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_4_1  | 2020-06-28 04:48:57,740 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_4_1  | 2020-06-28 04:48:57,740 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_4_1  | 2020-06-28 04:48:57,743 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_4_1  | 2020-06-28 04:48:57,743 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_4_1  | 2020-06-28 04:48:57,746 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_4_1  | 2020-06-28 04:48:57,746 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_4_1  | 2020-06-28 04:48:57,764 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_4_1  | 2020-06-28 04:48:57,775 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-06-28 04:48:57,775 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_4_1  | 2020-06-28 04:48:57,777 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_4_1  | 2020-06-28 04:48:57,781 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_4_1  | 2020-06-28 04:48:57,781 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_4_1  | 2020-06-28 04:48:57,781 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_4_1  | 2020-06-28 04:48:57,782 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_4_1  | 2020-06-28 04:48:57,787 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83
datanode_4_1  | 2020-06-28 04:48:57,791 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83
datanode_4_1  | 2020-06-28 04:48:57,792 [pool-19-thread-1] INFO impl.RaftServerImpl: 7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83: start as a follower, conf=-1: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null
datanode_4_1  | 2020-06-28 04:48:57,797 [pool-19-thread-1] INFO impl.RaftServerImpl: 7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_4_1  | 2020-06-28 04:48:57,797 [pool-19-thread-1] INFO impl.RoleInfo: 7112676b-d549-48b4-b648-8def29c22825: start FollowerState
datanode_4_1  | 2020-06-28 04:48:57,821 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DB6904F15B83,id=7112676b-d549-48b4-b648-8def29c22825
datanode_4_1  | 2020-06-28 04:48:57,821 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83
datanode_4_1  | 2020-06-28 04:49:01,734 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "7a741092-4377-4624-abe5-db6904f15b83"
datanode_4_1  | .
datanode_4_1  | 2020-06-28 04:49:02,419 [grpc-default-executor-1] INFO impl.RaftServerImpl: 7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9
datanode_4_1  | 2020-06-28 04:49:02,438 [grpc-default-executor-1] INFO impl.RoleInfo: 7112676b-d549-48b4-b648-8def29c22825: shutdown FollowerState
datanode_4_1  | 2020-06-28 04:49:02,438 [grpc-default-executor-1] INFO impl.RoleInfo: 7112676b-d549-48b4-b648-8def29c22825: start FollowerState
datanode_4_1  | 2020-06-28 04:49:02,438 [Thread-24] INFO impl.FollowerState: 7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_4_1  | 2020-06-28 04:49:02,571 [Thread-22] INFO impl.FollowerState: 7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-FollowerState: change to CANDIDATE, lastRpcTime:5131ms, electionTimeout:5117ms
datanode_4_1  | 2020-06-28 04:49:02,573 [Thread-22] INFO impl.RoleInfo: 7112676b-d549-48b4-b648-8def29c22825: shutdown FollowerState
datanode_4_1  | 2020-06-28 04:49:02,575 [Thread-22] INFO impl.RaftServerImpl: 7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_4_1  | 2020-06-28 04:49:02,577 [Thread-22] INFO impl.RoleInfo: 7112676b-d549-48b4-b648-8def29c22825: start LeaderElection
datanode_4_1  | 2020-06-28 04:49:02,635 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO impl.LeaderElection: 7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1: begin an election at term 1 for -1: [7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858], old=null
datanode_4_1  | 2020-06-28 04:49:02,636 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO impl.RoleInfo: 7112676b-d549-48b4-b648-8def29c22825: shutdown LeaderElection
datanode_4_1  | 2020-06-28 04:49:02,640 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO impl.RaftServerImpl: 7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_4_1  | 2020-06-28 04:49:02,640 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-FCF718F41080 with new leaderId: 7112676b-d549-48b4-b648-8def29c22825
datanode_4_1  | 2020-06-28 04:49:02,641 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO impl.RaftServerImpl: 7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080: change Leader from null to 7112676b-d549-48b4-b648-8def29c22825 at term 1 for becomeLeader, leader elected after 6561ms
datanode_4_1  | 2020-06-28 04:49:02,679 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_4_1  | 2020-06-28 04:49:02,691 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_4_1  | 2020-06-28 04:49:02,694 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080
datanode_4_1  | 2020-06-28 04:49:02,720 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_4_1  | 2020-06-28 04:49:02,724 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_4_1  | 2020-06-28 04:49:02,801 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_4_1  | 2020-06-28 04:49:02,803 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_4_1  | 2020-06-28 04:49:02,807 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_4_1  | 2020-06-28 04:49:02,919 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO impl.RoleInfo: 7112676b-d549-48b4-b648-8def29c22825: start LeaderState
datanode_4_1  | 2020-06-28 04:49:03,005 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-06-28 04:49:03,150 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-LeaderElection1] INFO impl.RaftServerImpl: 7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080: set configuration 0: [7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858], old=null at 0
datanode_4_1  | 2020-06-28 04:49:03,312 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-DB6904F15B83 with new leaderId: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9
datanode_4_1  | 2020-06-28 04:49:03,323 [grpc-default-executor-1] INFO impl.RaftServerImpl: 7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83: change Leader from null to a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9 at term 1 for appendEntries, leader elected after 5580ms
datanode_4_1  | 2020-06-28 04:49:03,399 [grpc-default-executor-1] INFO impl.RaftServerImpl: 7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83: set configuration 0: [33c58236-2210-4e24-acad-e8ad1ad12aba:10.5.0.5:9858, 7112676b-d549-48b4-b648-8def29c22825:10.5.0.7:9858, a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9:10.5.0.4:9858], old=null at 0
datanode_4_1  | 2020-06-28 04:49:03,441 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83-SegmentedRaftLogWorker: Starting segment from index:0
datanode_4_1  | 2020-06-28 04:49:03,734 [7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 7112676b-d549-48b4-b648-8def29c22825@group-FCF718F41080-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a84ba09c-c17f-4d14-a5de-fcf718f41080/current/log_inprogress_0
datanode_4_1  | 2020-06-28 04:49:03,736 [7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 7112676b-d549-48b4-b648-8def29c22825@group-DB6904F15B83-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7a741092-4377-4624-abe5-db6904f15b83/current/log_inprogress_0
datanode_4_1  | 2020-06-28 04:54:10,083 [RatisApplyTransactionExecutor 5] INFO interfaces.Container: Container 5 is synced with bcsId 137.
datanode_4_1  | 2020-06-28 04:54:10,084 [RatisApplyTransactionExecutor 5] INFO interfaces.Container: Container 5 is synced with bcsId 137.
datanode_4_1  | 2020-06-28 04:54:10,099 [RatisApplyTransactionExecutor 5] INFO interfaces.Container: Container 5 is closed with bcsId 137.
datanode_4_1  | 2020-06-28 04:54:10,220 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is synced with bcsId 140.
datanode_4_1  | 2020-06-28 04:54:10,231 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is synced with bcsId 140.
datanode_4_1  | 2020-06-28 04:54:10,249 [RatisApplyTransactionExecutor 7] INFO interfaces.Container: Container 7 is closed with bcsId 140.
datanode_5_1  | 2020-06-28 04:48:44,536 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_5_1  | 2020-06-28 04:48:46,712 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-06-28 04:48:47,713 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_5_1  | 2020-06-28 04:48:48,755 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_5_1  | java.net.SocketTimeoutException: Call From 1256b0818dea/10.5.0.8 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.8:39474 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_5_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_5_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_5_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_5_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_5_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_5_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_4_1  | 2020-06-28 04:54:10,278 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is synced with bcsId 155.
datanode_4_1  | 2020-06-28 04:54:10,278 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is synced with bcsId 155.
datanode_4_1  | 2020-06-28 04:54:10,288 [RatisApplyTransactionExecutor 9] INFO interfaces.Container: Container 9 is closed with bcsId 155.
datanode_4_1  | 2020-06-28 04:54:10,325 [RatisApplyTransactionExecutor 1] INFO interfaces.Container: Container 1 is synced with bcsId 50.
datanode_4_1  | 2020-06-28 04:54:10,327 [RatisApplyTransactionExecutor 1] INFO interfaces.Container: Container 1 is synced with bcsId 50.
datanode_4_1  | 2020-06-28 04:54:10,333 [RatisApplyTransactionExecutor 1] INFO interfaces.Container: Container 1 is closed with bcsId 50.
datanode_4_1  | 2020-06-28 04:54:10,375 [RatisApplyTransactionExecutor 3] INFO interfaces.Container: Container 3 is synced with bcsId 105.
datanode_4_1  | 2020-06-28 04:54:10,375 [RatisApplyTransactionExecutor 3] INFO interfaces.Container: Container 3 is synced with bcsId 105.
datanode_4_1  | 2020-06-28 04:54:10,380 [RatisApplyTransactionExecutor 3] INFO interfaces.Container: Container 3 is closed with bcsId 105.
datanode_5_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_5_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_5_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_5_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_5_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_5_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_5_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_5_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.8:39474 remote=scm/10.5.0.71:9861]
datanode_5_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_5_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_5_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_5_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_5_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_5_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_5_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_5_1  | 2020-06-28 04:48:49,322 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_5_1  | 2020-06-28 04:48:49,330 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_5_1  | 2020-06-28 04:48:49,334 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0 at port 9858
datanode_5_1  | 2020-06-28 04:48:49,463 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0: start RPC server
datanode_5_1  | 2020-06-28 04:48:50,079 [Datanode State Machine Thread - 1] INFO server.GrpcService: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_5_1  | 2020-06-28 04:48:54,915 [Command processor thread] INFO impl.RaftServerProxy: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0: addNew group-18B0906BF01E:[ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858] returns group-18B0906BF01E:java.util.concurrent.CompletableFuture@232d86a3[Not completed]
datanode_5_1  | 2020-06-28 04:48:55,306 [pool-19-thread-1] INFO impl.RaftServerImpl: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0: new RaftServerImpl for group-18B0906BF01E:[ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-06-28 04:48:55,333 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-06-28 04:48:55,356 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-06-28 04:48:55,361 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-06-28 04:48:55,370 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-06-28 04:48:55,408 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-06-28 04:48:55,466 [pool-19-thread-1] INFO impl.RaftServerImpl: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E: ConfigurationManager, init=-1: [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-06-28 04:48:55,492 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-06-28 04:48:55,619 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-06-28 04:48:55,621 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f18e2931-e295-4338-b778-18b0906bf01e does not exist. Creating ...
datanode_5_1  | 2020-06-28 04:48:55,649 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f18e2931-e295-4338-b778-18b0906bf01e/in_use.lock acquired by nodename 6@1256b0818dea
datanode_5_1  | 2020-06-28 04:48:55,661 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f18e2931-e295-4338-b778-18b0906bf01e has been successfully formatted.
datanode_5_1  | 2020-06-28 04:48:55,737 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-18B0906BF01E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-06-28 04:48:55,744 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-06-28 04:48:55,771 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-06-28 04:48:55,812 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-06-28 04:48:55,826 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-06-28 04:48:55,831 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-06-28 04:48:55,886 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E
datanode_5_1  | 2020-06-28 04:48:56,038 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-06-28 04:48:56,130 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/f18e2931-e295-4338-b778-18b0906bf01e
datanode_5_1  | 2020-06-28 04:48:56,143 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-06-28 04:48:56,151 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-06-28 04:48:56,157 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-06-28 04:48:56,164 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-06-28 04:48:56,171 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-06-28 04:48:56,172 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-06-28 04:48:56,193 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-06-28 04:48:56,211 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-06-28 04:48:56,213 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-06-28 04:48:56,421 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-06-28 04:48:56,473 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-28 04:48:56,474 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-28 04:48:56,588 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-06-28 04:48:56,599 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-06-28 04:48:56,602 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-06-28 04:48:56,603 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-06-28 04:48:56,608 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-06-28 04:48:56,750 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E
datanode_5_1  | 2020-06-28 04:48:56,794 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E
datanode_5_1  | 2020-06-28 04:48:56,827 [pool-19-thread-1] INFO impl.RaftServerImpl: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E: start as a follower, conf=-1: [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858], old=null
datanode_5_1  | 2020-06-28 04:48:56,832 [pool-19-thread-1] INFO impl.RaftServerImpl: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-06-28 04:48:56,839 [pool-19-thread-1] INFO impl.RoleInfo: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0: start FollowerState
datanode_5_1  | 2020-06-28 04:48:56,921 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-18B0906BF01E,id=ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0
datanode_5_1  | 2020-06-28 04:48:56,929 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E
datanode_5_1  | 2020-06-28 04:48:57,029 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "f18e2931-e295-4338-b778-18b0906bf01e"
datanode_5_1  | .
datanode_5_1  | 2020-06-28 04:48:57,035 [Command processor thread] INFO impl.RaftServerProxy: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0: addNew group-F277262A3CA5:[cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858] returns group-F277262A3CA5:java.util.concurrent.CompletableFuture@27a4355d[Not completed]
datanode_5_1  | 2020-06-28 04:48:57,063 [pool-19-thread-1] INFO impl.RaftServerImpl: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0: new RaftServerImpl for group-F277262A3CA5:[cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_5_1  | 2020-06-28 04:48:57,071 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_5_1  | 2020-06-28 04:48:57,071 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_5_1  | 2020-06-28 04:48:57,072 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_5_1  | 2020-06-28 04:48:57,072 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_5_1  | 2020-06-28 04:48:57,074 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_5_1  | 2020-06-28 04:48:57,074 [pool-19-thread-1] INFO impl.RaftServerImpl: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5: ConfigurationManager, init=-1: [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_5_1  | 2020-06-28 04:48:57,075 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_5_1  | 2020-06-28 04:48:57,075 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_5_1  | 2020-06-28 04:48:57,075 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/843592c9-09f2-4b01-86b3-f277262a3ca5 does not exist. Creating ...
datanode_5_1  | 2020-06-28 04:48:57,077 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/843592c9-09f2-4b01-86b3-f277262a3ca5/in_use.lock acquired by nodename 6@1256b0818dea
datanode_5_1  | 2020-06-28 04:48:57,079 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/843592c9-09f2-4b01-86b3-f277262a3ca5 has been successfully formatted.
datanode_5_1  | 2020-06-28 04:48:57,091 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-F277262A3CA5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_5_1  | 2020-06-28 04:48:57,092 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_5_1  | 2020-06-28 04:48:57,092 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_5_1  | 2020-06-28 04:48:57,092 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_5_1  | 2020-06-28 04:48:57,092 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_5_1  | 2020-06-28 04:48:57,092 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-06-28 04:48:57,092 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5
datanode_5_1  | 2020-06-28 04:48:57,092 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_5_1  | 2020-06-28 04:48:57,092 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/843592c9-09f2-4b01-86b3-f277262a3ca5
datanode_5_1  | 2020-06-28 04:48:57,092 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_5_1  | 2020-06-28 04:48:57,093 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_5_1  | 2020-06-28 04:48:57,093 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_5_1  | 2020-06-28 04:48:57,093 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_5_1  | 2020-06-28 04:48:57,093 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_5_1  | 2020-06-28 04:48:57,093 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_5_1  | 2020-06-28 04:48:57,093 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_5_1  | 2020-06-28 04:48:57,093 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_5_1  | 2020-06-28 04:48:57,093 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_5_1  | 2020-06-28 04:48:57,095 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_5_1  | 2020-06-28 04:48:57,127 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-28 04:48:57,127 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_5_1  | 2020-06-28 04:48:57,138 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_5_1  | 2020-06-28 04:48:57,138 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_5_1  | 2020-06-28 04:48:57,138 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_5_1  | 2020-06-28 04:48:57,138 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_5_1  | 2020-06-28 04:48:57,138 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_5_1  | 2020-06-28 04:48:57,139 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5
datanode_5_1  | 2020-06-28 04:48:57,143 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5
datanode_5_1  | 2020-06-28 04:48:57,144 [pool-19-thread-1] INFO impl.RaftServerImpl: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5: start as a follower, conf=-1: [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858], old=null
datanode_5_1  | 2020-06-28 04:48:57,144 [pool-19-thread-1] INFO impl.RaftServerImpl: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_5_1  | 2020-06-28 04:48:57,144 [pool-19-thread-1] INFO impl.RoleInfo: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0: start FollowerState
datanode_5_1  | 2020-06-28 04:48:57,170 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F277262A3CA5,id=ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0
datanode_5_1  | 2020-06-28 04:48:57,170 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5
datanode_5_1  | 2020-06-28 04:49:01,188 [grpc-default-executor-0] INFO impl.RaftServerImpl: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3
datanode_5_1  | 2020-06-28 04:49:01,203 [grpc-default-executor-0] INFO impl.RoleInfo: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0: shutdown FollowerState
datanode_5_1  | 2020-06-28 04:49:01,211 [grpc-default-executor-0] INFO impl.RoleInfo: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0: start FollowerState
datanode_5_1  | 2020-06-28 04:49:01,211 [Thread-25] INFO impl.FollowerState: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_5_1  | 2020-06-28 04:49:01,445 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 98421346-d987-4ede-a3e0-313c8456d352{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
datanode_5_1  | org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2.593984701s. [buffered_nanos=1359991367, remote_addr=/10.5.0.9:9858]
datanode_5_1  | 	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
datanode_5_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:86)
datanode_5_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:187)
datanode_5_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:156)
datanode_5_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:95)
datanode_5_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:337)
datanode_5_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:249)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:102)
datanode_5_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode_5_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode_5_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654)
datanode_5_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode_5_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode_5_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode_5_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode_5_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode_5_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:99)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_5_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:465)
datanode_5_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_5_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.593984701s. [buffered_nanos=1359991367, remote_addr=/10.5.0.9:9858]
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
datanode_5_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
datanode_5_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:284)
datanode_5_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:158)
datanode_5_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:185)
datanode_5_1  | 	... 18 more
datanode_3_1  | 2020-06-28 04:48:55,509 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-06-28 04:48:55,509 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5
datanode_3_1  | 2020-06-28 04:48:55,509 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3_1  | 2020-06-28 04:48:55,509 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/843592c9-09f2-4b01-86b3-f277262a3ca5
datanode_3_1  | 2020-06-28 04:48:55,509 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3_1  | 2020-06-28 04:48:55,509 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-28 04:48:55,509 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3_1  | 2020-06-28 04:48:55,509 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3_1  | 2020-06-28 04:48:55,509 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3_1  | 2020-06-28 04:48:55,509 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3_1  | 2020-06-28 04:48:55,509 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3_1  | 2020-06-28 04:48:55,510 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3_1  | 2020-06-28 04:48:55,510 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3_1  | 2020-06-28 04:48:55,585 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3_1  | 2020-06-28 04:48:55,585 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-28 04:48:55,585 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3_1  | 2020-06-28 04:48:55,595 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3_1  | 2020-06-28 04:48:55,596 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3_1  | 2020-06-28 04:48:55,597 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3_1  | 2020-06-28 04:48:55,597 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3_1  | 2020-06-28 04:48:55,599 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3_1  | 2020-06-28 04:48:55,599 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5
datanode_3_1  | 2020-06-28 04:48:55,601 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5
datanode_3_1  | 2020-06-28 04:48:55,603 [pool-19-thread-1] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5: start as a follower, conf=-1: [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858], old=null
datanode_3_1  | 2020-06-28 04:48:55,603 [pool-19-thread-1] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3_1  | 2020-06-28 04:48:55,603 [pool-19-thread-1] INFO impl.RoleInfo: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: start FollowerState
datanode_3_1  | 2020-06-28 04:48:55,604 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F277262A3CA5,id=cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3
datanode_3_1  | 2020-06-28 04:48:55,607 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5
datanode_3_1  | 2020-06-28 04:48:59,911 [Thread-23] INFO impl.FollowerState: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-FollowerState: change to CANDIDATE, lastRpcTime:5083ms, electionTimeout:5077ms
datanode_3_1  | 2020-06-28 04:48:59,914 [Thread-23] INFO impl.RoleInfo: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: shutdown FollowerState
datanode_3_1  | 2020-06-28 04:48:59,915 [Thread-23] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3_1  | 2020-06-28 04:48:59,921 [Thread-23] INFO impl.RoleInfo: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: start LeaderElection
datanode_3_1  | 2020-06-28 04:48:59,959 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO impl.LeaderElection: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1: begin an election at term 1 for -1: [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858], old=null
datanode_3_1  | 2020-06-28 04:48:59,961 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO impl.RoleInfo: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: shutdown LeaderElection
datanode_3_1  | 2020-06-28 04:48:59,998 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3_1  | 2020-06-28 04:49:00,007 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6155B05AAEDB with new leaderId: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3
datanode_3_1  | 2020-06-28 04:49:00,052 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB: change Leader from null to cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3 at term 1 for becomeLeader, leader elected after 6061ms
datanode_3_1  | 2020-06-28 04:49:00,134 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3_1  | 2020-06-28 04:49:00,139 [Command processor thread] WARN commandhandler.CreatePipelineCommandHandler: Add group failed for 98421346-d987-4ede-a3e0-313c8456d352{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
datanode_3_1  | org.apache.ratis.protocol.TimeoutIOException: deadline exceeded after 2.705469043s. [buffered_nanos=2227301634, remote_addr=/10.5.0.9:9858]
datanode_3_1  | 	at org.apache.ratis.grpc.GrpcUtil.tryUnwrapException(GrpcUtil.java:93)
datanode_3_1  | 	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:86)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:187)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:156)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:95)
datanode_3_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.sendRequest(RaftClientImpl.java:337)
datanode_5_1  | 2020-06-28 04:49:01,875 [Thread-23] INFO impl.FollowerState: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-FollowerState: change to CANDIDATE, lastRpcTime:5036ms, electionTimeout:5000ms
datanode_5_1  | 2020-06-28 04:49:01,877 [Thread-23] INFO impl.RoleInfo: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0: shutdown FollowerState
datanode_5_1  | 2020-06-28 04:49:01,877 [Thread-23] INFO impl.RaftServerImpl: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_5_1  | 2020-06-28 04:49:01,879 [Thread-23] INFO impl.RoleInfo: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0: start LeaderElection
datanode_5_1  | 2020-06-28 04:49:01,882 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO impl.LeaderElection: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1: begin an election at term 1 for -1: [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858], old=null
datanode_5_1  | 2020-06-28 04:49:01,884 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO impl.RoleInfo: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0: shutdown LeaderElection
datanode_5_1  | 2020-06-28 04:49:01,884 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO impl.RaftServerImpl: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_5_1  | 2020-06-28 04:49:01,884 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-18B0906BF01E with new leaderId: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0
datanode_5_1  | 2020-06-28 04:49:01,915 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO impl.RaftServerImpl: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E: change Leader from null to ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0 at term 1 for becomeLeader, leader elected after 6147ms
datanode_5_1  | 2020-06-28 04:49:01,948 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | 2020-06-28 04:49:01,950 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_5_1  | 2020-06-28 04:49:01,982 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E
datanode_5_1  | 2020-06-28 04:49:01,990 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_5_1  | 2020-06-28 04:49:02,004 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_5_1  | 2020-06-28 04:49:02,005 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F277262A3CA5 with new leaderId: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3
datanode_5_1  | 2020-06-28 04:49:02,005 [grpc-default-executor-0] INFO impl.RaftServerImpl: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5: change Leader from null to cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3 at term 1 for appendEntries, leader elected after 4913ms
datanode_5_1  | 2020-06-28 04:49:02,057 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_5_1  | 2020-06-28 04:49:02,071 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_5_1  | 2020-06-28 04:49:02,072 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_5_1  | 2020-06-28 04:49:02,214 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO impl.RoleInfo: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0: start LeaderState
datanode_5_1  | 2020-06-28 04:49:02,215 [grpc-default-executor-0] INFO impl.RaftServerImpl: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5: set configuration 0: [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858], old=null at 0
datanode_5_1  | 2020-06-28 04:49:02,344 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-06-28 04:49:02,350 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5-SegmentedRaftLogWorker: Starting segment from index:0
datanode_5_1  | 2020-06-28 04:49:02,376 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-LeaderElection1] INFO impl.RaftServerImpl: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E: set configuration 0: [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858], old=null at 0
datanode_5_1  | 2020-06-28 04:49:02,648 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "843592c9-09f2-4b01-86b3-f277262a3ca5"
datanode_5_1  | .
datanode_5_1  | 2020-06-28 04:49:02,831 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-F277262A3CA5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/843592c9-09f2-4b01-86b3-f277262a3ca5/current/log_inprogress_0
datanode_5_1  | 2020-06-28 04:49:02,836 [ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0@group-18B0906BF01E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f18e2931-e295-4338-b778-18b0906bf01e/current/log_inprogress_0
datanode_5_1  | 2020-06-28 04:54:12,949 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is synced with bcsId 147.
datanode_5_1  | 2020-06-28 04:54:12,949 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is synced with bcsId 147.
datanode_5_1  | 2020-06-28 04:54:12,969 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is closed with bcsId 147.
datanode_5_1  | 2020-06-28 04:54:13,073 [RatisApplyTransactionExecutor 8] INFO interfaces.Container: Container 8 is synced with bcsId 167.
datanode_5_1  | 2020-06-28 04:54:13,075 [RatisApplyTransactionExecutor 8] INFO interfaces.Container: Container 8 is synced with bcsId 167.
datanode_5_1  | 2020-06-28 04:54:13,084 [RatisApplyTransactionExecutor 8] INFO interfaces.Container: Container 8 is closed with bcsId 167.
datanode_5_1  | 2020-06-28 04:54:13,145 [RatisApplyTransactionExecutor 0] INFO interfaces.Container: Container 10 is synced with bcsId 174.
datanode_5_1  | 2020-06-28 04:54:13,145 [RatisApplyTransactionExecutor 0] INFO interfaces.Container: Container 10 is synced with bcsId 174.
datanode_5_1  | 2020-06-28 04:54:13,151 [RatisApplyTransactionExecutor 0] INFO interfaces.Container: Container 10 is closed with bcsId 174.
datanode_5_1  | 2020-06-28 04:54:13,191 [RatisApplyTransactionExecutor 2] INFO interfaces.Container: Container 2 is synced with bcsId 97.
datanode_5_1  | 2020-06-28 04:54:13,191 [RatisApplyTransactionExecutor 2] INFO interfaces.Container: Container 2 is synced with bcsId 97.
datanode_5_1  | 2020-06-28 04:54:13,198 [RatisApplyTransactionExecutor 2] INFO interfaces.Container: Container 2 is closed with bcsId 97.
datanode_5_1  | 2020-06-28 04:54:13,234 [RatisApplyTransactionExecutor 4] INFO interfaces.Container: Container 4 is synced with bcsId 129.
datanode_5_1  | 2020-06-28 04:54:13,235 [RatisApplyTransactionExecutor 4] INFO interfaces.Container: Container 4 is synced with bcsId 129.
datanode_3_1  | 	at org.apache.ratis.client.impl.RaftClientImpl.groupAdd(RaftClientImpl.java:249)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.lambda$handle$1(CreatePipelineCommandHandler.java:102)
datanode_3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
datanode_3_1  | 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
datanode_3_1  | 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1654)
datanode_3_1  | 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
datanode_3_1  | 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
datanode_3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
datanode_3_1  | 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
datanode_3_1  | 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
datanode_3_1  | 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CreatePipelineCommandHandler.handle(CreatePipelineCommandHandler.java:99)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
datanode_3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$1(DatanodeStateMachine.java:465)
datanode_3_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3_1  | Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.705469043s. [buffered_nanos=2227301634, remote_addr=/10.5.0.9:9858]
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
datanode_3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
datanode_3_1  | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:284)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$3(GrpcClientProtocolClient.java:158)
datanode_3_1  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:185)
datanode_3_1  | 	... 18 more
datanode_3_1  | 2020-06-28 04:49:00,147 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 2020-06-28 04:49:00,196 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB
datanode_3_1  | 2020-06-28 04:49:00,247 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-28 04:49:00,263 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-06-28 04:49:00,337 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3_1  | 2020-06-28 04:49:00,364 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-06-28 04:49:00,371 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-06-28 04:49:00,458 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO impl.RoleInfo: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: start LeaderState
datanode_3_1  | 2020-06-28 04:49:00,638 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-06-28 04:49:00,807 [Thread-25] INFO impl.FollowerState: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-FollowerState: change to CANDIDATE, lastRpcTime:5203ms, electionTimeout:5196ms
datanode_3_1  | 2020-06-28 04:49:00,835 [Thread-25] INFO impl.RoleInfo: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: shutdown FollowerState
datanode_3_1  | 2020-06-28 04:49:00,835 [Thread-25] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3_1  | 2020-06-28 04:49:00,836 [Thread-25] INFO impl.RoleInfo: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: start LeaderElection
datanode_3_1  | 2020-06-28 04:49:00,962 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-LeaderElection1] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB: set configuration 0: [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858], old=null at 0
datanode_3_1  | 2020-06-28 04:49:00,988 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO impl.LeaderElection: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2: begin an election at term 1 for -1: [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858], old=null
datanode_3_1  | 2020-06-28 04:49:01,010 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "843592c9-09f2-4b01-86b3-f277262a3ca5"
datanode_3_1  | .
datanode_3_1  | 2020-06-28 04:49:01,345 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO impl.LeaderElection: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2: Election PASSED; received 1 response(s) [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3<-ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0#0:OK-t1] and 0 exception(s); cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5:t1, leader=null, voted=cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3, raftlog=cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858], old=null
datanode_3_1  | 2020-06-28 04:49:01,345 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO impl.RoleInfo: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: shutdown LeaderElection
datanode_3_1  | 2020-06-28 04:49:01,347 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3_1  | 2020-06-28 04:49:01,347 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F277262A3CA5 with new leaderId: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3
datanode_3_1  | 2020-06-28 04:49:01,347 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5: change Leader from null to cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3 at term 1 for becomeLeader, leader elected after 5838ms
datanode_3_1  | 2020-06-28 04:49:01,349 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_5_1  | 2020-06-28 04:54:13,246 [RatisApplyTransactionExecutor 4] INFO interfaces.Container: Container 4 is closed with bcsId 129.
datanode_6_1  | Enabled profiling in kernel
datanode_6_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_6_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_6_1  | 2020-06-28 04:48:21,649 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_6_1  | /************************************************************
datanode_6_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_6_1  | STARTUP_MSG:   host = cf69ffa1fd70/10.5.0.9
datanode_6_1  | STARTUP_MSG:   args = []
datanode_6_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3_1  | 2020-06-28 04:49:01,359 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3_1  | 2020-06-28 04:49:01,363 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5
datanode_3_1  | 2020-06-28 04:49:01,363 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3_1  | 2020-06-28 04:49:01,365 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3_1  | 2020-06-28 04:49:01,369 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3_1  | 2020-06-28 04:49:01,375 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3_1  | 2020-06-28 04:49:01,375 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3_1  | 2020-06-28 04:49:01,383 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3_1  | 2020-06-28 04:49:01,389 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-28 04:49:01,392 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3_1  | 2020-06-28 04:49:01,435 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3_1  | 2020-06-28 04:49:01,436 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-06-28 04:49:01,441 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-06-28 04:49:01,453 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5
datanode_3_1  | 2020-06-28 04:49:01,492 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3_1  | 2020-06-28 04:49:01,499 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3_1  | 2020-06-28 04:49:01,502 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3_1  | 2020-06-28 04:49:01,502 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3_1  | 2020-06-28 04:49:01,503 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3_1  | 2020-06-28 04:49:01,503 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3_1  | 2020-06-28 04:49:01,504 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO impl.RoleInfo: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3: start LeaderState
datanode_3_1  | 2020-06-28 04:49:01,523 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3_1  | 2020-06-28 04:49:01,807 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-LeaderElection2] INFO impl.RaftServerImpl: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5: set configuration 0: [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858], old=null at 0
datanode_3_1  | 2020-06-28 04:49:02,158 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/843592c9-09f2-4b01-86b3-f277262a3ca5/current/log_inprogress_0
datanode_3_1  | 2020-06-28 04:49:02,168 [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-6155B05AAEDB-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/005d03de-8143-41d6-b8da-6155b05aaedb/current/log_inprogress_0
datanode_3_1  | 2020-06-28 04:49:04,588 [grpc-default-executor-0] INFO impl.FollowerInfo: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352: nextIndex: updateUnconditionally 1 -> 0
datanode_3_1  | 2020-06-28 04:50:04,590 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3,entriesCount=1,lastEntry=(t:1, i:0)
datanode_3_1  | 2020-06-28 04:50:19,385 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=9,entriesCount=1,lastEntry=(t:1, i:1)
datanode_3_1  | 2020-06-28 04:50:19,490 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=10,entriesCount=1,lastEntry=(t:1, i:2)
datanode_3_1  | 2020-06-28 04:50:21,276 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=11,entriesCount=1,lastEntry=(t:1, i:3)
datanode_3_1  | 2020-06-28 04:50:21,335 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=12,entriesCount=1,lastEntry=(t:1, i:4)
datanode_3_1  | 2020-06-28 04:50:24,043 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=14,entriesCount=1,lastEntry=(t:1, i:5)
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-06-28 04:48:17,809 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 995beb278a09/10.5.0.70
om_1          | STARTUP_MSG:   args = [--init]
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_6_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_6_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/04f8e6a7cb48fec22990dc37bb33bf5daefde5fa ; compiled by 'runner' on 2020-06-28T04:22Z
datanode_6_1  | STARTUP_MSG:   java = 11.0.6
datanode_6_1  | ************************************************************/
datanode_6_1  | 2020-06-28 04:48:21,752 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_6_1  | 2020-06-28 04:48:23,904 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_6_1  | 2020-06-28 04:48:24,871 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_6_1  | 2020-06-28 04:48:26,365 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_6_1  | 2020-06-28 04:48:26,381 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_6_1  | 2020-06-28 04:48:27,010 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:cf69ffa1fd70 ip:10.5.0.9
datanode_6_1  | 2020-06-28 04:48:27,964 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_6_1  | 2020-06-28 04:48:28,016 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_6_1  | 2020-06-28 04:48:28,031 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_6_1  | 2020-06-28 04:48:28,154 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_6_1  | 2020-06-28 04:48:28,678 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_6_1  | 2020-06-28 04:48:35,499 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_6_1  | 2020-06-28 04:48:35,809 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_6_1  | 2020-06-28 04:48:36,873 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_6_1  | 2020-06-28 04:48:36,876 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_6_1  | 2020-06-28 04:48:36,888 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-06-28 04:48:36,888 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_6_1  | 2020-06-28 04:48:36,892 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_6_1  | 2020-06-28 04:48:37,911 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-06-28 04:48:39,458 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_6_1  | 2020-06-28 04:48:39,603 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_6_1  | 2020-06-28 04:48:39,816 [main] INFO util.log: Logging initialized @26371ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_6_1  | 2020-06-28 04:48:40,560 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_6_1  | 2020-06-28 04:48:40,583 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_6_1  | 2020-06-28 04:48:40,613 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_6_1  | 2020-06-28 04:48:40,632 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_6_1  | 2020-06-28 04:48:40,641 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_6_1  | 2020-06-28 04:48:40,643 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_6_1  | 2020-06-28 04:48:40,827 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_6_1  | 2020-06-28 04:48:40,861 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_6_1  | 2020-06-28 04:48:40,863 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_6_1  | 2020-06-28 04:48:41,067 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_6_1  | 2020-06-28 04:48:41,068 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_6_1  | 2020-06-28 04:48:41,079 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_6_1  | 2020-06-28 04:48:41,245 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b4954b2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_6_1  | 2020-06-28 04:48:41,262 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57416e49{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_6_1  | 2020-06-28 04:48:41,799 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c27f72{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-5401141961589928248.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_6_1  | 2020-06-28 04:48:41,859 [main] INFO server.AbstractConnector: Started ServerConnector@25cde5bb{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_6_1  | 2020-06-28 04:48:41,859 [main] INFO server.Server: Started @28415ms
datanode_6_1  | 2020-06-28 04:48:41,879 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_6_1  | 2020-06-28 04:48:41,898 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_6_1  | 2020-06-28 04:48:41,905 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_6_1  | 2020-06-28 04:48:42,084 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@422606d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_6_1  | 2020-06-28 04:48:43,388 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_6_1  | 2020-06-28 04:48:45,531 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-06-28 04:48:46,532 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-06-28 04:48:47,533 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_6_1  | 2020-06-28 04:48:48,557 [Datanode State Machine Thread - 0] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_3_1  | 2020-06-28 04:50:24,050 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=15,entriesCount=1,lastEntry=(t:1, i:6)
datanode_3_1  | 2020-06-28 04:50:24,069 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=16,entriesCount=1,lastEntry=(t:1, i:7)
datanode_3_1  | 2020-06-28 04:50:24,091 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=17,entriesCount=1,lastEntry=(t:1, i:8)
datanode_3_1  | 2020-06-28 04:50:26,640 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=19,entriesCount=1,lastEntry=(t:1, i:9)
datanode_3_1  | 2020-06-28 04:50:26,649 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=20,entriesCount=1,lastEntry=(t:1, i:10)
datanode_3_1  | 2020-06-28 04:50:26,677 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=21,entriesCount=1,lastEntry=(t:1, i:11)
datanode_3_1  | 2020-06-28 04:50:26,689 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=22,entriesCount=1,lastEntry=(t:1, i:12)
datanode_3_1  | 2020-06-28 04:50:29,255 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=24,entriesCount=1,lastEntry=(t:1, i:13)
datanode_3_1  | 2020-06-28 04:50:29,264 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=25,entriesCount=1,lastEntry=(t:1, i:14)
datanode_3_1  | 2020-06-28 04:50:29,275 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=26,entriesCount=1,lastEntry=(t:1, i:15)
datanode_3_1  | 2020-06-28 04:50:29,287 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=27,entriesCount=1,lastEntry=(t:1, i:16)
datanode_3_1  | 2020-06-28 04:50:34,558 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=30,entriesCount=1,lastEntry=(t:1, i:17)
datanode_3_1  | 2020-06-28 04:50:34,583 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=31,entriesCount=1,lastEntry=(t:1, i:18)
datanode_3_1  | 2020-06-28 04:50:34,598 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=32,entriesCount=1,lastEntry=(t:1, i:19)
datanode_3_1  | 2020-06-28 04:50:34,611 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=33,entriesCount=1,lastEntry=(t:1, i:20)
datanode_3_1  | 2020-06-28 04:50:37,387 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=35,entriesCount=1,lastEntry=(t:1, i:21)
datanode_3_1  | 2020-06-28 04:50:37,392 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=36,entriesCount=1,lastEntry=(t:1, i:22)
datanode_3_1  | 2020-06-28 04:50:37,404 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=37,entriesCount=1,lastEntry=(t:1, i:23)
datanode_3_1  | 2020-06-28 04:50:37,414 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=38,entriesCount=1,lastEntry=(t:1, i:24)
datanode_3_1  | 2020-06-28 04:50:39,976 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=40,entriesCount=1,lastEntry=(t:1, i:25)
datanode_3_1  | 2020-06-28 04:50:39,989 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=41,entriesCount=1,lastEntry=(t:1, i:26)
datanode_3_1  | 2020-06-28 04:50:39,997 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=42,entriesCount=1,lastEntry=(t:1, i:27)
datanode_3_1  | 2020-06-28 04:50:40,013 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=43,entriesCount=1,lastEntry=(t:1, i:28)
datanode_6_1  | java.net.SocketTimeoutException: Call From cf69ffa1fd70/10.5.0.9 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:46080 remote=scm/10.5.0.71:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_6_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_6_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_6_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_6_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_6_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_6_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_6_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_6_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_6_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.5.0.9:46080 remote=scm/10.5.0.71:9861]
datanode_6_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_6_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_6_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_6_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_6_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_6_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_6_1  | 2020-06-28 04:48:49,243 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_6_1  | 2020-06-28 04:48:49,249 [Datanode State Machine Thread - 1] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_6_1  | 2020-06-28 04:48:49,255 [Datanode State Machine Thread - 1] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 98421346-d987-4ede-a3e0-313c8456d352 at port 9858
datanode_6_1  | 2020-06-28 04:48:49,421 [Datanode State Machine Thread - 1] INFO impl.RaftServerProxy: 98421346-d987-4ede-a3e0-313c8456d352: start RPC server
datanode_6_1  | 2020-06-28 04:48:49,977 [Datanode State Machine Thread - 1] INFO server.GrpcService: 98421346-d987-4ede-a3e0-313c8456d352: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_6_1  | 2020-06-28 04:49:00,606 [grpc-default-executor-0] INFO impl.RaftServerProxy: 98421346-d987-4ede-a3e0-313c8456d352: addNew group-F277262A3CA5:[cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858] returns group-F277262A3CA5:java.util.concurrent.CompletableFuture@381abb0f[Not completed]
datanode_6_1  | 2020-06-28 04:49:00,718 [pool-19-thread-1] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352: new RaftServerImpl for group-F277262A3CA5:[cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-06-28 04:49:00,742 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-06-28 04:49:00,767 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-06-28 04:49:00,767 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_6_1  | 2020-06-28 04:49:00,768 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-06-28 04:49:00,769 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-06-28 04:49:00,801 [pool-19-thread-1] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5: ConfigurationManager, init=-1: [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-06-28 04:49:00,813 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-06-28 04:49:00,817 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-06-28 04:49:00,838 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/843592c9-09f2-4b01-86b3-f277262a3ca5 does not exist. Creating ...
datanode_6_1  | 2020-06-28 04:49:00,893 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/843592c9-09f2-4b01-86b3-f277262a3ca5/in_use.lock acquired by nodename 6@cf69ffa1fd70
datanode_6_1  | 2020-06-28 04:49:00,904 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/843592c9-09f2-4b01-86b3-f277262a3ca5 has been successfully formatted.
datanode_6_1  | 2020-06-28 04:49:00,963 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-F277262A3CA5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-06-28 04:49:00,964 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_6_1  | 2020-06-28 04:49:00,966 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-06-28 04:49:01,017 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3_1  | 2020-06-28 04:50:42,552 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=45,entriesCount=1,lastEntry=(t:1, i:29)
datanode_3_1  | 2020-06-28 04:50:42,562 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=46,entriesCount=1,lastEntry=(t:1, i:30)
datanode_3_1  | 2020-06-28 04:50:42,578 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=47,entriesCount=1,lastEntry=(t:1, i:31)
datanode_3_1  | 2020-06-28 04:50:42,590 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=48,entriesCount=1,lastEntry=(t:1, i:32)
datanode_3_1  | 2020-06-28 04:50:45,159 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=50,entriesCount=1,lastEntry=(t:1, i:33)
datanode_3_1  | 2020-06-28 04:50:45,172 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=51,entriesCount=1,lastEntry=(t:1, i:34)
datanode_3_1  | 2020-06-28 04:50:45,177 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=52,entriesCount=1,lastEntry=(t:1, i:35)
datanode_3_1  | 2020-06-28 04:50:45,194 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=53,entriesCount=1,lastEntry=(t:1, i:36)
datanode_3_1  | 2020-06-28 04:50:47,886 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=55,entriesCount=1,lastEntry=(t:1, i:37)
datanode_3_1  | 2020-06-28 04:50:47,886 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=56,entriesCount=1,lastEntry=(t:1, i:38)
datanode_3_1  | 2020-06-28 04:50:47,898 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=57,entriesCount=1,lastEntry=(t:1, i:39)
datanode_3_1  | 2020-06-28 04:50:47,904 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=58,entriesCount=1,lastEntry=(t:1, i:40)
datanode_3_1  | 2020-06-28 04:50:50,532 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=60,entriesCount=1,lastEntry=(t:1, i:41)
datanode_3_1  | 2020-06-28 04:50:50,542 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=61,entriesCount=1,lastEntry=(t:1, i:42)
datanode_3_1  | 2020-06-28 04:50:50,553 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=62,entriesCount=1,lastEntry=(t:1, i:43)
datanode_3_1  | 2020-06-28 04:50:50,563 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=63,entriesCount=1,lastEntry=(t:1, i:44)
datanode_3_1  | 2020-06-28 04:50:53,125 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=65,entriesCount=1,lastEntry=(t:1, i:45)
datanode_3_1  | 2020-06-28 04:50:53,143 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=66,entriesCount=1,lastEntry=(t:1, i:46)
datanode_3_1  | 2020-06-28 04:50:53,145 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=67,entriesCount=1,lastEntry=(t:1, i:47)
datanode_3_1  | 2020-06-28 04:50:53,164 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=68,entriesCount=1,lastEntry=(t:1, i:48)
datanode_3_1  | 2020-06-28 04:50:55,716 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=70,entriesCount=1,lastEntry=(t:1, i:49)
datanode_3_1  | 2020-06-28 04:50:55,727 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=71,entriesCount=1,lastEntry=(t:1, i:50)
datanode_3_1  | 2020-06-28 04:50:55,737 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=72,entriesCount=1,lastEntry=(t:1, i:51)
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/04f8e6a7cb48fec22990dc37bb33bf5daefde5fa ; compiled by 'runner' on 2020-06-28T04:22Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-06-28 04:48:17,874 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-06-28 04:48:24,583 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-06-28 04:48:25,003 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-06-28 04:48:25,003 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-06-28 04:48:25,467 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-28 04:48:28,551 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-28 04:48:29,559 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-28 04:48:30,560 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-28 04:48:31,561 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-28 04:48:32,563 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-28 04:48:33,564 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-28 04:48:34,565 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-28 04:48:35,566 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-28 04:48:36,567 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-28 04:48:37,569 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-28 04:48:37,573 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1          | 2020-06-28 04:48:43,574 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-28 04:48:44,576 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-28 04:48:45,577 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-28 04:48:46,581 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | 2020-06-28 04:48:47,582 [main] INFO ipc.Client: Retrying connect to server: scm/10.5.0.71:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1          | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-b1bf8eb7-d557-4aff-a252-877a1c6d2f54
om_1          | 2020-06-28 04:48:49,653 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1          | /************************************************************
om_1          | SHUTDOWN_MSG: Shutting down OzoneManager at 995beb278a09/10.5.0.70
om_1          | ************************************************************/
om_1          | Enabled profiling in kernel
om_1          | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1          | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1          | 2020-06-28 04:48:57,590 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1          | /************************************************************
om_1          | STARTUP_MSG: Starting OzoneManager
om_1          | STARTUP_MSG:   host = 995beb278a09/10.5.0.70
om_1          | STARTUP_MSG:   args = []
om_1          | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3_1  | 2020-06-28 04:50:55,748 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=73,entriesCount=1,lastEntry=(t:1, i:52)
datanode_3_1  | 2020-06-28 04:50:58,410 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=75,entriesCount=1,lastEntry=(t:1, i:53)
datanode_3_1  | 2020-06-28 04:50:58,422 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=76,entriesCount=1,lastEntry=(t:1, i:54)
datanode_3_1  | 2020-06-28 04:50:58,432 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=77,entriesCount=1,lastEntry=(t:1, i:55)
datanode_3_1  | 2020-06-28 04:50:58,441 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=78,entriesCount=1,lastEntry=(t:1, i:56)
datanode_3_1  | 2020-06-28 04:51:01,093 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=80,entriesCount=1,lastEntry=(t:1, i:57)
datanode_3_1  | 2020-06-28 04:51:01,102 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=81,entriesCount=1,lastEntry=(t:1, i:58)
datanode_3_1  | 2020-06-28 04:51:01,112 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=82,entriesCount=1,lastEntry=(t:1, i:59)
datanode_3_1  | 2020-06-28 04:51:01,117 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=83,entriesCount=1,lastEntry=(t:1, i:60)
datanode_3_1  | 2020-06-28 04:51:03,684 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=85,entriesCount=1,lastEntry=(t:1, i:61)
datanode_3_1  | 2020-06-28 04:51:03,690 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=86,entriesCount=1,lastEntry=(t:1, i:62)
datanode_3_1  | 2020-06-28 04:51:03,691 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=87,entriesCount=1,lastEntry=(t:1, i:63)
datanode_3_1  | 2020-06-28 04:51:03,706 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=88,entriesCount=1,lastEntry=(t:1, i:64)
datanode_3_1  | 2020-06-28 04:51:06,337 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=90,entriesCount=1,lastEntry=(t:1, i:65)
datanode_3_1  | 2020-06-28 04:51:06,344 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=91,entriesCount=1,lastEntry=(t:1, i:66)
datanode_3_1  | 2020-06-28 04:51:06,345 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=92,entriesCount=1,lastEntry=(t:1, i:67)
datanode_3_1  | 2020-06-28 04:51:06,355 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=93,entriesCount=1,lastEntry=(t:1, i:68)
datanode_3_1  | 2020-06-28 04:51:08,888 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=95,entriesCount=1,lastEntry=(t:1, i:69)
datanode_3_1  | 2020-06-28 04:51:08,900 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=96,entriesCount=1,lastEntry=(t:1, i:70)
datanode_3_1  | 2020-06-28 04:51:08,917 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=97,entriesCount=1,lastEntry=(t:1, i:71)
datanode_3_1  | 2020-06-28 04:51:08,931 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=98,entriesCount=1,lastEntry=(t:1, i:72)
datanode_3_1  | 2020-06-28 04:51:11,492 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=100,entriesCount=1,lastEntry=(t:1, i:73)
datanode_3_1  | 2020-06-28 04:51:11,512 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=101,entriesCount=1,lastEntry=(t:1, i:74)
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-06-28 04:48:25,642 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = 30e33cc7c73f/10.5.0.71
scm_1         | STARTUP_MSG:   args = [--init]
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_6_1  | 2020-06-28 04:49:01,018 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-06-28 04:49:01,043 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-06-28 04:49:01,061 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5
datanode_6_1  | 2020-06-28 04:49:01,308 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-06-28 04:49:01,518 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/843592c9-09f2-4b01-86b3-f277262a3ca5
datanode_6_1  | 2020-06-28 04:49:01,519 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-06-28 04:49:01,531 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-06-28 04:49:01,532 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-06-28 04:49:01,532 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-06-28 04:49:01,544 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-06-28 04:49:01,544 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-06-28 04:49:01,552 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-06-28 04:49:01,552 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-06-28 04:49:01,552 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-06-28 04:49:01,722 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-06-28 04:49:01,837 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-28 04:49:01,837 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-28 04:49:02,128 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-06-28 04:49:02,144 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-06-28 04:49:02,155 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-06-28 04:49:02,156 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-06-28 04:49:02,179 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-06-28 04:49:02,562 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5
datanode_6_1  | 2020-06-28 04:49:02,642 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5
datanode_6_1  | 2020-06-28 04:49:02,766 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 98421346-d987-4ede-a3e0-313c8456d352: Failed requestVote cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3->98421346-d987-4ede-a3e0-313c8456d352#0: org.apache.ratis.protocol.ServerNotReadyException: 98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5 is not in [RUNNING]: current state is NEW
datanode_6_1  | 2020-06-28 04:49:02,781 [pool-19-thread-1] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5: start as a follower, conf=-1: [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858], old=null
datanode_6_1  | 2020-06-28 04:49:02,803 [pool-19-thread-1] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-06-28 04:49:02,833 [pool-19-thread-1] INFO impl.RoleInfo: 98421346-d987-4ede-a3e0-313c8456d352: start FollowerState
datanode_6_1  | 2020-06-28 04:49:02,945 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F277262A3CA5,id=98421346-d987-4ede-a3e0-313c8456d352
datanode_6_1  | 2020-06-28 04:49:02,959 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5
datanode_6_1  | 2020-06-28 04:49:04,492 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F277262A3CA5 with new leaderId: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3
datanode_6_1  | 2020-06-28 04:49:04,496 [grpc-default-executor-0] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5: change Leader from null to cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3 at term 1 for appendEntries, leader elected after 3527ms
datanode_6_1  | 2020-06-28 04:49:04,515 [grpc-default-executor-0] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode_6_1  | 2020-06-28 04:49:04,544 [grpc-default-executor-0] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5: inconsistency entries. Reply:cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3<-98421346-d987-4ede-a3e0-313c8456d352#2:FAIL,INCONSISTENCY,nextIndex:0,term:0,followerCommit:-1
datanode_6_1  | 2020-06-28 04:49:04,604 [grpc-default-executor-0] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5: set configuration 0: [cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:10.5.0.6:9858, 98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:10.5.0.8:9858], old=null at 0
datanode_6_1  | 2020-06-28 04:49:04,659 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-06-28 04:49:04,972 [98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 98421346-d987-4ede-a3e0-313c8456d352@group-F277262A3CA5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/843592c9-09f2-4b01-86b3-f277262a3ca5/current/log_inprogress_0
datanode_6_1  | 2020-06-28 04:49:23,215 [Command processor thread] INFO impl.RaftServerProxy: 98421346-d987-4ede-a3e0-313c8456d352: addNew group-F0ECD492E0E9:[98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858] returns group-F0ECD492E0E9:java.util.concurrent.CompletableFuture@31d65b6e[Not completed]
datanode_6_1  | 2020-06-28 04:49:23,217 [pool-19-thread-1] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352: new RaftServerImpl for group-F0ECD492E0E9:[98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858] with ContainerStateMachine:uninitialized
datanode_6_1  | 2020-06-28 04:49:23,219 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_6_1  | 2020-06-28 04:49:23,219 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_6_1  | 2020-06-28 04:49:23,221 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3_1  | 2020-06-28 04:51:11,512 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=102,entriesCount=1,lastEntry=(t:1, i:75)
datanode_3_1  | 2020-06-28 04:51:14,254 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=104,entriesCount=1,lastEntry=(t:1, i:76)
datanode_3_1  | 2020-06-28 04:51:14,264 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=105,entriesCount=1,lastEntry=(t:1, i:77)
datanode_3_1  | 2020-06-28 04:51:14,264 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=106,entriesCount=1,lastEntry=(t:1, i:78)
datanode_3_1  | 2020-06-28 04:51:14,288 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=107,entriesCount=1,lastEntry=(t:1, i:79)
datanode_3_1  | 2020-06-28 04:51:16,850 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=109,entriesCount=1,lastEntry=(t:1, i:80)
datanode_3_1  | 2020-06-28 04:51:16,861 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=110,entriesCount=1,lastEntry=(t:1, i:81)
datanode_3_1  | 2020-06-28 04:51:16,861 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=111,entriesCount=1,lastEntry=(t:1, i:82)
datanode_3_1  | 2020-06-28 04:51:16,879 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=112,entriesCount=1,lastEntry=(t:1, i:83)
datanode_3_1  | 2020-06-28 04:51:19,411 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=114,entriesCount=1,lastEntry=(t:1, i:84)
datanode_3_1  | 2020-06-28 04:51:19,419 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=115,entriesCount=1,lastEntry=(t:1, i:85)
datanode_3_1  | 2020-06-28 04:51:19,428 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=116,entriesCount=1,lastEntry=(t:1, i:86)
datanode_3_1  | 2020-06-28 04:51:19,434 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=117,entriesCount=1,lastEntry=(t:1, i:87)
datanode_3_1  | 2020-06-28 04:51:22,100 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=119,entriesCount=1,lastEntry=(t:1, i:88)
datanode_3_1  | 2020-06-28 04:51:22,123 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=120,entriesCount=1,lastEntry=(t:1, i:89)
datanode_3_1  | 2020-06-28 04:51:22,132 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=121,entriesCount=1,lastEntry=(t:1, i:90)
datanode_3_1  | 2020-06-28 04:51:22,135 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=122,entriesCount=1,lastEntry=(t:1, i:91)
datanode_3_1  | 2020-06-28 04:51:24,821 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=124,entriesCount=1,lastEntry=(t:1, i:92)
datanode_3_1  | 2020-06-28 04:51:24,827 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=125,entriesCount=1,lastEntry=(t:1, i:93)
datanode_3_1  | 2020-06-28 04:51:24,828 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=126,entriesCount=1,lastEntry=(t:1, i:94)
datanode_3_1  | 2020-06-28 04:51:24,857 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=127,entriesCount=1,lastEntry=(t:1, i:95)
datanode_3_1  | 2020-06-28 04:51:27,902 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=129,entriesCount=1,lastEntry=(t:1, i:96)
datanode_3_1  | 2020-06-28 04:51:27,908 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=130,entriesCount=1,lastEntry=(t:1, i:97)
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/04f8e6a7cb48fec22990dc37bb33bf5daefde5fa ; compiled by 'runner' on 2020-06-28T04:22Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-06-28 04:48:25,837 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-06-28 04:48:27,117 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-06-28 04:48:27,675 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-b1bf8eb7-d557-4aff-a252-877a1c6d2f54
scm_1         | 2020-06-28 04:48:27,757 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1         | /************************************************************
scm_1         | SHUTDOWN_MSG: Shutting down StorageContainerManager at 30e33cc7c73f/10.5.0.71
scm_1         | ************************************************************/
scm_1         | Enabled profiling in kernel
scm_1         | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1         | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1         | 2020-06-28 04:48:44,964 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1         | /************************************************************
scm_1         | STARTUP_MSG: Starting StorageContainerManager
scm_1         | STARTUP_MSG:   host = 30e33cc7c73f/10.5.0.71
scm_1         | STARTUP_MSG:   args = []
scm_1         | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
om_1          | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1          | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/04f8e6a7cb48fec22990dc37bb33bf5daefde5fa ; compiled by 'runner' on 2020-06-28T04:22Z
om_1          | STARTUP_MSG:   java = 11.0.6
om_1          | ************************************************************/
om_1          | 2020-06-28 04:48:57,641 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1          | 2020-06-28 04:49:03,689 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1          | 2020-06-28 04:49:04,096 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.5.0.70:9862
om_1          | 2020-06-28 04:49:04,096 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1          | 2020-06-28 04:49:04,159 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-28 04:49:04,191 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-28 04:49:06,790 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1          | 2020-06-28 04:49:07,796 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1          | 2020-06-28 04:49:07,824 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1          | 2020-06-28 04:49:08,197 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1          | 2020-06-28 04:49:08,315 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1          | 2020-06-28 04:49:08,315 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
datanode_6_1  | 2020-06-28 04:49:23,222 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_6_1  | 2020-06-28 04:49:23,222 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_6_1  | 2020-06-28 04:49:23,222 [pool-19-thread-1] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9: ConfigurationManager, init=-1: [98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_6_1  | 2020-06-28 04:49:23,222 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_6_1  | 2020-06-28 04:49:23,223 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_6_1  | 2020-06-28 04:49:23,223 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/abcf2ef9-6df5-4118-b0df-f0ecd492e0e9 does not exist. Creating ...
datanode_6_1  | 2020-06-28 04:49:23,226 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/abcf2ef9-6df5-4118-b0df-f0ecd492e0e9/in_use.lock acquired by nodename 6@cf69ffa1fd70
datanode_6_1  | 2020-06-28 04:49:23,228 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/abcf2ef9-6df5-4118-b0df-f0ecd492e0e9 has been successfully formatted.
datanode_6_1  | 2020-06-28 04:49:23,228 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-F0ECD492E0E9: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_6_1  | 2020-06-28 04:49:23,228 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_6_1  | 2020-06-28 04:49:23,229 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_6_1  | 2020-06-28 04:49:23,232 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_6_1  | 2020-06-28 04:49:23,232 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_6_1  | 2020-06-28 04:49:23,233 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-06-28 04:49:23,233 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9
datanode_6_1  | 2020-06-28 04:49:23,234 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_6_1  | 2020-06-28 04:49:23,234 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/abcf2ef9-6df5-4118-b0df-f0ecd492e0e9
datanode_6_1  | 2020-06-28 04:49:23,234 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_6_1  | 2020-06-28 04:49:23,235 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_6_1  | 2020-06-28 04:49:23,235 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_6_1  | 2020-06-28 04:49:23,236 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_6_1  | 2020-06-28 04:49:23,236 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_6_1  | 2020-06-28 04:49:23,236 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_6_1  | 2020-06-28 04:49:23,237 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_6_1  | 2020-06-28 04:49:23,237 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_6_1  | 2020-06-28 04:49:23,237 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_6_1  | 2020-06-28 04:49:23,240 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_6_1  | 2020-06-28 04:49:23,240 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-28 04:49:23,240 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_6_1  | 2020-06-28 04:49:23,246 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_6_1  | 2020-06-28 04:49:23,246 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_6_1  | 2020-06-28 04:49:23,247 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_6_1  | 2020-06-28 04:49:23,247 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_6_1  | 2020-06-28 04:49:23,248 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_6_1  | 2020-06-28 04:49:23,248 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9
datanode_6_1  | 2020-06-28 04:49:23,249 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9
datanode_6_1  | 2020-06-28 04:49:23,251 [pool-19-thread-1] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9: start as a follower, conf=-1: [98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858], old=null
datanode_6_1  | 2020-06-28 04:49:23,253 [pool-19-thread-1] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_6_1  | 2020-06-28 04:49:23,253 [pool-19-thread-1] INFO impl.RoleInfo: 98421346-d987-4ede-a3e0-313c8456d352: start FollowerState
datanode_6_1  | 2020-06-28 04:49:23,255 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F0ECD492E0E9,id=98421346-d987-4ede-a3e0-313c8456d352
datanode_6_1  | 2020-06-28 04:49:23,255 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9
datanode_6_1  | 2020-06-28 04:49:23,260 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "abcf2ef9-6df5-4118-b0df-f0ecd492e0e9"
datanode_6_1  | .
datanode_6_1  | 2020-06-28 04:49:28,429 [Thread-39] INFO impl.FollowerState: 98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-FollowerState: change to CANDIDATE, lastRpcTime:5176ms, electionTimeout:5173ms
datanode_6_1  | 2020-06-28 04:49:28,430 [Thread-39] INFO impl.RoleInfo: 98421346-d987-4ede-a3e0-313c8456d352: shutdown FollowerState
datanode_6_1  | 2020-06-28 04:49:28,430 [Thread-39] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_6_1  | 2020-06-28 04:49:28,433 [Thread-39] INFO impl.RoleInfo: 98421346-d987-4ede-a3e0-313c8456d352: start LeaderElection
datanode_6_1  | 2020-06-28 04:49:28,440 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO impl.LeaderElection: 98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1: begin an election at term 1 for -1: [98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858], old=null
scm_1         | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1         | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/04f8e6a7cb48fec22990dc37bb33bf5daefde5fa ; compiled by 'runner' on 2020-06-28T04:22Z
scm_1         | STARTUP_MSG:   java = 11.0.6
scm_1         | ************************************************************/
scm_1         | 2020-06-28 04:48:45,081 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1         | 2020-06-28 04:48:45,731 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-06-28 04:48:46,221 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1         | 2020-06-28 04:48:46,378 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@7e094740
scm_1         | 2020-06-28 04:48:46,379 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1         | 2020-06-28 04:48:46,527 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1         | 2020-06-28 04:48:46,619 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
scm_1         | 2020-06-28 04:48:46,647 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1         | 2020-06-28 04:48:46,732 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1         | 2020-06-28 04:48:46,736 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1         | 2020-06-28 04:48:46,785 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1         | 2020-06-28 04:48:47,355 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-06-28 04:48:47,378 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1         | 2020-06-28 04:48:47,417 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-06-28 04:48:47,417 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1         | 2020-06-28 04:48:47,434 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1         | 2020-06-28 04:48:47,436 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1         | 2020-06-28 04:48:47,466 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1         | 2020-06-28 04:48:47,466 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1         | 2020-06-28 04:48:47,492 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @17305ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1         | 2020-06-28 04:48:47,614 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1         | 2020-06-28 04:48:47,655 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1         | 2020-06-28 04:48:47,661 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1         | 2020-06-28 04:48:47,665 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1         | 2020-06-28 04:48:47,665 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1         | 2020-06-28 04:48:47,674 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1         | 2020-06-28 04:48:47,735 [Listener at 0.0.0.0/9860] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
scm_1         | 2020-06-28 04:48:47,790 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1         | 2020-06-28 04:48:47,946 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1         | 2020-06-28 04:48:48,013 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1         | 2020-06-28 04:48:48,013 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1         | 2020-06-28 04:48:48,273 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1         | 2020-06-28 04:48:48,279 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-06-28 04:48:48,280 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1         | 2020-06-28 04:48:48,342 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1         | 2020-06-28 04:48:48,346 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1         | 2020-06-28 04:48:48,347 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_3_1  | 2020-06-28 04:51:27,920 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=131,entriesCount=1,lastEntry=(t:1, i:98)
datanode_3_1  | 2020-06-28 04:51:27,939 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=132,entriesCount=1,lastEntry=(t:1, i:99)
datanode_3_1  | 2020-06-28 04:51:30,483 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=134,entriesCount=1,lastEntry=(t:1, i:100)
datanode_3_1  | 2020-06-28 04:51:30,489 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=135,entriesCount=1,lastEntry=(t:1, i:101)
datanode_3_1  | 2020-06-28 04:51:30,529 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=136,entriesCount=1,lastEntry=(t:1, i:102)
datanode_3_1  | 2020-06-28 04:51:30,534 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=137,entriesCount=1,lastEntry=(t:1, i:103)
datanode_3_1  | 2020-06-28 04:51:33,076 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=139,entriesCount=1,lastEntry=(t:1, i:104)
datanode_3_1  | 2020-06-28 04:51:33,094 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=140,entriesCount=1,lastEntry=(t:1, i:105)
datanode_3_1  | 2020-06-28 04:51:33,096 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=141,entriesCount=1,lastEntry=(t:1, i:106)
datanode_3_1  | 2020-06-28 04:51:33,108 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=142,entriesCount=1,lastEntry=(t:1, i:107)
datanode_3_1  | 2020-06-28 04:51:35,650 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=144,entriesCount=1,lastEntry=(t:1, i:108)
datanode_3_1  | 2020-06-28 04:51:35,660 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=145,entriesCount=1,lastEntry=(t:1, i:109)
datanode_3_1  | 2020-06-28 04:51:35,673 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=146,entriesCount=1,lastEntry=(t:1, i:110)
datanode_3_1  | 2020-06-28 04:51:35,679 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=147,entriesCount=1,lastEntry=(t:1, i:111)
datanode_3_1  | 2020-06-28 04:51:41,024 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=150,entriesCount=1,lastEntry=(t:1, i:112)
datanode_3_1  | 2020-06-28 04:51:41,038 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=151,entriesCount=1,lastEntry=(t:1, i:113)
datanode_3_1  | 2020-06-28 04:51:41,059 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=152,entriesCount=1,lastEntry=(t:1, i:114)
datanode_3_1  | 2020-06-28 04:51:41,066 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=153,entriesCount=1,lastEntry=(t:1, i:115)
datanode_3_1  | 2020-06-28 04:51:43,608 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=155,entriesCount=1,lastEntry=(t:1, i:116)
datanode_3_1  | 2020-06-28 04:51:43,618 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=156,entriesCount=1,lastEntry=(t:1, i:117)
datanode_3_1  | 2020-06-28 04:51:43,632 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=157,entriesCount=1,lastEntry=(t:1, i:118)
datanode_3_1  | 2020-06-28 04:51:43,642 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=158,entriesCount=1,lastEntry=(t:1, i:119)
datanode_6_1  | 2020-06-28 04:49:28,441 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO impl.RoleInfo: 98421346-d987-4ede-a3e0-313c8456d352: shutdown LeaderElection
datanode_6_1  | 2020-06-28 04:49:28,441 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_6_1  | 2020-06-28 04:49:28,441 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F0ECD492E0E9 with new leaderId: 98421346-d987-4ede-a3e0-313c8456d352
datanode_6_1  | 2020-06-28 04:49:28,441 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9: change Leader from null to 98421346-d987-4ede-a3e0-313c8456d352 at term 1 for becomeLeader, leader elected after 5212ms
datanode_6_1  | 2020-06-28 04:49:28,446 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_6_1  | 2020-06-28 04:49:28,446 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_6_1  | 2020-06-28 04:49:28,448 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9
datanode_6_1  | 2020-06-28 04:49:28,451 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_6_1  | 2020-06-28 04:49:28,452 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_6_1  | 2020-06-28 04:49:28,460 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_6_1  | 2020-06-28 04:49:28,460 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_6_1  | 2020-06-28 04:49:28,462 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_6_1  | 2020-06-28 04:49:28,468 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO impl.RoleInfo: 98421346-d987-4ede-a3e0-313c8456d352: start LeaderState
datanode_6_1  | 2020-06-28 04:49:28,470 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-SegmentedRaftLogWorker: Starting segment from index:0
datanode_6_1  | 2020-06-28 04:49:28,472 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/abcf2ef9-6df5-4118-b0df-f0ecd492e0e9/current/log_inprogress_0
datanode_6_1  | 2020-06-28 04:49:28,476 [98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9-LeaderElection1] INFO impl.RaftServerImpl: 98421346-d987-4ede-a3e0-313c8456d352@group-F0ECD492E0E9: set configuration 0: [98421346-d987-4ede-a3e0-313c8456d352:10.5.0.9:9858], old=null at 0
datanode_6_1  | 2020-06-28 04:51:06,607 [grpc-default-executor-2] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 129 .Container 4 bcsId is 126. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 129 .Container 4 bcsId is 126.
datanode_6_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:177)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:473)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:181)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:155)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:304)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-06-28 04:51:22,098 [grpc-default-executor-2] INFO impl.HddsDispatcher: Operation: GetBlock , Trace ID:  , Message: ContainerID 6 does not exist , Result: CONTAINER_NOT_FOUND , StorageContainerException Occurred.
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 6 does not exist
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:275)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_3_1  | 2020-06-28 04:51:46,175 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=160,entriesCount=1,lastEntry=(t:1, i:120)
datanode_3_1  | 2020-06-28 04:51:46,183 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=161,entriesCount=1,lastEntry=(t:1, i:121)
datanode_3_1  | 2020-06-28 04:51:46,187 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=162,entriesCount=1,lastEntry=(t:1, i:122)
datanode_3_1  | 2020-06-28 04:51:46,188 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=163,entriesCount=1,lastEntry=(t:1, i:123)
datanode_3_1  | 2020-06-28 04:51:48,725 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=165,entriesCount=1,lastEntry=(t:1, i:124)
datanode_3_1  | 2020-06-28 04:51:48,740 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=166,entriesCount=1,lastEntry=(t:1, i:125)
datanode_3_1  | 2020-06-28 04:51:48,741 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=167,entriesCount=1,lastEntry=(t:1, i:126)
datanode_3_1  | 2020-06-28 04:51:48,755 [java.util.concurrent.ThreadPoolExecutor$Worker@4f1c416d[State = -1, empty queue]] WARN server.GrpcLogAppender: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5->98421346-d987-4ede-a3e0-313c8456d352-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=168,entriesCount=1,lastEntry=(t:1, i:127)
datanode_3_1  | 2020-06-28 04:53:51,560 [Thread-199] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-7B35C758E8CF->cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5, cid=183, seq=0, Watch-ALL_COMMITTED(129), Message:<EMPTY>, reply=RaftClientReply:client-7B35C758E8CF->cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5, cid=183, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 183 and log index 129 is not yet replicated to ALL_COMMITTED, logIndex=129, commits[cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:c172, 98421346-d987-4ede-a3e0-313c8456d352:c127, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:c172]
datanode_3_1  | 2020-06-28 04:54:07,556 [Thread-205] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-C43AD01CAD0E->cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5, cid=195, seq=0, Watch-ALL_COMMITTED(133), Message:<EMPTY>, reply=RaftClientReply:client-C43AD01CAD0E->cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3@group-F277262A3CA5, cid=195, FAILED org.apache.ratis.protocol.NotReplicatedException: Request with call Id 195 and log index 133 is not yet replicated to ALL_COMMITTED, logIndex=133, commits[cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3:c176, 98421346-d987-4ede-a3e0-313c8456d352:c127, ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0:c176]
datanode_3_1  | 2020-06-28 04:54:12,931 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is synced with bcsId 147.
datanode_3_1  | 2020-06-28 04:54:12,939 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is synced with bcsId 147.
datanode_3_1  | 2020-06-28 04:54:12,966 [RatisApplyTransactionExecutor 6] INFO interfaces.Container: Container 6 is closed with bcsId 147.
datanode_3_1  | 2020-06-28 04:54:13,057 [RatisApplyTransactionExecutor 8] INFO interfaces.Container: Container 8 is synced with bcsId 167.
datanode_3_1  | 2020-06-28 04:54:13,058 [RatisApplyTransactionExecutor 8] INFO interfaces.Container: Container 8 is synced with bcsId 167.
datanode_3_1  | 2020-06-28 04:54:13,117 [RatisApplyTransactionExecutor 8] INFO interfaces.Container: Container 8 is closed with bcsId 167.
datanode_3_1  | 2020-06-28 04:54:13,155 [RatisApplyTransactionExecutor 0] INFO interfaces.Container: Container 10 is synced with bcsId 174.
datanode_3_1  | 2020-06-28 04:54:13,155 [RatisApplyTransactionExecutor 0] INFO interfaces.Container: Container 10 is synced with bcsId 174.
datanode_3_1  | 2020-06-28 04:54:13,167 [RatisApplyTransactionExecutor 0] INFO interfaces.Container: Container 10 is closed with bcsId 174.
datanode_3_1  | 2020-06-28 04:54:13,190 [RatisApplyTransactionExecutor 2] INFO interfaces.Container: Container 2 is synced with bcsId 97.
datanode_3_1  | 2020-06-28 04:54:13,191 [RatisApplyTransactionExecutor 2] INFO interfaces.Container: Container 2 is synced with bcsId 97.
datanode_3_1  | 2020-06-28 04:54:13,202 [RatisApplyTransactionExecutor 2] INFO interfaces.Container: Container 2 is closed with bcsId 97.
datanode_3_1  | 2020-06-28 04:54:13,230 [RatisApplyTransactionExecutor 4] INFO interfaces.Container: Container 4 is synced with bcsId 129.
datanode_3_1  | 2020-06-28 04:54:13,231 [RatisApplyTransactionExecutor 4] INFO interfaces.Container: Container 4 is synced with bcsId 129.
datanode_3_1  | 2020-06-28 04:54:13,238 [RatisApplyTransactionExecutor 4] INFO interfaces.Container: Container 4 is closed with bcsId 129.
om_1          | 2020-06-28 04:49:08,391 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/10.5.0.70:9862
om_1          | 2020-06-28 04:49:08,436 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1          | 2020-06-28 04:49:08,543 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1          | 2020-06-28 04:49:08,591 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1          | 2020-06-28 04:49:08,592 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1          | 2020-06-28 04:49:08,648 [Listener at om/9862] INFO util.log: Logging initialized @18297ms to org.eclipse.jetty.util.log.Slf4jLog
om_1          | 2020-06-28 04:49:08,818 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1          | 2020-06-28 04:49:08,828 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1          | 2020-06-28 04:49:08,839 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1          | 2020-06-28 04:49:08,851 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1          | 2020-06-28 04:49:08,851 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1          | 2020-06-28 04:49:08,851 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1          | 2020-06-28 04:49:08,949 [Listener at om/9862] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om_1          | 2020-06-28 04:49:08,954 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1          | 2020-06-28 04:49:08,955 [Listener at om/9862] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1          | 2020-06-28 04:49:09,028 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1          | 2020-06-28 04:49:09,029 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1          | 2020-06-28 04:49:09,032 [Listener at om/9862] INFO server.session: node0 Scavenging every 660000ms
om_1          | 2020-06-28 04:49:09,050 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@408d945b{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1          | 2020-06-28 04:49:09,056 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@351e86b2{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1          | 2020-06-28 04:49:09,248 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@63f2d024{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-3493747229921263655.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1          | 2020-06-28 04:49:09,256 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@7a247711{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1          | 2020-06-28 04:49:09,256 [Listener at om/9862] INFO server.Server: Started @18905ms
om_1          | 2020-06-28 04:49:09,259 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1          | 2020-06-28 04:49:09,260 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1          | 2020-06-28 04:49:09,264 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1          | 2020-06-28 04:49:09,276 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4db16677] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1          | 2020-06-28 04:49:13,984 [IPC Server handler 0 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-42703 for user:hadoop
om_1          | 2020-06-28 04:49:14,025 [IPC Server handler 49 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-81267 for user:hadoop
om_1          | 2020-06-28 04:49:14,032 [IPC Server handler 46 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-53213 for user:hadoop
om_1          | 2020-06-28 04:49:14,040 [IPC Server handler 30 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-30093 for user:hadoop
om_1          | 2020-06-28 04:49:14,049 [IPC Server handler 28 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-63224 for user:hadoop
scm_1         | 2020-06-28 04:48:48,348 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1         | 2020-06-28 04:48:48,422 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1         | 2020-06-28 04:48:48,423 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1         | 2020-06-28 04:48:48,427 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1         | 2020-06-28 04:48:48,430 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1         | 2020-06-28 04:48:48,485 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1         | 2020-06-28 04:48:48,496 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1         | 2020-06-28 04:48:48,687 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1         | 2020-06-28 04:48:48,687 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1         | 2020-06-28 04:48:48,688 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1         | 2020-06-28 04:48:48,807 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5faeeb56{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1         | 2020-06-28 04:48:48,809 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@33324c05{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1         | 2020-06-28 04:48:48,945 [IPC Server handler 2 on default port 9861] WARN ipc.Server: IPC Server handler 2 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.5:44498: output error
scm_1         | 2020-06-28 04:48:48,947 [IPC Server handler 1 on default port 9861] WARN ipc.Server: IPC Server handler 1 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.9:46080: output error
scm_1         | 2020-06-28 04:48:48,947 [IPC Server handler 5 on default port 9861] WARN ipc.Server: IPC Server handler 5 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.6:60742: output error
scm_1         | 2020-06-28 04:48:48,947 [IPC Server handler 4 on default port 9861] WARN ipc.Server: IPC Server handler 4 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.5.0.8:39474: output error
scm_1         | 2020-06-28 04:48:49,171 [IPC Server handler 4 on default port 9861] INFO ipc.Server: IPC Server handler 4 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-28 04:48:49,201 [IPC Server handler 1 on default port 9861] INFO ipc.Server: IPC Server handler 1 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-28 04:48:49,202 [IPC Server handler 2 on default port 9861] INFO ipc.Server: IPC Server handler 2 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-06-28 04:51:37,229 [grpc-default-executor-2] INFO impl.HddsDispatcher: Operation: GetBlock , Trace ID:  , Message: ContainerID 6 does not exist , Result: CONTAINER_NOT_FOUND , StorageContainerException Occurred.
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 6 does not exist
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:275)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-06-28 04:51:52,608 [grpc-default-executor-2] INFO impl.HddsDispatcher: Operation: GetBlock , Trace ID:  , Message: ContainerID 6 does not exist , Result: CONTAINER_NOT_FOUND , StorageContainerException Occurred.
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 6 does not exist
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:275)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-06-28 04:52:02,975 [grpc-default-executor-2] INFO impl.HddsDispatcher: Operation: GetBlock , Trace ID:  , Message: ContainerID 6 does not exist , Result: CONTAINER_NOT_FOUND , StorageContainerException Occurred.
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 6 does not exist
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:275)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-06-28 04:52:18,107 [grpc-default-executor-2] INFO impl.HddsDispatcher: Operation: GetBlock , Trace ID:  , Message: ContainerID 6 does not exist , Result: CONTAINER_NOT_FOUND , StorageContainerException Occurred.
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 6 does not exist
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:275)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-28 04:48:49,202 [IPC Server handler 5 on default port 9861] INFO ipc.Server: IPC Server handler 5 on default port 9861 caught an exception
scm_1         | java.nio.channels.AsynchronousCloseException
scm_1         | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1         | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1         | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1         | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-06-28 04:52:33,378 [grpc-default-executor-2] INFO impl.HddsDispatcher: Operation: GetBlock , Trace ID:  , Message: ContainerID 8 does not exist , Result: CONTAINER_NOT_FOUND , StorageContainerException Occurred.
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 8 does not exist
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:275)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-06-28 04:52:53,508 [grpc-default-executor-2] INFO impl.HddsDispatcher: Operation: GetBlock , Trace ID:  , Message: ContainerID 8 does not exist , Result: CONTAINER_NOT_FOUND , StorageContainerException Occurred.
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 8 does not exist
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:275)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-06-28 04:53:08,637 [grpc-default-executor-2] INFO impl.HddsDispatcher: Operation: GetBlock , Trace ID:  , Message: ContainerID 8 does not exist , Result: CONTAINER_NOT_FOUND , StorageContainerException Occurred.
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 8 does not exist
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:275)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-06-28 04:53:18,752 [grpc-default-executor-2] INFO impl.HddsDispatcher: Operation: GetBlock , Trace ID:  , Message: ContainerID 8 does not exist , Result: CONTAINER_NOT_FOUND , StorageContainerException Occurred.
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1         | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1         | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1         | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1         | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1         | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1         | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1         | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1         | 2020-06-28 04:48:49,954 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7f6b57f2{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-13753691365224033573.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
scm_1         | 2020-06-28 04:48:50,103 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@27ab206{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1         | 2020-06-28 04:48:50,110 [Listener at 0.0.0.0/9860] INFO server.Server: Started @19923ms
scm_1         | 2020-06-28 04:48:50,156 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1         | 2020-06-28 04:48:50,160 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1         | 2020-06-28 04:48:50,171 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1         | 2020-06-28 04:48:50,257 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@521ba38f] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1         | 2020-06-28 04:48:50,653 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3
scm_1         | 2020-06-28 04:48:50,653 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered Data node : cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-06-28 04:48:50,653 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/98421346-d987-4ede-a3e0-313c8456d352
scm_1         | 2020-06-28 04:48:50,675 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 98421346-d987-4ede-a3e0-313c8456d352{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-06-28 04:48:50,684 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-28 04:48:50,684 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-28 04:48:50,820 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 4 required.
scm_1         | 2020-06-28 04:48:50,860 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 4 required.
scm_1         | 2020-06-28 04:48:50,910 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=abcf2ef9-6df5-4118-b0df-f0ecd492e0e9 to datanode:98421346-d987-4ede-a3e0-313c8456d352
scm_1         | 2020-06-28 04:48:51,178 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: abcf2ef9-6df5-4118-b0df-f0ecd492e0e9, Nodes: 98421346-d987-4ede-a3e0-313c8456d352{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-28T04:48:50.862953Z]
scm_1         | 2020-06-28 04:48:51,226 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=005d03de-8143-41d6-b8da-6155b05aaedb to datanode:cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3
scm_1         | 2020-06-28 04:48:51,255 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 005d03de-8143-41d6-b8da-6155b05aaedb, Nodes: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-28T04:48:51.226869Z]
scm_1         | 2020-06-28 04:48:51,271 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
scm_1         | 2020-06-28 04:48:51,559 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/33c58236-2210-4e24-acad-e8ad1ad12aba
scm_1         | 2020-06-28 04:48:51,562 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 33c58236-2210-4e24-acad-e8ad1ad12aba{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-06-28 04:48:51,563 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-28 04:48:51,565 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 4 required.
scm_1         | 2020-06-28 04:48:51,593 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=89434bcf-f0f0-4ce9-b210-f6be55194031 to datanode:33c58236-2210-4e24-acad-e8ad1ad12aba
scm_1         | 2020-06-28 04:48:51,595 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 89434bcf-f0f0-4ce9-b210-f6be55194031, Nodes: 33c58236-2210-4e24-acad-e8ad1ad12aba{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-28T04:48:51.593065Z]
scm_1         | 2020-06-28 04:48:51,600 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1         | 2020-06-28 04:48:51,795 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0
scm_1         | 2020-06-28 04:48:51,821 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-06-28 04:48:51,822 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-28 04:48:51,802 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f18e2931-e295-4338-b778-18b0906bf01e to datanode:ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 8 does not exist
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:275)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-06-28 04:53:38,882 [grpc-default-executor-2] INFO impl.HddsDispatcher: Operation: GetBlock , Trace ID:  , Message: ContainerID 8 does not exist , Result: CONTAINER_NOT_FOUND , StorageContainerException Occurred.
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 8 does not exist
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:275)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-06-28 04:53:56,895 [grpc-default-executor-2] INFO impl.HddsDispatcher: Operation: GetBlock , Trace ID:  , Message: ContainerID 10 does not exist , Result: CONTAINER_NOT_FOUND , StorageContainerException Occurred.
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 10 does not exist
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:275)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_6_1  | 2020-06-28 04:54:12,008 [grpc-default-executor-2] INFO impl.HddsDispatcher: Operation: GetBlock , Trace ID:  , Message: ContainerID 10 does not exist , Result: CONTAINER_NOT_FOUND , StorageContainerException Occurred.
datanode_6_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: ContainerID 10 does not exist
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:275)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:166)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_6_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_6_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
scm_1         | 2020-06-28 04:48:51,822 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: f18e2931-e295-4338-b778-18b0906bf01e, Nodes: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-28T04:48:51.802316Z]
scm_1         | 2020-06-28 04:48:51,822 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 4 DataNodes registered, 4 required.
scm_1         | 2020-06-28 04:48:51,829 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-06-28 04:48:51,839 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1         | 2020-06-28 04:48:51,839 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 4 nodes. Healthy nodes 4
scm_1         | 2020-06-28 04:48:51,887 [IPC Server handler 8 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack1/a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9
scm_1         | 2020-06-28 04:48:51,887 [IPC Server handler 8 on default port 9861] INFO node.SCMNodeManager: Registered Data node : a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}
scm_1         | 2020-06-28 04:48:51,888 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-28 04:48:51,888 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-06-28 04:48:51,933 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=843592c9-09f2-4b01-86b3-f277262a3ca5 to datanode:98421346-d987-4ede-a3e0-313c8456d352
scm_1         | 2020-06-28 04:48:51,948 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=843592c9-09f2-4b01-86b3-f277262a3ca5 to datanode:cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3
scm_1         | 2020-06-28 04:48:51,954 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=843592c9-09f2-4b01-86b3-f277262a3ca5 to datanode:ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0
scm_1         | 2020-06-28 04:48:51,955 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 843592c9-09f2-4b01-86b3-f277262a3ca5, Nodes: 98421346-d987-4ede-a3e0-313c8456d352{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-28T04:48:51.933029Z]
scm_1         | 2020-06-28 04:48:51,969 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 2
scm_1         | 2020-06-28 04:48:52,205 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopology: Added a new node: /rack2/7112676b-d549-48b4-b648-8def29c22825
scm_1         | 2020-06-28 04:48:52,230 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 7112676b-d549-48b4-b648-8def29c22825{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}
scm_1         | 2020-06-28 04:48:52,231 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1         | 2020-06-28 04:48:52,233 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1         | 2020-06-28 04:48:52,222 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=02c2667e-f50b-4f03-ae5c-31d93a00eb7a to datanode:a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9
scm_1         | 2020-06-28 04:48:52,242 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 02c2667e-f50b-4f03-ae5c-31d93a00eb7a, Nodes: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-28T04:48:52.222590Z]
scm_1         | 2020-06-28 04:48:52,244 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a84ba09c-c17f-4d14-a5de-fcf718f41080 to datanode:7112676b-d549-48b4-b648-8def29c22825
scm_1         | 2020-06-28 04:48:52,244 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: a84ba09c-c17f-4d14-a5de-fcf718f41080, Nodes: 7112676b-d549-48b4-b648-8def29c22825{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-28T04:48:52.244314Z]
scm_1         | 2020-06-28 04:48:52,256 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-06-28 04:48:52,257 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7a741092-4377-4624-abe5-db6904f15b83 to datanode:a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9
scm_1         | 2020-06-28 04:48:52,265 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7a741092-4377-4624-abe5-db6904f15b83 to datanode:7112676b-d549-48b4-b648-8def29c22825
scm_1         | 2020-06-28 04:48:52,265 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7a741092-4377-4624-abe5-db6904f15b83 to datanode:33c58236-2210-4e24-acad-e8ad1ad12aba
scm_1         | 2020-06-28 04:48:52,266 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 7a741092-4377-4624-abe5-db6904f15b83, Nodes: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}7112676b-d549-48b4-b648-8def29c22825{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}33c58236-2210-4e24-acad-e8ad1ad12aba{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-28T04:48:52.257160Z]
scm_1         | 2020-06-28 04:48:52,266 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_6_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_6_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_6_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1         | 2020-06-28 04:48:54,715 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 005d03de-8143-41d6-b8da-6155b05aaedb, Nodes: cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3, CreationTimestamp2020-06-28T04:48:51.226869Z] moved to OPEN state
scm_1         | 2020-06-28 04:48:54,727 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-28 04:48:54,751 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-28 04:48:56,527 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 89434bcf-f0f0-4ce9-b210-f6be55194031, Nodes: 33c58236-2210-4e24-acad-e8ad1ad12aba{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:33c58236-2210-4e24-acad-e8ad1ad12aba, CreationTimestamp2020-06-28T04:48:51.593065Z] moved to OPEN state
scm_1         | 2020-06-28 04:48:56,528 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-28 04:48:56,528 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-28 04:48:56,613 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 02c2667e-f50b-4f03-ae5c-31d93a00eb7a, Nodes: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9, CreationTimestamp2020-06-28T04:48:52.222590Z] moved to OPEN state
scm_1         | 2020-06-28 04:48:56,614 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-28 04:48:56,614 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-28 04:48:56,681 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: f18e2931-e295-4338-b778-18b0906bf01e, Nodes: ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0, CreationTimestamp2020-06-28T04:48:51.802316Z] moved to OPEN state
scm_1         | 2020-06-28 04:48:56,681 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-28 04:48:56,683 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-28 04:48:57,267 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: a84ba09c-c17f-4d14-a5de-fcf718f41080, Nodes: 7112676b-d549-48b4-b648-8def29c22825{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:7112676b-d549-48b4-b648-8def29c22825, CreationTimestamp2020-06-28T04:48:52.244314Z] moved to OPEN state
scm_1         | 2020-06-28 04:48:57,269 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1         | 2020-06-28 04:48:57,269 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-28 04:49:02,696 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 7a741092-4377-4624-abe5-db6904f15b83, Nodes: a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}7112676b-d549-48b4-b648-8def29c22825{ip: 10.5.0.7, host: ozone-topology_datanode_4_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}33c58236-2210-4e24-acad-e8ad1ad12aba{ip: 10.5.0.5, host: ozone-topology_datanode_2_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9, CreationTimestamp2020-06-28T04:48:52.257160Z] moved to OPEN state
scm_1         | 2020-06-28 04:49:02,700 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1         | 2020-06-28 04:49:02,703 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1         | 2020-06-28 04:49:02,711 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1         | 2020-06-28 04:49:02,711 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1         | 2020-06-28 04:49:02,714 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1         | 2020-06-28 04:49:03,247 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 843592c9-09f2-4b01-86b3-f277262a3ca5, Nodes: 98421346-d987-4ede-a3e0-313c8456d352{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null}ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3, CreationTimestamp2020-06-28T04:48:51.933029Z] moved to OPEN state
scm_1         | 2020-06-28 04:49:19,117 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:23,231 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: abcf2ef9-6df5-4118-b0df-f0ecd492e0e9, Nodes: 98421346-d987-4ede-a3e0-313c8456d352{ip: 10.5.0.9, host: ozone-topology_datanode_6_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:98421346-d987-4ede-a3e0-313c8456d352, CreationTimestamp2020-06-28T04:48:50.862953Z] moved to OPEN state
scm_1         | 2020-06-28 04:49:23,875 [IPC Server handler 4 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:24,037 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:26,620 [IPC Server handler 0 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:29,239 [IPC Server handler 43 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:31,838 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:31,953 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:34,549 [IPC Server handler 93 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:37,165 [IPC Server handler 42 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:37,250 [IPC Server handler 34 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:37,360 [IPC Server handler 40 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:39,948 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:42,542 [IPC Server handler 93 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:45,137 [IPC Server handler 42 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:47,730 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:47,879 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:50,427 [IPC Server handler 44 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:50,512 [IPC Server handler 93 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:53,092 [IPC Server handler 43 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:55,693 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:58,275 [IPC Server handler 40 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:49:58,387 [IPC Server handler 44 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:00,969 [IPC Server handler 42 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:01,063 [IPC Server handler 38 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:03,646 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:06,238 [IPC Server handler 40 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:06,328 [IPC Server handler 44 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:08,881 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:11,461 [IPC Server handler 51 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:14,047 [IPC Server handler 34 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:14,145 [IPC Server handler 33 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:14,242 [IPC Server handler 48 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:16,815 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:19,399 [IPC Server handler 51 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:21,960 [IPC Server handler 43 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:22,093 [IPC Server handler 33 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:24,664 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:24,748 [IPC Server handler 42 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:24,840 [IPC Server handler 34 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:27,386 [IPC Server handler 51 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:27,473 [IPC Server handler 30 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:27,565 [IPC Server handler 89 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:27,670 [IPC Server handler 43 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:27,720 [IPC Server handler 42 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:27,801 [IPC Server handler 40 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:27,882 [IPC Server handler 48 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:30,460 [IPC Server handler 30 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:33,063 [IPC Server handler 52 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:35,641 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:38,206 [IPC Server handler 30 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:38,341 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:40,921 [IPC Server handler 52 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:41,024 [IPC Server handler 30 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:43,593 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:46,165 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:46,790 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-06-28 04:50:46,790 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-06-28 04:50:48,718 [IPC Server handler 34 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:51,279 [IPC Server handler 29 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:51,385 [IPC Server handler 41 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:50:51,474 [IPC Server handler 47 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:51:01,581 [IPC Server handler 85 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:51:06,827 [IPC Server handler 38 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:51:06,897 [IPC Server handler 52 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:51:17,050 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:51:32,210 [IPC Server handler 26 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:51:37,317 [IPC Server handler 41 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:51:37,384 [IPC Server handler 47 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:51:37,450 [IPC Server handler 21 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:51:47,542 [IPC Server handler 63 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:51:52,691 [IPC Server handler 42 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:51:52,762 [IPC Server handler 38 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:51:52,846 [IPC Server handler 33 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:52:02,957 [IPC Server handler 30 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:52:18,081 [IPC Server handler 26 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:52:23,226 [IPC Server handler 41 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:52:33,355 [IPC Server handler 47 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:52:46,791 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 6 nodes. Healthy nodes 6
scm_1         | 2020-06-28 04:52:46,792 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1         | 2020-06-28 04:52:48,485 [IPC Server handler 8 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:53:03,618 [IPC Server handler 80 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:53:18,733 [IPC Server handler 38 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:53:33,849 [IPC Server handler 33 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:53:39,044 [IPC Server handler 28 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:53:39,124 [IPC Server handler 41 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:53:41,685 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:53:41,753 [IPC Server handler 40 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:53:51,870 [IPC Server handler 52 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:54:02,757 [EventQueue-Delayed safe mode statusForReplicationManager] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1         | 2020-06-28 04:54:02,771 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 13 milliseconds for processing 10 containers.
scm_1         | 2020-06-28 04:54:02,772 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #5
scm_1         | 2020-06-28 04:54:02,773 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #6
scm_1         | 2020-06-28 04:54:02,774 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #7
scm_1         | 2020-06-28 04:54:02,774 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #8
scm_1         | 2020-06-28 04:54:02,775 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #9
scm_1         | 2020-06-28 04:54:02,775 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #10
scm_1         | 2020-06-28 04:54:02,775 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1
scm_1         | 2020-06-28 04:54:02,776 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2
scm_1         | 2020-06-28 04:54:02,777 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #3
scm_1         | 2020-06-28 04:54:02,777 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #4
scm_1         | 2020-06-28 04:54:06,990 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.5.0.71
scm_1         | 2020-06-28 04:54:10,103 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #5 to CLOSED state, datanode a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-06-28 04:54:10,195 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #7 to CLOSED state, datanode a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-06-28 04:54:10,252 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #9 to CLOSED state, datanode a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-06-28 04:54:10,316 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-06-28 04:54:10,358 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #3 to CLOSED state, datanode a2aceebf-a5a1-442a-ab52-ef4a6ceda2b9{ip: 10.5.0.4, host: ozone-topology_datanode_1_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-06-28 04:54:12,979 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #6 to CLOSED state, datanode cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-06-28 04:54:13,087 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #8 to CLOSED state, datanode ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-06-28 04:54:13,155 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #10 to CLOSED state, datanode ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-06-28 04:54:13,204 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode ebf10bc3-1db8-4654-b26b-4a6c8b7c4ef0{ip: 10.5.0.8, host: ozone-topology_datanode_5_1.ozone-topology_net, networkLocation: /rack2, certSerialId: null} reported CLOSED replica.
scm_1         | 2020-06-28 04:54:13,241 [EventQueue-IncrementalContainerReportForIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #4 to CLOSED state, datanode cbccd380-c3ad-40d4-8d5d-c3e0f877ccd3{ip: 10.5.0.6, host: ozone-topology_datanode_3_1.ozone-topology_net, networkLocation: /rack1, certSerialId: null} reported CLOSED replica.
