Attaching to ozone_s3g_1, ozone_datanode_2, ozone_datanode_3, ozone_datanode_1, ozone_recon_1, ozone_scm_1, ozone_om_1
datanode_2  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2020-06-03 22:46:23,447 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = 73e78c2f163b/172.22.0.4
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/aec7a9345e8cecdacc1367562fdd82dd4dfc34df ; compiled by 'jenkins1001' on 2020-06-03T22:20Z
datanode_2  | STARTUP_MSG:   java = 11.0.6
datanode_2  | ************************************************************/
datanode_2  | 2020-06-03 22:46:23,529 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2020-06-03 22:46:25,860 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2020-06-03 22:46:26,327 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2020-06-03 22:46:27,512 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2020-06-03 22:46:27,512 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2020-06-03 22:46:27,999 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:73e78c2f163b ip:172.22.0.4
datanode_2  | 2020-06-03 22:46:28,338 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2  | 2020-06-03 22:46:28,363 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2  | 2020-06-03 22:46:28,364 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2020-06-03 22:46:28,446 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2  | 2020-06-03 22:46:28,608 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2020-06-03 22:46:34,122 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-06-03 22:46:34,423 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2020-06-03 22:46:34,802 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2  | 2020-06-03 22:46:34,827 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2  | 2020-06-03 22:46:34,839 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-06-03 22:46:34,840 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2  | 2020-06-03 22:46:34,843 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-06-03 22:46:36,047 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-06-03 22:46:37,157 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 2020-06-03 22:46:37,311 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2  | 2020-06-03 22:46:37,434 [main] INFO util.log: Logging initialized @16536ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | 2020-06-03 22:46:37,923 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2020-06-03 22:46:37,943 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2020-06-03 22:46:37,975 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2020-06-03 22:46:37,977 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_2  | 2020-06-03 22:46:37,977 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_2  | 2020-06-03 22:46:37,977 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_2  | 2020-06-03 22:46:38,255 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2020-06-03 22:46:38,262 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2  | 2020-06-03 22:46:38,534 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2020-06-03 22:46:38,534 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2020-06-03 22:46:38,540 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2  | 2020-06-03 22:46:38,610 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2020-06-03 22:46:38,618 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@56a4f272{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2020-06-03 22:46:38,630 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3c3a0032{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2020-06-03 22:46:39,025 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@40e32762{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-787326757606227565.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 2020-06-03 22:46:39,065 [main] INFO server.AbstractConnector: Started ServerConnector@6caf7803{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2  | 2020-06-03 22:46:39,074 [main] INFO server.Server: Started @18176ms
datanode_2  | 2020-06-03 22:46:39,107 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2020-06-03 22:46:39,107 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2020-06-03 22:46:39,111 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2020-06-03 22:46:39,231 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@674f412c] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2020-06-03 22:46:39,844 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.22.0.3:9891
datanode_2  | 2020-06-03 22:46:40,241 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2  | 2020-06-03 22:46:42,474 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-03 22:46:43,475 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-03 22:46:44,475 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-03 22:46:45,476 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-03 22:46:46,477 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9861. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-03 22:46:47,478 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9861. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-03 22:46:48,479 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9861. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-03 22:46:49,496 [Datanode State Machine Thread - 1] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2  | java.net.SocketTimeoutException: Call From 73e78c2f163b/172.22.0.4 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.22.0.4:53822 remote=scm/172.22.0.8:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_2  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_2  | 	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.22.0.4:53822 remote=scm/172.22.0.8:9861]
datanode_2  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_2  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_2  | 2020-06-03 22:46:50,089 [Datanode State Machine Thread - 3] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2020-06-03 22:46:50,091 [Datanode State Machine Thread - 3] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2  | 2020-06-03 22:46:50,091 [Datanode State Machine Thread - 3] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis f3811c11-6df2-4867-ae20-220ae7889355 at port 9858
datanode_2  | 2020-06-03 22:46:50,135 [Datanode State Machine Thread - 3] INFO impl.RaftServerProxy: f3811c11-6df2-4867-ae20-220ae7889355: start RPC server
datanode_2  | 2020-06-03 22:46:50,368 [Datanode State Machine Thread - 3] INFO server.GrpcService: f3811c11-6df2-4867-ae20-220ae7889355: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2  | 2020-06-03 22:46:54,319 [Command processor thread] INFO impl.RaftServerProxy: f3811c11-6df2-4867-ae20-220ae7889355: addNew group-E4C1326E3A66:[f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858] returns group-E4C1326E3A66:java.util.concurrent.CompletableFuture@7613015a[Not completed]
datanode_2  | 2020-06-03 22:46:54,377 [pool-19-thread-1] INFO impl.RaftServerImpl: f3811c11-6df2-4867-ae20-220ae7889355: new RaftServerImpl for group-E4C1326E3A66:[f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-06-03 22:46:54,384 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-06-03 22:46:54,390 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-06-03 22:46:54,391 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-06-03 22:46:54,392 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-06-03 22:46:54,393 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-06-03 22:46:54,408 [pool-19-thread-1] INFO impl.RaftServerImpl: f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66: ConfigurationManager, init=-1: [f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-06-03 22:46:54,408 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-06-03 22:46:54,440 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-06-03 22:46:54,444 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e735236f-a353-4a1c-b29d-e4c1326e3a66 does not exist. Creating ...
datanode_2  | 2020-06-03 22:46:54,473 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e735236f-a353-4a1c-b29d-e4c1326e3a66/in_use.lock acquired by nodename 6@73e78c2f163b
datanode_2  | 2020-06-03 22:46:54,484 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e735236f-a353-4a1c-b29d-e4c1326e3a66 has been successfully formatted.
datanode_2  | 2020-06-03 22:46:54,487 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-E4C1326E3A66: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-06-03 22:46:54,493 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-06-03 22:46:54,512 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-06-03 22:46:54,520 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-06-03 22:46:54,520 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-06-03 22:46:54,522 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-06-03 22:46:54,545 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.f3811c11-6df2-4867-ae20-220ae7889355
datanode_2  | 2020-06-03 22:46:54,584 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-06-03 22:46:54,603 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/e735236f-a353-4a1c-b29d-e4c1326e3a66
datanode_2  | 2020-06-03 22:46:54,607 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-06-03 22:46:54,609 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-06-03 22:46:54,610 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-06-03 22:46:54,619 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-06-03 22:46:54,620 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-06-03 22:46:54,621 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-06-03 22:46:54,627 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-06-03 22:46:54,628 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-06-03 22:46:54,631 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-06-03 22:46:54,692 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-06-03 22:46:54,753 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-06-03 22:46:54,768 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-06-03 22:46:54,775 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-06-03 22:46:54,776 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-06-03 22:46:54,776 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-06-03 22:46:54,779 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-06-03 22:46:54,844 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66
datanode_2  | 2020-06-03 22:46:54,850 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66
datanode_2  | 2020-06-03 22:46:54,853 [pool-19-thread-1] INFO impl.RaftServerImpl: f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66: start as a follower, conf=-1: [f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858], old=null
datanode_2  | 2020-06-03 22:46:54,877 [pool-19-thread-1] INFO impl.RaftServerImpl: f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-06-03 22:46:54,892 [pool-19-thread-1] INFO impl.RoleInfo: f3811c11-6df2-4867-ae20-220ae7889355: start FollowerState
datanode_2  | 2020-06-03 22:46:54,941 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E4C1326E3A66,id=f3811c11-6df2-4867-ae20-220ae7889355
datanode_2  | 2020-06-03 22:46:54,943 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66
datanode_2  | 2020-06-03 22:46:55,036 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "e735236f-a353-4a1c-b29d-e4c1326e3a66"
datanode_2  | .
datanode_2  | 2020-06-03 22:46:55,057 [Command processor thread] INFO impl.RaftServerProxy: f3811c11-6df2-4867-ae20-220ae7889355: addNew group-33A3FA0446CA:[f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858] returns group-33A3FA0446CA:java.util.concurrent.CompletableFuture@1d52884c[Not completed]
datanode_2  | 2020-06-03 22:46:55,060 [pool-19-thread-1] INFO impl.RaftServerImpl: f3811c11-6df2-4867-ae20-220ae7889355: new RaftServerImpl for group-33A3FA0446CA:[f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-06-03 22:46:55,063 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-06-03 22:46:55,063 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-06-03 22:46:55,063 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-06-03 22:46:55,065 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-06-03 22:46:55,065 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-06-03 22:46:55,065 [pool-19-thread-1] INFO impl.RaftServerImpl: f3811c11-6df2-4867-ae20-220ae7889355@group-33A3FA0446CA: ConfigurationManager, init=-1: [f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-06-03 22:46:55,065 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-06-03 22:46:55,066 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-06-03 22:46:55,067 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2a11b1d1-500f-4f30-95f4-33a3fa0446ca does not exist. Creating ...
datanode_2  | 2020-06-03 22:46:55,069 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2a11b1d1-500f-4f30-95f4-33a3fa0446ca/in_use.lock acquired by nodename 6@73e78c2f163b
datanode_2  | 2020-06-03 22:46:55,072 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2a11b1d1-500f-4f30-95f4-33a3fa0446ca has been successfully formatted.
datanode_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2020-06-03 22:46:28,833 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = 1f16ccd291f1/172.22.0.7
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/aec7a9345e8cecdacc1367562fdd82dd4dfc34df ; compiled by 'jenkins1001' on 2020-06-03T22:20Z
datanode_1  | STARTUP_MSG:   java = 11.0.6
datanode_1  | ************************************************************/
datanode_1  | 2020-06-03 22:46:28,905 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2020-06-03 22:46:31,031 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2020-06-03 22:46:31,551 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2020-06-03 22:46:32,895 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2020-06-03 22:46:32,895 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2020-06-03 22:46:33,299 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:1f16ccd291f1 ip:172.22.0.7
datanode_1  | 2020-06-03 22:46:33,633 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2020-06-03 22:46:33,658 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1  | 2020-06-03 22:46:33,660 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2020-06-03 22:46:33,712 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2020-06-03 22:46:33,840 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2020-06-03 22:46:38,909 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2020-06-03 22:46:39,185 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1  | 2020-06-03 22:46:39,549 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1  | 2020-06-03 22:46:39,559 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  | 2020-06-03 22:46:39,571 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-06-03 22:46:39,577 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1  | 2020-06-03 22:46:39,584 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2020-06-03 22:46:40,901 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-06-03 22:46:41,890 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2020-06-03 22:46:42,087 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1  | 2020-06-03 22:46:42,275 [main] INFO util.log: Logging initialized @18607ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2020-06-03 22:46:42,937 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2020-06-03 22:46:42,941 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2020-06-03 22:46:42,994 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2020-06-03 22:46:43,006 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_1  | 2020-06-03 22:46:43,006 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_1  | 2020-06-03 22:46:43,006 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_1  | 2020-06-03 22:46:43,298 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2020-06-03 22:46:43,305 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1  | 2020-06-03 22:46:43,440 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  | 2020-06-03 22:46:43,443 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2020-06-03 22:46:43,446 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_1  | 2020-06-03 22:46:43,499 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2020-06-03 22:46:43,510 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@56a4f272{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2020-06-03 22:46:43,520 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3c3a0032{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2020-06-03 22:46:43,918 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@40e32762{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-2608590263720358500.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1  | 2020-06-03 22:46:43,961 [main] INFO server.AbstractConnector: Started ServerConnector@6caf7803{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1  | 2020-06-03 22:46:43,962 [main] INFO server.Server: Started @20294ms
datanode_1  | 2020-06-03 22:46:43,993 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2020-06-03 22:46:43,993 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2020-06-03 22:46:44,008 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1  | 2020-06-03 22:46:44,115 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3f645d60] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2020-06-03 22:46:44,443 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.22.0.3:9891
datanode_1  | 2020-06-03 22:46:44,755 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1  | 2020-06-03 22:46:47,185 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-06-03 22:46:48,187 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-06-03 22:46:49,215 [Datanode State Machine Thread - 1] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_1  | java.net.SocketTimeoutException: Call From 1f16ccd291f1/172.22.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.22.0.7:53272 remote=scm/172.22.0.8:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_1  | 	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.22.0.7:53272 remote=scm/172.22.0.8:9861]
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_1  | 2020-06-03 22:46:50,072 [Datanode State Machine Thread - 3] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 2020-06-03 22:46:50,073 [Datanode State Machine Thread - 3] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1  | 2020-06-03 22:46:50,074 [Datanode State Machine Thread - 3] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 622eccab-f286-4bed-94f9-9d148dcbff73 at port 9858
datanode_1  | 2020-06-03 22:46:50,119 [Datanode State Machine Thread - 3] INFO impl.RaftServerProxy: 622eccab-f286-4bed-94f9-9d148dcbff73: start RPC server
datanode_1  | 2020-06-03 22:46:50,292 [Datanode State Machine Thread - 3] INFO server.GrpcService: 622eccab-f286-4bed-94f9-9d148dcbff73: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1  | 2020-06-03 22:46:55,181 [Command processor thread] INFO impl.RaftServerProxy: 622eccab-f286-4bed-94f9-9d148dcbff73: addNew group-C5072C5A9ED0:[622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858] returns group-C5072C5A9ED0:java.util.concurrent.CompletableFuture@47186037[Not completed]
datanode_1  | 2020-06-03 22:46:55,276 [pool-19-thread-1] INFO impl.RaftServerImpl: 622eccab-f286-4bed-94f9-9d148dcbff73: new RaftServerImpl for group-C5072C5A9ED0:[622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-06-03 22:46:55,287 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-06-03 22:46:55,291 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-06-03 22:46:55,296 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-06-03 22:46:55,297 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-06-03 22:46:55,300 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-06-03 22:46:55,319 [pool-19-thread-1] INFO impl.RaftServerImpl: 622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0: ConfigurationManager, init=-1: [622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-06-03 22:46:55,329 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-06-03 22:46:55,359 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-06-03 22:46:55,363 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/15639143-720d-4e1a-8cd4-c5072c5a9ed0 does not exist. Creating ...
datanode_1  | 2020-06-03 22:46:55,387 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/15639143-720d-4e1a-8cd4-c5072c5a9ed0/in_use.lock acquired by nodename 7@1f16ccd291f1
datanode_1  | 2020-06-03 22:46:55,398 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/15639143-720d-4e1a-8cd4-c5072c5a9ed0 has been successfully formatted.
datanode_1  | 2020-06-03 22:46:55,415 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-C5072C5A9ED0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-06-03 22:46:55,418 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-06-03 22:46:55,443 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-06-03 22:46:55,474 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-06-03 22:46:55,475 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-06-03 22:46:55,480 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-06-03 22:46:55,503 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.622eccab-f286-4bed-94f9-9d148dcbff73
datanode_1  | 2020-06-03 22:46:55,569 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-06-03 22:46:55,073 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-33A3FA0446CA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-06-03 22:46:55,075 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-06-03 22:46:55,075 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-06-03 22:46:55,076 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-06-03 22:46:55,077 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-06-03 22:46:55,078 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-06-03 22:46:55,082 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-06-03 22:46:55,083 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new f3811c11-6df2-4867-ae20-220ae7889355@group-33A3FA0446CA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2a11b1d1-500f-4f30-95f4-33a3fa0446ca
datanode_2  | 2020-06-03 22:46:55,084 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-06-03 22:46:55,085 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-06-03 22:46:55,089 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-06-03 22:46:55,089 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-06-03 22:46:55,090 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-06-03 22:46:55,090 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-06-03 22:46:55,092 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-06-03 22:46:55,095 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-06-03 22:46:55,096 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-06-03 22:46:55,104 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-06-03 22:46:55,107 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: f3811c11-6df2-4867-ae20-220ae7889355@group-33A3FA0446CA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-06-03 22:46:55,111 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-06-03 22:46:55,111 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-06-03 22:46:55,111 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-06-03 22:46:55,112 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-06-03 22:46:55,113 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-06-03 22:46:55,114 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.f3811c11-6df2-4867-ae20-220ae7889355@group-33A3FA0446CA
datanode_2  | 2020-06-03 22:46:55,114 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.f3811c11-6df2-4867-ae20-220ae7889355@group-33A3FA0446CA
datanode_2  | 2020-06-03 22:46:55,119 [pool-19-thread-1] INFO impl.RaftServerImpl: f3811c11-6df2-4867-ae20-220ae7889355@group-33A3FA0446CA: start as a follower, conf=-1: [f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858], old=null
datanode_2  | 2020-06-03 22:46:55,127 [pool-19-thread-1] INFO impl.RaftServerImpl: f3811c11-6df2-4867-ae20-220ae7889355@group-33A3FA0446CA: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-06-03 22:46:55,127 [pool-19-thread-1] INFO impl.RoleInfo: f3811c11-6df2-4867-ae20-220ae7889355: start FollowerState
datanode_2  | 2020-06-03 22:46:55,129 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-33A3FA0446CA,id=f3811c11-6df2-4867-ae20-220ae7889355
datanode_2  | 2020-06-03 22:46:55,132 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.f3811c11-6df2-4867-ae20-220ae7889355@group-33A3FA0446CA
datanode_2  | 2020-06-03 22:46:57,770 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "2a11b1d1-500f-4f30-95f4-33a3fa0446ca"
datanode_2  | .
datanode_2  | 2020-06-03 22:46:59,935 [grpc-default-executor-0] INFO impl.RaftServerImpl: f3811c11-6df2-4867-ae20-220ae7889355@group-33A3FA0446CA: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:33aee425-864c-4906-8eb4-b838cd19e298
datanode_2  | 2020-06-03 22:46:59,935 [grpc-default-executor-0] INFO impl.RoleInfo: f3811c11-6df2-4867-ae20-220ae7889355: shutdown FollowerState
datanode_2  | 2020-06-03 22:46:59,935 [Thread-24] INFO impl.FollowerState: f3811c11-6df2-4867-ae20-220ae7889355@group-33A3FA0446CA-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2  | 2020-06-03 22:46:59,944 [grpc-default-executor-0] INFO impl.RoleInfo: f3811c11-6df2-4867-ae20-220ae7889355: start FollowerState
datanode_2  | 2020-06-03 22:47:00,026 [Thread-22] INFO impl.FollowerState: f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-FollowerState: change to CANDIDATE, lastRpcTime:5134ms, electionTimeout:5102ms
datanode_2  | 2020-06-03 22:47:00,034 [Thread-22] INFO impl.RoleInfo: f3811c11-6df2-4867-ae20-220ae7889355: shutdown FollowerState
datanode_2  | 2020-06-03 22:47:00,034 [Thread-22] INFO impl.RaftServerImpl: f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-06-03 22:47:00,039 [Thread-22] INFO impl.RoleInfo: f3811c11-6df2-4867-ae20-220ae7889355: start LeaderElection
datanode_2  | 2020-06-03 22:47:00,068 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO impl.LeaderElection: f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1: begin an election at term 1 for -1: [f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858], old=null
datanode_2  | 2020-06-03 22:47:00,071 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO impl.RoleInfo: f3811c11-6df2-4867-ae20-220ae7889355: shutdown LeaderElection
datanode_2  | 2020-06-03 22:47:00,075 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO impl.RaftServerImpl: f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-06-03 22:47:00,078 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-E4C1326E3A66 with new leaderId: f3811c11-6df2-4867-ae20-220ae7889355
datanode_2  | 2020-06-03 22:47:00,080 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO impl.RaftServerImpl: f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66: change Leader from null to f3811c11-6df2-4867-ae20-220ae7889355 at term 1 for becomeLeader, leader elected after 5585ms
datanode_2  | 2020-06-03 22:47:00,100 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-06-03 22:47:00,101 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2020-06-03 22:47:00,106 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66
datanode_2  | 2020-06-03 22:47:00,133 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2020-06-03 22:47:00,134 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-06-03 22:47:00,147 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-06-03 22:47:00,147 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-06-03 22:47:00,154 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2020-06-03 22:47:00,170 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO impl.RoleInfo: f3811c11-6df2-4867-ae20-220ae7889355: start LeaderState
datanode_2  | 2020-06-03 22:47:00,199 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-33A3FA0446CA with new leaderId: 33aee425-864c-4906-8eb4-b838cd19e298
datanode_2  | 2020-06-03 22:47:00,199 [grpc-default-executor-0] INFO impl.RaftServerImpl: f3811c11-6df2-4867-ae20-220ae7889355@group-33A3FA0446CA: change Leader from null to 33aee425-864c-4906-8eb4-b838cd19e298 at term 1 for appendEntries, leader elected after 5123ms
datanode_2  | 2020-06-03 22:47:00,288 [grpc-default-executor-0] INFO impl.RaftServerImpl: f3811c11-6df2-4867-ae20-220ae7889355@group-33A3FA0446CA: set configuration 0: [f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858], old=null at 0
datanode_2  | 2020-06-03 22:47:00,289 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: f3811c11-6df2-4867-ae20-220ae7889355@group-33A3FA0446CA-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-06-03 22:47:00,289 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-06-03 22:47:00,404 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-LeaderElection1] INFO impl.RaftServerImpl: f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66: set configuration 0: [f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858], old=null at 0
datanode_2  | 2020-06-03 22:47:00,535 [f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f3811c11-6df2-4867-ae20-220ae7889355@group-E4C1326E3A66-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e735236f-a353-4a1c-b29d-e4c1326e3a66/current/log_inprogress_0
datanode_2  | 2020-06-03 22:47:00,543 [f3811c11-6df2-4867-ae20-220ae7889355@group-33A3FA0446CA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f3811c11-6df2-4867-ae20-220ae7889355@group-33A3FA0446CA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2a11b1d1-500f-4f30-95f4-33a3fa0446ca/current/log_inprogress_0
datanode_2  | 2020-06-03 22:47:41,467 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: recon/172.22.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=60000 MILLISECONDS)
datanode_3  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2020-06-03 22:46:30,175 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = 8028961d7b92/172.22.0.5
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/aec7a9345e8cecdacc1367562fdd82dd4dfc34df ; compiled by 'jenkins1001' on 2020-06-03T22:20Z
datanode_3  | STARTUP_MSG:   java = 11.0.6
datanode_3  | ************************************************************/
datanode_3  | 2020-06-03 22:46:30,217 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2020-06-03 22:46:32,165 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2020-06-03 22:46:32,747 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2020-06-03 22:46:33,979 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2020-06-03 22:46:33,987 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2020-06-03 22:46:34,510 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:8028961d7b92 ip:172.22.0.5
datanode_3  | 2020-06-03 22:46:34,871 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3  | 2020-06-03 22:46:34,919 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3  | 2020-06-03 22:46:34,920 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2020-06-03 22:46:35,015 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2020-06-03 22:46:35,189 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2020-06-03 22:46:40,480 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-06-03 22:46:40,698 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3  | 2020-06-03 22:46:40,967 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3  | 2020-06-03 22:46:40,968 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3  | 2020-06-03 22:46:40,971 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-06-03 22:46:40,972 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3  | 2020-06-03 22:46:40,973 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-06-03 22:46:41,817 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-06-03 22:46:42,808 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2020-06-03 22:46:42,872 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3  | 2020-06-03 22:46:43,032 [main] INFO util.log: Logging initialized @17909ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2020-06-03 22:46:43,755 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2020-06-03 22:46:43,763 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2020-06-03 22:46:43,771 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2020-06-03 22:46:43,778 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_3  | 2020-06-03 22:46:43,778 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_3  | 2020-06-03 22:46:43,778 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_3  | 2020-06-03 22:46:44,012 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2020-06-03 22:46:44,013 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3  | 2020-06-03 22:46:44,135 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2020-06-03 22:46:44,135 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 2020-06-03 22:46:44,136 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_3  | 2020-06-03 22:46:44,200 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-06-03 22:46:29,702 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = 19c2583a5805/172.22.0.6
om_1        | STARTUP_MSG:   args = [--init]
om_1        | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3  | 2020-06-03 22:46:44,224 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@56a4f272{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2020-06-03 22:46:44,228 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3c3a0032{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2020-06-03 22:46:44,647 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@40e32762{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-6447231135575501942.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2020-06-03 22:46:44,715 [main] INFO server.AbstractConnector: Started ServerConnector@6caf7803{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3  | 2020-06-03 22:46:44,715 [main] INFO server.Server: Started @19592ms
datanode_3  | 2020-06-03 22:46:44,746 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2020-06-03 22:46:44,746 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2020-06-03 22:46:44,765 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3  | 2020-06-03 22:46:44,848 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3f645d60] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2020-06-03 22:46:45,312 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.22.0.3:9891
datanode_3  | 2020-06-03 22:46:45,511 [Datanode State Machine Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3  | 2020-06-03 22:46:47,988 [Datanode State Machine Thread - 1] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-06-03 22:46:49,016 [Datanode State Machine Thread - 1] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_3  | java.net.SocketTimeoutException: Call From 8028961d7b92/172.22.0.5 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.22.0.5:39010 remote=scm/172.22.0.8:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_3  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_3  | 	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.22.0.5:39010 remote=scm/172.22.0.8:9861]
datanode_3  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_3  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_3  | 2020-06-03 22:46:50,154 [Datanode State Machine Thread - 3] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3  | 2020-06-03 22:46:50,156 [Datanode State Machine Thread - 3] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3  | 2020-06-03 22:46:50,167 [Datanode State Machine Thread - 3] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 33aee425-864c-4906-8eb4-b838cd19e298 at port 9858
datanode_3  | 2020-06-03 22:46:50,365 [Datanode State Machine Thread - 3] INFO impl.RaftServerProxy: 33aee425-864c-4906-8eb4-b838cd19e298: start RPC server
datanode_3  | 2020-06-03 22:46:50,613 [Datanode State Machine Thread - 3] INFO server.GrpcService: 33aee425-864c-4906-8eb4-b838cd19e298: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3  | 2020-06-03 22:46:53,925 [Command processor thread] INFO impl.RaftServerProxy: 33aee425-864c-4906-8eb4-b838cd19e298: addNew group-4C8CD1A355B4:[33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858] returns group-4C8CD1A355B4:java.util.concurrent.CompletableFuture@246ee6c2[Not completed]
datanode_3  | 2020-06-03 22:46:53,988 [pool-19-thread-1] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298: new RaftServerImpl for group-4C8CD1A355B4:[33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-06-03 22:46:53,989 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-06-03 22:46:54,021 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-06-03 22:46:54,024 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-06-03 22:46:54,025 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-06-03 22:46:54,025 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/aec7a9345e8cecdacc1367562fdd82dd4dfc34df ; compiled by 'jenkins1001' on 2020-06-03T22:21Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-06-03 22:46:29,729 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-06-03 22:46:35,312 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-06-03 22:46:35,702 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.22.0.6:9862
om_1        | 2020-06-03 22:46:35,709 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-06-03 22:46:35,753 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-06-03 22:46:38,150 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-03 22:46:39,150 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-03 22:46:40,151 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-03 22:46:41,152 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-03 22:46:42,153 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-03 22:46:43,154 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-03 22:46:44,155 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-03 22:46:45,156 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-03 22:46:46,157 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-03 22:46:47,158 [main] INFO ipc.Client: Retrying connect to server: scm/172.22.0.8:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-03 22:46:47,160 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-61a6734d-2449-43d2-bcd0-c0caf5935f82
om_1        | 2020-06-03 22:46:52,228 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1        | /************************************************************
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at 19c2583a5805/172.22.0.6
om_1        | ************************************************************/
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-06-03 22:46:53,354 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = 19c2583a5805/172.22.0.6
om_1        | STARTUP_MSG:   args = []
om_1        | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_1  | 2020-06-03 22:46:55,599 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/15639143-720d-4e1a-8cd4-c5072c5a9ed0
datanode_1  | 2020-06-03 22:46:55,606 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-06-03 22:46:55,607 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-06-03 22:46:55,609 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-06-03 22:46:55,613 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-06-03 22:46:55,614 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-06-03 22:46:55,618 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-06-03 22:46:55,624 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-06-03 22:46:55,627 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-06-03 22:46:55,627 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-06-03 22:46:55,696 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-06-03 22:46:55,720 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-06-03 22:46:55,744 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-06-03 22:46:55,749 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-06-03 22:46:55,750 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-06-03 22:46:55,753 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-06-03 22:46:55,760 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-06-03 22:46:55,888 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0
datanode_1  | 2020-06-03 22:46:55,907 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0
datanode_1  | 2020-06-03 22:46:55,920 [pool-19-thread-1] INFO impl.RaftServerImpl: 622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0: start as a follower, conf=-1: [622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858], old=null
datanode_1  | 2020-06-03 22:46:55,924 [pool-19-thread-1] INFO impl.RaftServerImpl: 622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-06-03 22:46:55,932 [pool-19-thread-1] INFO impl.RoleInfo: 622eccab-f286-4bed-94f9-9d148dcbff73: start FollowerState
datanode_1  | 2020-06-03 22:46:55,966 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5072C5A9ED0,id=622eccab-f286-4bed-94f9-9d148dcbff73
datanode_1  | 2020-06-03 22:46:55,972 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0
datanode_1  | 2020-06-03 22:46:56,156 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "15639143-720d-4e1a-8cd4-c5072c5a9ed0"
datanode_1  | .
datanode_1  | 2020-06-03 22:46:56,177 [Command processor thread] INFO impl.RaftServerProxy: 622eccab-f286-4bed-94f9-9d148dcbff73: addNew group-33A3FA0446CA:[f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858] returns group-33A3FA0446CA:java.util.concurrent.CompletableFuture@44dc1fae[Not completed]
datanode_1  | 2020-06-03 22:46:56,229 [pool-19-thread-1] INFO impl.RaftServerImpl: 622eccab-f286-4bed-94f9-9d148dcbff73: new RaftServerImpl for group-33A3FA0446CA:[f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-06-03 22:46:56,230 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-06-03 22:46:56,235 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-06-03 22:46:56,235 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-06-03 22:46:56,235 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-06-03 22:46:56,235 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-06-03 22:46:56,235 [pool-19-thread-1] INFO impl.RaftServerImpl: 622eccab-f286-4bed-94f9-9d148dcbff73@group-33A3FA0446CA: ConfigurationManager, init=-1: [f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-06-03 22:46:56,239 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-06-03 22:46:56,240 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-06-03 22:46:56,240 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2a11b1d1-500f-4f30-95f4-33a3fa0446ca does not exist. Creating ...
datanode_1  | 2020-06-03 22:46:56,246 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2a11b1d1-500f-4f30-95f4-33a3fa0446ca/in_use.lock acquired by nodename 7@1f16ccd291f1
datanode_1  | 2020-06-03 22:46:56,259 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2a11b1d1-500f-4f30-95f4-33a3fa0446ca has been successfully formatted.
datanode_1  | 2020-06-03 22:46:56,260 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-33A3FA0446CA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-06-03 22:46:56,262 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-06-03 22:46:56,263 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-06-03 22:46:56,283 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-06-03 22:46:56,283 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-06-03 22:46:56,284 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-06-03 22:46:56,301 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-06-03 22:46:56,302 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 622eccab-f286-4bed-94f9-9d148dcbff73@group-33A3FA0446CA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2a11b1d1-500f-4f30-95f4-33a3fa0446ca
datanode_3  | 2020-06-03 22:46:54,068 [pool-19-thread-1] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4: ConfigurationManager, init=-1: [33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-06-03 22:46:54,073 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-06-03 22:46:54,085 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-06-03 22:46:54,100 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/491e149a-7258-4931-85b3-4c8cd1a355b4 does not exist. Creating ...
datanode_3  | 2020-06-03 22:46:54,119 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/491e149a-7258-4931-85b3-4c8cd1a355b4/in_use.lock acquired by nodename 6@8028961d7b92
datanode_3  | 2020-06-03 22:46:54,124 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/491e149a-7258-4931-85b3-4c8cd1a355b4 has been successfully formatted.
datanode_3  | 2020-06-03 22:46:54,131 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-4C8CD1A355B4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-06-03 22:46:54,138 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-06-03 22:46:54,145 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-06-03 22:46:54,152 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-06-03 22:46:54,161 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-06-03 22:46:54,165 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-06-03 22:46:54,173 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.33aee425-864c-4906-8eb4-b838cd19e298
datanode_3  | 2020-06-03 22:46:54,227 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-06-03 22:46:54,239 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/491e149a-7258-4931-85b3-4c8cd1a355b4
datanode_3  | 2020-06-03 22:46:54,242 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-06-03 22:46:54,246 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-06-03 22:46:54,247 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-06-03 22:46:54,257 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-06-03 22:46:54,261 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-06-03 22:46:54,261 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-06-03 22:46:54,266 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-06-03 22:46:54,266 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-06-03 22:46:54,267 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-06-03 22:46:54,356 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-06-03 22:46:54,367 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-06-03 22:46:54,414 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-06-03 22:46:54,433 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-06-03 22:46:54,439 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-06-03 22:46:54,440 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-06-03 22:46:54,446 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-06-03 22:46:54,509 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4
datanode_3  | 2020-06-03 22:46:54,520 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4
datanode_3  | 2020-06-03 22:46:54,534 [pool-19-thread-1] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4: start as a follower, conf=-1: [33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858], old=null
datanode_3  | 2020-06-03 22:46:54,539 [pool-19-thread-1] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-06-03 22:46:54,540 [pool-19-thread-1] INFO impl.RoleInfo: 33aee425-864c-4906-8eb4-b838cd19e298: start FollowerState
datanode_3  | 2020-06-03 22:46:54,554 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4C8CD1A355B4,id=33aee425-864c-4906-8eb4-b838cd19e298
datanode_3  | 2020-06-03 22:46:54,557 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4
datanode_3  | 2020-06-03 22:46:54,586 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "491e149a-7258-4931-85b3-4c8cd1a355b4"
datanode_3  | .
datanode_3  | 2020-06-03 22:46:54,587 [Command processor thread] INFO impl.RaftServerProxy: 33aee425-864c-4906-8eb4-b838cd19e298: addNew group-33A3FA0446CA:[f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858] returns group-33A3FA0446CA:java.util.concurrent.CompletableFuture@49e22962[Not completed]
datanode_3  | 2020-06-03 22:46:54,619 [pool-19-thread-1] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298: new RaftServerImpl for group-33A3FA0446CA:[f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-06-03 22:46:54,620 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-06-03 22:46:54,620 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-06-03 22:46:54,620 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-06-03 22:46:54,621 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-06-03 22:46:54,621 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-06-03 22:46:54,621 [pool-19-thread-1] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA: ConfigurationManager, init=-1: [f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-06-03 22:46:54,621 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-06-03 22:46:54,621 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-06-03 22:46:54,621 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/2a11b1d1-500f-4f30-95f4-33a3fa0446ca does not exist. Creating ...
datanode_3  | 2020-06-03 22:46:54,630 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/2a11b1d1-500f-4f30-95f4-33a3fa0446ca/in_use.lock acquired by nodename 6@8028961d7b92
datanode_3  | 2020-06-03 22:46:54,636 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/2a11b1d1-500f-4f30-95f4-33a3fa0446ca has been successfully formatted.
datanode_3  | 2020-06-03 22:46:54,637 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-33A3FA0446CA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-06-03 22:46:54,637 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-06-03 22:46:54,637 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-06-03 22:46:54,637 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-06-03 22:46:54,637 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-06-03 22:46:54,637 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-06-03 22:46:54,637 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-06-03 22:46:54,637 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/2a11b1d1-500f-4f30-95f4-33a3fa0446ca
datanode_3  | 2020-06-03 22:46:54,637 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-06-03 22:46:54,637 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-06-03 22:46:54,641 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-06-03 22:46:54,641 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-06-03 22:46:54,641 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-06-03 22:46:54,642 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-06-03 22:46:54,642 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-06-03 22:46:54,642 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-06-03 22:46:54,642 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-06-03 22:46:54,652 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-06-03 22:46:54,652 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-06-03 22:46:54,653 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-06-03 22:46:54,653 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-06-03 22:46:54,653 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-06-03 22:46:54,654 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-06-03 22:46:54,654 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-06-03 22:46:54,655 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA
datanode_3  | 2020-06-03 22:46:54,655 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA
datanode_3  | 2020-06-03 22:46:54,656 [pool-19-thread-1] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA: start as a follower, conf=-1: [f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858], old=null
datanode_3  | 2020-06-03 22:46:54,656 [pool-19-thread-1] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-06-03 22:46:54,656 [pool-19-thread-1] INFO impl.RoleInfo: 33aee425-864c-4906-8eb4-b838cd19e298: start FollowerState
datanode_1  | 2020-06-03 22:46:56,302 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-06-03 22:46:56,302 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-06-03 22:46:56,302 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-06-03 22:46:56,302 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-06-03 22:46:56,302 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-06-03 22:46:56,302 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-06-03 22:46:56,303 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-06-03 22:46:56,303 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-06-03 22:46:56,305 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-06-03 22:46:56,305 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-06-03 22:46:56,315 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 622eccab-f286-4bed-94f9-9d148dcbff73@group-33A3FA0446CA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-06-03 22:46:56,343 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-06-03 22:46:56,343 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-06-03 22:46:56,343 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-06-03 22:46:56,343 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-06-03 22:46:56,343 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-06-03 22:46:56,344 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.622eccab-f286-4bed-94f9-9d148dcbff73@group-33A3FA0446CA
datanode_1  | 2020-06-03 22:46:56,344 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.622eccab-f286-4bed-94f9-9d148dcbff73@group-33A3FA0446CA
datanode_1  | 2020-06-03 22:46:56,345 [pool-19-thread-1] INFO impl.RaftServerImpl: 622eccab-f286-4bed-94f9-9d148dcbff73@group-33A3FA0446CA: start as a follower, conf=-1: [f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858], old=null
datanode_1  | 2020-06-03 22:46:56,345 [pool-19-thread-1] INFO impl.RaftServerImpl: 622eccab-f286-4bed-94f9-9d148dcbff73@group-33A3FA0446CA: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-06-03 22:46:56,356 [pool-19-thread-1] INFO impl.RoleInfo: 622eccab-f286-4bed-94f9-9d148dcbff73: start FollowerState
datanode_1  | 2020-06-03 22:46:56,356 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-33A3FA0446CA,id=622eccab-f286-4bed-94f9-9d148dcbff73
datanode_1  | 2020-06-03 22:46:56,356 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.622eccab-f286-4bed-94f9-9d148dcbff73@group-33A3FA0446CA
datanode_1  | 2020-06-03 22:46:57,701 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "2a11b1d1-500f-4f30-95f4-33a3fa0446ca"
datanode_1  | .
datanode_1  | 2020-06-03 22:46:59,917 [grpc-default-executor-0] INFO impl.RaftServerImpl: 622eccab-f286-4bed-94f9-9d148dcbff73@group-33A3FA0446CA: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:33aee425-864c-4906-8eb4-b838cd19e298
datanode_1  | 2020-06-03 22:46:59,918 [grpc-default-executor-0] INFO impl.RoleInfo: 622eccab-f286-4bed-94f9-9d148dcbff73: shutdown FollowerState
datanode_1  | 2020-06-03 22:46:59,919 [grpc-default-executor-0] INFO impl.RoleInfo: 622eccab-f286-4bed-94f9-9d148dcbff73: start FollowerState
datanode_1  | 2020-06-03 22:46:59,919 [Thread-24] INFO impl.FollowerState: 622eccab-f286-4bed-94f9-9d148dcbff73@group-33A3FA0446CA-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1  | 2020-06-03 22:47:00,240 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-33A3FA0446CA with new leaderId: 33aee425-864c-4906-8eb4-b838cd19e298
datanode_1  | 2020-06-03 22:47:00,243 [grpc-default-executor-0] INFO impl.RaftServerImpl: 622eccab-f286-4bed-94f9-9d148dcbff73@group-33A3FA0446CA: change Leader from null to 33aee425-864c-4906-8eb4-b838cd19e298 at term 1 for appendEntries, leader elected after 3980ms
datanode_1  | 2020-06-03 22:47:00,335 [grpc-default-executor-0] INFO impl.RaftServerImpl: 622eccab-f286-4bed-94f9-9d148dcbff73@group-33A3FA0446CA: set configuration 0: [f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858], old=null at 0
datanode_1  | 2020-06-03 22:47:00,361 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 622eccab-f286-4bed-94f9-9d148dcbff73@group-33A3FA0446CA-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-06-03 22:47:00,558 [622eccab-f286-4bed-94f9-9d148dcbff73@group-33A3FA0446CA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 622eccab-f286-4bed-94f9-9d148dcbff73@group-33A3FA0446CA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2a11b1d1-500f-4f30-95f4-33a3fa0446ca/current/log_inprogress_0
datanode_1  | 2020-06-03 22:47:01,080 [Thread-22] INFO impl.FollowerState: 622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-FollowerState: change to CANDIDATE, lastRpcTime:5148ms, electionTimeout:5115ms
datanode_1  | 2020-06-03 22:47:01,081 [Thread-22] INFO impl.RoleInfo: 622eccab-f286-4bed-94f9-9d148dcbff73: shutdown FollowerState
datanode_1  | 2020-06-03 22:47:01,081 [Thread-22] INFO impl.RaftServerImpl: 622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2020-06-03 22:47:01,083 [Thread-22] INFO impl.RoleInfo: 622eccab-f286-4bed-94f9-9d148dcbff73: start LeaderElection
datanode_1  | 2020-06-03 22:47:01,090 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO impl.LeaderElection: 622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1: begin an election at term 1 for -1: [622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858], old=null
datanode_1  | 2020-06-03 22:47:01,092 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO impl.RoleInfo: 622eccab-f286-4bed-94f9-9d148dcbff73: shutdown LeaderElection
datanode_1  | 2020-06-03 22:47:01,092 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO impl.RaftServerImpl: 622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2020-06-03 22:47:01,092 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C5072C5A9ED0 with new leaderId: 622eccab-f286-4bed-94f9-9d148dcbff73
datanode_1  | 2020-06-03 22:47:01,093 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO impl.RaftServerImpl: 622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0: change Leader from null to 622eccab-f286-4bed-94f9-9d148dcbff73 at term 1 for becomeLeader, leader elected after 5677ms
datanode_1  | 2020-06-03 22:47:01,095 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2020-06-03 22:47:01,096 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2020-06-03 22:47:01,098 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0
datanode_1  | 2020-06-03 22:47:01,117 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2020-06-03 22:47:01,119 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1  | 2020-06-03 22:47:01,129 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2020-06-03 22:47:01,130 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2020-06-03 22:47:01,131 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2020-06-03 22:47:01,137 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO impl.RoleInfo: 622eccab-f286-4bed-94f9-9d148dcbff73: start LeaderState
datanode_1  | 2020-06-03 22:47:01,141 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-06-03 22:47:01,142 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-LeaderElection1] INFO impl.RaftServerImpl: 622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0: set configuration 0: [622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858], old=null at 0
datanode_1  | 2020-06-03 22:47:01,143 [622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 622eccab-f286-4bed-94f9-9d148dcbff73@group-C5072C5A9ED0-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/15639143-720d-4e1a-8cd4-c5072c5a9ed0/current/log_inprogress_0
datanode_1  | 2020-06-03 22:47:46,185 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: recon/172.22.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=60000 MILLISECONDS)
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/aec7a9345e8cecdacc1367562fdd82dd4dfc34df ; compiled by 'jenkins1001' on 2020-06-03T22:21Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-06-03 22:46:53,373 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-06-03 22:46:55,721 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-06-03 22:46:55,851 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.22.0.6:9862
om_1        | 2020-06-03 22:46:55,855 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-06-03 22:46:55,876 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-06-03 22:46:55,917 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-06-03 22:46:58,173 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-06-03 22:46:58,639 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2020-06-03 22:46:58,665 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1        | 2020-06-03 22:46:58,980 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | 2020-06-03 22:46:59,135 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2020-06-03 22:46:59,135 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1        | 2020-06-03 22:46:59,236 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.22.0.6:9862
om_1        | 2020-06-03 22:46:59,264 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1        | 2020-06-03 22:46:59,385 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1        | 2020-06-03 22:46:59,660 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1        | 2020-06-03 22:46:59,660 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1        | 2020-06-03 22:46:59,710 [Listener at om/9862] INFO util.log: Logging initialized @7350ms to org.eclipse.jetty.util.log.Slf4jLog
om_1        | 2020-06-03 22:47:00,156 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1        | 2020-06-03 22:47:00,175 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1        | 2020-06-03 22:47:00,186 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1        | 2020-06-03 22:47:00,190 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om_1        | 2020-06-03 22:47:00,191 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om_1        | 2020-06-03 22:47:00,191 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om_1        | 2020-06-03 22:47:00,354 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1        | 2020-06-03 22:47:00,360 [Listener at om/9862] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1        | 2020-06-03 22:47:00,520 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 2020-06-03 22:47:00,521 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1        | 2020-06-03 22:47:00,524 [Listener at om/9862] INFO server.session: node0 Scavenging every 600000ms
om_1        | 2020-06-03 22:47:00,547 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1        | 2020-06-03 22:47:00,567 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@32130e61{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 2020-06-03 22:47:00,571 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@75d4a80f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | 2020-06-03 22:47:00,798 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@65d8dff8{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-16979108856411114420.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1        | 2020-06-03 22:47:00,805 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@7a81065e{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1        | 2020-06-03 22:47:00,805 [Listener at om/9862] INFO server.Server: Started @8446ms
om_1        | 2020-06-03 22:47:00,808 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2020-06-03 22:47:00,808 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 2020-06-03 22:47:00,812 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1        | 2020-06-03 22:47:00,826 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7a3e5cd3] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1        | 2020-06-03 22:47:09,049 [IPC Server handler 0 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-05208 for user:hadoop
om_1        | 2020-06-03 22:47:09,067 [IPC Server handler 2 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-51806 for user:hadoop
om_1        | 2020-06-03 22:47:09,077 [IPC Server handler 5 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-06643 for user:hadoop
om_1        | 2020-06-03 22:47:09,086 [IPC Server handler 8 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-02546 for user:hadoop
om_1        | 2020-06-03 22:47:09,099 [IPC Server handler 9 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-99264 for user:hadoop
om_1        | 2020-06-03 22:47:50,896 [qtp248146548-132] INFO om.OMDBCheckpointServlet: Received request to obtain OM DB checkpoint snapshot
om_1        | 2020-06-03 22:47:50,917 [qtp248146548-132] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1591224470897 in 19 milliseconds
om_1        | 2020-06-03 22:47:50,943 [qtp248146548-132] INFO om.OMDBCheckpointServlet: Time taken to write the checkpoint to response output stream: 24 milliseconds
om_1        | 2020-06-03 22:47:50,943 [qtp248146548-132] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1591224470897
om_1        | 2020-06-03 22:48:22,236 [IPC Server handler 44 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:48353-rpcwoport for user:hadoop
om_1        | 2020-06-03 22:49:25,769 [IPC Server handler 23 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:48353-rpcwoport2 for user:hadoop
om_1        | 2020-06-03 22:49:45,253 [IPC Server handler 49 on default port 9862] ERROR acl.OMBucketAddAclRequest: Add acl [user:superuser1:rwxy[ACCESS]] to path /48353-rpcwoport2/bb1 failed, because acl already exist
om_1        | 2020-06-03 22:50:16,087 [IPC Server handler 43 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:48353-rpcwport for user:hadoop
om_1        | 2020-06-03 22:51:19,211 [IPC Server handler 48 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:48353-rpcwoscheme for user:hadoop
om_1        | 2020-06-03 22:52:25,739 [IPC Server handler 23 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:rudzs for user:hadoop
om_1        | 2020-06-03 22:53:19,249 [IPC Server handler 61 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:fstest for user:hadoop
om_1        | 2020-06-03 22:53:21,083 [IPC Server handler 45 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:fstest2 for user:hadoop
om_1        | 2020-06-03 22:56:09,129 [IPC Server handler 50 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:s3v for user:hadoop
om_1        | 2020-06-03 22:56:12,902 [IPC Server handler 40 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
datanode_3  | 2020-06-03 22:46:54,669 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-33A3FA0446CA,id=33aee425-864c-4906-8eb4-b838cd19e298
datanode_3  | 2020-06-03 22:46:54,669 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA
datanode_3  | 2020-06-03 22:46:57,274 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "2a11b1d1-500f-4f30-95f4-33a3fa0446ca"
datanode_3  | .
datanode_3  | 2020-06-03 22:46:59,703 [Thread-22] INFO impl.FollowerState: 33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-FollowerState: change to CANDIDATE, lastRpcTime:5163ms, electionTimeout:5159ms
datanode_3  | 2020-06-03 22:46:59,705 [Thread-22] INFO impl.RoleInfo: 33aee425-864c-4906-8eb4-b838cd19e298: shutdown FollowerState
datanode_3  | 2020-06-03 22:46:59,705 [Thread-22] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2020-06-03 22:46:59,707 [Thread-22] INFO impl.RoleInfo: 33aee425-864c-4906-8eb4-b838cd19e298: start LeaderElection
datanode_3  | 2020-06-03 22:46:59,722 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO impl.LeaderElection: 33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1: begin an election at term 1 for -1: [33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858], old=null
datanode_3  | 2020-06-03 22:46:59,723 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO impl.RoleInfo: 33aee425-864c-4906-8eb4-b838cd19e298: shutdown LeaderElection
datanode_3  | 2020-06-03 22:46:59,725 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-06-03 22:46:59,725 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4C8CD1A355B4 with new leaderId: 33aee425-864c-4906-8eb4-b838cd19e298
datanode_3  | 2020-06-03 22:46:59,726 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4: change Leader from null to 33aee425-864c-4906-8eb4-b838cd19e298 at term 1 for becomeLeader, leader elected after 5587ms
datanode_3  | 2020-06-03 22:46:59,729 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-06-03 22:46:59,743 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-06-03 22:46:59,749 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4
datanode_3  | 2020-06-03 22:46:59,752 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-06-03 22:46:59,755 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-06-03 22:46:59,763 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-06-03 22:46:59,770 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-06-03 22:46:59,771 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-06-03 22:46:59,771 [Thread-24] INFO impl.FollowerState: 33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-FollowerState: change to CANDIDATE, lastRpcTime:5114ms, electionTimeout:5101ms
datanode_3  | 2020-06-03 22:46:59,778 [Thread-24] INFO impl.RoleInfo: 33aee425-864c-4906-8eb4-b838cd19e298: shutdown FollowerState
datanode_3  | 2020-06-03 22:46:59,778 [Thread-24] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2020-06-03 22:46:59,778 [Thread-24] INFO impl.RoleInfo: 33aee425-864c-4906-8eb4-b838cd19e298: start LeaderElection
datanode_3  | 2020-06-03 22:46:59,823 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO impl.RoleInfo: 33aee425-864c-4906-8eb4-b838cd19e298: start LeaderState
datanode_3  | 2020-06-03 22:46:59,824 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO impl.LeaderElection: 33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2: begin an election at term 1 for -1: [f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858], old=null
datanode_3  | 2020-06-03 22:46:59,934 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-06-03 22:47:00,004 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO impl.LeaderElection: 33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2: Election PASSED; received 1 response(s) [33aee425-864c-4906-8eb4-b838cd19e298<-622eccab-f286-4bed-94f9-9d148dcbff73#0:OK-t1] and 0 exception(s); 33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA:t1, leader=null, voted=33aee425-864c-4906-8eb4-b838cd19e298, raftlog=33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858], old=null
datanode_3  | 2020-06-03 22:47:00,006 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO impl.RoleInfo: 33aee425-864c-4906-8eb4-b838cd19e298: shutdown LeaderElection
datanode_3  | 2020-06-03 22:47:00,007 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-06-03 22:47:00,007 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-33A3FA0446CA with new leaderId: 33aee425-864c-4906-8eb4-b838cd19e298
datanode_3  | 2020-06-03 22:47:00,007 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA: change Leader from null to 33aee425-864c-4906-8eb4-b838cd19e298 at term 1 for becomeLeader, leader elected after 5370ms
datanode_3  | 2020-06-03 22:47:00,008 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-06-03 22:47:00,008 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-06-03 22:47:00,009 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA
datanode_3  | 2020-06-03 22:47:00,009 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-06-03 22:47:00,009 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-06-03 22:47:00,010 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-06-03 22:47:00,013 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-06-03 22:47:00,014 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-06-03 22:47:00,056 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-LeaderElection1] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4: set configuration 0: [33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858], old=null at 0
datanode_3  | 2020-06-03 22:47:00,059 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2020-06-03 22:47:00,080 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-06-03 22:47:00,081 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 2020-06-03 22:47:00,085 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2020-06-03 22:47:00,087 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-06-03 22:47:00,087 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-06-03 22:47:00,094 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2020-06-03 22:47:00,101 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-06-03 22:47:00,101 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 2020-06-03 22:47:00,102 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2020-06-03 22:47:00,102 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-06-03 22:47:00,103 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-06-03 22:47:00,107 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO impl.RoleInfo: 33aee425-864c-4906-8eb4-b838cd19e298: start LeaderState
datanode_3  | 2020-06-03 22:47:00,109 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-06-03 22:47:00,119 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-LeaderElection2] INFO impl.RaftServerImpl: 33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA: set configuration 0: [f3811c11-6df2-4867-ae20-220ae7889355:172.22.0.4:9858, 622eccab-f286-4bed-94f9-9d148dcbff73:172.22.0.7:9858, 33aee425-864c-4906-8eb4-b838cd19e298:172.22.0.5:9858], old=null at 0
datanode_3  | 2020-06-03 22:47:00,372 [33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 33aee425-864c-4906-8eb4-b838cd19e298@group-33A3FA0446CA-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/2a11b1d1-500f-4f30-95f4-33a3fa0446ca/current/log_inprogress_0
datanode_3  | 2020-06-03 22:47:00,383 [33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 33aee425-864c-4906-8eb4-b838cd19e298@group-4C8CD1A355B4-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/491e149a-7258-4931-85b3-4c8cd1a355b4/current/log_inprogress_0
datanode_3  | 2020-06-03 22:47:46,992 [Datanode State Machine Thread - 0] INFO ipc.Client: Retrying connect to server: recon/172.22.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=60000 MILLISECONDS)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:56:22,218 [IPC Server handler 66 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
recon_1     | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
recon_1     | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1     | 2020-06-03 22:46:28,954 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1     | /************************************************************
recon_1     | STARTUP_MSG: Starting ReconServer
recon_1     | STARTUP_MSG:   host = 63273ed2de79/172.22.0.3
recon_1     | STARTUP_MSG:   args = []
recon_1     | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-06-03 22:46:32,604 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = f3a9057ab8af/172.22.0.8
scm_1       | STARTUP_MSG:   args = [--init]
scm_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/aec7a9345e8cecdacc1367562fdd82dd4dfc34df ; compiled by 'jenkins1001' on 2020-06-03T22:20Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-06-03 22:46:32,648 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-06-03 22:46:33,331 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-06-03 22:46:33,703 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-61a6734d-2449-43d2-bcd0-c0caf5935f82
scm_1       | 2020-06-03 22:46:33,997 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at f3a9057ab8af/172.22.0.8
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-06-03 22:46:44,964 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = f3a9057ab8af/172.22.0.8
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/aec7a9345e8cecdacc1367562fdd82dd4dfc34df ; compiled by 'jenkins1001' on 2020-06-03T22:20Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-06-03 22:46:45,013 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-06-03 22:46:45,358 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-06-03 22:46:45,706 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-06-03 22:46:45,947 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@4b520ea8
scm_1       | 2020-06-03 22:46:45,948 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1       | 2020-06-03 22:46:46,135 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1       | 2020-06-03 22:46:46,485 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       | 2020-06-03 22:46:46,533 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1       | 2020-06-03 22:46:46,613 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2020-06-03 22:46:46,620 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1       | 2020-06-03 22:46:46,673 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1       | 2020-06-03 22:46:47,770 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-06-03 22:46:47,816 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2020-06-03 22:46:47,871 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-06-03 22:46:47,872 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1       | 2020-06-03 22:46:47,891 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-06-03 22:46:47,900 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1       | 2020-06-03 22:46:47,955 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:56:24,036 [IPC Server handler 61 on default port 9862] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-62833 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:186)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:56:28,665 [IPC Server handler 17 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:56:30,478 [IPC Server handler 82 on default port 9862] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket doesn't exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:121)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-reconcodegen-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.27.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar
recon_1     | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/aec7a9345e8cecdacc1367562fdd82dd4dfc34df ; compiled by 'jenkins1001' on 2020-06-03T22:21Z
recon_1     | STARTUP_MSG:   java = 11.0.6
recon_1     | ************************************************************/
recon_1     | 2020-06-03 22:46:29,017 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1     | WARNING: An illegal reflective access operation has occurred
recon_1     | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
recon_1     | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | WARNING: All illegal access operations will be denied in a future release
recon_1     | 2020-06-03 22:46:33,096 [main] INFO recon.ReconRestServletModule: rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1     | 2020-06-03 22:46:34,973 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1     | 2020-06-03 22:46:36,465 [main] INFO persistence.DerbyDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1     | 2020-06-03 22:46:41,689 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | 2020-06-03 22:46:43,333 [main] INFO persistence.DerbyDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1     | 2020-06-03 22:46:43,496 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | 2020-06-03 22:46:43,536 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1     | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
recon_1     | 2020-06-03 22:46:45,741 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1     | 2020-06-03 22:46:45,763 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
recon_1     | 2020-06-03 22:46:45,782 [main] INFO util.log: Logging initialized @20622ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1     | 2020-06-03 22:46:45,942 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1     | 2020-06-03 22:46:45,951 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1     | 2020-06-03 22:46:45,965 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1     | 2020-06-03 22:46:45,972 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1     | 2020-06-03 22:46:45,972 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1     | 2020-06-03 22:46:45,972 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1     | 2020-06-03 22:46:46,233 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1     | 2020-06-03 22:46:46,668 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1     | 2020-06-03 22:46:46,914 [main] INFO Configuration.deprecation: No unit for recon.om.connection.request.timeout(5000) assuming MILLISECONDS
recon_1     | 2020-06-03 22:46:47,306 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-06-03 22:46:47,529 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-06-03 22:46:47,552 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@26275b46
recon_1     | 2020-06-03 22:46:47,553 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1     | 2020-06-03 22:46:47,692 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-06-03 22:46:47,772 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1     | 2020-06-03 22:46:47,783 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-06-03 22:46:47,818 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
s3g_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
s3g_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1       | 2020-06-03 22:46:24,039 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1       | 2020-06-03 22:46:24,040 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
s3g_1       | 2020-06-03 22:46:24,232 [main] INFO util.log: Logging initialized @3389ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1       | 2020-06-03 22:46:25,448 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 2020-06-03 22:46:25,648 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1       | 2020-06-03 22:46:25,682 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1       | 2020-06-03 22:46:25,684 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1       | 2020-06-03 22:46:25,690 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1       | 2020-06-03 22:46:25,690 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1       | 2020-06-03 22:46:25,899 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1       | /************************************************************
s3g_1       | STARTUP_MSG: Starting Gateway
s3g_1       | STARTUP_MSG:   host = 3aa9e6fb53c5/172.22.0.2
s3g_1       | STARTUP_MSG:   args = []
s3g_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
scm_1       | 2020-06-03 22:46:47,956 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1       | 2020-06-03 22:46:47,982 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @11858ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       | 2020-06-03 22:46:48,135 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2020-06-03 22:46:48,153 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1       | 2020-06-03 22:46:48,159 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       | 2020-06-03 22:46:48,167 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm_1       | 2020-06-03 22:46:48,168 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm_1       | 2020-06-03 22:46:48,174 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm_1       | 2020-06-03 22:46:48,240 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1       | 2020-06-03 22:46:48,518 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | 2020-06-03 22:46:48,690 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1       | 2020-06-03 22:46:48,691 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1       | 2020-06-03 22:46:49,369 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1       | 2020-06-03 22:46:49,369 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-06-03 22:46:49,422 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1       | 2020-06-03 22:46:49,423 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1       | 2020-06-03 22:46:49,424 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1       | 2020-06-03 22:46:49,424 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-06-03 22:46:49,424 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1       | 2020-06-03 22:46:49,565 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1       | 2020-06-03 22:46:49,567 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1       | 2020-06-03 22:46:49,571 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-06-03 22:46:49,572 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1       | 2020-06-03 22:46:49,676 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1       | 2020-06-03 22:46:49,687 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1       | 2020-06-03 22:46:49,719 [IPC Server handler 6 on default port 9861] INFO ipc.Server: IPC Server handler 6 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.22.0.5:39010
scm_1       | 2020-06-03 22:46:49,719 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.22.0.4:53822
scm_1       | 2020-06-03 22:46:49,719 [IPC Server handler 4 on default port 9861] INFO ipc.Server: IPC Server handler 4 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.22.0.7:53272
scm_1       | 2020-06-03 22:46:49,824 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1       | 2020-06-03 22:46:49,824 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2020-06-03 22:46:49,833 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1       | 2020-06-03 22:46:49,903 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2020-06-03 22:46:49,922 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@141e879d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1       | 2020-06-03 22:46:49,923 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@42e22a53{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | 2020-06-03 22:46:50,976 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=491e149a-7258-4931-85b3-4c8cd1a355b4 to datanode:33aee425-864c-4906-8eb4-b838cd19e298
scm_1       | 2020-06-03 22:46:51,008 [IPC Server handler 3 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/33aee425-864c-4906-8eb4-b838cd19e298
scm_1       | 2020-06-03 22:46:51,011 [IPC Server handler 3 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 33aee425-864c-4906-8eb4-b838cd19e298{ip: 172.22.0.5, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-06-03 22:46:51,063 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1       | 2020-06-03 22:46:51,072 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 491e149a-7258-4931-85b3-4c8cd1a355b4, Nodes: 33aee425-864c-4906-8eb4-b838cd19e298{ip: 172.22.0.5, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-03T22:46:50.974788Z]
scm_1       | 2020-06-03 22:46:51,094 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 1 nodes. Healthy nodes 1
scm_1       | 2020-06-03 22:46:51,067 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-06-03 22:46:51,135 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@59f93db8{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-12528824895448511483.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
scm_1       | 2020-06-03 22:46:51,159 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@159a48a6{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1       | 2020-06-03 22:46:51,159 [Listener at 0.0.0.0/9860] INFO server.Server: Started @15036ms
scm_1       | 2020-06-03 22:46:51,163 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | 2020-06-03 22:46:51,163 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1       | 2020-06-03 22:46:51,173 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1       | 2020-06-03 22:46:51,185 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4047d2d9] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2020-06-03 22:46:51,300 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e735236f-a353-4a1c-b29d-e4c1326e3a66 to datanode:f3811c11-6df2-4867-ae20-220ae7889355
scm_1       | 2020-06-03 22:46:51,301 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e735236f-a353-4a1c-b29d-e4c1326e3a66, Nodes: f3811c11-6df2-4867-ae20-220ae7889355{ip: 172.22.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-03T22:46:51.300302Z]
scm_1       | 2020-06-03 22:46:51,301 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
scm_1       | 2020-06-03 22:46:51,293 [IPC Server handler 46 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/f3811c11-6df2-4867-ae20-220ae7889355
scm_1       | 2020-06-03 22:46:51,302 [IPC Server handler 46 on default port 9861] INFO node.SCMNodeManager: Registered Data node : f3811c11-6df2-4867-ae20-220ae7889355{ip: 172.22.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-06-03 22:46:51,304 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-06-03 22:46:51,304 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1       | 2020-06-03 22:46:52,164 [IPC Server handler 46 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/622eccab-f286-4bed-94f9-9d148dcbff73
scm_1       | 2020-06-03 22:46:52,164 [IPC Server handler 46 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 622eccab-f286-4bed-94f9-9d148dcbff73{ip: 172.22.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
scm_1       | 2020-06-03 22:46:52,167 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-06-03 22:46:52,168 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1       | 2020-06-03 22:46:52,168 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=15639143-720d-4e1a-8cd4-c5072c5a9ed0 to datanode:622eccab-f286-4bed-94f9-9d148dcbff73
scm_1       | 2020-06-03 22:46:52,169 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 15639143-720d-4e1a-8cd4-c5072c5a9ed0, Nodes: 622eccab-f286-4bed-94f9-9d148dcbff73{ip: 172.22.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-03T22:46:52.168911Z]
scm_1       | 2020-06-03 22:46:52,169 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-03 22:46:52,170 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2020-06-03 22:46:52,170 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1       | 2020-06-03 22:46:52,171 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-03 22:46:52,176 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2a11b1d1-500f-4f30-95f4-33a3fa0446ca to datanode:f3811c11-6df2-4867-ae20-220ae7889355
scm_1       | 2020-06-03 22:46:52,176 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2a11b1d1-500f-4f30-95f4-33a3fa0446ca to datanode:622eccab-f286-4bed-94f9-9d148dcbff73
scm_1       | 2020-06-03 22:46:52,176 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2a11b1d1-500f-4f30-95f4-33a3fa0446ca to datanode:33aee425-864c-4906-8eb4-b838cd19e298
scm_1       | 2020-06-03 22:46:52,177 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 2a11b1d1-500f-4f30-95f4-33a3fa0446ca, Nodes: f3811c11-6df2-4867-ae20-220ae7889355{ip: 172.22.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}622eccab-f286-4bed-94f9-9d148dcbff73{ip: 172.22.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}33aee425-864c-4906-8eb4-b838cd19e298{ip: 172.22.0.5, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-03T22:46:52.176224Z]
scm_1       | 2020-06-03 22:46:52,178 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-06-03 22:46:54,468 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 491e149a-7258-4931-85b3-4c8cd1a355b4, Nodes: 33aee425-864c-4906-8eb4-b838cd19e298{ip: 172.22.0.5, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:33aee425-864c-4906-8eb4-b838cd19e298, CreationTimestamp2020-06-03T22:46:50.974788Z] moved to OPEN state
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:56:34,284 [IPC Server handler 79 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:56:40,088 [IPC Server handler 56 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:56:45,048 [IPC Server handler 58 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:57:00,104 [IPC Server handler 67 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-76340/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om_1        | 2020-06-03 22:57:00,104 [IPC Server handler 67 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey2 in Volume/Bucket s3v/bucket-76340
om_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: s3vbucket: bucket-76340key: multipartKey2
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:241)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1       | 2020-06-03 22:46:54,473 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-06-03 22:46:54,488 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-06-03 22:46:55,013 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: e735236f-a353-4a1c-b29d-e4c1326e3a66, Nodes: f3811c11-6df2-4867-ae20-220ae7889355{ip: 172.22.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:f3811c11-6df2-4867-ae20-220ae7889355, CreationTimestamp2020-06-03T22:46:51.300302Z] moved to OPEN state
scm_1       | 2020-06-03 22:46:55,014 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-06-03 22:46:55,020 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-06-03 22:46:55,968 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 15639143-720d-4e1a-8cd4-c5072c5a9ed0, Nodes: 622eccab-f286-4bed-94f9-9d148dcbff73{ip: 172.22.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:622eccab-f286-4bed-94f9-9d148dcbff73, CreationTimestamp2020-06-03T22:46:52.168911Z] moved to OPEN state
scm_1       | 2020-06-03 22:46:55,968 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-06-03 22:46:55,975 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-06-03 22:47:00,083 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 2a11b1d1-500f-4f30-95f4-33a3fa0446ca, Nodes: f3811c11-6df2-4867-ae20-220ae7889355{ip: 172.22.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}622eccab-f286-4bed-94f9-9d148dcbff73{ip: 172.22.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}33aee425-864c-4906-8eb4-b838cd19e298{ip: 172.22.0.5, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:33aee425-864c-4906-8eb4-b838cd19e298, CreationTimestamp2020-06-03T22:46:52.176224Z] moved to OPEN state
scm_1       | 2020-06-03 22:47:00,086 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-06-03 22:47:00,086 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1       | 2020-06-03 22:47:00,089 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1       | 2020-06-03 22:47:00,090 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1       | 2020-06-03 22:47:00,090 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1       | 2020-06-03 22:48:46,691 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-03 22:48:46,692 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-06-03 22:48:59,409 [IPC Server handler 11 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
scm_1       | 2020-06-03 22:48:59,411 [IPC Server handler 11 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282490508345470 bcsId: 0
scm_1       | 2020-06-03 22:49:59,455 [IPC Server handler 27 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
scm_1       | 2020-06-03 22:49:59,456 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282491301331071 bcsId: 0
scm_1       | 2020-06-03 22:49:59,457 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282490032947325 bcsId: 0
scm_1       | 2020-06-03 22:50:46,692 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-03 22:50:46,693 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-06-03 22:50:59,461 [IPC Server handler 11 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
scm_1       | 2020-06-03 22:50:59,462 [IPC Server handler 11 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282498646868099 bcsId: 0
scm_1       | 2020-06-03 22:50:59,462 [IPC Server handler 11 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282497926234242 bcsId: 0
scm_1       | 2020-06-03 22:51:59,467 [IPC Server handler 11 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
scm_1       | 2020-06-03 22:51:59,467 [IPC Server handler 11 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282502089408645 bcsId: 0
scm_1       | 2020-06-03 22:51:59,468 [IPC Server handler 11 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282497465778305 bcsId: 0
scm_1       | 2020-06-03 22:52:00,104 [EventQueue-Delayed safe mode statusForReplicationManager] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1       | 2020-06-03 22:52:00,121 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 8 milliseconds for processing 1 containers.
scm_1       | 2020-06-03 22:52:46,695 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-03 22:52:46,696 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-06-03 22:52:59,476 [IPC Server handler 27 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 4 blocks
scm_1       | 2020-06-03 22:52:59,476 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282502808928390 bcsId: 0
scm_1       | 2020-06-03 22:52:59,476 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282501615976580 bcsId: 0
scm_1       | 2020-06-03 22:52:59,476 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282505306570887 bcsId: 0
scm_1       | 2020-06-03 22:52:59,477 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282506047127688 bcsId: 0
scm_1       | 2020-06-03 22:53:59,480 [IPC Server handler 27 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
scm_1       | 2020-06-03 22:53:59,481 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282506821042313 bcsId: 0
scm_1       | 2020-06-03 22:53:59,481 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282507590369418 bcsId: 0
scm_1       | 2020-06-03 22:54:46,700 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-03 22:54:46,700 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-06-03 22:54:59,485 [IPC Server handler 27 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
scm_1       | 2020-06-03 22:54:59,486 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282509599768715 bcsId: 0
scm_1       | 2020-06-03 22:54:59,486 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282510111342732 bcsId: 0
scm_1       | 2020-06-03 22:54:59,486 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282511059386509 bcsId: 0
scm_1       | 2020-06-03 22:56:46,701 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-03 22:56:46,702 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-06-03 22:56:59,490 [IPC Server handler 27 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
scm_1       | 2020-06-03 22:56:59,491 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282522091454614 bcsId: 0
scm_1       | 2020-06-03 22:57:00,122 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2020-06-03 22:57:59,495 [IPC Server handler 52 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 6 blocks
scm_1       | 2020-06-03 22:57:59,495 [IPC Server handler 52 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282526150426796 bcsId: 0
scm_1       | 2020-06-03 22:57:59,496 [IPC Server handler 52 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282526406410413 bcsId: 0
scm_1       | 2020-06-03 22:57:59,496 [IPC Server handler 52 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282524059500707 bcsId: 0,conID: 1 locID: 104282524055961761 bcsId: 0,conID: 1 locID: 104282524056158370 bcsId: 0
scm_1       | 2020-06-03 22:57:59,496 [IPC Server handler 52 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282523289125021 bcsId: 0
scm_1       | 2020-06-03 22:57:59,496 [IPC Server handler 52 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282523762884767 bcsId: 0
scm_1       | 2020-06-03 22:57:59,497 [IPC Server handler 52 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282523831894176 bcsId: 0
scm_1       | 2020-06-03 22:58:46,704 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-03 22:58:46,704 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-06-03 22:58:59,501 [IPC Server handler 39 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 3 blocks
scm_1       | 2020-06-03 22:58:59,502 [IPC Server handler 39 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282526765744302 bcsId: 0
scm_1       | 2020-06-03 22:58:59,502 [IPC Server handler 39 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282527282823343 bcsId: 0
scm_1       | 2020-06-03 22:58:59,502 [IPC Server handler 39 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104282527325487280 bcsId: 0
scm_1       | 2020-06-03 22:59:17,497 [IPC Server handler 39 on default port 9863] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 333d1e9c-fd38-4970-a5b7-f9b2f7c37069, Nodes: f3811c11-6df2-4867-ae20-220ae7889355{ip: 172.22.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN, leaderId:null, CreationTimestamp2020-06-03T22:59:17.496865Z]
recon_1     | 2020-06-03 22:46:47,838 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1     | 2020-06-03 22:46:47,860 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1     | 2020-06-03 22:46:47,901 [Listener at 0.0.0.0/9891] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
recon_1     | 2020-06-03 22:46:47,925 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1     | 2020-06-03 22:46:47,925 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1     | 2020-06-03 22:46:48,029 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1     | 2020-06-03 22:46:48,088 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1     | 2020-06-03 22:46:48,088 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1     | 2020-06-03 22:46:48,454 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1     | 2020-06-03 22:46:48,459 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
recon_1     | 2020-06-03 22:46:48,543 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1     | 2020-06-03 22:46:48,544 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1     | 2020-06-03 22:46:48,551 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1     | 2020-06-03 22:46:48,582 [Listener at 0.0.0.0/9891] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1     | 2020-06-03 22:46:48,600 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4c5a2baf{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1     | 2020-06-03 22:46:48,601 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@44114b9f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1     | 2020-06-03 22:46:50,723 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@571db8b4{recon,/,file:///tmp/jetty-0_0_0_0-9888-hadoop-ozone-recon-0_6_0-SNAPSHOT_jar-_-any-14591826122739679867.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar!/webapps/recon}
recon_1     | 2020-06-03 22:46:50,748 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@106b014e{HTTP/1.1,[http/1.1]}{0.0.0.0:9888}
recon_1     | 2020-06-03 22:46:50,749 [Listener at 0.0.0.0/9891] INFO server.Server: Started @25598ms
recon_1     | 2020-06-03 22:46:50,759 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1     | 2020-06-03 22:46:50,760 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1     | 2020-06-03 22:46:50,774 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1     | 2020-06-03 22:46:50,780 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1     | 2020-06-03 22:46:50,799 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1     | 2020-06-03 22:46:50,813 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1     | 2020-06-03 22:46:50,819 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1     | 2020-06-03 22:46:50,819 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-06-03 22:46:50,820 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1     | 2020-06-03 22:46:50,821 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1     | 2020-06-03 22:46:51,030 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1     | 2020-06-03 22:46:51,035 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2020-06-03 22:46:51,035 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1     | 2020-06-03 22:46:51,038 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1     | 2020-06-03 22:46:51,071 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1     | 2020-06-03 22:46:51,129 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered MissingContainerTask task 
recon_1     | 2020-06-03 22:46:51,129 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting MissingContainerTask Thread.
recon_1     | 2020-06-03 22:46:51,141 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1     | 2020-06-03 22:46:51,141 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1     | 2020-06-03 22:46:51,209 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2020-06-03 22:46:51,209 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=491e149a-7258-4931-85b3-4c8cd1a355b4 from SCM.
recon_1     | 2020-06-03 22:46:51,242 [MissingContainerTask] INFO fsck.MissingContainerTask: Missing Container task Thread took 100 milliseconds for processing 0 containers.
recon_1     | 2020-06-03 22:46:51,243 [PipelineSyncTask] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 491e149a-7258-4931-85b3-4c8cd1a355b4, Nodes: 33aee425-864c-4906-8eb4-b838cd19e298{ip: 172.22.0.5, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-06-03T22:46:50.974Z]
recon_1     | 2020-06-03 22:46:51,244 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 85 milliseconds.
recon_1     | 2020-06-03 22:47:50,821 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-03 22:47:50,822 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1     | 2020-06-03 22:47:50,992 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1591224470822
recon_1     | 2020-06-03 22:47:51,020 [pool-12-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1591224470822.
recon_1     | 2020-06-03 22:47:51,035 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
recon_1     | 2020-06-03 22:47:51,040 [pool-13-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1     | 2020-06-03 22:47:51,062 [pool-13-thread-1] INFO impl.ContainerDBServiceProviderImpl: Creating new Recon Container DB at /data/metadata/recon/recon-container-key.db_1591224471040
recon_1     | 2020-06-03 22:47:51,062 [pool-13-thread-1] INFO impl.ContainerDBServiceProviderImpl: Cleaning up old Recon Container DB at /data/metadata/recon/recon-container-key.db_1591224395418.
recon_1     | 2020-06-03 22:47:51,153 [pool-13-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
recon_1     | 2020-06-03 22:47:51,154 [pool-13-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.113 seconds to process 72 keys.
s3g_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.27.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.10.3.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-cac3336-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar
s3g_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/aec7a9345e8cecdacc1367562fdd82dd4dfc34df ; compiled by 'jenkins1001' on 2020-06-03T22:21Z
s3g_1       | STARTUP_MSG:   java = 11.0.6
s3g_1       | ************************************************************/
s3g_1       | 2020-06-03 22:46:25,964 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | 2020-06-03 22:46:26,242 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1       | 2020-06-03 22:46:26,305 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1       | 2020-06-03 22:46:26,322 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
s3g_1       | 2020-06-03 22:46:26,694 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1       | 2020-06-03 22:46:26,709 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1       | 2020-06-03 22:46:26,727 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1       | 2020-06-03 22:46:26,818 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 2020-06-03 22:46:26,858 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@38145825{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 2020-06-03 22:46:26,870 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1e4f4a5c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
s3g_1       | WARNING: An illegal reflective access operation has occurred
s3g_1       | WARNING: Illegal reflective access by org.jboss.classfilewriter.ClassFile$1 (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int)
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.jboss.classfilewriter.ClassFile$1
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1       | WARNING: All illegal access operations will be denied in a future release
s3g_1       | Jun 03, 2020 10:46:43 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1       | 
s3g_1       | 2020-06-03 22:46:43,960 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@260e3837{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-0_6_0-SNAPSHOT_jar-_-any-2731877391044649222.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1       | 2020-06-03 22:46:43,988 [main] INFO server.AbstractConnector: Started ServerConnector@33f676f6{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
s3g_1       | 2020-06-03 22:46:43,989 [main] INFO server.Server: Started @23167ms
s3g_1       | 2020-06-03 22:46:43,994 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1       | 2020-06-03 22:56:13,592 [qtp1804379080-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:14,093 [qtp1804379080-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-61034, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-03 22:56:14,105 [qtp1804379080-19] INFO endpoint.BucketEndpoint: Location is /bucket-61034
s3g_1       | 2020-06-03 22:56:14,642 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:15,201 [qtp1804379080-15] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1       | 2020-06-03 22:56:15,231 [qtp1804379080-15] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1       | 2020-06-03 22:56:15,231 [qtp1804379080-15] INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
s3g_1       | 2020-06-03 22:56:15,235 [qtp1804379080-15] WARN impl.MetricsSystemImpl: Sink prometheus already exists!
s3g_1       | 2020-06-03 22:56:16,566 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:17,190 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:17,716 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:18,263 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:22,802 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:22,820 [qtp1804379080-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-82062, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-03 22:56:22,825 [qtp1804379080-18] INFO endpoint.BucketEndpoint: Location is /bucket-82062
s3g_1       | 2020-06-03 22:56:23,418 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:23,433 [qtp1804379080-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-62833, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-03 22:56:23,437 [qtp1804379080-20] INFO endpoint.BucketEndpoint: Location is /bucket-62833
s3g_1       | 2020-06-03 22:56:24,021 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:24,034 [qtp1804379080-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-62833, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-03 22:56:24,039 [qtp1804379080-18] INFO endpoint.BucketEndpoint: Location is /bucket-62833
s3g_1       | 2020-06-03 22:56:24,609 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:24,634 [qtp1804379080-20] ERROR endpoint.BucketEndpoint: Error in Create Bucket Request for bucket: bucket_1
s3g_1       | INVALID_BUCKET_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Bucket or Volume name has an unsupported character : _
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.verifyBucketName(RpcClient.java:469)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:419)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:410)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneVolume.createBucket(OzoneVolume.java:213)
s3g_1       | 	at org.apache.hadoop.ozone.client.ObjectStore.createS3Bucket(ObjectStore.java:118)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.createS3Bucket(EndpointBase.java:96)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:205)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:57:00,111 [IPC Server handler 67 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s3v"
om_1        |   bucketName: "bucket-76340"
om_1        |   keyName: "multipartKey2"
recon_1     | 2020-06-03 22:47:51,306 [pool-13-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
recon_1     | 2020-06-03 22:48:11,410 [IPC Server handler 0 on default port 9891] INFO net.NetworkTopology: Added a new node: /default-rack/f3811c11-6df2-4867-ae20-220ae7889355
recon_1     | 2020-06-03 22:48:11,413 [IPC Server handler 12 on default port 9891] INFO net.NetworkTopology: Added a new node: /default-rack/33aee425-864c-4906-8eb4-b838cd19e298
recon_1     | 2020-06-03 22:48:11,413 [IPC Server handler 12 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 33aee425-864c-4906-8eb4-b838cd19e298{ip: 172.22.0.5, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-06-03 22:48:11,410 [IPC Server handler 0 on default port 9891] INFO node.SCMNodeManager: Registered Data node : f3811c11-6df2-4867-ae20-220ae7889355{ip: 172.22.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-06-03 22:48:11,411 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node f3811c11-6df2-4867-ae20-220ae7889355 to Node DB.
recon_1     | 2020-06-03 22:48:11,418 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 33aee425-864c-4906-8eb4-b838cd19e298 to Node DB.
recon_1     | 2020-06-03 22:48:11,421 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=e735236f-a353-4a1c-b29d-e4c1326e3a66. Trying to get from SCM.
recon_1     | 2020-06-03 22:48:11,422 [EventQueue-ContainerReportForReconContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ozone_datanode_3.ozone_default.
recon_1     | 2020-06-03 22:48:11,455 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: e735236f-a353-4a1c-b29d-e4c1326e3a66, Nodes: f3811c11-6df2-4867-ae20-220ae7889355{ip: 172.22.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:f3811c11-6df2-4867-ae20-220ae7889355, CreationTimestamp2020-06-03T22:46:51.300Z] to Recon pipeline metadata.
recon_1     | 2020-06-03 22:48:11,457 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e735236f-a353-4a1c-b29d-e4c1326e3a66, Nodes: f3811c11-6df2-4867-ae20-220ae7889355{ip: 172.22.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:f3811c11-6df2-4867-ae20-220ae7889355, CreationTimestamp2020-06-03T22:46:51.300Z]
recon_1     | 2020-06-03 22:48:11,458 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=2a11b1d1-500f-4f30-95f4-33a3fa0446ca. Trying to get from SCM.
recon_1     | 2020-06-03 22:48:11,461 [EventQueue-ContainerReportForReconContainerReportHandler] INFO scm.ReconContainerManager: Exception while adding container #1 .
recon_1     | java.io.IOException: Pipeline PipelineID=2a11b1d1-500f-4f30-95f4-33a3fa0446ca not found. Cannot add container #1
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.addNewContainer(ReconContainerManager.java:117)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.checkAndAddNewContainer(ReconContainerManager.java:91)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerReportHandler.onMessage(ReconContainerReportHandler.java:62)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerReportHandler.onMessage(ReconContainerReportHandler.java:38)
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-06-03 22:48:11,462 [EventQueue-ContainerReportForReconContainerReportHandler] ERROR scm.ReconContainerReportHandler: Exception while checking and adding new container.
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=2a11b1d1-500f-4f30-95f4-33a3fa0446ca not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removeContainerFromPipeline(PipelineStateMap.java:353)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removeContainerFromPipeline(PipelineStateManager.java:111)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removeContainerFromPipeline(SCMPipelineManager.java:350)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.addNewContainer(ReconContainerManager.java:124)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.checkAndAddNewContainer(ReconContainerManager.java:91)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerReportHandler.onMessage(ReconContainerReportHandler.java:62)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerReportHandler.onMessage(ReconContainerReportHandler.java:38)
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-06-03 22:48:11,463 [EventQueue-ContainerReportForReconContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ozone_datanode_2.ozone_default.
recon_1     | 2020-06-03 22:48:11,462 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 2a11b1d1-500f-4f30-95f4-33a3fa0446ca, Nodes: f3811c11-6df2-4867-ae20-220ae7889355{ip: 172.22.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}622eccab-f286-4bed-94f9-9d148dcbff73{ip: 172.22.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}33aee425-864c-4906-8eb4-b838cd19e298{ip: 172.22.0.5, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:33aee425-864c-4906-8eb4-b838cd19e298, CreationTimestamp2020-06-03T22:46:52.176Z] to Recon pipeline metadata.
recon_1     | 2020-06-03 22:48:11,463 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 2a11b1d1-500f-4f30-95f4-33a3fa0446ca, Nodes: f3811c11-6df2-4867-ae20-220ae7889355{ip: 172.22.0.4, host: ozone_datanode_2.ozone_default, networkLocation: /default-rack, certSerialId: null}622eccab-f286-4bed-94f9-9d148dcbff73{ip: 172.22.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}33aee425-864c-4906-8eb4-b838cd19e298{ip: 172.22.0.5, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:33aee425-864c-4906-8eb4-b838cd19e298, CreationTimestamp2020-06-03T22:46:52.176Z]
recon_1     | 2020-06-03 22:48:11,464 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline ONE PipelineID=491e149a-7258-4931-85b3-4c8cd1a355b4 reported by 33aee425-864c-4906-8eb4-b838cd19e298{ip: 172.22.0.5, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
om_1        |   multipartUploadID: "121e461c-d6c5-4e31-89aa-2f24023ba9ac-104282522785874077"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "dlfknslnfslf"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1591225020103
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 1
om_1        |   partName: "/s3v/bucket-76340/multipartKey2104282522822312094"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "/s3v/bucket-76340/multipartKey2104282522870022303"
om_1        | }
om_1        | 
om_1        | 2020-06-03 22:57:01,182 [IPC Server handler 71 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-76340/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om_1        | partName: "etag1"
om_1        | , partNumber: 2
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2020-06-03 22:57:01,183 [IPC Server handler 71 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s3v/bucket-76340
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-76340key: multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:181)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:57:01,184 [IPC Server handler 71 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s3v"
om_1        |   bucketName: "bucket-76340"
om_1        |   keyName: "multipartKey3"
om_1        |   multipartUploadID: "b0ed3d2b-23c4-42b2-9e26-52b59b6eaa72-104282522951483552"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "dlfknslnfslf"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1591225021182
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 1
om_1        |   partName: "etag1"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "etag2"
om_1        | }
om_1        | 
om_1        | 2020-06-03 22:57:01,706 [IPC Server handler 26 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-76340/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om_1        | partName: "etag1"
om_1        | , partNumber: 1
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2020-06-03 22:57:01,708 [IPC Server handler 26 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s3v/bucket-76340
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-76340key: multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:181)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:57:01,709 [IPC Server handler 26 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s3v"
om_1        |   bucketName: "bucket-76340"
om_1        |   keyName: "multipartKey3"
om_1        |   multipartUploadID: "b0ed3d2b-23c4-42b2-9e26-52b59b6eaa72-104282522951483552"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "dlfknslnfslf"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1591225021705
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "etag1"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 1
om_1        |   partName: "etag2"
om_1        | }
om_1        | 
om_1        | 2020-06-03 22:57:07,402 [IPC Server handler 93 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s3v/bucket-76340
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-76340key: multipartKey3. Provided Part info is { etag1, 1}, where as OM has partName /s3v/bucket-76340/multipartKey3104282523062108321
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:223)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-03 22:56:29,248 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:29,265 [qtp1804379080-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-30020, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-03 22:56:29,268 [qtp1804379080-18] INFO endpoint.BucketEndpoint: Location is /bucket-30020
s3g_1       | 2020-06-03 22:56:29,854 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:30,452 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:34,846 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:34,861 [qtp1804379080-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-98683, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-03 22:56:34,941 [qtp1804379080-18] INFO endpoint.BucketEndpoint: Location is /bucket-98683
s3g_1       | 2020-06-03 22:56:35,553 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:36,153 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:36,173 [qtp1804379080-18] ERROR endpoint.BucketEndpoint: Exception occurred in headBucket
s3g_1       | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:107)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:72)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:253)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:57:07,403 [IPC Server handler 93 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s3v"
om_1        |   bucketName: "bucket-76340"
om_1        |   keyName: "multipartKey3"
om_1        |   multipartUploadID: "b0ed3d2b-23c4-42b2-9e26-52b59b6eaa72-104282522951483552"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "dlfknslnfslf"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1591225027401
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 1
om_1        |   partName: "etag1"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "etag2"
om_1        | }
om_1        | 
om_1        | 2020-06-03 22:57:07,930 [IPC Server handler 44 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s3v/bucket-76340
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-76340key: multipartKey3. Provided Part info is { etag2, 2}, where as OM has partName /s3v/bucket-76340/multipartKey3104282523288797346
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:223)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:57:07,931 [IPC Server handler 44 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s3v"
om_1        |   bucketName: "bucket-76340"
om_1        |   keyName: "multipartKey3"
om_1        |   multipartUploadID: "b0ed3d2b-23c4-42b2-9e26-52b59b6eaa72-104282522951483552"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "dlfknslnfslf"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1591225027929
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-03 22:56:40,570 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:40,581 [qtp1804379080-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-87705, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-03 22:56:40,584 [qtp1804379080-20] INFO endpoint.BucketEndpoint: Location is /bucket-87705
s3g_1       | 2020-06-03 22:56:41,159 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:45,599 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:45,639 [qtp1804379080-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-76340, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-03 22:56:45,643 [qtp1804379080-18] INFO endpoint.BucketEndpoint: Location is /bucket-76340
s3g_1       | 2020-06-03 22:56:46,243 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:46,841 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:47,469 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:51,026 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:54,464 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:55,084 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:56,006 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:56,737 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:57,299 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:58,076 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:58,632 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:56:59,361 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:00,084 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:00,112 [qtp1804379080-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-76340, , key: multipartKey2
s3g_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: s3vbucket: bucket-76340key: multipartKey2
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:884)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:900)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 1
om_1        |   partName: "/s3v/bucket-76340/multipartKey3104282523062108321"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "etag2"
om_1        | }
om_1        | 
om_1        | 2020-06-03 22:57:08,451 [IPC Server handler 90 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-76340/multipartKey3
om_1        | 2020-06-03 22:57:08,452 [IPC Server handler 90 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s3v/bucket-76340
om_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-76340key: multipartKey3because parts are in Invalid order.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:57:08,452 [IPC Server handler 90 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s3v"
om_1        |   bucketName: "bucket-76340"
om_1        |   keyName: "multipartKey3"
om_1        |   multipartUploadID: "b0ed3d2b-23c4-42b2-9e26-52b59b6eaa72-104282522951483552"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "dlfknslnfslf"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1591225028450
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 4
om_1        |   partName: "/s3v/bucket-76340/multipartKey3104282523062108321"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "etag2"
om_1        | }
om_1        | 
om_1        | 2020-06-03 22:57:11,344 [IPC Server handler 72 on default port 9862] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName multipartKey5 in VolumeName/Bucket s3v/bucket-76340
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-76340key: multipartKey5
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:120)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-03 22:57:00,607 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:01,163 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:01,185 [qtp1804379080-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-76340, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-76340key: multipartKey3
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:884)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:900)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:57:11,345 [IPC Server handler 72 on default port 9862] ERROR multipart.S3MultipartUploadAbortRequest: Unrecognized Result for S3MultipartUploadAbortRequest: keyArgs {
om_1        |   volumeName: "s3v"
om_1        |   bucketName: "bucket-76340"
om_1        |   keyName: "multipartKey5"
om_1        |   multipartUploadID: "random"
om_1        |   modificationTime: 1591225031343
om_1        | }
om_1        | 
om_1        | 2020-06-03 22:57:11,876 [IPC Server handler 41 on default port 9862] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-76340, KeymultipartKey. Exception:{}
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:372)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:314)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:215)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:57:34,975 [IPC Server handler 51 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:57:48,233 [IPC Server handler 80 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:58:05,528 [IPC Server handler 11 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:58:09,224 [IPC Server handler 95 on default port 9862] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-48141, Keymultidelete/f4. Exception:{}
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:130)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-03 22:57:01,684 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:01,711 [qtp1804379080-18] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-76340, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-76340key: multipartKey3
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:884)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:900)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-03 22:57:02,296 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:05,750 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:06,672 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:07,388 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:07,408 [qtp1804379080-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-76340, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-76340key: multipartKey3. Provided Part info is { etag1, 1}, where as OM has partName /s3v/bucket-76340/multipartKey3104282523062108321
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:884)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:900)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:58:13,484 [IPC Server handler 55 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:58:28,504 [IPC Server handler 17 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:hadoop volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:226)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-03 22:58:37,041 [IPC Server handler 69 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-63011 for user:hadoop
om_1        | 2020-06-03 22:59:17,450 [IPC Server handler 1 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-35410 for user:hadoop
om_1        | 2020-06-03 22:59:24,782 [IPC Server handler 62 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:hadoop
recon_1     | 2020-06-03 22:48:11,465 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 491e149a-7258-4931-85b3-4c8cd1a355b4, Nodes: 33aee425-864c-4906-8eb4-b838cd19e298{ip: 172.22.0.5, host: ozone_datanode_3.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:33aee425-864c-4906-8eb4-b838cd19e298, CreationTimestamp2020-06-03T22:46:50.974Z] moved to OPEN state
recon_1     | 2020-06-03 22:48:11,475 [EventQueue-ContainerReportForReconContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1     | 2020-06-03 22:48:11,495 [IPC Server handler 2 on default port 9891] INFO net.NetworkTopology: Added a new node: /default-rack/622eccab-f286-4bed-94f9-9d148dcbff73
recon_1     | 2020-06-03 22:48:11,498 [IPC Server handler 2 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 622eccab-f286-4bed-94f9-9d148dcbff73{ip: 172.22.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}
recon_1     | 2020-06-03 22:48:11,496 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 622eccab-f286-4bed-94f9-9d148dcbff73 to Node DB.
recon_1     | 2020-06-03 22:48:11,499 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=15639143-720d-4e1a-8cd4-c5072c5a9ed0. Trying to get from SCM.
recon_1     | 2020-06-03 22:48:11,501 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 15639143-720d-4e1a-8cd4-c5072c5a9ed0, Nodes: 622eccab-f286-4bed-94f9-9d148dcbff73{ip: 172.22.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:622eccab-f286-4bed-94f9-9d148dcbff73, CreationTimestamp2020-06-03T22:46:52.168Z] to Recon pipeline metadata.
recon_1     | 2020-06-03 22:48:11,502 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 15639143-720d-4e1a-8cd4-c5072c5a9ed0, Nodes: 622eccab-f286-4bed-94f9-9d148dcbff73{ip: 172.22.0.7, host: ozone_datanode_1.ozone_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:622eccab-f286-4bed-94f9-9d148dcbff73, CreationTimestamp2020-06-03T22:46:52.168Z]
recon_1     | 2020-06-03 22:48:51,310 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-03 22:48:51,312 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-03 22:48:51,520 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 112
recon_1     | 2020-06-03 22:48:51,585 [pool-13-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 55 OM DB update event(s).
recon_1     | 2020-06-03 22:48:51,819 [pool-13-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-03 22:49:51,827 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-03 22:49:51,827 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-03 22:49:51,857 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 16
recon_1     | 2020-06-03 22:49:51,895 [pool-13-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 6 OM DB update event(s).
recon_1     | 2020-06-03 22:49:51,902 [pool-13-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-03 22:50:51,917 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-03 22:50:51,917 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-03 22:50:51,927 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 17
recon_1     | 2020-06-03 22:50:51,941 [pool-13-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 6 OM DB update event(s).
recon_1     | 2020-06-03 22:50:51,956 [pool-13-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-03 22:51:51,267 [MissingContainerTask] INFO fsck.MissingContainerTask: Missing Container task Thread took 25 milliseconds for processing 1 containers.
recon_1     | 2020-06-03 22:51:51,961 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-03 22:51:51,961 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-03 22:51:51,969 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 14
recon_1     | 2020-06-03 22:51:51,975 [pool-13-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 7 OM DB update event(s).
recon_1     | 2020-06-03 22:51:51,992 [pool-13-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-03 22:52:51,999 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-03 22:52:51,999 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-03 22:52:52,017 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 18
recon_1     | 2020-06-03 22:52:52,031 [pool-13-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 9 OM DB update event(s).
recon_1     | 2020-06-03 22:52:52,040 [pool-13-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-03 22:53:52,059 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-03 22:53:52,059 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-03 22:53:52,068 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 20
recon_1     | 2020-06-03 22:53:52,082 [pool-13-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 12 OM DB update event(s).
recon_1     | 2020-06-03 22:53:52,099 [pool-13-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-03 22:54:52,113 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-03 22:54:52,113 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-03 22:54:52,125 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 35
recon_1     | 2020-06-03 22:54:52,143 [pool-13-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 33 OM DB update event(s).
recon_1     | 2020-06-03 22:54:52,187 [pool-13-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-03 22:55:52,197 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-03 22:55:52,198 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-03 22:55:52,202 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 1
recon_1     | 2020-06-03 22:56:51,263 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
recon_1     | 2020-06-03 22:56:51,264 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 15 milliseconds.
recon_1     | 2020-06-03 22:56:51,289 [MissingContainerTask] INFO fsck.MissingContainerTask: Missing Container task Thread took 16 milliseconds for processing 1 containers.
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-03 22:57:07,907 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:07,936 [qtp1804379080-18] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-76340, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-76340key: multipartKey3. Provided Part info is { etag2, 2}, where as OM has partName /s3v/bucket-76340/multipartKey3104282523288797346
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:884)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:900)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-03 22:57:08,437 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:08,455 [qtp1804379080-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-76340, , key: multipartKey3
s3g_1       | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-76340key: multipartKey3because parts are in Invalid order.
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:884)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:900)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
recon_1     | 2020-06-03 22:56:52,205 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-03 22:56:52,205 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-03 22:56:52,211 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 28
recon_1     | 2020-06-03 22:56:52,216 [pool-13-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 2 OM DB update event(s).
recon_1     | 2020-06-03 22:56:52,219 [pool-13-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-03 22:57:52,225 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-03 22:57:52,225 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-03 22:57:52,232 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 91
recon_1     | 2020-06-03 22:57:53,398 [pool-13-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 13 OM DB update event(s).
recon_1     | 2020-06-03 22:57:53,438 [pool-13-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-03 22:58:38,549 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #4 got from ozone_datanode_1.ozone_default.
recon_1     | 2020-06-03 22:58:38,568 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #4 to Recon.
recon_1     | 2020-06-03 22:58:38,608 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #3 got from ozone_datanode_3.ozone_default.
recon_1     | 2020-06-03 22:58:38,635 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #3 to Recon.
recon_1     | 2020-06-03 22:58:38,667 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #2 got from ozone_datanode_2.ozone_default.
recon_1     | 2020-06-03 22:58:38,672 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1     | 2020-06-03 22:58:53,463 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-03 22:58:53,463 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-03 22:58:53,467 [pool-12-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 47
recon_1     | 2020-06-03 22:58:53,491 [pool-13-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 21 OM DB update event(s).
recon_1     | 2020-06-03 22:58:53,506 [pool-13-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-03 22:59:18,577 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #5 got from ozone_datanode_2.ozone_default.
recon_1     | 2020-06-03 22:59:18,583 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Exception while adding container #5 .
recon_1     | java.io.IOException: Pipeline PipelineID=333d1e9c-fd38-4970-a5b7-f9b2f7c37069 not found. Cannot add container #5
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.addNewContainer(ReconContainerManager.java:117)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.checkAndAddNewContainer(ReconContainerManager.java:91)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconIncrementalContainerReportHandler.onMessage(ReconIncrementalContainerReportHandler.java:68)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconIncrementalContainerReportHandler.onMessage(ReconIncrementalContainerReportHandler.java:39)
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
recon_1     | 2020-06-03 22:59:18,584 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] ERROR scm.ReconIncrementalContainerReportHandler: Exception while checking and adding new container.
recon_1     | org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=333d1e9c-fd38-4970-a5b7-f9b2f7c37069 not found
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.removeContainerFromPipeline(PipelineStateMap.java:353)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManager.removeContainerFromPipeline(PipelineStateManager.java:111)
recon_1     | 	at org.apache.hadoop.hdds.scm.pipeline.SCMPipelineManager.removeContainerFromPipeline(SCMPipelineManager.java:350)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.addNewContainer(ReconContainerManager.java:124)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconContainerManager.checkAndAddNewContainer(ReconContainerManager.java:91)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconIncrementalContainerReportHandler.onMessage(ReconIncrementalContainerReportHandler.java:68)
recon_1     | 	at org.apache.hadoop.ozone.recon.scm.ReconIncrementalContainerReportHandler.onMessage(ReconIncrementalContainerReportHandler.java:39)
recon_1     | 	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:81)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-03 22:57:08,925 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:09,436 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:10,142 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:10,699 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:11,332 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:11,863 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:12,355 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:12,986 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:14,032 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:14,765 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:15,384 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:15,989 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:16,554 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:17,343 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:17,451 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:17,458 [qtp1804379080-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:17,480 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:18,597 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:19,123 [qtp1804379080-21] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:19,264 [qtp1804379080-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:19,268 [qtp1804379080-21] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:19,269 [qtp1804379080-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:20,247 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:21,005 [qtp1804379080-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:22,001 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:22,556 [qtp1804379080-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:23,608 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:24,100 [qtp1804379080-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:24,927 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:25,963 [qtp1804379080-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:26,523 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:27,853 [qtp1804379080-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:28,573 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:29,087 [qtp1804379080-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:29,956 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:30,514 [qtp1804379080-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:31,073 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:35,538 [qtp1804379080-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:35,544 [qtp1804379080-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-29883, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-03 22:57:35,547 [qtp1804379080-19] INFO endpoint.BucketEndpoint: Location is /bucket-29883
s3g_1       | 2020-06-03 22:57:36,130 [qtp1804379080-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:36,138 [qtp1804379080-19] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-53724, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-03 22:57:36,140 [qtp1804379080-19] INFO endpoint.BucketEndpoint: Location is /destbucket-53724
s3g_1       | 2020-06-03 22:57:36,725 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:40,069 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:40,592 [qtp1804379080-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:41,169 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:41,710 [qtp1804379080-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:42,296 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:42,799 [qtp1804379080-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:43,318 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:43,817 [qtp1804379080-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:44,338 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:48,797 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:48,820 [qtp1804379080-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-38209, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-03 22:57:48,823 [qtp1804379080-17] INFO endpoint.BucketEndpoint: Location is /bucket-38209
s3g_1       | 2020-06-03 22:57:49,423 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:50,106 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:50,610 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:51,204 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:51,691 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:52,205 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:52,798 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:53,332 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:56,573 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:57,077 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:57,677 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:58,165 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:58,815 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:59,489 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:57:59,986 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:00,556 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:01,058 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:01,669 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:06,101 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:06,109 [qtp1804379080-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-48141, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-03 22:58:06,111 [qtp1804379080-17] INFO endpoint.BucketEndpoint: Location is /bucket-48141
s3g_1       | 2020-06-03 22:58:06,701 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:07,348 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:08,041 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:08,720 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:09,209 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:09,705 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:14,032 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:14,038 [qtp1804379080-15] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-48152, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-03 22:58:14,041 [qtp1804379080-15] INFO endpoint.BucketEndpoint: Location is /bucket-48152
s3g_1       | 2020-06-03 22:58:14,634 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:15,292 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:15,804 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:16,394 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:16,881 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:17,410 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:17,936 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:18,485 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:19,038 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:19,513 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:20,035 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:20,567 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:21,115 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:21,672 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:22,229 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:22,732 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:23,300 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:23,835 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:24,304 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:24,791 [qtp1804379080-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:29,090 [qtp1804379080-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-03 22:58:29,107 [qtp1804379080-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-55227, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-03 22:58:29,110 [qtp1804379080-17] INFO endpoint.BucketEndpoint: Location is /bucket-55227
