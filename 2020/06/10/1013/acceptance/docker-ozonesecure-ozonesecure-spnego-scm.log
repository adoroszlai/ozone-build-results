Attaching to ozonesecure_s3g_1, ozonesecure_kms_1, ozonesecure_kdc_1, ozonesecure_datanode_3, ozonesecure_datanode_2, ozonesecure_om_1, ozonesecure_datanode_1, ozonesecure_recon_1, ozonesecure_scm_1
datanode_2  | Sleeping for 5 seconds
datanode_2  | Setting up kerberos!!
datanode_2  | KDC ISSUER_SERVER => kdc:8081
datanode_2  | Sleeping for 5 seconds
datanode_2  | Got 200, KDC service ready!!
datanode_2  | Download dn/e740903365c7@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_2  | --2020-06-10 23:49:58--  http://kdc:8081/keytab/e740903365c7/dn
datanode_2  | Resolving kdc (kdc)... 172.26.0.8
datanode_2  | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_2  | Length: 158 [application/octet-stream]
datanode_2  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_2  | 
datanode_2  |      0K                                                       100% 26.4M=0s
datanode_2  | 
datanode_2  | 2020-06-10 23:49:58 (26.4 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode_2  | 
datanode_2  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_2  | KVNO Timestamp         Principal
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_2  |    2 06/10/20 23:49:58 dn/e740903365c7@EXAMPLE.COM
datanode_2  |    2 06/10/20 23:49:58 dn/e740903365c7@EXAMPLE.COM
datanode_2  | Download HTTP/e740903365c7@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_2  | --2020-06-10 23:49:58--  http://kdc:8081/keytab/e740903365c7/HTTP
datanode_2  | Resolving kdc (kdc)... 172.26.0.8
datanode_2  | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
datanode_2  | HTTP request sent, awaiting response... 200 OK
datanode_2  | Length: 162 [application/octet-stream]
datanode_2  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_2  | 
datanode_2  |      0K                                                       100% 31.5M=0s
datanode_2  | 
datanode_2  | 2020-06-10 23:49:59 (31.5 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode_2  | 
datanode_2  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_2  | KVNO Timestamp         Principal
datanode_2  | ---- ----------------- --------------------------------------------------------
datanode_2  |    2 06/10/20 23:49:59 HTTP/e740903365c7@EXAMPLE.COM
datanode_2  |    2 06/10/20 23:49:59 HTTP/e740903365c7@EXAMPLE.COM
datanode_2  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2020-06-10 23:50:04,645 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = e740903365c7/172.26.0.2
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/33992bd7f4c16024bb749900e60f3134e980d16a ; compiled by 'jenkins1001' on 2020-06-10T22:19Z
datanode_2  | STARTUP_MSG:   java = 11.0.6
datanode_2  | ************************************************************/
datanode_2  | 2020-06-10 23:50:04,693 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2020-06-10 23:50:06,910 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2020-06-10 23:50:07,565 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2020-06-10 23:50:08,491 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2020-06-10 23:50:08,491 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2020-06-10 23:50:08,946 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:e740903365c7 ip:172.26.0.2
datanode_2  | 2020-06-10 23:50:11,705 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_2  | WARNING: An illegal reflective access operation has occurred
datanode_2  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar) to method sun.security.krb5.Config.getInstance()
datanode_2  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
datanode_2  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_2  | WARNING: All illegal access operations will be denied in a future release
datanode_2  | 2020-06-10 23:50:12,829 [main] INFO security.UserGroupInformation: Login successful for user dn/e740903365c7@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode_2  | 2020-06-10 23:50:12,843 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode_2  | 2020-06-10 23:50:12,847 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode_2  | 2020-06-10 23:50:12,851 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_2  | 2020-06-10 23:50:12,855 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode_2  | 2020-06-10 23:50:12,863 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_2  | 2020-06-10 23:50:16,960 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode_2  | 2020-06-10 23:50:17,016 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.26.0.2,host:e740903365c7
datanode_2  | 2020-06-10 23:50:17,023 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_2  | 2020-06-10 23:50:17,026 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@e740903365c7
datanode_2  | 2020-06-10 23:50:18,951 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-10 23:50:19,952 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-10 23:50:20,953 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-10 23:50:21,954 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-10 23:50:22,955 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-10 23:50:23,956 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-10 23:50:24,957 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-10 23:50:25,958 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-10 23:50:26,959 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-06-10 23:50:31,078 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode_2  | 2020-06-10 23:50:31,262 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2  | 2020-06-10 23:50:31,276 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2  | 2020-06-10 23:50:31,277 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2020-06-10 23:50:31,312 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2  | 2020-06-10 23:50:31,397 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2020-06-10 23:50:33,407 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-06-10 23:50:33,634 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2020-06-10 23:50:34,291 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2  | 2020-06-10 23:50:34,296 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2  | 2020-06-10 23:50:34,310 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-06-10 23:50:34,312 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2  | 2020-06-10 23:50:34,322 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-06-10 23:50:35,122 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-06-10 23:50:35,421 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 2020-06-10 23:50:35,425 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_2  | 2020-06-10 23:50:35,425 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode_2  | 2020-06-10 23:50:35,549 [main] INFO util.log: Logging initialized @36200ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | 2020-06-10 23:50:36,020 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2020-06-10 23:50:36,050 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2020-06-10 23:50:36,058 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_2  | 2020-06-10 23:50:36,058 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_2  | 2020-06-10 23:50:36,058 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_2  | 2020-06-10 23:50:36,064 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode_2  | 2020-06-10 23:50:36,303 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2020-06-10 23:50:36,305 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_2  | 2020-06-10 23:50:36,371 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2020-06-10 23:50:36,372 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2020-06-10 23:50:36,373 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1  | Sleeping for 5 seconds
datanode_1  | Setting up kerberos!!
datanode_1  | KDC ISSUER_SERVER => kdc:8081
datanode_1  | Sleeping for 5 seconds
datanode_1  | Got 200, KDC service ready!!
datanode_1  | Download dn/29984dc17d72@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_1  | --2020-06-10 23:49:58--  http://kdc:8081/keytab/29984dc17d72/dn
datanode_1  | Resolving kdc (kdc)... 172.26.0.8
datanode_1  | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
datanode_1  | HTTP request sent, awaiting response... 200 OK
datanode_1  | Length: 158 [application/octet-stream]
datanode_1  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_1  | 
datanode_1  |      0K                                                       100% 34.2M=0s
datanode_1  | 
datanode_1  | 2020-06-10 23:49:58 (34.2 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode_1  | 
datanode_1  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_1  | KVNO Timestamp         Principal
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_1  |    2 06/10/20 23:49:58 dn/29984dc17d72@EXAMPLE.COM
datanode_1  |    2 06/10/20 23:49:58 dn/29984dc17d72@EXAMPLE.COM
datanode_1  | Download HTTP/29984dc17d72@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_1  | --2020-06-10 23:49:58--  http://kdc:8081/keytab/29984dc17d72/HTTP
datanode_1  | Resolving kdc (kdc)... 172.26.0.8
datanode_1  | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
datanode_1  | HTTP request sent, awaiting response... 200 OK
datanode_1  | Length: 162 [application/octet-stream]
datanode_1  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_1  | 
datanode_1  |      0K                                                       100% 33.6M=0s
datanode_1  | 
datanode_1  | 2020-06-10 23:49:58 (33.6 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode_1  | 
datanode_1  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_1  | KVNO Timestamp         Principal
datanode_1  | ---- ----------------- --------------------------------------------------------
datanode_1  |    2 06/10/20 23:49:58 HTTP/29984dc17d72@EXAMPLE.COM
datanode_1  |    2 06/10/20 23:49:58 HTTP/29984dc17d72@EXAMPLE.COM
datanode_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2020-06-10 23:50:04,298 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = 29984dc17d72/172.26.0.9
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_2  | 2020-06-10 23:50:36,403 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/e740903365c7@EXAMPLE.COM
datanode_2  | 2020-06-10 23:50:36,421 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3dce6dd8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2020-06-10 23:50:36,423 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@28babeca{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2020-06-10 23:50:36,676 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/e740903365c7@EXAMPLE.COM
datanode_2  | 2020-06-10 23:50:36,720 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@44f0ff2b{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-5348413876299704816.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 2020-06-10 23:50:36,758 [main] INFO server.AbstractConnector: Started ServerConnector@2c1f8dbd{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_2  | 2020-06-10 23:50:36,766 [main] INFO server.Server: Started @37413ms
datanode_2  | 2020-06-10 23:50:36,803 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2020-06-10 23:50:36,804 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2020-06-10 23:50:36,807 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2020-06-10 23:50:36,912 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6efc5b15] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2020-06-10 23:50:37,017 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.26.0.6:9891
datanode_2  | 2020-06-10 23:50:39,168 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2020-06-10 23:50:39,179 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2  | 2020-06-10 23:50:39,179 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 41410284-0e36-4425-9317-2f8ae5197d6c at port 9858
datanode_2  | 2020-06-10 23:50:39,219 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 41410284-0e36-4425-9317-2f8ae5197d6c: start RPC server
datanode_2  | 2020-06-10 23:50:39,432 [Datanode State Machine Thread - 0] INFO server.GrpcService: 41410284-0e36-4425-9317-2f8ae5197d6c: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2  | 2020-06-10 23:50:43,917 [Command processor thread] INFO impl.RaftServerProxy: 41410284-0e36-4425-9317-2f8ae5197d6c: addNew group-14E1D47FDFEF:[41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858] returns group-14E1D47FDFEF:java.util.concurrent.CompletableFuture@2cdc54f1[Not completed]
datanode_2  | 2020-06-10 23:50:44,027 [pool-20-thread-1] INFO impl.RaftServerImpl: 41410284-0e36-4425-9317-2f8ae5197d6c: new RaftServerImpl for group-14E1D47FDFEF:[41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-06-10 23:50:44,044 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-06-10 23:50:44,046 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-06-10 23:50:44,047 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-06-10 23:50:44,056 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-06-10 23:50:44,059 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/33992bd7f4c16024bb749900e60f3134e980d16a ; compiled by 'jenkins1001' on 2020-06-10T22:19Z
datanode_1  | STARTUP_MSG:   java = 11.0.6
datanode_1  | ************************************************************/
datanode_1  | 2020-06-10 23:50:04,368 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2020-06-10 23:50:06,478 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2020-06-10 23:50:07,148 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2020-06-10 23:50:08,317 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2020-06-10 23:50:08,317 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2020-06-10 23:50:08,860 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:29984dc17d72 ip:172.26.0.9
datanode_1  | 2020-06-10 23:50:11,774 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_1  | WARNING: An illegal reflective access operation has occurred
datanode_1  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar) to method sun.security.krb5.Config.getInstance()
datanode_1  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
datanode_1  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_1  | WARNING: All illegal access operations will be denied in a future release
datanode_1  | 2020-06-10 23:50:13,162 [main] INFO security.UserGroupInformation: Login successful for user dn/29984dc17d72@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode_1  | 2020-06-10 23:50:13,162 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode_1  | 2020-06-10 23:50:13,162 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode_1  | 2020-06-10 23:50:13,162 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_1  | 2020-06-10 23:50:13,163 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode_1  | 2020-06-10 23:50:13,195 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_1  | 2020-06-10 23:50:16,275 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode_1  | 2020-06-10 23:50:16,313 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.26.0.9,host:29984dc17d72
datanode_1  | 2020-06-10 23:50:16,332 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_1  | 2020-06-10 23:50:16,340 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@29984dc17d72
datanode_1  | 2020-06-10 23:50:18,579 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-06-10 23:50:19,580 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-06-10 23:50:20,582 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-06-10 23:50:21,583 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-06-10 23:50:22,584 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-06-10 23:50:23,585 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-06-10 23:50:24,587 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-06-10 23:50:25,588 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-06-10 23:50:26,589 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-06-10 23:50:31,286 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode_2  | 2020-06-10 23:50:44,081 [pool-20-thread-1] INFO impl.RaftServerImpl: 41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF: ConfigurationManager, init=-1: [41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-06-10 23:50:44,094 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-06-10 23:50:44,115 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-06-10 23:50:44,125 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a6cd6bc9-48b1-4d34-b2ca-14e1d47fdfef does not exist. Creating ...
datanode_2  | 2020-06-10 23:50:44,143 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a6cd6bc9-48b1-4d34-b2ca-14e1d47fdfef/in_use.lock acquired by nodename 6@e740903365c7
datanode_2  | 2020-06-10 23:50:44,155 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a6cd6bc9-48b1-4d34-b2ca-14e1d47fdfef has been successfully formatted.
datanode_2  | 2020-06-10 23:50:44,191 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-14E1D47FDFEF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-06-10 23:50:44,194 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-06-10 23:50:44,281 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-06-10 23:50:44,330 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-06-10 23:50:44,330 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-06-10 23:50:44,339 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-06-10 23:50:44,367 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF
datanode_2  | 2020-06-10 23:50:44,454 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-06-10 23:50:44,491 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new 41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/a6cd6bc9-48b1-4d34-b2ca-14e1d47fdfef
datanode_2  | 2020-06-10 23:50:44,495 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-06-10 23:50:44,497 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-06-10 23:50:44,507 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-06-10 23:50:44,509 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-06-10 23:50:44,521 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-06-10 23:50:44,527 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-06-10 23:50:44,535 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-06-10 23:50:44,538 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-06-10 23:50:44,538 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-06-10 23:50:44,652 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-06-10 23:50:44,698 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-06-10 23:50:44,721 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-06-10 23:50:44,736 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-06-10 23:50:44,742 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-06-10 23:50:44,743 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-06-10 23:50:44,746 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-06-10 23:50:44,746 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-06-10 23:50:44,832 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF
datanode_2  | 2020-06-10 23:50:44,835 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF
datanode_2  | 2020-06-10 23:50:44,870 [pool-20-thread-1] INFO impl.RaftServerImpl: 41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF: start as a follower, conf=-1: [41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858], old=null
datanode_2  | 2020-06-10 23:50:44,877 [pool-20-thread-1] INFO impl.RaftServerImpl: 41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-06-10 23:50:44,879 [pool-20-thread-1] INFO impl.RoleInfo: 41410284-0e36-4425-9317-2f8ae5197d6c: start FollowerState
datanode_2  | 2020-06-10 23:50:44,936 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-14E1D47FDFEF,id=41410284-0e36-4425-9317-2f8ae5197d6c
datanode_2  | 2020-06-10 23:50:44,938 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF
datanode_2  | 2020-06-10 23:50:45,065 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "a6cd6bc9-48b1-4d34-b2ca-14e1d47fdfef"
datanode_2  | .
datanode_2  | 2020-06-10 23:50:45,067 [Command processor thread] INFO impl.RaftServerProxy: 41410284-0e36-4425-9317-2f8ae5197d6c: addNew group-D686C3CE217F:[51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858] returns group-D686C3CE217F:java.util.concurrent.CompletableFuture@3ba873e8[Not completed]
datanode_2  | 2020-06-10 23:50:45,111 [pool-20-thread-1] INFO impl.RaftServerImpl: 41410284-0e36-4425-9317-2f8ae5197d6c: new RaftServerImpl for group-D686C3CE217F:[51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-06-10 23:50:45,119 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-06-10 23:50:45,124 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-06-10 23:50:45,124 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_2  | 2020-06-10 23:50:45,125 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-06-10 23:50:45,125 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-06-10 23:50:31,541 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2020-06-10 23:50:31,563 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1  | 2020-06-10 23:50:31,568 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2020-06-10 23:50:31,590 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2020-06-10 23:50:31,758 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2020-06-10 23:50:33,761 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2020-06-10 23:50:33,910 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1  | 2020-06-10 23:50:34,147 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1  | 2020-06-10 23:50:34,178 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  | 2020-06-10 23:50:34,179 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-06-10 23:50:34,179 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1  | 2020-06-10 23:50:34,183 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2020-06-10 23:50:35,312 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-06-10 23:50:35,609 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2020-06-10 23:50:35,609 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_1  | 2020-06-10 23:50:35,609 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode_1  | 2020-06-10 23:50:35,685 [main] INFO util.log: Logging initialized @36469ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2020-06-10 23:50:36,025 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2020-06-10 23:50:36,044 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2020-06-10 23:50:36,071 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_1  | 2020-06-10 23:50:36,071 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_1  | 2020-06-10 23:50:36,074 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_1  | 2020-06-10 23:50:36,088 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode_1  | 2020-06-10 23:50:36,234 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2020-06-10 23:50:36,239 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_1  | 2020-06-10 23:50:36,429 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  | 2020-06-10 23:50:36,432 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2020-06-10 23:50:36,438 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1  | 2020-06-10 23:50:36,466 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/29984dc17d72@EXAMPLE.COM
datanode_1  | 2020-06-10 23:50:36,472 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3dce6dd8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2020-06-10 23:50:36,483 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@28babeca{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2020-06-10 23:50:36,829 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/29984dc17d72@EXAMPLE.COM
datanode_1  | 2020-06-10 23:50:36,854 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@44f0ff2b{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-6552945839858970566.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1  | 2020-06-10 23:50:36,874 [main] INFO server.AbstractConnector: Started ServerConnector@2c1f8dbd{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_1  | 2020-06-10 23:50:36,878 [main] INFO server.Server: Started @37662ms
datanode_1  | 2020-06-10 23:50:36,888 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2020-06-10 23:50:36,889 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2020-06-10 23:50:36,893 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1  | 2020-06-10 23:50:36,979 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@77a4baaa] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2020-06-10 23:50:37,104 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.26.0.6:9891
datanode_1  | 2020-06-10 23:50:39,228 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 2020-06-10 23:50:39,248 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1  | 2020-06-10 23:50:39,248 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 51d66525-f84b-46be-9310-54df40bdb627 at port 9858
datanode_1  | 2020-06-10 23:50:39,330 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 51d66525-f84b-46be-9310-54df40bdb627: start RPC server
datanode_1  | 2020-06-10 23:50:39,609 [Datanode State Machine Thread - 0] INFO server.GrpcService: 51d66525-f84b-46be-9310-54df40bdb627: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1  | 2020-06-10 23:50:44,045 [Command processor thread] INFO impl.RaftServerProxy: 51d66525-f84b-46be-9310-54df40bdb627: addNew group-E62E5EF3DA8A:[51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858] returns group-E62E5EF3DA8A:java.util.concurrent.CompletableFuture@1e14d8c8[Not completed]
datanode_1  | 2020-06-10 23:50:44,124 [pool-20-thread-1] INFO impl.RaftServerImpl: 51d66525-f84b-46be-9310-54df40bdb627: new RaftServerImpl for group-E62E5EF3DA8A:[51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-06-10 23:50:44,126 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-06-10 23:50:44,126 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-06-10 23:50:44,126 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-06-10 23:50:44,129 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-06-10 23:50:44,130 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-06-10 23:50:44,148 [pool-20-thread-1] INFO impl.RaftServerImpl: 51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A: ConfigurationManager, init=-1: [51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-06-10 23:50:44,151 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-06-10 23:50:44,168 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-06-10 23:50:44,171 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/479f6f03-ae93-4e92-83ec-e62e5ef3da8a does not exist. Creating ...
datanode_1  | 2020-06-10 23:50:44,184 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/479f6f03-ae93-4e92-83ec-e62e5ef3da8a/in_use.lock acquired by nodename 6@29984dc17d72
datanode_1  | 2020-06-10 23:50:44,193 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/479f6f03-ae93-4e92-83ec-e62e5ef3da8a has been successfully formatted.
datanode_1  | 2020-06-10 23:50:44,209 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-E62E5EF3DA8A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-06-10 23:50:44,209 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-06-10 23:50:44,229 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-06-10 23:50:44,252 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-06-10 23:50:44,259 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-06-10 23:50:44,263 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-06-10 23:50:44,272 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A
datanode_1  | 2020-06-10 23:50:44,322 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-06-10 23:50:44,360 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new 51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/479f6f03-ae93-4e92-83ec-e62e5ef3da8a
datanode_1  | 2020-06-10 23:50:44,361 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-06-10 23:50:44,378 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-06-10 23:50:44,379 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-06-10 23:50:44,383 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-06-10 23:50:44,385 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-06-10 23:50:44,385 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-06-10 23:50:44,389 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-06-10 23:50:44,391 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-06-10 23:50:44,392 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-06-10 23:50:44,449 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-06-10 23:50:44,485 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-06-10 23:50:44,485 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-06-10 23:50:44,495 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-06-10 23:50:44,514 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-06-10 23:50:44,515 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-06-10 23:50:44,516 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-06-10 23:50:44,516 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-06-10 23:50:44,639 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A
datanode_1  | 2020-06-10 23:50:44,649 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A
datanode_1  | 2020-06-10 23:50:44,666 [pool-20-thread-1] INFO impl.RaftServerImpl: 51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A: start as a follower, conf=-1: [51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858], old=null
datanode_1  | 2020-06-10 23:50:44,716 [pool-20-thread-1] INFO impl.RaftServerImpl: 51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-06-10 23:50:44,717 [pool-20-thread-1] INFO impl.RoleInfo: 51d66525-f84b-46be-9310-54df40bdb627: start FollowerState
datanode_2  | 2020-06-10 23:50:45,125 [pool-20-thread-1] INFO impl.RaftServerImpl: 41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F: ConfigurationManager, init=-1: [51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-06-10 23:50:45,125 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-06-10 23:50:45,125 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-06-10 23:50:45,125 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e8e97232-1ec5-4e87-b560-d686c3ce217f does not exist. Creating ...
datanode_2  | 2020-06-10 23:50:45,151 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e8e97232-1ec5-4e87-b560-d686c3ce217f/in_use.lock acquired by nodename 6@e740903365c7
datanode_2  | 2020-06-10 23:50:45,167 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e8e97232-1ec5-4e87-b560-d686c3ce217f has been successfully formatted.
datanode_2  | 2020-06-10 23:50:45,171 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-D686C3CE217F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-06-10 23:50:45,185 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2020-06-10 23:50:45,185 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-06-10 23:50:45,185 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-06-10 23:50:45,185 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-06-10 23:50:45,185 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-06-10 23:50:45,186 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F
datanode_2  | 2020-06-10 23:50:45,186 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-06-10 23:50:45,186 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new 41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/e8e97232-1ec5-4e87-b560-d686c3ce217f
datanode_2  | 2020-06-10 23:50:45,186 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-06-10 23:50:45,186 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-06-10 23:50:45,186 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-06-10 23:50:45,186 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-06-10 23:50:45,186 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-06-10 23:50:45,186 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-06-10 23:50:45,186 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-06-10 23:50:45,187 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-06-10 23:50:45,187 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-06-10 23:50:45,194 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-06-10 23:50:45,195 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-06-10 23:50:45,195 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-06-10 23:50:45,203 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-06-10 23:50:45,203 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-06-10 23:50:45,203 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-06-10 23:50:45,203 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-06-10 23:50:45,203 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-06-10 23:50:45,204 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F
datanode_2  | 2020-06-10 23:50:45,204 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F
datanode_2  | 2020-06-10 23:50:45,206 [pool-20-thread-1] INFO impl.RaftServerImpl: 41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F: start as a follower, conf=-1: [51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858], old=null
datanode_2  | 2020-06-10 23:50:45,206 [pool-20-thread-1] INFO impl.RaftServerImpl: 41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-06-10 23:50:45,206 [pool-20-thread-1] INFO impl.RoleInfo: 41410284-0e36-4425-9317-2f8ae5197d6c: start FollowerState
datanode_2  | 2020-06-10 23:50:45,207 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D686C3CE217F,id=41410284-0e36-4425-9317-2f8ae5197d6c
datanode_2  | 2020-06-10 23:50:45,208 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F
datanode_2  | 2020-06-10 23:50:47,300 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "e8e97232-1ec5-4e87-b560-d686c3ce217f"
datanode_2  | .
datanode_2  | 2020-06-10 23:50:49,556 [grpc-default-executor-1] INFO impl.RaftServerImpl: 41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:6ece063b-e1a0-4363-8e78-5ecf0377c4b0
datanode_2  | 2020-06-10 23:50:49,560 [grpc-default-executor-1] INFO impl.RoleInfo: 41410284-0e36-4425-9317-2f8ae5197d6c: shutdown FollowerState
datanode_2  | 2020-06-10 23:50:49,561 [Thread-24] INFO impl.FollowerState: 41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_2  | 2020-06-10 23:50:49,562 [grpc-default-executor-1] INFO impl.RoleInfo: 41410284-0e36-4425-9317-2f8ae5197d6c: start FollowerState
datanode_2  | 2020-06-10 23:50:49,864 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D686C3CE217F with new leaderId: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0
datanode_1  | 2020-06-10 23:50:44,747 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E62E5EF3DA8A,id=51d66525-f84b-46be-9310-54df40bdb627
datanode_1  | 2020-06-10 23:50:44,748 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A
datanode_1  | 2020-06-10 23:50:44,823 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "479f6f03-ae93-4e92-83ec-e62e5ef3da8a"
datanode_1  | .
datanode_1  | 2020-06-10 23:50:44,823 [Command processor thread] INFO impl.RaftServerProxy: 51d66525-f84b-46be-9310-54df40bdb627: addNew group-D686C3CE217F:[51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858] returns group-D686C3CE217F:java.util.concurrent.CompletableFuture@65daf752[Not completed]
datanode_1  | 2020-06-10 23:50:44,850 [pool-20-thread-1] INFO impl.RaftServerImpl: 51d66525-f84b-46be-9310-54df40bdb627: new RaftServerImpl for group-D686C3CE217F:[51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-06-10 23:50:44,864 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-06-10 23:50:44,864 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-06-10 23:50:44,864 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_1  | 2020-06-10 23:50:44,864 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-06-10 23:50:44,865 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | Sleeping for 5 seconds
datanode_3  | Setting up kerberos!!
datanode_3  | KDC ISSUER_SERVER => kdc:8081
datanode_3  | Sleeping for 5 seconds
datanode_3  | Got 200, KDC service ready!!
datanode_3  | Download dn/7ed8bbd12868@EXAMPLE.COM keytab file to /etc/security/keytabs/dn.keytab
datanode_3  | --2020-06-10 23:49:59--  http://kdc:8081/keytab/7ed8bbd12868/dn
datanode_3  | Resolving kdc (kdc)... 172.26.0.8
datanode_3  | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_3  | Length: 158 [application/octet-stream]
datanode_3  | Saving to: '/etc/security/keytabs/dn.keytab'
datanode_3  | 
datanode_3  |      0K                                                       100% 9.36M=0s
datanode_3  | 
datanode_3  | 2020-06-10 23:50:00 (9.36 MB/s) - '/etc/security/keytabs/dn.keytab' saved [158/158]
datanode_3  | 
datanode_3  | Keytab name: FILE:/etc/security/keytabs/dn.keytab
datanode_3  | KVNO Timestamp         Principal
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_3  |    2 06/10/20 23:50:00 dn/7ed8bbd12868@EXAMPLE.COM
datanode_3  |    2 06/10/20 23:50:00 dn/7ed8bbd12868@EXAMPLE.COM
datanode_3  | Download HTTP/7ed8bbd12868@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
datanode_3  | --2020-06-10 23:50:00--  http://kdc:8081/keytab/7ed8bbd12868/HTTP
datanode_3  | Resolving kdc (kdc)... 172.26.0.8
datanode_3  | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
datanode_3  | HTTP request sent, awaiting response... 200 OK
datanode_3  | Length: 162 [application/octet-stream]
datanode_3  | Saving to: '/etc/security/keytabs/HTTP.keytab'
datanode_3  | 
datanode_3  |      0K                                                       100% 26.6M=0s
datanode_3  | 
datanode_3  | 2020-06-10 23:50:00 (26.6 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [162/162]
datanode_3  | 
datanode_3  | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
datanode_3  | KVNO Timestamp         Principal
datanode_3  | ---- ----------------- --------------------------------------------------------
datanode_3  |    2 06/10/20 23:50:00 HTTP/7ed8bbd12868@EXAMPLE.COM
datanode_3  |    2 06/10/20 23:50:00 HTTP/7ed8bbd12868@EXAMPLE.COM
datanode_3  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2020-06-10 23:50:06,315 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = 7ed8bbd12868/172.26.0.10
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.6.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/33992bd7f4c16024bb749900e60f3134e980d16a ; compiled by 'jenkins1001' on 2020-06-10T22:19Z
datanode_3  | STARTUP_MSG:   java = 11.0.6
datanode_3  | ************************************************************/
datanode_3  | 2020-06-10 23:50:06,354 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2020-06-10 23:50:08,588 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2020-06-10 23:50:09,295 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2020-06-10 23:50:10,566 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2020-06-10 23:50:10,567 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2020-06-10 23:50:11,163 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:7ed8bbd12868 ip:172.26.0.10
datanode_3  | 2020-06-10 23:50:13,977 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/_HOST@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_3  | WARNING: An illegal reflective access operation has occurred
datanode_3  | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar) to method sun.security.krb5.Config.getInstance()
datanode_3  | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
datanode_3  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_3  | WARNING: All illegal access operations will be denied in a future release
datanode_3  | 2020-06-10 23:50:15,040 [main] INFO security.UserGroupInformation: Login successful for user dn/7ed8bbd12868@EXAMPLE.COM using keytab file /etc/security/keytabs/dn.keytab
datanode_3  | 2020-06-10 23:50:15,040 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode_3  | 2020-06-10 23:50:15,043 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode_3  | 2020-06-10 23:50:15,045 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_3  | 2020-06-10 23:50:15,055 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode_3  | 2020-06-10 23:50:15,056 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_3  | 2020-06-10 23:50:17,781 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode_3  | 2020-06-10 23:50:17,851 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.26.0.10,host:7ed8bbd12868
datanode_3  | 2020-06-10 23:50:17,851 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_3  | 2020-06-10 23:50:17,865 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@7ed8bbd12868
datanode_3  | 2020-06-10 23:50:19,755 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-06-10 23:50:20,755 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-06-10 23:50:21,756 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-06-10 23:50:22,757 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-06-10 23:50:23,759 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-06-10 23:50:24,760 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-06-10 23:50:25,761 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-06-10 23:50:26,761 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9961. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-06-10 23:50:30,930 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode_3  | 2020-06-10 23:50:31,184 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3  | 2020-06-10 23:50:31,191 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3  | 2020-06-10 23:50:31,325 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2020-06-10 23:50:31,346 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2020-06-10 23:50:31,499 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2020-06-10 23:50:33,376 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-06-10 23:50:33,573 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3  | 2020-06-10 23:50:33,861 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3  | 2020-06-10 23:50:33,865 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3  | 2020-06-10 23:50:33,866 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-06-10 23:50:33,868 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3  | 2020-06-10 23:50:33,881 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-06-10 23:50:34,853 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-06-10 23:50:35,114 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2020-06-10 23:50:35,116 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_3  | 2020-06-10 23:50:35,124 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode_3  | 2020-06-10 23:50:35,189 [main] INFO util.log: Logging initialized @34421ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2020-06-10 23:50:35,637 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2020-06-10 23:50:35,650 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2020-06-10 23:50:35,685 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_3  | 2020-06-10 23:50:35,687 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_3  | 2020-06-10 23:50:35,687 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_3  | 2020-06-10 23:50:35,703 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode_3  | 2020-06-10 23:50:35,790 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2020-06-10 23:50:35,797 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
datanode_3  | 2020-06-10 23:50:35,926 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2020-06-10 23:50:35,943 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 2020-06-10 23:50:35,951 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_3  | 2020-06-10 23:50:35,982 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/7ed8bbd12868@EXAMPLE.COM
datanode_3  | 2020-06-10 23:50:35,984 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@19b02dfd{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2020-06-10 23:50:35,985 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3a7c678b{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2020-06-10 23:50:36,333 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/7ed8bbd12868@EXAMPLE.COM
datanode_3  | 2020-06-10 23:50:36,364 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@31834a2b{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_6_0-SNAPSHOT_jar-_-any-17220954736642133122.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2020-06-10 23:50:36,407 [main] INFO server.AbstractConnector: Started ServerConnector@4cdba2ed{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
datanode_3  | 2020-06-10 23:50:36,407 [main] INFO server.Server: Started @35639ms
datanode_3  | 2020-06-10 23:50:36,456 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2020-06-10 23:50:36,457 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2020-06-10 23:50:36,475 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3  | 2020-06-10 23:50:36,620 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@533f89e5] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2020-06-10 23:50:36,708 [Datanode State Machine Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.26.0.6:9891
datanode_3  | 2020-06-10 23:50:39,055 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3  | 2020-06-10 23:50:39,056 [Datanode State Machine Thread - 0] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3  | 2020-06-10 23:50:39,056 [Datanode State Machine Thread - 0] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 6ece063b-e1a0-4363-8e78-5ecf0377c4b0 at port 9858
datanode_3  | 2020-06-10 23:50:39,122 [Datanode State Machine Thread - 0] INFO impl.RaftServerProxy: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: start RPC server
datanode_3  | 2020-06-10 23:50:39,324 [Datanode State Machine Thread - 0] INFO server.GrpcService: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3  | 2020-06-10 23:50:43,612 [Command processor thread] INFO impl.RaftServerProxy: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: addNew group-4B093F28D9DC:[6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858] returns group-4B093F28D9DC:java.util.concurrent.CompletableFuture@10c1a978[Not completed]
datanode_3  | 2020-06-10 23:50:43,648 [pool-20-thread-1] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: new RaftServerImpl for group-4B093F28D9DC:[6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-06-10 23:50:43,652 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-06-10 23:50:43,652 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-06-10 23:50:43,652 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-06-10 23:50:43,653 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-06-10 23:50:43,654 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-06-10 23:50:43,663 [pool-20-thread-1] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC: ConfigurationManager, init=-1: [6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-06-10 23:50:43,664 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-06-10 23:50:44,865 [pool-20-thread-1] INFO impl.RaftServerImpl: 51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F: ConfigurationManager, init=-1: [51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-06-10 23:50:44,871 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-06-10 23:50:44,871 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-06-10 23:50:44,871 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e8e97232-1ec5-4e87-b560-d686c3ce217f does not exist. Creating ...
datanode_1  | 2020-06-10 23:50:44,895 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e8e97232-1ec5-4e87-b560-d686c3ce217f/in_use.lock acquired by nodename 6@29984dc17d72
datanode_1  | 2020-06-10 23:50:44,903 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e8e97232-1ec5-4e87-b560-d686c3ce217f has been successfully formatted.
datanode_1  | 2020-06-10 23:50:44,912 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-D686C3CE217F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-06-10 23:50:44,912 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2020-06-10 23:50:44,912 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-06-10 23:50:44,913 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-06-10 23:50:44,913 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-06-10 23:50:44,920 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-06-10 23:50:44,921 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F
datanode_1  | 2020-06-10 23:50:44,930 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-06-10 23:50:44,930 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new 51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/e8e97232-1ec5-4e87-b560-d686c3ce217f
datanode_1  | 2020-06-10 23:50:44,931 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-06-10 23:50:44,931 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-06-10 23:50:44,931 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-06-10 23:50:44,931 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-06-10 23:50:44,931 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-06-10 23:50:44,931 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-06-10 23:50:44,931 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-06-10 23:50:44,931 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-06-10 23:50:44,931 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-06-10 23:50:44,933 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-06-10 23:50:44,933 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-06-10 23:50:44,933 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-06-10 23:50:44,933 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-06-10 23:50:44,934 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-06-10 23:50:44,934 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-06-10 23:50:44,934 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-06-10 23:50:44,934 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-06-10 23:50:44,934 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F
datanode_1  | 2020-06-10 23:50:44,935 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F
datanode_1  | 2020-06-10 23:50:44,935 [pool-20-thread-1] INFO impl.RaftServerImpl: 51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F: start as a follower, conf=-1: [51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858], old=null
datanode_1  | 2020-06-10 23:50:44,936 [pool-20-thread-1] INFO impl.RaftServerImpl: 51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-06-10 23:50:44,936 [pool-20-thread-1] INFO impl.RoleInfo: 51d66525-f84b-46be-9310-54df40bdb627: start FollowerState
datanode_1  | 2020-06-10 23:50:44,945 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D686C3CE217F,id=51d66525-f84b-46be-9310-54df40bdb627
datanode_1  | 2020-06-10 23:50:44,946 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F
datanode_1  | 2020-06-10 23:50:47,218 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "e8e97232-1ec5-4e87-b560-d686c3ce217f"
datanode_1  | .
datanode_1  | 2020-06-10 23:50:49,548 [grpc-default-executor-0] INFO impl.RaftServerImpl: 51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:6ece063b-e1a0-4363-8e78-5ecf0377c4b0
datanode_1  | 2020-06-10 23:50:49,548 [grpc-default-executor-0] INFO impl.RoleInfo: 51d66525-f84b-46be-9310-54df40bdb627: shutdown FollowerState
datanode_1  | 2020-06-10 23:50:49,551 [grpc-default-executor-0] INFO impl.RoleInfo: 51d66525-f84b-46be-9310-54df40bdb627: start FollowerState
datanode_1  | 2020-06-10 23:50:49,558 [Thread-24] INFO impl.FollowerState: 51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
datanode_1  | 2020-06-10 23:50:49,757 [Thread-22] INFO impl.FollowerState: 51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-FollowerState: change to CANDIDATE, lastRpcTime:5040ms, electionTimeout:5019ms
datanode_1  | 2020-06-10 23:50:49,760 [Thread-22] INFO impl.RoleInfo: 51d66525-f84b-46be-9310-54df40bdb627: shutdown FollowerState
datanode_2  | 2020-06-10 23:50:49,883 [grpc-default-executor-1] INFO impl.RaftServerImpl: 41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F: change Leader from null to 6ece063b-e1a0-4363-8e78-5ecf0377c4b0 at term 1 for appendEntries, leader elected after 4679ms
datanode_2  | 2020-06-10 23:50:49,941 [Thread-22] INFO impl.FollowerState: 41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-FollowerState: change to CANDIDATE, lastRpcTime:5062ms, electionTimeout:5036ms
datanode_2  | 2020-06-10 23:50:49,946 [Thread-22] INFO impl.RoleInfo: 41410284-0e36-4425-9317-2f8ae5197d6c: shutdown FollowerState
datanode_2  | 2020-06-10 23:50:49,946 [Thread-22] INFO impl.RaftServerImpl: 41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-06-10 23:50:49,948 [Thread-22] INFO impl.RoleInfo: 41410284-0e36-4425-9317-2f8ae5197d6c: start LeaderElection
datanode_2  | 2020-06-10 23:50:49,986 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO impl.LeaderElection: 41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1: begin an election at term 1 for -1: [41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858], old=null
datanode_2  | 2020-06-10 23:50:50,004 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO impl.RoleInfo: 41410284-0e36-4425-9317-2f8ae5197d6c: shutdown LeaderElection
datanode_2  | 2020-06-10 23:50:50,004 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO impl.RaftServerImpl: 41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-06-10 23:50:50,004 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-14E1D47FDFEF with new leaderId: 41410284-0e36-4425-9317-2f8ae5197d6c
datanode_2  | 2020-06-10 23:50:50,005 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO impl.RaftServerImpl: 41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF: change Leader from null to 41410284-0e36-4425-9317-2f8ae5197d6c at term 1 for becomeLeader, leader elected after 5813ms
datanode_2  | 2020-06-10 23:50:50,028 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-06-10 23:50:50,028 [grpc-default-executor-1] INFO impl.RaftServerImpl: 41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F: set configuration 0: [51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858], old=null at 0
datanode_2  | 2020-06-10 23:50:50,039 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2020-06-10 23:50:50,041 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF
datanode_2  | 2020-06-10 23:50:50,072 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2020-06-10 23:50:50,065 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-06-10 23:50:50,080 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-06-10 23:50:50,099 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-06-10 23:50:50,099 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-06-10 23:50:50,100 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2020-06-10 23:50:50,175 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO impl.RoleInfo: 41410284-0e36-4425-9317-2f8ae5197d6c: start LeaderState
datanode_2  | 2020-06-10 23:50:50,198 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-06-10 23:50:50,216 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-LeaderElection1] INFO impl.RaftServerImpl: 41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF: set configuration 0: [41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858], old=null at 0
datanode_2  | 2020-06-10 23:50:50,325 [41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 41410284-0e36-4425-9317-2f8ae5197d6c@group-14E1D47FDFEF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a6cd6bc9-48b1-4d34-b2ca-14e1d47fdfef/current/log_inprogress_0
datanode_2  | 2020-06-10 23:50:50,328 [41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 41410284-0e36-4425-9317-2f8ae5197d6c@group-D686C3CE217F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e8e97232-1ec5-4e87-b560-d686c3ce217f/current/log_inprogress_0
datanode_2  | 2020-06-10 23:51:04,600 [ChunkWriter-8-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:5768277597818.
kms_1       | Sleeping for 5 seconds
kms_1       | Setting up kerberos!!
kms_1       | KDC ISSUER_SERVER => kdc:8081
kms_1       | Sleeping for  seconds
kms_1       | /opt/starter.sh: line 66: SLEEP_SECONDS: command not found
kms_1       | Got 200, KDC service ready!!
kms_1       | # Licensed to the Apache Software Foundation (ASF) under one or more
kms_1       | # contributor license agreements.  See the NOTICE file distributed with
kms_1       | # this work for additional information regarding copyright ownership.
kms_1       | # The ASF licenses this file to You under the Apache License, Version 2.0
kms_1       | # (the "License"); you may not use this file except in compliance with
kms_1       | # the License.  You may obtain a copy of the License at
kms_1       | #
kms_1       | #     http://www.apache.org/licenses/LICENSE-2.0
kms_1       | #
kms_1       | # Unless required by applicable law or agreed to in writing, software
kms_1       | # distributed under the License is distributed on an "AS IS" BASIS,
kms_1       | # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
kms_1       | # See the License for the specific language governing permissions and
kms_1       | # limitations under the License.
kms_1       | 
kms_1       | [logging]
kms_1       |  default = FILE:/var/log/krb5libs.log
kms_1       |  kdc = FILE:/var/log/krb5kdc.log
kms_1       |  admin_server = FILE:/var/log/kadmind.log
kms_1       | 
kms_1       | [libdefaults]
kms_1       |  dns_canonicalize_hostname = false
kms_1       |  dns_lookup_realm = false
kms_1       |  ticket_lifetime = 24h
kms_1       |  renew_lifetime = 7d
kms_1       |  forwardable = true
kms_1       |  rdns = false
kms_1       |  default_realm = EXAMPLE.COM
kms_1       | 
kms_1       | [realms]
kms_1       |  EXAMPLE.COM = {
kms_1       |   kdc = kdc
kms_1       |   admin_server = kdc
kms_1       |  }
kms_1       | 
kms_1       | [domain_realm]
kms_1       |  .example.com = EXAMPLE.COM
kms_1       | WARNING: /opt/hadoop/temp does not exist. Creating.
kms_1       | WARNING: /opt/hadoop/logs does not exist. Creating.
kms_1       | Jun 10, 2020 11:50:08 PM com.sun.jersey.api.core.PackagesResourceConfig init
kms_1       | INFO: Scanning for root resource and provider classes in the packages:
kms_1       |   org.apache.hadoop.crypto.key.kms.server
kms_1       | Jun 10, 2020 11:50:08 PM com.sun.jersey.api.core.ScanningResourceConfig logClasses
kms_1       | INFO: Root resource classes found:
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMS
kms_1       | Jun 10, 2020 11:50:08 PM com.sun.jersey.api.core.ScanningResourceConfig logClasses
kms_1       | INFO: Provider classes found:
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
kms_1       |   class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
kms_1       | Jun 10, 2020 11:50:08 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
kms_1       | INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
datanode_1  | 2020-06-10 23:50:49,760 [Thread-22] INFO impl.RaftServerImpl: 51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2020-06-10 23:50:49,762 [Thread-22] INFO impl.RoleInfo: 51d66525-f84b-46be-9310-54df40bdb627: start LeaderElection
datanode_1  | 2020-06-10 23:50:49,781 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO impl.LeaderElection: 51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1: begin an election at term 1 for -1: [51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858], old=null
datanode_1  | 2020-06-10 23:50:49,792 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO impl.RoleInfo: 51d66525-f84b-46be-9310-54df40bdb627: shutdown LeaderElection
datanode_1  | 2020-06-10 23:50:49,798 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO impl.RaftServerImpl: 51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2020-06-10 23:50:49,798 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-E62E5EF3DA8A with new leaderId: 51d66525-f84b-46be-9310-54df40bdb627
datanode_1  | 2020-06-10 23:50:49,811 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO impl.RaftServerImpl: 51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A: change Leader from null to 51d66525-f84b-46be-9310-54df40bdb627 at term 1 for becomeLeader, leader elected after 5589ms
datanode_1  | 2020-06-10 23:50:49,838 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2020-06-10 23:50:49,841 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2020-06-10 23:50:49,843 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A
datanode_1  | 2020-06-10 23:50:49,852 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2020-06-10 23:50:49,853 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1  | 2020-06-10 23:50:49,968 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D686C3CE217F with new leaderId: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0
datanode_1  | 2020-06-10 23:50:49,970 [grpc-default-executor-0] INFO impl.RaftServerImpl: 51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F: change Leader from null to 6ece063b-e1a0-4363-8e78-5ecf0377c4b0 at term 1 for appendEntries, leader elected after 5056ms
datanode_1  | 2020-06-10 23:50:49,988 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2020-06-10 23:50:50,017 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2020-06-10 23:50:50,026 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2020-06-10 23:50:50,032 [grpc-default-executor-0] INFO impl.RaftServerImpl: 51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F: set configuration 0: [51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858], old=null at 0
datanode_1  | 2020-06-10 23:50:50,067 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO impl.RoleInfo: 51d66525-f84b-46be-9310-54df40bdb627: start LeaderState
datanode_1  | 2020-06-10 23:50:50,127 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-06-10 23:50:50,165 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-06-10 23:50:50,255 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-LeaderElection1] INFO impl.RaftServerImpl: 51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A: set configuration 0: [51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858], old=null at 0
datanode_1  | 2020-06-10 23:50:50,473 [51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 51d66525-f84b-46be-9310-54df40bdb627@group-D686C3CE217F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e8e97232-1ec5-4e87-b560-d686c3ce217f/current/log_inprogress_0
datanode_1  | 2020-06-10 23:50:50,476 [51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 51d66525-f84b-46be-9310-54df40bdb627@group-E62E5EF3DA8A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/479f6f03-ae93-4e92-83ec-e62e5ef3da8a/current/log_inprogress_0
datanode_1  | 2020-06-10 23:51:04,700 [ChunkWriter-6-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:5768277597818.
datanode_3  | 2020-06-10 23:50:43,667 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-06-10 23:50:43,673 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fc783735-ce9d-42da-9b1f-4b093f28d9dc does not exist. Creating ...
datanode_3  | 2020-06-10 23:50:43,687 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fc783735-ce9d-42da-9b1f-4b093f28d9dc/in_use.lock acquired by nodename 6@7ed8bbd12868
datanode_3  | 2020-06-10 23:50:43,694 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fc783735-ce9d-42da-9b1f-4b093f28d9dc has been successfully formatted.
datanode_3  | 2020-06-10 23:50:43,701 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-4B093F28D9DC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-06-10 23:50:43,702 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-06-10 23:50:43,704 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-06-10 23:50:43,725 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-06-10 23:50:43,725 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-06-10 23:50:43,727 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-06-10 23:50:43,741 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC
datanode_3  | 2020-06-10 23:50:43,763 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-06-10 23:50:43,785 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/fc783735-ce9d-42da-9b1f-4b093f28d9dc
datanode_3  | 2020-06-10 23:50:43,789 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-06-10 23:50:43,790 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-06-10 23:50:43,790 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-06-10 23:50:43,791 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-06-10 23:50:43,791 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-06-10 23:50:43,791 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-06-10 23:50:43,795 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-06-10 23:50:43,796 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-06-10 23:50:43,800 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-06-10 23:50:43,831 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-06-10 23:50:43,841 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-06-10 23:50:43,841 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-06-10 23:50:43,856 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-06-10 23:50:43,863 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-06-10 23:50:43,869 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-06-10 23:50:43,870 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-06-10 23:50:43,870 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-06-10 23:50:44,089 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC
datanode_3  | 2020-06-10 23:50:44,093 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC
datanode_3  | 2020-06-10 23:50:44,128 [pool-20-thread-1] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC: start as a follower, conf=-1: [6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858], old=null
datanode_3  | 2020-06-10 23:50:44,131 [pool-20-thread-1] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-06-10 23:50:44,133 [pool-20-thread-1] INFO impl.RoleInfo: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: start FollowerState
datanode_3  | 2020-06-10 23:50:44,170 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4B093F28D9DC,id=6ece063b-e1a0-4363-8e78-5ecf0377c4b0
datanode_3  | 2020-06-10 23:50:44,171 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC
datanode_3  | 2020-06-10 23:50:44,244 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: "fc783735-ce9d-42da-9b1f-4b093f28d9dc"
datanode_3  | .
datanode_3  | 2020-06-10 23:50:44,245 [Command processor thread] INFO impl.RaftServerProxy: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: addNew group-D686C3CE217F:[51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858] returns group-D686C3CE217F:java.util.concurrent.CompletableFuture@1522ec6[Not completed]
datanode_3  | 2020-06-10 23:50:44,248 [pool-20-thread-1] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: new RaftServerImpl for group-D686C3CE217F:[51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-06-10 23:50:44,252 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-06-10 23:50:44,253 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-06-10 23:50:44,253 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
datanode_3  | 2020-06-10 23:50:44,253 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-06-10 23:50:44,253 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-06-10 23:50:44,253 [pool-20-thread-1] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F: ConfigurationManager, init=-1: [51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-06-10 23:50:44,253 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-06-10 23:50:44,254 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-06-10 23:50:44,255 [pool-20-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e8e97232-1ec5-4e87-b560-d686c3ce217f does not exist. Creating ...
datanode_3  | 2020-06-10 23:50:44,267 [pool-20-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e8e97232-1ec5-4e87-b560-d686c3ce217f/in_use.lock acquired by nodename 6@7ed8bbd12868
datanode_3  | 2020-06-10 23:50:44,278 [pool-20-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e8e97232-1ec5-4e87-b560-d686c3ce217f has been successfully formatted.
datanode_3  | 2020-06-10 23:50:44,278 [pool-20-thread-1] INFO ratis.ContainerStateMachine: group-D686C3CE217F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-06-10 23:50:44,292 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_3  | 2020-06-10 23:50:44,292 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-06-10 23:50:44,292 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-06-10 23:50:44,294 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-06-10 23:50:44,295 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-06-10 23:50:44,298 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F
datanode_3  | 2020-06-10 23:50:44,298 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-06-10 23:50:44,298 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: new 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/e8e97232-1ec5-4e87-b560-d686c3ce217f
datanode_3  | 2020-06-10 23:50:44,299 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-06-10 23:50:44,300 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-06-10 23:50:44,300 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-06-10 23:50:44,300 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-06-10 23:50:44,300 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-06-10 23:50:44,301 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-06-10 23:50:44,301 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-06-10 23:50:44,301 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-06-10 23:50:44,302 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-06-10 23:50:44,307 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-06-10 23:50:44,307 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-06-10 23:50:44,311 [pool-20-thread-1] INFO segmented.SegmentedRaftLogWorker: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-06-10 23:50:44,319 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-06-10 23:50:44,319 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-06-10 23:50:44,319 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-06-10 23:50:44,319 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-06-10 23:50:44,320 [pool-20-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-06-10 23:50:44,320 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F
datanode_3  | 2020-06-10 23:50:44,320 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F
datanode_3  | 2020-06-10 23:50:44,323 [pool-20-thread-1] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F: start as a follower, conf=-1: [51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858], old=null
datanode_3  | 2020-06-10 23:50:44,323 [pool-20-thread-1] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-06-10 23:50:44,323 [pool-20-thread-1] INFO impl.RoleInfo: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: start FollowerState
datanode_3  | 2020-06-10 23:50:44,323 [pool-20-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D686C3CE217F,id=6ece063b-e1a0-4363-8e78-5ecf0377c4b0
datanode_3  | 2020-06-10 23:50:44,327 [pool-20-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F
datanode_3  | 2020-06-10 23:50:47,227 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE #id: "e8e97232-1ec5-4e87-b560-d686c3ce217f"
datanode_3  | .
datanode_3  | 2020-06-10 23:50:49,185 [Thread-22] INFO impl.FollowerState: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-FollowerState: change to CANDIDATE, lastRpcTime:5052ms, electionTimeout:5016ms
datanode_3  | 2020-06-10 23:50:49,187 [Thread-22] INFO impl.RoleInfo: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: shutdown FollowerState
datanode_3  | 2020-06-10 23:50:49,187 [Thread-22] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2020-06-10 23:50:49,190 [Thread-22] INFO impl.RoleInfo: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: start LeaderElection
datanode_3  | 2020-06-10 23:50:49,273 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO impl.LeaderElection: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1: begin an election at term 1 for -1: [6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858], old=null
datanode_3  | 2020-06-10 23:50:49,275 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO impl.RoleInfo: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: shutdown LeaderElection
kdc_1       | krb5kdc: starting...
kdc_1       | Issuer is listening on : 8081kadmind: starting...
kdc_1       | otp: Loaded
kdc_1       | Jun 10 23:49:51 kdc krb5kdc[11](info): setting up network...
kdc_1       | krb5kdc: setsockopt(9,IPV6_V6ONLY,1) worked
kdc_1       | krb5kdc: setsockopt(11,IPV6_V6ONLY,1) worked
kdc_1       | Jun 10 23:49:51 kdc krb5kdc[11](info): set up 4 sockets
kdc_1       | Jun 10 23:49:51 kdc krb5kdc[11](info): commencing operation
kdc_1       | Jun 10 23:44:23 31fed8a01bd2 kadmin.local[1](info): No dictionary file specified, continuing without one.
kdc_1       | Jun 10 23:44:24 b005dd801e2b kadmin.local[1](info): No dictionary file specified, continuing without one.
kdc_1       | Jun 10 23:49:55 kdc kadmind[16](info): No dictionary file specified, continuing without one.
kdc_1       | Jun 10 23:49:55 kdc kadmind[16](info): setting up network...
kdc_1       | kadmind: setsockopt(9,IPV6_V6ONLY,1) worked
kdc_1       | kadmind: setsockopt(11,IPV6_V6ONLY,1) worked
kdc_1       | kadmind: setsockopt(13,IPV6_V6ONLY,1) worked
kdc_1       | Jun 10 23:49:55 kdc kadmind[16](info): set up 6 sockets
kdc_1       | Jun 10 23:49:55 kdc kadmind[16](info): Seeding random number generator
kdc_1       | Jun 10 23:49:55 kdc kadmind[16](info): starting
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for test/test@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "test/test@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
kdc_1       | Entry for principal test/test@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/test.test.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for dn/29984dc17d72@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "dn/29984dc17d72@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal dn/29984dc17d72@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.29984dc17d72.keytab.
kdc_1       | Entry for principal dn/29984dc17d72@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.29984dc17d72.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for dn/e740903365c7@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "dn/e740903365c7@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal dn/e740903365c7@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.e740903365c7.keytab.
kdc_1       | Entry for principal dn/e740903365c7@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.e740903365c7.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/29984dc17d72@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/29984dc17d72@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/29984dc17d72@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.29984dc17d72.keytab.
kdc_1       | Entry for principal HTTP/29984dc17d72@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.29984dc17d72.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/e740903365c7@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/e740903365c7@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/e740903365c7@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.e740903365c7.keytab.
kdc_1       | Entry for principal HTTP/e740903365c7@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.e740903365c7.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for om/om@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "om/om@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal om/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om.keytab.
kdc_1       | Entry for principal om/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/om.om.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/om@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/om@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/om@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om.keytab.
kdc_1       | Entry for principal HTTP/om@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.om.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for scm/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "scm/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832998, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832998, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832998, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832998, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | Sleeping for 5 seconds
om_1        | Setting up kerberos!!
om_1        | KDC ISSUER_SERVER => kdc:8081
om_1        | Sleeping for 5 seconds
om_1        | Got 200, KDC service ready!!
om_1        | Download om/om@EXAMPLE.COM keytab file to /etc/security/keytabs/om.keytab
om_1        | --2020-06-10 23:49:59--  http://kdc:8081/keytab/om/om
om_1        | Resolving kdc (kdc)... 172.26.0.8
om_1        | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
om_1        | HTTP request sent, awaiting response... 200 OK
om_1        | Length: 138 [application/octet-stream]
om_1        | Saving to: '/etc/security/keytabs/om.keytab'
om_1        | 
om_1        |      0K                                                       100% 18.5M=0s
om_1        | 
om_1        | 2020-06-10 23:49:59 (18.5 MB/s) - '/etc/security/keytabs/om.keytab' saved [138/138]
om_1        | 
om_1        | Keytab name: FILE:/etc/security/keytabs/om.keytab
om_1        | KVNO Timestamp         Principal
om_1        | ---- ----------------- --------------------------------------------------------
om_1        |    2 06/10/20 23:49:59 om/om@EXAMPLE.COM
om_1        |    2 06/10/20 23:49:59 om/om@EXAMPLE.COM
om_1        | Download HTTP/om@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
om_1        | --2020-06-10 23:49:59--  http://kdc:8081/keytab/om/HTTP
om_1        | Resolving kdc (kdc)... 172.26.0.8
om_1        | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
om_1        | HTTP request sent, awaiting response... 200 OK
om_1        | Length: 142 [application/octet-stream]
om_1        | Saving to: '/etc/security/keytabs/HTTP.keytab'
om_1        | 
om_1        |      0K                                                       100% 20.2M=0s
om_1        | 
om_1        | 2020-06-10 23:49:59 (20.2 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [142/142]
om_1        | 
om_1        | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
om_1        | KVNO Timestamp         Principal
om_1        | ---- ----------------- --------------------------------------------------------
om_1        |    2 06/10/20 23:49:59 HTTP/om@EXAMPLE.COM
om_1        |    2 06/10/20 23:49:59 HTTP/om@EXAMPLE.COM
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-06-10 23:50:06,364 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = om/172.26.0.3
om_1        | STARTUP_MSG:   args = [--init]
om_1        | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832998, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832998, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832998, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832998, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_create_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_get_principal, test/test@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_create_principal, dn/29984dc17d72@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, dn/29984dc17d72@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_get_principal, dn/29984dc17d72@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](info): closing down fd 18
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/33992bd7f4c16024bb749900e60f3134e980d16a ; compiled by 'jenkins1001' on 2020-06-10T22:20Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-06-10 23:50:06,457 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-06-10 23:50:11,617 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-06-10 23:50:11,894 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.26.0.3:9862
om_1        | 2020-06-10 23:50:11,894 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | WARNING: An illegal reflective access operation has occurred
om_1        | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar) to method sun.security.krb5.Config.getInstance()
om_1        | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
om_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
om_1        | WARNING: All illegal access operations will be denied in a future release
om_1        | 2020-06-10 23:50:13,449 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om_1        | 2020-06-10 23:50:13,457 [main] INFO om.OzoneManager: Ozone Manager login successful.
om_1        | 2020-06-10 23:50:13,495 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-06-10 23:50:15,351 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-10 23:50:16,352 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-10 23:50:17,353 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-10 23:50:18,354 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-10 23:50:19,355 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-10 23:50:20,357 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-10 23:50:21,358 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-10 23:50:22,358 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-10 23:50:23,359 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-10 23:50:24,360 [main] INFO ipc.Client: Retrying connect to server: scm/172.26.0.4:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1        | 2020-06-10 23:50:24,365 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1        | 2020-06-10 23:50:30,355 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om_1        | 2020-06-10 23:50:31,787 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om_1        | 2020-06-10 23:50:31,788 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om_1        | 2020-06-10 23:50:31,789 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om_1        | 2020-06-10 23:50:34,897 [main] INFO om.OzoneManager: Init response: GETCERT
om_1        | 2020-06-10 23:50:34,989 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.26.0.3,host:om
om_1        | 2020-06-10 23:50:35,011 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om_1        | 2020-06-10 23:50:35,014 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-06-10 23:50:35,027 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.26.0.3:9862
om_1        | 2020-06-10 23:50:35,027 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-06-10 23:50:35,029 [main] INFO om.OzoneManager: Creating csr for OM->dns:om,ip:172.26.0.3,scmId:2ec909ec-40cc-460d-9ba3-fb00ab4f7548,clusterId:CID-c55b3d7f-33e0-4d68-8f03-e77183ab587e,subject:root@om
om_1        | 2020-06-10 23:50:35,491 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om_1        | value: 9862
om_1        | ]
om_1        | 2020-06-10 23:50:35,901 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-c55b3d7f-33e0-4d68-8f03-e77183ab587e
om_1        | 2020-06-10 23:50:35,996 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om_1        | /************************************************************
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om/172.26.0.3
om_1        | ************************************************************/
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2020-06-10 23:50:38,638 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = om/172.26.0.3
om_1        | STARTUP_MSG:   args = []
om_1        | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/33992bd7f4c16024bb749900e60f3134e980d16a ; compiled by 'jenkins1001' on 2020-06-10T22:20Z
om_1        | STARTUP_MSG:   java = 11.0.6
om_1        | ************************************************************/
om_1        | 2020-06-10 23:50:38,668 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2020-06-10 23:50:40,822 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2020-06-10 23:50:40,916 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/172.26.0.3:9862
om_1        | 2020-06-10 23:50:40,921 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2020-06-10 23:50:40,926 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | WARNING: An illegal reflective access operation has occurred
om_1        | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar) to method sun.security.krb5.Config.getInstance()
om_1        | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
om_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
om_1        | WARNING: All illegal access operations will be denied in a future release
om_1        | 2020-06-10 23:50:41,282 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file /etc/security/keytabs/om.keytab
om_1        | 2020-06-10 23:50:41,282 [main] INFO om.OzoneManager: Ozone Manager login successful.
om_1        | 2020-06-10 23:50:41,283 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-06-10 23:50:42,758 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om_1        | 2020-06-10 23:50:42,937 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1.crt.
om_1        | 2020-06-10 23:50:42,945 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/5768277597818.crt.
om_1        | 2020-06-10 23:50:42,971 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2020-06-10 23:50:43,421 [main] INFO Configuration.deprecation: No unit for ozone.manager.delegation.remover.scan.interval(3600000) assuming MILLISECONDS
om_1        | 2020-06-10 23:50:43,424 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om_1        | 2020-06-10 23:50:43,424 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om_1        | 2020-06-10 23:50:43,483 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2020-06-10 23:50:43,489 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1        | 2020-06-10 23:50:43,710 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | 2020-06-10 23:50:43,844 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2020-06-10 23:50:43,844 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1        | 2020-06-10 23:50:43,938 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.26.0.3:9862
om_1        | 2020-06-10 23:50:43,946 [Listener at om/9862] INFO om.OzoneManager: Reading keypair and certificate from file system.
om_1        | 2020-06-10 23:50:44,006 [Listener at om/9862] INFO om.OzoneManager: Starting OM block token secret manager
om_1        | 2020-06-10 23:50:44,011 [Listener at om/9862] INFO security.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om_1        | 2020-06-10 23:50:44,012 [Listener at om/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om_1        | 2020-06-10 23:50:44,017 [Listener at om/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om_1        | 2020-06-10 23:50:44,030 [Thread[Thread-8,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om_1        | 2020-06-10 23:50:44,110 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1        | 2020-06-10 23:50:44,133 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1        | 2020-06-10 23:50:44,489 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1        | 2020-06-10 23:50:44,534 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om_1        | 2020-06-10 23:50:44,535 [Listener at om/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om_1        | 2020-06-10 23:50:44,639 [Listener at om/9862] INFO util.log: Logging initialized @8211ms to org.eclipse.jetty.util.log.Slf4jLog
om_1        | 2020-06-10 23:50:44,898 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1        | 2020-06-10 23:50:44,910 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1        | 2020-06-10 23:50:44,912 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om_1        | 2020-06-10 23:50:44,913 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om_1        | 2020-06-10 23:50:44,914 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_create_principal, dn/e740903365c7@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, dn/e740903365c7@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_get_principal, dn/e740903365c7@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_create_principal, HTTP/29984dc17d72@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, HTTP/29984dc17d72@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](Notice): Request: kadm5_get_principal, HTTP/29984dc17d72@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:58 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_create_principal, HTTP/e740903365c7@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, HTTP/e740903365c7@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_principal, HTTP/e740903365c7@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_create_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_principal, om/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_create_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_principal, HTTP/om@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_create_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_principal, scm/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
datanode_3  | 2020-06-10 23:50:49,283 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-06-10 23:50:49,283 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4B093F28D9DC with new leaderId: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0
datanode_3  | 2020-06-10 23:50:49,285 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC: change Leader from null to 6ece063b-e1a0-4363-8e78-5ecf0377c4b0 at term 1 for becomeLeader, leader elected after 5582ms
datanode_3  | 2020-06-10 23:50:49,293 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-06-10 23:50:49,311 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-06-10 23:50:49,313 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC
datanode_3  | 2020-06-10 23:50:49,326 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-06-10 23:50:49,338 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-06-10 23:50:49,326 [Thread-24] INFO impl.FollowerState: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-FollowerState: change to CANDIDATE, lastRpcTime:5002ms, electionTimeout:5002ms
datanode_3  | 2020-06-10 23:50:49,341 [Thread-24] INFO impl.RoleInfo: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: shutdown FollowerState
datanode_3  | 2020-06-10 23:50:49,341 [Thread-24] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2020-06-10 23:50:49,341 [Thread-24] INFO impl.RoleInfo: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: start LeaderElection
datanode_3  | 2020-06-10 23:50:49,364 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO impl.LeaderElection: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2: begin an election at term 1 for -1: [51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858], old=null
datanode_3  | 2020-06-10 23:50:49,386 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-06-10 23:50:49,387 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-06-10 23:50:49,390 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-06-10 23:50:49,502 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO impl.RoleInfo: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: start LeaderState
datanode_3  | 2020-06-10 23:50:49,617 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO impl.LeaderElection: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2: Election PASSED; received 1 response(s) [6ece063b-e1a0-4363-8e78-5ecf0377c4b0<-51d66525-f84b-46be-9310-54df40bdb627#0:OK-t1] and 0 exception(s); 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F:t1, leader=null, voted=6ece063b-e1a0-4363-8e78-5ecf0377c4b0, raftlog=6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858], old=null
datanode_3  | 2020-06-10 23:50:49,618 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO impl.RoleInfo: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: shutdown LeaderElection
datanode_3  | 2020-06-10 23:50:49,618 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-06-10 23:50:49,618 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D686C3CE217F with new leaderId: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0
datanode_3  | 2020-06-10 23:50:49,618 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F: change Leader from null to 6ece063b-e1a0-4363-8e78-5ecf0377c4b0 at term 1 for becomeLeader, leader elected after 5325ms
datanode_3  | 2020-06-10 23:50:49,621 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-06-10 23:50:49,621 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-06-10 23:50:49,623 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F
datanode_3  | 2020-06-10 23:50:49,623 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-06-10 23:50:49,623 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-06-10 23:50:49,623 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-06-10 23:50:49,623 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-06-10 23:50:49,624 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-06-10 23:50:49,607 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-06-10 23:50:49,668 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2020-06-10 23:50:49,678 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-06-10 23:50:49,679 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 2020-06-10 23:50:49,685 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2020-06-10 23:50:49,690 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-06-10 23:50:49,690 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-06-10 23:50:49,691 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F
datanode_3  | 2020-06-10 23:50:49,707 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2020-06-10 23:50:49,707 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-06-10 23:50:49,707 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 2020-06-10 23:50:49,717 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2020-06-10 23:50:49,717 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-06-10 23:50:49,718 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-06-10 23:50:49,731 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO impl.RoleInfo: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0: start LeaderState
datanode_3  | 2020-06-10 23:50:49,731 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-06-10 23:50:49,776 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-LeaderElection2] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F: set configuration 0: [51d66525-f84b-46be-9310-54df40bdb627:172.26.0.9:9858, 6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858, 41410284-0e36-4425-9317-2f8ae5197d6c:172.26.0.2:9858], old=null at 0
datanode_3  | 2020-06-10 23:50:49,787 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-LeaderElection1] INFO impl.RaftServerImpl: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC: set configuration 0: [6ece063b-e1a0-4363-8e78-5ecf0377c4b0:172.26.0.10:9858], old=null at 0
datanode_3  | 2020-06-10 23:50:50,269 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-D686C3CE217F-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e8e97232-1ec5-4e87-b560-d686c3ce217f/current/log_inprogress_0
datanode_3  | 2020-06-10 23:50:50,279 [6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0@group-4B093F28D9DC-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fc783735-ce9d-42da-9b1f-4b093f28d9dc/current/log_inprogress_0
datanode_3  | 2020-06-10 23:51:04,332 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:5768277597818.
datanode_3  | 2020-06-11 00:02:19,003 [grpc-default-executor-4] ERROR ratis.ContainerStateMachine: startTransaction validation failed on leader
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Block token verification failed. Fail to find any token (empty or null.)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.validateContainerCommand(HddsDispatcher.java:495)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.startTransaction(ContainerStateMachine.java:314)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:623)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$7(RaftServerProxy.java:338)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$5(RaftServerProxy.java:333)
datanode_3  | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:109)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$6(RaftServerProxy.java:333)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1106)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2235)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:332)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:338)
datanode_3  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:225)
datanode_3  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolService$OrderedRequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:331)
datanode_3  | 	at org.apache.ratis.util.SlidingWindow$Server.processRequestsFromHead(SlidingWindow.java:429)
datanode_3  | 	at org.apache.ratis.util.SlidingWindow$Server.receivedRequest(SlidingWindow.java:421)
datanode_3  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolService$OrderedRequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:355)
datanode_3  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:245)
datanode_3  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:168)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.hadoop.hdds.security.token.BlockTokenException: Fail to find any token (empty or null.)
datanode_3  | 	at org.apache.hadoop.hdds.security.token.BlockTokenVerifier.verify(BlockTokenVerifier.java:68)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.validateBlockToken(HddsDispatcher.java:426)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.validateContainerCommand(HddsDispatcher.java:492)
datanode_3  | 	... 26 more
datanode_3  | 2020-06-11 00:02:19,170 [grpc-default-executor-5] ERROR ratis.ContainerStateMachine: startTransaction validation failed on leader
kdc_1       | Entry for principal scm/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/scm.scm.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
kdc_1       | Entry for principal HTTP/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.scm.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
kdc_1       | Entry for principal testuser/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.scm.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for recon/recon@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "recon/recon@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal recon/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/recon.recon.keytab.
kdc_1       | Entry for principal recon/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/recon.recon.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser2/scm@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser2/scm@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
kdc_1       | Entry for principal testuser2/scm@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser2.scm.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for dn/7ed8bbd12868@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "dn/7ed8bbd12868@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal dn/7ed8bbd12868@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.7ed8bbd12868.keytab.
kdc_1       | Entry for principal dn/7ed8bbd12868@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/dn.7ed8bbd12868.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/recon@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/recon@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
kdc_1       | Entry for principal HTTP/recon@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.recon.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/7ed8bbd12868@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/7ed8bbd12868@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/7ed8bbd12868@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.7ed8bbd12868.keytab.
kdc_1       | Entry for principal HTTP/7ed8bbd12868@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.7ed8bbd12868.keytab.
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_create_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_principal, HTTP/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_create_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_principal, testuser/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Block token verification failed. Fail to find any token (empty or null.)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.validateContainerCommand(HddsDispatcher.java:495)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.startTransaction(ContainerStateMachine.java:314)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:623)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$7(RaftServerProxy.java:338)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$5(RaftServerProxy.java:333)
datanode_3  | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:109)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$6(RaftServerProxy.java:333)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1106)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2235)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:332)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:338)
datanode_3  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:225)
datanode_3  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolService$OrderedRequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:331)
datanode_3  | 	at org.apache.ratis.util.SlidingWindow$Server.processRequestsFromHead(SlidingWindow.java:429)
datanode_3  | 	at org.apache.ratis.util.SlidingWindow$Server.receivedRequest(SlidingWindow.java:421)
datanode_3  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolService$OrderedRequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:355)
datanode_3  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:245)
datanode_3  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:168)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.hadoop.hdds.security.token.BlockTokenException: Fail to find any token (empty or null.)
datanode_3  | 	at org.apache.hadoop.hdds.security.token.BlockTokenVerifier.verify(BlockTokenVerifier.java:68)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.validateBlockToken(HddsDispatcher.java:426)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.validateContainerCommand(HddsDispatcher.java:492)
datanode_3  | 	... 26 more
datanode_3  | 2020-06-11 00:02:19,288 [grpc-default-executor-5] ERROR ratis.ContainerStateMachine: startTransaction validation failed on leader
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Block token verification failed. Fail to find any token (empty or null.)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.validateContainerCommand(HddsDispatcher.java:495)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.ratis.ContainerStateMachine.startTransaction(ContainerStateMachine.java:314)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:623)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitClientRequestAsync$7(RaftServerProxy.java:338)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$null$5(RaftServerProxy.java:333)
datanode_3  | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:109)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.lambda$submitRequest$6(RaftServerProxy.java:333)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1106)
datanode_3  | 	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2235)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.submitRequest(RaftServerProxy.java:332)
datanode_3  | 	at org.apache.ratis.server.impl.RaftServerProxy.submitClientRequestAsync(RaftServerProxy.java:338)
datanode_3  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:225)
datanode_3  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolService$OrderedRequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:331)
datanode_3  | 	at org.apache.ratis.util.SlidingWindow$Server.processRequestsFromHead(SlidingWindow.java:429)
datanode_3  | 	at org.apache.ratis.util.SlidingWindow$Server.receivedRequest(SlidingWindow.java:421)
datanode_3  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolService$OrderedRequestStreamObserver.processClientRequest(GrpcClientProtocolService.java:355)
datanode_3  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:245)
datanode_3  | 	at org.apache.ratis.grpc.client.GrpcClientProtocolService$RequestStreamObserver.onNext(GrpcClientProtocolService.java:168)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:782)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: org.apache.hadoop.hdds.security.token.BlockTokenException: Fail to find any token (empty or null.)
datanode_3  | 	at org.apache.hadoop.hdds.security.token.BlockTokenVerifier.verify(BlockTokenVerifier.java:68)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.validateBlockToken(HddsDispatcher.java:426)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.validateContainerCommand(HddsDispatcher.java:492)
datanode_3  | 	... 26 more
om_1        | 2020-06-10 23:50:44,924 [Listener at om/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om_1        | 2020-06-10 23:50:45,008 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1        | 2020-06-10 23:50:45,009 [Listener at om/9862] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
om_1        | 2020-06-10 23:50:45,114 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 2020-06-10 23:50:45,114 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1        | 2020-06-10 23:50:45,140 [Listener at om/9862] INFO server.session: node0 Scavenging every 660000ms
om_1        | 2020-06-10 23:50:45,297 [Listener at om/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om_1        | 2020-06-10 23:50:45,304 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4f169009{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 2020-06-10 23:50:45,305 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@76e90da5{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | 2020-06-10 23:50:46,323 [Listener at om/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om_1        | 2020-06-10 23:50:46,401 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@27fe059d{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_6_0-SNAPSHOT_jar-_-any-16569061555501036929.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1        | 2020-06-10 23:50:46,441 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@2349f14d{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1        | 2020-06-10 23:50:46,454 [Listener at om/9862] INFO server.Server: Started @10026ms
om_1        | 2020-06-10 23:50:46,465 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1        | 2020-06-10 23:50:46,465 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 2020-06-10 23:50:46,469 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1        | 2020-06-10 23:50:46,520 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5403799b] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1        | 2020-06-10 23:50:49,666 [qtp1916139819-131] INFO om.OMDBCheckpointServlet: Received request to obtain OM DB checkpoint snapshot
om_1        | 2020-06-10 23:50:49,698 [qtp1916139819-131] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1591833049671 in 23 milliseconds
om_1        | 2020-06-10 23:50:49,747 [qtp1916139819-131] INFO om.OMDBCheckpointServlet: Time taken to write the checkpoint to response output stream: 47 milliseconds
om_1        | 2020-06-10 23:50:49,747 [qtp1916139819-131] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1591833049671
om_1        | 2020-06-10 23:51:01,160 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:51:01,170 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:51:02,150 [IPC Server handler 1 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-94665 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-10 23:51:02,510 [IPC Server handler 4 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-1-45214 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-10 23:51:02,522 [IPC Server handler 7 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-2-73598 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-10 23:51:02,535 [IPC Server handler 3 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-3-53489 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-10 23:51:02,545 [IPC Server handler 8 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-4-05448 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-10 23:51:50,499 [qtp1916139819-134] INFO om.OMDBCheckpointServlet: Received request to obtain OM DB checkpoint snapshot
om_1        | 2020-06-10 23:51:50,636 [qtp1916139819-134] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1591833110500 in 131 milliseconds
om_1        | 2020-06-10 23:51:50,651 [qtp1916139819-134] INFO om.OMDBCheckpointServlet: Time taken to write the checkpoint to response output stream: 14 milliseconds
om_1        | 2020-06-10 23:51:50,651 [qtp1916139819-134] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1591833110500
om_1        | 2020-06-10 23:51:50,814 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:51:50,824 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:51:52,933 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:51:52,952 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:51:53,181 [IPC Server handler 89 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:28206-rpcwoport for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-10 23:51:54,985 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:51:54,999 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:51:57,057 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:51:57,071 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:51:59,291 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:51:59,324 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:01,469 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:01,482 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:03,629 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:03,640 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:05,893 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:05,902 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:08,052 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:08,063 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:10,337 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:10,363 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:14,065 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:14,077 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:17,647 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:17,655 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:21,421 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:21,449 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:24,932 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:24,945 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:27,213 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:27,232 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:29,238 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:29,249 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:33,212 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:33,225 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:36,908 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:36,923 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:38,895 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:38,906 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:40,898 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:40,908 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:44,439 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:44,455 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:46,813 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:46,837 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:49,330 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:49,343 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:51,279 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:51,284 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:51,511 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:51,535 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:53,839 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:53,867 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:56,045 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:56,060 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:52:58,284 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:52:58,299 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:00,478 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:00,494 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:00,753 [IPC Server handler 60 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:28206-rpcwoport2 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-10 23:53:02,532 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:02,562 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:04,762 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:04,787 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:06,971 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:06,980 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:09,165 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:09,179 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:11,173 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:11,186 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:13,357 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:13,371 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:15,371 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:15,387 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:17,886 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:17,900 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:19,998 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:20,022 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:22,268 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:22,278 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:22,497 [IPC Server handler 96 on default port 9862] ERROR acl.OMBucketAddAclRequest: Add acl [user:superuser1:rwxy[ACCESS]] to path /28206-rpcwoport2/bb1 failed, because acl already exist
om_1        | 2020-06-10 23:53:24,279 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:24,292 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:26,589 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:26,597 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:28,605 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:28,619 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:30,751 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:30,765 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:32,791 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:32,803 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:35,181 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:35,191 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:38,709 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:38,723 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:40,768 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:40,781 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:42,799 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:42,810 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:45,169 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:45,177 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_create_principal, recon/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, recon/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_principal, recon/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_create_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_principal, testuser2/scm@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](Notice): Request: kadm5_create_principal, dn/7ed8bbd12868@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:49:59 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, dn/7ed8bbd12868@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_get_principal, dn/7ed8bbd12868@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_create_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_get_principal, HTTP/recon@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_create_principal, HTTP/7ed8bbd12868@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, HTTP/7ed8bbd12868@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_get_principal, HTTP/7ed8bbd12868@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
om_1        | 2020-06-10 23:53:47,267 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:47,283 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:49,573 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:49,590 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:51,482 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:51,504 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:51,698 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:51,709 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:54,037 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:54,087 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:56,060 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:56,069 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:53:56,301 [IPC Server handler 91 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:28206-rpcwport for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-10 23:53:58,031 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:53:58,041 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:00,232 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:00,248 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:02,413 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:02,427 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:04,593 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:04,609 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:06,843 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:06,853 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:09,083 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:09,095 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:11,389 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:11,397 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:13,606 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:13,629 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:17,426 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:17,441 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:20,815 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:20,827 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:24,545 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:24,557 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:27,993 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:28,005 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:30,169 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:30,182 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:32,130 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:32,144 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:36,289 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:36,301 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:39,795 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:39,806 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:41,783 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:41,795 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:43,636 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:43,651 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:47,181 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:47,195 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:49,466 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:49,480 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:51,563 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:51,585 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:51,821 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:51,833 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:53,873 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:53,887 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:56,107 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:56,123 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:54:58,248 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:54:58,256 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:00,234 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:00,246 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:02,232 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:02,240 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:49:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591832999, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591833000, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591833000, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591833000, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591833000, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for s3g/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "s3g/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
kdc_1       | Entry for principal s3g/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/s3g.s3g.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for HTTP/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "HTTP/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
kdc_1       | Entry for principal HTTP/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/HTTP.s3g.keytab.
kdc_1       | Generiting keytab
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | WARNING: no policy specified for testuser/s3g@EXAMPLE.COM; defaulting to no policy
kdc_1       | Principal "testuser/s3g@EXAMPLE.COM" created.
kdc_1       | Authenticating as principal admin/admin with keytab /tmp/admin.keytab.
kdc_1       | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
kdc_1       | Entry for principal testuser/s3g@EXAMPLE.COM with kvno 2, encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:/data/testuser.s3g.keytab.
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_create_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_get_principal, s3g/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
recon_1     | Sleeping for 5 seconds
recon_1     | Setting up kerberos!!
recon_1     | KDC ISSUER_SERVER => kdc:8081
recon_1     | Sleeping for 5 seconds
recon_1     | Got 200, KDC service ready!!
recon_1     | Download recon/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/recon.keytab
recon_1     | --2020-06-10 23:49:59--  http://kdc:8081/keytab/recon/recon
recon_1     | Resolving kdc (kdc)... 172.26.0.8
recon_1     | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
recon_1     | HTTP request sent, awaiting response... 200 OK
recon_1     | Length: 150 [application/octet-stream]
recon_1     | Saving to: '/etc/security/keytabs/recon.keytab'
recon_1     | 
recon_1     |      0K                                                       100% 20.7M=0s
recon_1     | 
recon_1     | 2020-06-10 23:49:59 (20.7 MB/s) - '/etc/security/keytabs/recon.keytab' saved [150/150]
recon_1     | 
recon_1     | Keytab name: FILE:/etc/security/keytabs/recon.keytab
recon_1     | KVNO Timestamp         Principal
recon_1     | ---- ----------------- --------------------------------------------------------
recon_1     |    2 06/10/20 23:49:59 recon/recon@EXAMPLE.COM
recon_1     |    2 06/10/20 23:49:59 recon/recon@EXAMPLE.COM
recon_1     | Download HTTP/recon@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
recon_1     | --2020-06-10 23:49:59--  http://kdc:8081/keytab/recon/HTTP
recon_1     | Resolving kdc (kdc)... 172.26.0.8
recon_1     | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
recon_1     | HTTP request sent, awaiting response... 200 OK
recon_1     | Length: 148 [application/octet-stream]
recon_1     | Saving to: '/etc/security/keytabs/HTTP.keytab'
recon_1     | 
recon_1     |      0K                                                       100% 35.3M=0s
recon_1     | 
recon_1     | 2020-06-10 23:50:00 (35.3 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [148/148]
recon_1     | 
recon_1     | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
recon_1     | KVNO Timestamp         Principal
recon_1     | ---- ----------------- --------------------------------------------------------
recon_1     |    2 06/10/20 23:50:00 HTTP/recon@EXAMPLE.COM
recon_1     |    2 06/10/20 23:50:00 HTTP/recon@EXAMPLE.COM
recon_1     | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
recon_1     | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1     | 2020-06-10 23:50:05,006 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1     | /************************************************************
recon_1     | STARTUP_MSG: Starting ReconServer
recon_1     | STARTUP_MSG:   host = recon/172.26.0.6
recon_1     | STARTUP_MSG:   args = []
recon_1     | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
s3g_1       | Sleeping for 5 seconds
s3g_1       | Setting up kerberos!!
s3g_1       | KDC ISSUER_SERVER => kdc:8081
s3g_1       | Sleeping for 5 seconds
s3g_1       | Got 200, KDC service ready!!
s3g_1       | Download s3g/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/s3g.keytab
s3g_1       | --2020-06-10 23:50:00--  http://kdc:8081/keytab/s3g/s3g
s3g_1       | Resolving kdc (kdc)... 172.26.0.8
s3g_1       | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
s3g_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Length: 142 [application/octet-stream]
s3g_1       | Saving to: '/etc/security/keytabs/s3g.keytab'
s3g_1       | 
s3g_1       |      0K                                                       100% 26.0M=0s
s3g_1       | 
s3g_1       | 2020-06-10 23:50:00 (26.0 MB/s) - '/etc/security/keytabs/s3g.keytab' saved [142/142]
s3g_1       | 
s3g_1       | Keytab name: FILE:/etc/security/keytabs/s3g.keytab
s3g_1       | KVNO Timestamp         Principal
s3g_1       | ---- ----------------- --------------------------------------------------------
s3g_1       |    2 06/10/20 23:50:00 s3g/s3g@EXAMPLE.COM
s3g_1       |    2 06/10/20 23:50:00 s3g/s3g@EXAMPLE.COM
s3g_1       | Download HTTP/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
s3g_1       | --2020-06-10 23:50:00--  http://kdc:8081/keytab/s3g/HTTP
s3g_1       | Resolving kdc (kdc)... 172.26.0.8
s3g_1       | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
s3g_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Length: 144 [application/octet-stream]
s3g_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
s3g_1       | 
s3g_1       |      0K                                                       100% 26.4M=0s
s3g_1       | 
s3g_1       | 2020-06-10 23:50:00 (26.4 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
s3g_1       | 
s3g_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
s3g_1       | KVNO Timestamp         Principal
s3g_1       | ---- ----------------- --------------------------------------------------------
s3g_1       |    2 06/10/20 23:50:00 HTTP/s3g@EXAMPLE.COM
s3g_1       |    2 06/10/20 23:50:00 HTTP/s3g@EXAMPLE.COM
s3g_1       | Download testuser/s3g@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
s3g_1       | --2020-06-10 23:50:00--  http://kdc:8081/keytab/s3g/testuser
s3g_1       | Resolving kdc (kdc)... 172.26.0.8
s3g_1       | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
s3g_1       | HTTP request sent, awaiting response... 200 OK
s3g_1       | Length: 152 [application/octet-stream]
s3g_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
s3g_1       | 
s3g_1       |      0K                                                       100% 20.1M=0s
s3g_1       | 
s3g_1       | 2020-06-10 23:50:01 (20.1 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
s3g_1       | 
s3g_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
s3g_1       | KVNO Timestamp         Principal
s3g_1       | ---- ----------------- --------------------------------------------------------
s3g_1       |    2 06/10/20 23:50:01 testuser/s3g@EXAMPLE.COM
s3g_1       |    2 06/10/20 23:50:01 testuser/s3g@EXAMPLE.COM
s3g_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
s3g_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1       | WARNING: An illegal reflective access operation has occurred
s3g_1       | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar) to method sun.security.krb5.Config.getInstance()
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1       | WARNING: All illegal access operations will be denied in a future release
s3g_1       | 2020-06-10 23:50:09,195 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1       | 2020-06-10 23:50:09,237 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1       | 2020-06-10 23:50:09,239 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1       | 2020-06-10 23:50:09,435 [main] INFO util.log: Logging initialized @7608ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1       | 2020-06-10 23:50:10,363 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1       | 2020-06-10 23:50:10,403 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1       | 2020-06-10 23:50:10,405 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1       | 2020-06-10 23:50:10,405 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1       | 2020-06-10 23:50:10,405 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1       | 2020-06-10 23:50:10,406 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1       | 2020-06-10 23:50:10,611 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1       | /************************************************************
s3g_1       | STARTUP_MSG: Starting Gateway
s3g_1       | STARTUP_MSG:   host = s3g/172.26.0.7
s3g_1       | STARTUP_MSG:   args = []
s3g_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
s3g_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.27.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.10.3.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar
s3g_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/33992bd7f4c16024bb749900e60f3134e980d16a ; compiled by 'jenkins1001' on 2020-06-10T22:20Z
s3g_1       | STARTUP_MSG:   java = 11.0.6
om_1        | 2020-06-10 23:55:04,300 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:04,313 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:04,595 [IPC Server handler 10 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:28206-rpcwoscheme for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-10 23:55:06,567 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | ************************************************************/
s3g_1       | 2020-06-10 23:50:10,648 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | 2020-06-10 23:50:10,892 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1       | 2020-06-10 23:50:10,937 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1       | 2020-06-10 23:50:10,938 [main] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
s3g_1       | 2020-06-10 23:50:11,553 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1       | 2020-06-10 23:50:11,563 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1       | 2020-06-10 23:50:11,569 [main] INFO server.session: node0 Scavenging every 660000ms
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_create_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](Notice): Request: kadm5_get_principal, HTTP/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:00 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:50:01 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:50:01 kdc kadmind[16](Notice): Request: kadm5_get_policy, default, Policy does not exist, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:01 kdc kadmind[16](Notice): Request: kadm5_create_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:01 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:50:01 kdc kadmind[16](Notice): Request: kadm5_init, admin/admin@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1, vers=4, flavor=6
kdc_1       | Jun 10 23:50:01 kdc kadmind[16](Notice): Request: kadm5_randkey_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:01 kdc kadmind[16](Notice): Request: kadm5_get_principal, testuser/s3g@EXAMPLE.COM, success, client=admin/admin@EXAMPLE.COM, service=kadmin/admin@EXAMPLE.COM, addr=127.0.0.1
kdc_1       | Jun 10 23:50:01 kdc kadmind[16](info): closing down fd 18
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591833000, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591833000, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591833000, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:50:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591833000, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:50:01 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:50:01 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591833001, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:50:01 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: SERVER_NOT_FOUND: admin/admin@EXAMPLE.COM for kadmin/localhost@EXAMPLE.COM, Server not found in Kerberos database
kdc_1       | Jun 10 23:50:01 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 127.0.0.1: ISSUE: authtime 1591833001, etypes {rep=18 tkt=18 ses=18}, admin/admin@EXAMPLE.COM for kadmin/admin@EXAMPLE.COM
kdc_1       | Jun 10 23:50:03 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833003, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:50:12 kdc krb5kdc[11](info): AS_REQ (2 etypes {18 17}) 172.26.0.2: ISSUE: authtime 1591833012, etypes {rep=18 tkt=18 ses=18}, dn/e740903365c7@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:50:12 kdc krb5kdc[11](info): AS_REQ (2 etypes {18 17}) 172.26.0.9: ISSUE: authtime 1591833012, etypes {rep=18 tkt=18 ses=18}, dn/29984dc17d72@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:50:12 kdc krb5kdc[11](info): AS_REQ (2 etypes {18 17}) 172.26.0.3: ISSUE: authtime 1591833012, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:50:13 kdc krb5kdc[11](info): AS_REQ (2 etypes {18 17}) 172.26.0.6: ISSUE: authtime 1591833013, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:50:14 kdc krb5kdc[11](info): AS_REQ (2 etypes {18 17}) 172.26.0.10: ISSUE: authtime 1591833014, etypes {rep=18 tkt=18 ses=18}, dn/7ed8bbd12868@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:50:22 kdc krb5kdc[11](info): AS_REQ (2 etypes {18 17}) 172.26.0.4: ISSUE: authtime 1591833022, etypes {rep=18 tkt=18 ses=18}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:50:29 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.10: ISSUE: authtime 1591833014, etypes {rep=18 tkt=18 ses=18}, dn/7ed8bbd12868@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jun 10 23:50:29 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.2: ISSUE: authtime 1591833012, etypes {rep=18 tkt=18 ses=18}, dn/e740903365c7@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jun 10 23:50:29 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.9: ISSUE: authtime 1591833012, etypes {rep=18 tkt=18 ses=18}, dn/29984dc17d72@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jun 10 23:50:29 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.6: ISSUE: authtime 1591833013, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jun 10 23:50:29 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.3: ISSUE: authtime 1591833012, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jun 10 23:50:30 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833003, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jun 10 23:50:35 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833035, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:50:38 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.10: ISSUE: authtime 1591833014, etypes {rep=18 tkt=18 ses=18}, dn/7ed8bbd12868@EXAMPLE.COM for recon/recon@EXAMPLE.COM
recon_1     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-reconcodegen-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.27.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar
recon_1     | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/33992bd7f4c16024bb749900e60f3134e980d16a ; compiled by 'jenkins1001' on 2020-06-10T22:20Z
recon_1     | STARTUP_MSG:   java = 11.0.6
recon_1     | ************************************************************/
recon_1     | 2020-06-10 23:50:05,070 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1     | WARNING: An illegal reflective access operation has occurred
recon_1     | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
recon_1     | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | WARNING: All illegal access operations will be denied in a future release
recon_1     | 2020-06-10 23:50:09,474 [main] INFO recon.ReconRestServletModule: rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1     | 2020-06-10 23:50:11,513 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1     | 2020-06-10 23:50:12,236 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1     | 2020-06-10 23:50:13,801 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file /etc/security/keytabs/recon.keytab
recon_1     | 2020-06-10 23:50:13,806 [main] INFO recon.ReconServer: Recon login successful.
recon_1     | 2020-06-10 23:50:14,697 [main] INFO persistence.DerbyDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1     | 2020-06-10 23:50:20,534 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | 2020-06-10 23:50:21,525 [main] INFO persistence.DerbyDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1     | 2020-06-10 23:50:21,563 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | 2020-06-10 23:50:21,581 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1     | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
recon_1     | 2020-06-10 23:50:23,642 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1     | 2020-06-10 23:50:23,642 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1     | 2020-06-10 23:50:23,642 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1     | 2020-06-10 23:50:23,667 [main] INFO util.log: Logging initialized @22773ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1     | 2020-06-10 23:50:23,778 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1     | 2020-06-10 23:50:23,783 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1     | 2020-06-10 23:50:23,785 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1     | 2020-06-10 23:50:23,785 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1     | 2020-06-10 23:50:23,786 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1     | 2020-06-10 23:50:23,788 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1     | 2020-06-10 23:50:23,869 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1     | 2020-06-10 23:50:24,279 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1     | 2020-06-10 23:50:24,656 [main] INFO Configuration.deprecation: No unit for recon.om.connection.request.timeout(5000) assuming MILLISECONDS
recon_1     | 2020-06-10 23:50:24,899 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-06-10 23:50:25,120 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-06-10 23:50:25,158 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@ac4915e
recon_1     | 2020-06-10 23:50:25,164 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1     | 2020-06-10 23:50:25,309 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-06-10 23:50:25,460 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1     | 2020-06-10 23:50:25,491 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-06-10 23:50:25,537 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1     | 2020-06-10 23:50:25,540 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1     | 2020-06-10 23:50:25,592 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1     | 2020-06-10 23:50:25,657 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1     | 2020-06-10 23:50:25,779 [Listener at 0.0.0.0/9891] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
recon_1     | 2020-06-10 23:50:25,869 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1     | 2020-06-10 23:50:25,869 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1     | 2020-06-10 23:50:26,046 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1     | 2020-06-10 23:50:26,139 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1     | 2020-06-10 23:50:26,139 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1     | 2020-06-10 23:50:26,653 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1     | 2020-06-10 23:50:26,660 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
recon_1     | 2020-06-10 23:50:26,763 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1     | 2020-06-10 23:50:26,764 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1     | 2020-06-10 23:50:26,765 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1     | 2020-06-10 23:50:26,780 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1     | 2020-06-10 23:50:26,804 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5856dbe4{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1     | 2020-06-10 23:50:26,818 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@32d418a9{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1     | 2020-06-10 23:50:27,523 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1     | 2020-06-10 23:50:29,030 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4dd752e8{recon,/,file:///tmp/jetty-0_0_0_0-9888-hadoop-ozone-recon-0_6_0-SNAPSHOT_jar-_-any-1177512717719867730.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.6.0-SNAPSHOT.jar!/webapps/recon}
recon_1     | 2020-06-10 23:50:29,040 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@6a32191e{HTTP/1.1,[http/1.1]}{0.0.0.0:9888}
recon_1     | 2020-06-10 23:50:29,040 [Listener at 0.0.0.0/9891] INFO server.Server: Started @28146ms
recon_1     | 2020-06-10 23:50:29,051 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1     | 2020-06-10 23:50:29,051 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1     | 2020-06-10 23:50:29,055 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1     | 2020-06-10 23:50:29,055 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1     | 2020-06-10 23:50:29,071 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1     | 2020-06-10 23:50:29,089 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1     | 2020-06-10 23:50:29,090 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1     | 2020-06-10 23:50:29,090 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2020-06-10 23:50:29,090 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1     | 2020-06-10 23:50:29,105 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1     | 2020-06-10 23:50:30,676 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1     | 2020-06-10 23:50:30,679 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
kdc_1       | Jun 10 23:50:38 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.2: ISSUE: authtime 1591833012, etypes {rep=18 tkt=18 ses=18}, dn/e740903365c7@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1       | Jun 10 23:50:39 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.9: ISSUE: authtime 1591833012, etypes {rep=18 tkt=18 ses=18}, dn/29984dc17d72@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1       | Jun 10 23:50:41 kdc krb5kdc[11](info): AS_REQ (2 etypes {18 17}) 172.26.0.3: ISSUE: authtime 1591833041, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:50:41 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.3: ISSUE: authtime 1591833041, etypes {rep=18 tkt=18 ses=18}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jun 10 23:50:42 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833035, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jun 10 23:50:46 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833046, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:50:49 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.6: ISSUE: authtime 1591833013, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for HTTP/om@EXAMPLE.COM
kdc_1       | Jun 10 23:50:50 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833046, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jun 10 23:50:52 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833052, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:50:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833058, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:50:59 kdc krb5kdc[11](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833058, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
kdc_1       | Jun 10 23:50:59 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833059, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:51:01 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833059, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:51:49 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:51:50 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.6: ISSUE: authtime 1591833013, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for HTTP/om@EXAMPLE.COM
kdc_1       | Jun 10 23:51:50 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:51:52 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:51:54 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:51:57 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:51:59 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:01 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:03 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:05 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:08 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:10 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:14 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:17 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:21 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:24 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:27 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:29 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:33 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:36 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:38 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:40 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:44 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:46 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:49 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:51 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.6: ISSUE: authtime 1591833013, etypes {rep=18 tkt=18 ses=18}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:51 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:53 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:56 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:58 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833109, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:52:58 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833178, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:53:00 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833178, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:02 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833178, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:04 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833178, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:06 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833178, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:09 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833178, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:11 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833178, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:13 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833178, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:15 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833178, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:15 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833195, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:53:17 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833195, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:19 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833195, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:22 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833195, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:24 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833195, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:26 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833195, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:28 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833195, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:30 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833195, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:32 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833195, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:33 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833213, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:53:35 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833213, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:38 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833213, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:40 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833213, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:42 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833213, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:45 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833213, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:47 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833213, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:49 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833213, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:51 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833213, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:52 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:53:54 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:56 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:53:58 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:00 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:02 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:04 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:06 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:09 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:11 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:13 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:17 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:20 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:24 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:27 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:30 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:32 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:36 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:39 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:41 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:43 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:47 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:49 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:51 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:53 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:56 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:54:58 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:00 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833232, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:55:02 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:04 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:06 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:08 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:10 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:13 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:15 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:17 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:19 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:22 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:25 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:29 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:32 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:36 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:39 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:40 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:44 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:48 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:50 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:52 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:55 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:55:58 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:00 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:02 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:04 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:07 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:09 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833300, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:16 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833376, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:56:18 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833376, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:19 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
recon_1     | 2020-06-10 23:50:30,679 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1     | 2020-06-10 23:50:30,683 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1     | 2020-06-10 23:50:30,697 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1     | 2020-06-10 23:50:30,875 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1     | 2020-06-10 23:50:30,875 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1     | 2020-06-10 23:50:30,947 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2020-06-10 23:50:30,948 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 46 milliseconds.
recon_1     | 2020-06-10 23:50:30,964 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1     | 2020-06-10 23:50:30,964 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1     | 2020-06-10 23:50:31,358 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 323 milliseconds to process 0 existing database records.
recon_1     | 2020-06-10 23:50:31,428 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 70 milliseconds for processing 0 containers.
recon_1     | 2020-06-10 23:50:38,721 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:50:38,727 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:50:39,025 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:50:39,071 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:50:39,126 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:50:39,161 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:50:40,668 [IPC Server handler 0 on default port 9891] INFO net.NetworkTopology: Added a new node: /default-rack/6ece063b-e1a0-4363-8e78-5ecf0377c4b0
recon_1     | 2020-06-10 23:50:40,668 [IPC Server handler 0 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 6ece063b-e1a0-4363-8e78-5ecf0377c4b0{ip: 172.26.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 5763072321478}
recon_1     | 2020-06-10 23:50:40,691 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 6ece063b-e1a0-4363-8e78-5ecf0377c4b0 to Node DB.
recon_1     | 2020-06-10 23:50:40,918 [IPC Server handler 37 on default port 9891] INFO net.NetworkTopology: Added a new node: /default-rack/41410284-0e36-4425-9317-2f8ae5197d6c
recon_1     | 2020-06-10 23:50:40,919 [IPC Server handler 37 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 41410284-0e36-4425-9317-2f8ae5197d6c{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 5763078802613}
recon_1     | 2020-06-10 23:50:40,921 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 41410284-0e36-4425-9317-2f8ae5197d6c to Node DB.
recon_1     | 2020-06-10 23:50:41,002 [IPC Server handler 2 on default port 9891] INFO net.NetworkTopology: Added a new node: /default-rack/51d66525-f84b-46be-9310-54df40bdb627
recon_1     | 2020-06-10 23:50:41,003 [IPC Server handler 2 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 51d66525-f84b-46be-9310-54df40bdb627{ip: 172.26.0.9, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 5763283495140}
recon_1     | 2020-06-10 23:50:41,004 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 51d66525-f84b-46be-9310-54df40bdb627 to Node DB.
recon_1     | 2020-06-10 23:50:43,942 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=fc783735-ce9d-42da-9b1f-4b093f28d9dc. Trying to get from SCM.
recon_1     | 2020-06-10 23:50:44,026 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: fc783735-ce9d-42da-9b1f-4b093f28d9dc, Nodes: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0{ip: 172.26.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:6ece063b-e1a0-4363-8e78-5ecf0377c4b0, CreationTimestamp2020-06-10T23:50:40.716Z] to Recon pipeline metadata.
recon_1     | 2020-06-10 23:50:44,035 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: fc783735-ce9d-42da-9b1f-4b093f28d9dc, Nodes: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0{ip: 172.26.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:6ece063b-e1a0-4363-8e78-5ecf0377c4b0, CreationTimestamp2020-06-10T23:50:40.716Z]
recon_1     | 2020-06-10 23:50:44,294 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=e8e97232-1ec5-4e87-b560-d686c3ce217f. Trying to get from SCM.
recon_1     | 2020-06-10 23:50:44,296 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: e8e97232-1ec5-4e87-b560-d686c3ce217f, Nodes: 51d66525-f84b-46be-9310-54df40bdb627{ip: 172.26.0.9, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}6ece063b-e1a0-4363-8e78-5ecf0377c4b0{ip: 172.26.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}41410284-0e36-4425-9317-2f8ae5197d6c{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-10T23:50:41.044Z] to Recon pipeline metadata.
recon_1     | 2020-06-10 23:50:44,297 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e8e97232-1ec5-4e87-b560-d686c3ce217f, Nodes: 51d66525-f84b-46be-9310-54df40bdb627{ip: 172.26.0.9, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}6ece063b-e1a0-4363-8e78-5ecf0377c4b0{ip: 172.26.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}41410284-0e36-4425-9317-2f8ae5197d6c{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-10T23:50:41.044Z]
recon_1     | 2020-06-10 23:50:44,297 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=e8e97232-1ec5-4e87-b560-d686c3ce217f reported by 6ece063b-e1a0-4363-8e78-5ecf0377c4b0{ip: 172.26.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 5763072321478}
scm_1       | Sleeping for 5 seconds
scm_1       | Setting up kerberos!!
scm_1       | KDC ISSUER_SERVER => kdc:8081
scm_1       | Sleeping for 5 seconds
scm_1       | Got 200, KDC service ready!!
scm_1       | Download scm/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/scm.keytab
scm_1       | --2020-06-10 23:49:59--  http://kdc:8081/keytab/scm/scm
scm_1       | Resolving kdc (kdc)... 172.26.0.8
scm_1       | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 142 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/scm.keytab'
scm_1       | 
scm_1       |      0K                                                       100% 27.6M=0s
scm_1       | 
scm_1       | 2020-06-10 23:49:59 (27.6 MB/s) - '/etc/security/keytabs/scm.keytab' saved [142/142]
scm_1       | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/scm.keytab
scm_1       | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
scm_1       |    2 06/10/20 23:49:59 scm/scm@EXAMPLE.COM
scm_1       |    2 06/10/20 23:49:59 scm/scm@EXAMPLE.COM
scm_1       | Download HTTP/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/HTTP.keytab
scm_1       | --2020-06-10 23:49:59--  http://kdc:8081/keytab/scm/HTTP
scm_1       | Resolving kdc (kdc)... 172.26.0.8
scm_1       | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 144 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/HTTP.keytab'
scm_1       | 
scm_1       |      0K                                                       100% 5.56M=0s
scm_1       | 
scm_1       | 2020-06-10 23:49:59 (5.56 MB/s) - '/etc/security/keytabs/HTTP.keytab' saved [144/144]
scm_1       | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/HTTP.keytab
scm_1       | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
scm_1       |    2 06/10/20 23:49:59 HTTP/scm@EXAMPLE.COM
scm_1       |    2 06/10/20 23:49:59 HTTP/scm@EXAMPLE.COM
scm_1       | Download testuser/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser.keytab
scm_1       | --2020-06-10 23:49:59--  http://kdc:8081/keytab/scm/testuser
scm_1       | Resolving kdc (kdc)... 172.26.0.8
scm_1       | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 152 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/testuser.keytab'
scm_1       | 
scm_1       |      0K                                                       100% 22.3M=0s
scm_1       | 
scm_1       | 2020-06-10 23:49:59 (22.3 MB/s) - '/etc/security/keytabs/testuser.keytab' saved [152/152]
scm_1       | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/testuser.keytab
scm_1       | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
scm_1       |    2 06/10/20 23:49:59 testuser/scm@EXAMPLE.COM
scm_1       |    2 06/10/20 23:49:59 testuser/scm@EXAMPLE.COM
scm_1       | Download testuser2/scm@EXAMPLE.COM keytab file to /etc/security/keytabs/testuser2.keytab
scm_1       | --2020-06-10 23:49:59--  http://kdc:8081/keytab/scm/testuser2
scm_1       | Resolving kdc (kdc)... 172.26.0.8
scm_1       | Connecting to kdc (kdc)|172.26.0.8|:8081... connected.
scm_1       | HTTP request sent, awaiting response... 200 OK
scm_1       | Length: 154 [application/octet-stream]
scm_1       | Saving to: '/etc/security/keytabs/testuser2.keytab'
scm_1       | 
scm_1       |      0K                                                       100% 22.9M=0s
scm_1       | 
scm_1       | 2020-06-10 23:49:59 (22.9 MB/s) - '/etc/security/keytabs/testuser2.keytab' saved [154/154]
scm_1       | 
scm_1       | Keytab name: FILE:/etc/security/keytabs/testuser2.keytab
scm_1       | KVNO Timestamp         Principal
scm_1       | ---- ----------------- --------------------------------------------------------
kdc_1       | Jun 10 23:56:20 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:22 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:24 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:27 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:29 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:31 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:33 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:35 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:37 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:39 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:41 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:43 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:45 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:47 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:50 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:52 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:54 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:56 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:56:59 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:01 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:03 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:05 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:07 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:11 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:13 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:15 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 2020-06-10 23:50:44,526 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=479f6f03-ae93-4e92-83ec-e62e5ef3da8a. Trying to get from SCM.
recon_1     | 2020-06-10 23:50:44,528 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 479f6f03-ae93-4e92-83ec-e62e5ef3da8a, Nodes: 51d66525-f84b-46be-9310-54df40bdb627{ip: 172.26.0.9, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:51d66525-f84b-46be-9310-54df40bdb627, CreationTimestamp2020-06-10T23:50:41.014Z] to Recon pipeline metadata.
recon_1     | 2020-06-10 23:50:44,530 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 479f6f03-ae93-4e92-83ec-e62e5ef3da8a, Nodes: 51d66525-f84b-46be-9310-54df40bdb627{ip: 172.26.0.9, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:51d66525-f84b-46be-9310-54df40bdb627, CreationTimestamp2020-06-10T23:50:41.014Z]
recon_1     | 2020-06-10 23:50:44,618 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=a6cd6bc9-48b1-4d34-b2ca-14e1d47fdfef. Trying to get from SCM.
recon_1     | 2020-06-10 23:50:44,622 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: a6cd6bc9-48b1-4d34-b2ca-14e1d47fdfef, Nodes: 41410284-0e36-4425-9317-2f8ae5197d6c{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-10T23:50:40.933Z] to Recon pipeline metadata.
recon_1     | 2020-06-10 23:50:44,623 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: a6cd6bc9-48b1-4d34-b2ca-14e1d47fdfef, Nodes: 41410284-0e36-4425-9317-2f8ae5197d6c{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-10T23:50:40.933Z]
recon_1     | 2020-06-10 23:50:44,623 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline ONE PipelineID=a6cd6bc9-48b1-4d34-b2ca-14e1d47fdfef reported by 41410284-0e36-4425-9317-2f8ae5197d6c{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 5763078802613}
recon_1     | 2020-06-10 23:50:44,624 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: a6cd6bc9-48b1-4d34-b2ca-14e1d47fdfef, Nodes: 41410284-0e36-4425-9317-2f8ae5197d6c{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:41410284-0e36-4425-9317-2f8ae5197d6c, CreationTimestamp2020-06-10T23:50:40.933Z] moved to OPEN state
recon_1     | 2020-06-10 23:50:44,915 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=e8e97232-1ec5-4e87-b560-d686c3ce217f reported by 51d66525-f84b-46be-9310-54df40bdb627{ip: 172.26.0.9, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 5763283495140}
recon_1     | 2020-06-10 23:50:45,180 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=e8e97232-1ec5-4e87-b560-d686c3ce217f reported by 41410284-0e36-4425-9317-2f8ae5197d6c{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 5763078802613}
recon_1     | 2020-06-10 23:50:49,091 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-10 23:50:49,092 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1     | 2020-06-10 23:50:49,288 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=e8e97232-1ec5-4e87-b560-d686c3ce217f reported by 6ece063b-e1a0-4363-8e78-5ecf0377c4b0{ip: 172.26.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 5763072321478}
recon_1     | 2020-06-10 23:50:49,672 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=e8e97232-1ec5-4e87-b560-d686c3ce217f reported by 6ece063b-e1a0-4363-8e78-5ecf0377c4b0{ip: 172.26.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 5763072321478}
recon_1     | 2020-06-10 23:50:49,673 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: e8e97232-1ec5-4e87-b560-d686c3ce217f, Nodes: 51d66525-f84b-46be-9310-54df40bdb627{ip: 172.26.0.9, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}6ece063b-e1a0-4363-8e78-5ecf0377c4b0{ip: 172.26.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}41410284-0e36-4425-9317-2f8ae5197d6c{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:6ece063b-e1a0-4363-8e78-5ecf0377c4b0, CreationTimestamp2020-06-10T23:50:41.044Z] moved to OPEN state
recon_1     | 2020-06-10 23:50:49,791 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1591833049092
recon_1     | 2020-06-10 23:50:50,006 [pool-13-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1591833049092.
recon_1     | 2020-06-10 23:50:50,071 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
recon_1     | 2020-06-10 23:50:50,075 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1     | 2020-06-10 23:50:50,164 [pool-14-thread-1] INFO impl.ContainerDBServiceProviderImpl: Creating new Recon Container DB at /data/metadata/recon/recon-container-key.db_1591833050077
recon_1     | 2020-06-10 23:50:50,164 [pool-14-thread-1] INFO impl.ContainerDBServiceProviderImpl: Cleaning up old Recon Container DB at /data/metadata/recon/recon-container-key.db_1591833013816.
recon_1     | 2020-06-10 23:50:50,437 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
recon_1     | 2020-06-10 23:50:50,437 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.36 seconds to process 0 keys.
recon_1     | 2020-06-10 23:50:50,439 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
recon_1     | 2020-06-10 23:51:05,120 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:51:05,141 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:51:05,151 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ozonesecure_datanode_3.ozonesecure_default.
recon_1     | 2020-06-10 23:51:05,254 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1     | 2020-06-10 23:51:05,410 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 2020-06-10 23:50:11,840 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1       | 2020-06-10 23:50:12,048 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4b8729ff{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 2020-06-10 23:50:12,052 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2bdd8394{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
s3g_1       | 2020-06-10 23:50:21,125 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1       | Jun 10, 2020 11:50:23 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1       | 
s3g_1       | 2020-06-10 23:50:23,568 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@608cd501{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-0_6_0-SNAPSHOT_jar-_-any-9958357516973973385.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.6.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1       | 2020-06-10 23:50:23,596 [main] INFO server.AbstractConnector: Started ServerConnector@42e25b0b{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
s3g_1       | 2020-06-10 23:50:23,608 [main] INFO server.Server: Started @21777ms
s3g_1       | 2020-06-10 23:50:23,612 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1       | 2020-06-10 23:58:17,466 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-10 23:58:18,142 [qtp1270038388-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-test123, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-10 23:58:18,157 [qtp1270038388-20] INFO endpoint.BucketEndpoint: Location is /bucket-test123
s3g_1       | 2020-06-10 23:58:18,716 [qtp1270038388-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-10 23:58:20,538 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-10 23:58:20,549 [qtp1270038388-18] WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235820Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 4f10b6f740f310080273f0cd1a26da62fb87e2a910fa29b3797054025368c914, signature=59d460d5063cb512fa5af91462138452fffb4c3d613ff33904acae3f67866929, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 2020-06-10 23:58:20,552 [qtp1270038388-18] ERROR client.OzoneClientFactory: Couldn't create RpcClient protocol exception: 
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235820Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 4f10b6f740f310080273f0cd1a26da62fb87e2a910fa29b3797054025368c914, signature=59d460d5063cb512fa5af91462138452fffb4c3d613ff33904acae3f67866929, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:209)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1003)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:112)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:68)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
recon_1     | 2020-06-10 23:51:05,454 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:51:05,583 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:51:05,623 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:51:35,102 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:51:35,112 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:51:35,392 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:51:35,407 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:51:35,531 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:51:35,538 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:51:50,454 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-10 23:51:50,454 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1     | 2020-06-10 23:51:50,687 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1591833110454
recon_1     | 2020-06-10 23:51:50,689 [pool-13-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Cleaning up old OM snapshot db at /data/metadata/om.snapshot.db_1591833049092.
recon_1     | 2020-06-10 23:51:50,755 [pool-13-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1591833110454.
recon_1     | 2020-06-10 23:51:50,795 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
recon_1     | 2020-06-10 23:51:50,795 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1     | 2020-06-10 23:51:50,869 [pool-14-thread-1] INFO impl.ContainerDBServiceProviderImpl: Creating new Recon Container DB at /data/metadata/recon/recon-container-key.db_1591833110795
recon_1     | 2020-06-10 23:51:50,869 [pool-14-thread-1] INFO impl.ContainerDBServiceProviderImpl: Cleaning up old Recon Container DB at /data/metadata/recon/recon-container-key.db_1591833050077.
recon_1     | 2020-06-10 23:51:51,019 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
recon_1     | 2020-06-10 23:51:51,019 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.223 seconds to process 125 keys.
recon_1     | 2020-06-10 23:51:51,216 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
recon_1     | 2020-06-10 23:52:05,100 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:52:05,105 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:52:05,390 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:52:05,398 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:52:05,512 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:52:05,519 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:52:35,089 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:52:35,098 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:52:35,383 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:52:35,394 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:52:35,552 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:52:35,561 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:52:51,229 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-10 23:52:51,230 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-10 23:52:51,381 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 13
recon_1     | 2020-06-10 23:52:51,417 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 7 OM DB update event(s).
recon_1     | 2020-06-10 23:52:51,438 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-10 23:53:05,099 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:53:05,126 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:53:05,389 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:53:05,394 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:53:05,525 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Jun 10 23:57:18 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:20 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:22 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:24 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:26 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833379, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:27 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833447, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:57:28 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833447, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:30 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833447, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:32 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833447, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:33 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833453, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:57:34 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833453, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:35 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833455, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:57:37 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833455, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:39 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833455, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:41 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833455, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:43 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833455, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:45 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833455, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:45 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833465, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:57:47 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833465, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:49 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833465, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:50 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833470, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:57:52 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833470, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:54 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833470, etypes {rep=18 tkt=18 ses=18}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:57:54 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833474, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:58:11 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 10 23:58:13 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:58:16 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:58:30 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:58:34 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:58:36 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:58:45 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:58:47 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:58:49 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:58:51 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:58:53 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:58:56 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:58:58 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:00 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:02 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       |    2 06/10/20 23:49:59 testuser2/scm@EXAMPLE.COM
scm_1       |    2 06/10/20 23:49:59 testuser2/scm@EXAMPLE.COM
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-06-10 23:50:11,121 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = scm/172.26.0.4
scm_1       | STARTUP_MSG:   args = [--init]
scm_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
om_1        | 2020-06-10 23:55:06,580 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:08,858 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:08,880 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:10,969 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:10,983 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:13,271 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:13,295 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:15,479 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:15,488 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:17,763 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:17,777 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:20,010 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:20,021 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:22,293 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:22,309 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:25,998 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:26,015 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:29,401 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:29,435 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:33,018 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:33,031 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:36,730 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:36,743 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:39,091 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:39,099 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:41,003 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:41,014 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:44,949 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:44,960 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:48,432 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:48,440 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:50,309 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:50,319 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:51,641 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:51,649 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:52,529 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:52,544 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:55:55,865 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:55,873 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
recon_1     | 2020-06-10 23:53:05,533 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:53:35,075 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:53:35,086 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:53:35,394 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:53:35,412 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:53:35,519 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:53:35,524 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:53:51,455 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-10 23:53:51,455 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-10 23:53:51,506 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 17
recon_1     | 2020-06-10 23:53:51,518 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
recon_1     | 2020-06-10 23:53:51,541 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-10 23:54:05,083 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:54:05,091 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:54:05,397 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:54:05,400 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:54:05,512 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:54:05,521 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:54:35,074 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:54:35,080 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:54:35,384 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:54:35,410 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:54:35,515 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:54:35,526 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:54:51,552 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-10 23:54:51,552 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-10 23:54:51,586 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 12
recon_1     | 2020-06-10 23:54:51,601 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 5 OM DB update event(s).
recon_1     | 2020-06-10 23:54:51,615 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-10 23:55:05,100 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:55:05,103 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:55:05,393 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:55:05,420 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:55:05,510 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:55:05,529 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:55:31,430 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds to process 0 existing database records.
recon_1     | 2020-06-10 23:55:31,440 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 10 milliseconds for processing 1 containers.
recon_1     | 2020-06-10 23:55:35,080 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:55:35,104 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:55:35,404 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:55:35,419 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:55:35,530 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:55:35,539 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/33992bd7f4c16024bb749900e60f3134e980d16a ; compiled by 'jenkins1001' on 2020-06-10T22:19Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-06-10 23:50:11,198 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-06-10 23:50:11,988 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-06-10 23:50:12,485 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-c55b3d7f-33e0-4d68-8f03-e77183ab587e
scm_1       | 2020-06-10 23:50:12,636 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm/172.26.0.4
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-06-10 23:50:21,566 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = scm/172.26.0.4
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 0.6.0-SNAPSHOT
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Jun 10, 2020 11:58:20 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/ratis-proto-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.6.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.6.0-6ab75ae-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.6.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone/33992bd7f4c16024bb749900e60f3134e980d16a ; compiled by 'jenkins1001' on 2020-06-10T22:19Z
scm_1       | STARTUP_MSG:   java = 11.0.6
scm_1       | ************************************************************/
scm_1       | 2020-06-10 23:50:21,606 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-06-10 23:50:22,011 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | WARNING: An illegal reflective access operation has occurred
scm_1       | WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar) to method sun.security.krb5.Config.getInstance()
scm_1       | WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
scm_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
scm_1       | WARNING: All illegal access operations will be denied in a future release
scm_1       | 2020-06-10 23:50:23,252 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file /etc/security/keytabs/scm.keytab
scm_1       | 2020-06-10 23:50:23,252 [main] INFO server.StorageContainerManager: SCM login successful.
scm_1       | 2020-06-10 23:50:23,712 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-06-10 23:50:25,990 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-06-10 23:50:26,014 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm_1       | 2020-06-10 23:50:26,152 [Listener at 0.0.0.0/9961] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@37d00a23
om_1        | 2020-06-10 23:55:58,277 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:55:58,292 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:00,677 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:00,689 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:02,747 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:02,757 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:04,909 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:04,921 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:07,189 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:07,201 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:09,169 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:09,180 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:18,573 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:18,587 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:18,864 [IPC Server handler 31 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have CREATE permission to access volume /fstest/null/null
om_1        | 2020-06-10 23:56:18,871 [IPC Server handler 31 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:testuser2/scm@EXAMPLE.COM volume:fstest
om_1        | PERMISSION_DENIED org.apache.hadoop.ozone.om.exceptions.OMException: User testuser2/scm@EXAMPLE.COM doesn't have CREATE permission to access volume
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.checkAcls(OzoneManager.java:1655)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.checkAcls(OzoneManager.java:1621)
om_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:152)
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:132)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-10 23:56:20,781 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:20,795 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:21,106 [IPC Server handler 90 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:fstest17 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-10 23:56:22,909 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:22,921 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:23,207 [IPC Server handler 92 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:fstest217 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-10 23:56:24,976 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:24,992 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:27,039 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:27,051 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:29,068 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:29,086 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:31,308 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:55:51,632 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-10 23:55:51,633 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-10 23:55:51,652 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 16
recon_1     | 2020-06-10 23:55:51,669 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 8 OM DB update event(s).
recon_1     | 2020-06-10 23:55:51,691 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-10 23:56:05,081 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:56:05,090 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:56:05,384 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:56:05,395 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:56:05,527 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:56:05,552 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:56:35,088 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:56:35,102 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:56:35,384 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:56:35,393 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:56:35,516 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:56:35,538 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:56:51,701 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-10 23:56:51,701 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-10 23:56:51,728 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 16
recon_1     | 2020-06-10 23:56:51,743 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
recon_1     | 2020-06-10 23:56:51,752 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-10 23:57:05,074 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:57:05,076 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:57:05,394 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:57:05,415 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:57:05,522 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:57:05,542 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:57:35,079 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:57:35,085 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:57:35,408 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:57:35,414 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:57:35,526 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:57:35,531 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:57:51,766 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-10 23:57:51,766 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-10 23:57:51,787 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 13
recon_1     | 2020-06-10 23:57:51,847 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 2 OM DB update event(s).
recon_1     | 2020-06-10 23:57:51,852 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-10 23:58:05,084 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:58:05,097 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:58:05,409 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:58:05,418 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:58:05,528 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
kdc_1       | Jun 10 23:59:05 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:08 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:11 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:13 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:17 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:20 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:22 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:25 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:27 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:30 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:33 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:36 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:38 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:42 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:44 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:46 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:48 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:51 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:53 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:56 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 10 23:59:58 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:00:00 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:00:02 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:00:06 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:00:10 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:00:12 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:00:14 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:00:17 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:00:21 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:00:24 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:00:28 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:00:31 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:00:33 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:00:37 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:01:01 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.7: ISSUE: authtime 1591833661, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:01:02 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833661, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:01:06 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833661, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:01:07 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.7: ISSUE: authtime 1591833667, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:248)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:112)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:68)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 104 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235820Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 4f10b6f740f310080273f0cd1a26da62fb87e2a910fa29b3797054025368c914, signature=59d460d5063cb512fa5af91462138452fffb4c3d613ff33904acae3f67866929, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
scm_1       | 2020-06-10 23:50:26,156 [Listener at 0.0.0.0/9961] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1       | 2020-06-10 23:50:26,336 [Listener at 0.0.0.0/9961] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1       | 2020-06-10 23:50:26,498 [Listener at 0.0.0.0/9961] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       | 2020-06-10 23:50:26,515 [Listener at 0.0.0.0/9961] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1       | 2020-06-10 23:50:26,589 [Listener at 0.0.0.0/9961] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2020-06-10 23:50:26,590 [Listener at 0.0.0.0/9961] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1       | 2020-06-10 23:50:26,714 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 0 nodes. Healthy nodes 0
scm_1       | 2020-06-10 23:50:27,365 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-06-10 23:50:27,366 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2020-06-10 23:50:27,459 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-06-10 23:50:27,471 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1       | 2020-06-10 23:50:27,528 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-06-10 23:50:27,539 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1       | 2020-06-10 23:50:27,621 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1       | 2020-06-10 23:50:27,621 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm_1       | 2020-06-10 23:50:27,622 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm_1       | 2020-06-10 23:50:27,653 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @12999ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       | 2020-06-10 23:50:27,924 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1       | 2020-06-10 23:50:27,930 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       | 2020-06-10 23:50:27,932 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm_1       | 2020-06-10 23:50:27,932 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm_1       | 2020-06-10 23:50:27,935 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm_1       | 2020-06-10 23:50:27,936 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm_1       | 2020-06-10 23:50:27,978 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1       | 2020-06-10 23:50:28,083 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | 2020-06-10 23:50:28,148 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1       | 2020-06-10 23:50:28,148 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1       | 2020-06-10 23:50:28,457 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1       | 2020-06-10 23:50:28,472 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-06-10 23:50:28,474 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1       | 2020-06-10 23:50:28,736 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1       | 2020-06-10 23:50:28,737 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1       | 2020-06-10 23:50:28,737 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-06-10 23:50:28,738 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1       | 2020-06-10 23:50:28,854 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1       | 2020-06-10 23:50:28,865 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1       | 2020-06-10 23:50:28,867 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-06-10 23:50:28,867 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1       | 2020-06-10 23:50:28,967 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm_1       | 2020-06-10 23:50:28,974 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-06-10 23:50:28,975 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm_1       | 2020-06-10 23:50:28,983 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1       | 2020-06-10 23:50:28,993 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.6+10-LTS
scm_1       | 2020-06-10 23:50:29,077 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1       | 2020-06-10 23:50:29,077 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2020-06-10 23:50:29,078 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1       | 2020-06-10 23:50:29,152 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm_1       | 2020-06-10 23:50:29,177 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5984feef{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1       | 2020-06-10 23:50:29,178 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1f67761b{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | 2020-06-10 23:50:29,885 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:29,909 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:29,892 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:29,985 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:50:29,986 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-10 23:50:29,999 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:30,004 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-06-10 23:50:30,025 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:30,027 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-06-10 23:50:30,044 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-06-10 23:50:30,105 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:30,142 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-06-10 23:50:30,235 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 7ed8bbd12868, UUID: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0
scm_1       | 2020-06-10 23:50:30,219 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn e740903365c7, UUID: 41410284-0e36-4425-9317-2f8ae5197d6c
scm_1       | 2020-06-10 23:50:30,357 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm_1       | 2020-06-10 23:50:30,433 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5042e3d0{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_6_0-SNAPSHOT_jar-_-any-831840210671319378.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.6.0-SNAPSHOT.jar!/webapps/scm}
scm_1       | 2020-06-10 23:50:30,537 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@7a4d582c{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1       | 2020-06-10 23:50:30,547 [Listener at 0.0.0.0/9860] INFO server.Server: Started @15893ms
scm_1       | 2020-06-10 23:50:30,557 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | 2020-06-10 23:50:30,557 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1       | 2020-06-10 23:50:30,571 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1       | 2020-06-10 23:50:30,626 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 29984dc17d72, UUID: 51d66525-f84b-46be-9310-54df40bdb627
scm_1       | 2020-06-10 23:50:30,748 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@193bb809] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2020-06-10 23:50:31,641 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:31,680 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-10 23:50:35,679 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:35,686 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:209)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1003)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:241)
s3g_1       | 	... 113 more
s3g_1       | 
s3g_1       | 
s3g_1       | 23:58:20.564 [qtp1270038388-18] ERROR org.jboss.weld.Bean - WELD-000019: Error destroying an instance org.apache.hadoop.ozone.s3.OzoneClientProducer@15139169 of Managed Bean [class org.apache.hadoop.ozone.s3.OzoneClientProducer] with qualifiers [@Any @Default]
s3g_1       | 2020-06-10 23:58:20,571 [qtp1270038388-18] WARN server.HttpChannel: handleException /bucket-test123 java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 2020-06-10 23:58:20,572 [qtp1270038388-18] WARN server.HttpChannelState: unhandled due to prior sendError
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
kdc_1       | Jun 11 00:01:08 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833667, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:01:12 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833667, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:01:17 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.7: ISSUE: authtime 1591833677, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:01:19 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833677, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:01:22 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833677, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:01:26 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.7: ISSUE: authtime 1591833686, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:01:27 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833686, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:01:31 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833686, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:01:33 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.7: ISSUE: authtime 1591833693, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:01:35 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833693, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:01:39 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833693, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:01:41 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.7: ISSUE: authtime 1591833701, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:01:43 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833701, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:01:46 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833701, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:01:48 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.7: ISSUE: authtime 1591833708, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:01:49 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833708, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:01:53 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833708, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:02:35 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.7: ISSUE: authtime 1591833755, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:02:37 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833755, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:02:40 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833755, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:02:47 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.7: ISSUE: authtime 1591833767, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:02:49 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833767, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:02:53 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833767, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:03:05 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.7: ISSUE: authtime 1591833785, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:03:07 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833785, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:03:10 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833785, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:03:15 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.7: ISSUE: authtime 1591833795, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:03:16 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833795, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:03:20 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833795, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:03:31 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.7: ISSUE: authtime 1591833811, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:03:33 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833811, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:03:36 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.7: ISSUE: authtime 1591833811, etypes {rep=18 tkt=18 ses=18}, testuser/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:03:37 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.7: ISSUE: authtime 1591833817, etypes {rep=18 tkt=18 ses=18}, HTTP/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:03:37 kdc krb5kdc[11](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.7: ISSUE: authtime 1591833817, etypes {rep=18 tkt=18 ses=18}, HTTP/s3g@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
kdc_1       | Jun 11 00:03:45 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jun 11 00:03:48 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jun 11 00:03:50 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833491, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jun 11 00:03:56 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833836, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:03:58 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833836, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:04:04 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833844, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:04:14 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833854, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:04:24 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833864, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:04:34 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833874, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:04:44 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833884, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:04:54 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833894, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:04:54 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833894, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:04:54 kdc krb5kdc[11](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833894, etypes {rep=18 tkt=18 ses=18}, HTTP/scm@EXAMPLE.COM for HTTP/recon@EXAMPLE.COM
kdc_1       | Jun 11 00:05:00 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833900, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:05:02 kdc krb5kdc[11](info): TGS_REQ (6 etypes {18 17 20 19 16 23}) 172.26.0.4: ISSUE: authtime 1591833900, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jun 11 00:05:08 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833908, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:05:08 kdc krb5kdc[11](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833908, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for HTTP/om@EXAMPLE.COM
kdc_1       | Jun 11 00:05:08 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833908, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:05:08 kdc krb5kdc[11](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833908, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for HTTP/om@EXAMPLE.COM
kdc_1       | Jun 11 00:05:08 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833908, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:05:08 kdc krb5kdc[11](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833908, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for HTTP/om@EXAMPLE.COM
kdc_1       | Jun 11 00:05:08 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833908, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:05:08 kdc krb5kdc[11](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833908, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
kdc_1       | Jun 11 00:05:08 kdc krb5kdc[11](info): AS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833908, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jun 11 00:05:08 kdc krb5kdc[11](info): TGS_REQ (8 etypes {18 17 20 19 16 23 25 26}) 172.26.0.4: ISSUE: authtime 1591833908, etypes {rep=18 tkt=18 ses=18}, testuser/scm@EXAMPLE.COM for HTTP/recon@EXAMPLE.COM
scm_1       | 2020-06-10 23:50:35,693 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om, UUID: 6685c061-4d5e-4cbe-96a0-d1691d5eaa6b
scm_1       | 2020-06-10 23:50:38,682 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:38,692 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:50:38,950 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:38,993 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:50:39,060 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:39,099 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:50:40,706 [IPC Server handler 2 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/6ece063b-e1a0-4363-8e78-5ecf0377c4b0
scm_1       | 2020-06-10 23:50:40,717 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fc783735-ce9d-42da-9b1f-4b093f28d9dc to datanode:6ece063b-e1a0-4363-8e78-5ecf0377c4b0
scm_1       | 2020-06-10 23:50:40,709 [IPC Server handler 2 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 6ece063b-e1a0-4363-8e78-5ecf0377c4b0{ip: 172.26.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: 5763072321478}
scm_1       | 2020-06-10 23:50:40,748 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: fc783735-ce9d-42da-9b1f-4b093f28d9dc, Nodes: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0{ip: 172.26.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-10T23:50:40.716145Z]
scm_1       | 2020-06-10 23:50:40,765 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 1 nodes. Healthy nodes 1
scm_1       | 2020-06-10 23:50:40,766 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
recon_1     | 2020-06-10 23:58:05,538 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:58:35,097 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:58:35,113 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:58:35,383 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:58:35,390 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:58:35,514 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:58:35,522 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:58:51,862 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-10 23:58:51,863 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-10 23:58:51,889 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 12
recon_1     | 2020-06-10 23:58:51,896 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2020-06-10 23:58:51,897 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-10 23:59:05,084 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:59:05,090 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:59:05,392 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:59:05,405 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:59:05,515 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:59:05,517 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:59:35,083 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:59:35,104 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:59:35,393 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:59:35,399 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:59:35,531 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-10 23:59:35,544 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-10 23:59:51,918 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-10 23:59:51,918 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-10 23:59:51,946 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 19
recon_1     | 2020-06-10 23:59:51,963 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 17 OM DB update event(s).
recon_1     | 2020-06-10 23:59:51,973 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-11 00:00:05,082 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:00:05,098 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:00:05,399 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:00:05,411 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:00:05,515 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:00:05,528 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:00:31,335 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
recon_1     | 2020-06-11 00:00:31,339 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 29 milliseconds.
recon_1     | 2020-06-11 00:00:31,442 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 0 milliseconds to process 0 existing database records.
recon_1     | 2020-06-11 00:00:31,449 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 7 milliseconds for processing 1 containers.
recon_1     | 2020-06-11 00:00:35,081 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:00:35,084 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:00:35,380 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:00:35,387 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2020-06-10 23:50:40,772 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1       | 2020-06-10 23:50:40,923 [IPC Server handler 46 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/41410284-0e36-4425-9317-2f8ae5197d6c
scm_1       | 2020-06-10 23:50:40,930 [IPC Server handler 46 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 41410284-0e36-4425-9317-2f8ae5197d6c{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: 5763078802613}
scm_1       | 2020-06-10 23:50:40,931 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-06-10 23:50:40,931 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1       | 2020-06-10 23:50:40,933 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a6cd6bc9-48b1-4d34-b2ca-14e1d47fdfef to datanode:41410284-0e36-4425-9317-2f8ae5197d6c
scm_1       | 2020-06-10 23:50:40,940 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: a6cd6bc9-48b1-4d34-b2ca-14e1d47fdfef, Nodes: 41410284-0e36-4425-9317-2f8ae5197d6c{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-10T23:50:40.933430Z]
scm_1       | 2020-06-10 23:50:40,940 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 2 nodes. Healthy nodes 2
scm_1       | 2020-06-10 23:50:41,009 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopology: Added a new node: /default-rack/51d66525-f84b-46be-9310-54df40bdb627
scm_1       | 2020-06-10 23:50:41,015 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 51d66525-f84b-46be-9310-54df40bdb627{ip: 172.26.0.9, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: 5763283495140}
scm_1       | 2020-06-10 23:50:41,016 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-06-10 23:50:41,014 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=479f6f03-ae93-4e92-83ec-e62e5ef3da8a to datanode:51d66525-f84b-46be-9310-54df40bdb627
scm_1       | 2020-06-10 23:50:41,016 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1       | 2020-06-10 23:50:41,024 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 479f6f03-ae93-4e92-83ec-e62e5ef3da8a, Nodes: 51d66525-f84b-46be-9310-54df40bdb627{ip: 172.26.0.9, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-10T23:50:41.014557Z]
scm_1       | 2020-06-10 23:50:41,025 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-10 23:50:41,026 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2020-06-10 23:50:41,026 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1       | 2020-06-10 23:50:41,028 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-10 23:50:41,044 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e8e97232-1ec5-4e87-b560-d686c3ce217f to datanode:51d66525-f84b-46be-9310-54df40bdb627
scm_1       | 2020-06-10 23:50:41,045 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e8e97232-1ec5-4e87-b560-d686c3ce217f to datanode:6ece063b-e1a0-4363-8e78-5ecf0377c4b0
scm_1       | 2020-06-10 23:50:41,050 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e8e97232-1ec5-4e87-b560-d686c3ce217f to datanode:41410284-0e36-4425-9317-2f8ae5197d6c
scm_1       | 2020-06-10 23:50:41,051 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: e8e97232-1ec5-4e87-b560-d686c3ce217f, Nodes: 51d66525-f84b-46be-9310-54df40bdb627{ip: 172.26.0.9, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}6ece063b-e1a0-4363-8e78-5ecf0377c4b0{ip: 172.26.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}41410284-0e36-4425-9317-2f8ae5197d6c{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-06-10T23:50:41.044290Z]
scm_1       | 2020-06-10 23:50:41,058 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-06-10 23:50:41,707 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:41,720 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:50:42,285 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:42,307 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-06-10 23:50:42,544 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:42,555 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-10 23:50:43,923 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: fc783735-ce9d-42da-9b1f-4b093f28d9dc, Nodes: 6ece063b-e1a0-4363-8e78-5ecf0377c4b0{ip: 172.26.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:6ece063b-e1a0-4363-8e78-5ecf0377c4b0, CreationTimestamp2020-06-10T23:50:40.716145Z] moved to OPEN state
scm_1       | 2020-06-10 23:50:43,925 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-06-10 23:50:43,931 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-06-10 23:50:43,997 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:44,019 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-10 23:50:44,511 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 479f6f03-ae93-4e92-83ec-e62e5ef3da8a, Nodes: 51d66525-f84b-46be-9310-54df40bdb627{ip: 172.26.0.9, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:51d66525-f84b-46be-9310-54df40bdb627, CreationTimestamp2020-06-10T23:50:41.014557Z] moved to OPEN state
scm_1       | 2020-06-10 23:50:44,511 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-06-10 23:50:44,511 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-06-10 23:50:44,622 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: a6cd6bc9-48b1-4d34-b2ca-14e1d47fdfef, Nodes: 41410284-0e36-4425-9317-2f8ae5197d6c{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:41410284-0e36-4425-9317-2f8ae5197d6c, CreationTimestamp2020-06-10T23:50:40.933430Z] moved to OPEN state
scm_1       | 2020-06-10 23:50:44,623 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-06-10 23:50:44,623 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-06-10 23:50:49,669 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: e8e97232-1ec5-4e87-b560-d686c3ce217f, Nodes: 51d66525-f84b-46be-9310-54df40bdb627{ip: 172.26.0.9, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}6ece063b-e1a0-4363-8e78-5ecf0377c4b0{ip: 172.26.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}41410284-0e36-4425-9317-2f8ae5197d6c{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:6ece063b-e1a0-4363-8e78-5ecf0377c4b0, CreationTimestamp2020-06-10T23:50:41.044290Z] moved to OPEN state
scm_1       | 2020-06-10 23:50:49,671 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1       | 2020-06-10 23:50:49,673 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-06-10 23:50:49,678 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1       | 2020-06-10 23:50:49,679 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1       | 2020-06-10 23:50:49,679 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1       | 2020-06-10 23:50:50,425 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:50,476 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-06-10 23:50:50,695 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:50:50,700 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-10 23:51:01,479 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:51:01,498 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-10 23:51:02,857 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:51:02,865 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:51:04,429 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:51:04,458 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-06-10 23:51:04,670 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:51:04,683 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-06-10 23:51:04,772 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:51:04,790 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-06-10 23:51:05,116 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:51:05,126 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:51:05,196 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:51:05,203 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-10 23:51:05,408 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:51:05,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:51:05,692 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:51:05,717 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:51:35,082 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:51:35,095 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:51:35,390 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:51:35,406 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:51:35,513 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:51:35,539 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:52:05,084 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:52:05,091 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:52:05,409 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:52:05,424 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:52:05,534 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:52:05,546 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:52:10,632 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:52:10,633 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:52:26,715 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-10 23:52:26,716 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-06-10 23:52:29,680 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:52:29,687 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:52:35,105 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:52:35,116 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:52:35,424 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:52:35,426 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:52:35,574 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:52:35,602 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:52:44,248 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:52:44,257 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:52:44,266 [IPC Server handler 18 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
scm_1       | 2020-06-10 23:52:44,269 [IPC Server handler 18 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322377297952895 bcsId: 0
scm_1       | 2020-06-10 23:52:44,276 [IPC Server handler 18 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322376527904894 bcsId: 0
scm_1       | 2020-06-10 23:53:05,098 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:53:05,130 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:53:05,399 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:53:05,408 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:53:05,537 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:53:05,540 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:53:35,118 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 45 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 72 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:248)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:112)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:68)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 104 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235820Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 4f10b6f740f310080273f0cd1a26da62fb87e2a910fa29b3797054025368c914, signature=59d460d5063cb512fa5af91462138452fffb4c3d613ff33904acae3f67866929, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
scm_1       | 2020-06-10 23:53:35,129 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:53:35,396 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:53:35,420 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:53:35,526 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:53:35,530 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:53:35,531 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:53:35,534 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:53:44,309 [IPC Server handler 32 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
scm_1       | 2020-06-10 23:53:44,309 [IPC Server handler 32 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322376049295485 bcsId: 0
scm_1       | 2020-06-10 23:54:05,101 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:54:05,106 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:54:05,406 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:54:05,407 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:54:05,537 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:54:05,544 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:54:13,913 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:54:13,918 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:54:26,717 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-10 23:54:26,717 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-06-10 23:54:32,453 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:54:32,458 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:54:35,095 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:54:35,101 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:54:35,412 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:54:35,425 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:54:35,543 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:54:35,552 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:54:44,334 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:54:44,336 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:54:44,336 [IPC Server handler 36 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
scm_1       | 2020-06-10 23:54:44,337 [IPC Server handler 36 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322385343807619 bcsId: 0
scm_1       | 2020-06-10 23:54:44,337 [IPC Server handler 36 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322384600760450 bcsId: 0
scm_1       | 2020-06-10 23:55:05,125 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:55:05,135 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:55:05,397 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:55:05,412 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:55:05,531 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:55:05,541 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:55:22,585 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:00:35,518 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:00:35,524 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:00:51,984 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-11 00:00:51,984 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-11 00:00:52,031 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 26
recon_1     | 2020-06-11 00:00:52,312 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 24 OM DB update event(s).
recon_1     | 2020-06-11 00:00:52,922 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-11 00:01:05,095 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:01:05,131 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:01:05,395 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:01:05,406 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:01:05,535 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:01:05,586 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:01:35,083 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:01:35,090 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:01:35,391 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:01:35,407 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:01:35,525 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:01:35,543 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:01:52,931 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-11 00:01:52,931 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-11 00:01:52,969 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 25
recon_1     | 2020-06-11 00:01:52,983 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 2 OM DB update event(s).
recon_1     | 2020-06-11 00:01:52,997 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-11 00:02:05,084 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:02:05,102 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:02:05,404 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:02:05,423 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:02:05,527 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:02:05,538 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:02:35,078 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:02:35,090 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:02:35,388 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:02:35,399 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:02:35,517 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:02:35,527 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:02:53,023 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-11 00:02:53,023 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-11 00:02:53,058 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 98
recon_1     | 2020-06-11 00:02:53,927 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 11 OM DB update event(s).
recon_1     | 2020-06-11 00:02:54,003 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-11 00:03:05,087 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:03:05,119 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:03:05,402 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:31,324 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:33,206 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:33,216 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:33,447 [IPC Server handler 88 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:fstest317 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-10 23:56:35,186 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:35,199 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:37,365 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:37,373 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:39,350 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:39,363 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:41,668 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:41,679 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:43,577 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:43,586 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:45,775 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:45,785 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:47,768 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:47,800 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:50,243 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:50,253 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:51,710 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:51,721 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:52,575 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:52,588 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:54,877 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:54,905 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:55,166 [IPC Server handler 81 on default port 9862] ERROR acl.OMBucketAddAclRequest: Add acl [user:superuser1:rwxy[ACCESS]] to path /fstest317/bk1 failed, because acl already exist
om_1        | 2020-06-10 23:56:56,861 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:56,875 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:56:59,313 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:56:59,334 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:01,415 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:01,426 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:03,621 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:03,633 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:05,832 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:05,841 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:08,013 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:08,024 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:11,566 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:209)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1003)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:241)
s3g_1       | 	... 113 more
s3g_1       | 2020-06-10 23:58:20,917 [qtp1270038388-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-10 23:58:20,925 [qtp1270038388-19] WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235820Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 4f10b6f740f310080273f0cd1a26da62fb87e2a910fa29b3797054025368c914, signature=59d460d5063cb512fa5af91462138452fffb4c3d613ff33904acae3f67866929, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 2020-06-10 23:58:20,925 [qtp1270038388-19] ERROR client.OzoneClientFactory: Couldn't create RpcClient protocol exception: 
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235820Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 4f10b6f740f310080273f0cd1a26da62fb87e2a910fa29b3797054025368c914, signature=59d460d5063cb512fa5af91462138452fffb4c3d613ff33904acae3f67866929, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:209)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1003)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:112)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:68)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
recon_1     | 2020-06-11 00:03:05,410 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:03:05,516 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:03:05,525 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:03:35,103 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:03:35,117 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:03:35,389 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:03:35,399 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:03:35,539 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:03:35,578 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:03:54,019 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-11 00:03:54,019 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-11 00:03:54,036 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 35
recon_1     | 2020-06-11 00:03:54,065 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 13 OM DB update event(s).
recon_1     | 2020-06-11 00:03:54,079 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-11 00:03:59,959 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:03:59,968 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:03:59,980 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:04:00,002 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:04:00,007 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #3 got from ozonesecure_datanode_2.ozonesecure_default.
recon_1     | 2020-06-11 00:04:00,011 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:04:00,067 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #3 to Recon.
recon_1     | 2020-06-11 00:04:00,073 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #2 got from ozonesecure_datanode_1.ozonesecure_default.
recon_1     | 2020-06-11 00:04:00,081 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1     | 2020-06-11 00:04:00,092 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:04:00,099 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #4 got from ozonesecure_datanode_3.ozonesecure_default.
recon_1     | 2020-06-11 00:04:00,127 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #4 to Recon.
recon_1     | 2020-06-11 00:04:29,970 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:04:29,989 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:04:30,002 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:04:30,006 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:04:30,010 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:04:30,013 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:04:54,089 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2020-06-11 00:04:54,089 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2020-06-11 00:04:54,104 [pool-13-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 12
recon_1     | 2020-06-11 00:04:54,137 [pool-14-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 10 OM DB update event(s).
recon_1     | 2020-06-11 00:04:54,142 [pool-14-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2020-06-11 00:05:00,006 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:05:00,019 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:05:00,024 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
recon_1     | 2020-06-11 00:05:00,038 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:05:00,046 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2020-06-11 00:05:00,053 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2020-06-10 23:57:11,593 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:13,861 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:13,877 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:15,898 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:15,915 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:18,556 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:18,567 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:20,612 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:20,624 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:22,819 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:22,827 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:24,787 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:24,800 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:26,969 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:26,985 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:28,989 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:29,016 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:29,267 [IPC Server handler 91 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access volume /fstest317/null/null
om_1        | 2020-06-10 23:57:31,013 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:31,025 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:31,247 [IPC Server handler 93 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access volume /fstest317/null/null
om_1        | 2020-06-10 23:57:33,006 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:33,020 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:33,218 [IPC Server handler 86 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have WRITE_ACL permission to access volume /fstest317/null/null
om_1        | 2020-06-10 23:57:33,219 [IPC Server handler 86 on default port 9862] ERROR acl.OMVolumeAddAclRequest: Add acl user:testuser2/scm@EXAMPLE.COM:xy[ACCESS] to volume fstest317 failed!
om_1        | PERMISSION_DENIED org.apache.hadoop.ozone.om.exceptions.OMException: User testuser2/scm@EXAMPLE.COM doesn't have WRITE_ACL permission to access volume
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.checkAcls(OzoneManager.java:1655)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.checkAcls(OzoneManager.java:1621)
om_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:152)
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.acl.OMVolumeAclRequest.validateAndUpdateCache(OMVolumeAclRequest.java:81)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-10 23:57:34,953 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:34,964 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:37,118 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:37,128 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2020-06-10 23:55:22,591 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:55:35,098 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:55:35,106 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:55:35,423 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:55:35,436 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:55:35,553 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:55:35,565 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:55:41,309 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:55:41,314 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:55:44,350 [IPC Server handler 36 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
scm_1       | 2020-06-10 23:55:44,350 [IPC Server handler 36 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322389097709701 bcsId: 0
scm_1       | 2020-06-10 23:55:44,350 [IPC Server handler 36 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322384128835713 bcsId: 0
scm_1       | 2020-06-10 23:55:49,687 [EventQueue-Delayed safe mode statusForReplicationManager] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1       | 2020-06-10 23:55:49,709 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 14 milliseconds for processing 1 containers.
scm_1       | 2020-06-10 23:56:05,092 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:56:05,100 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:56:05,398 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:56:05,414 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:56:05,511 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:56:05,515 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:56:26,718 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-10 23:56:26,719 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-06-10 23:56:35,074 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:56:35,092 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:56:35,398 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:56:35,411 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:56:35,537 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:56:35,544 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:56:44,394 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:56:44,408 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:56:44,408 [IPC Server handler 46 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
scm_1       | 2020-06-10 23:56:44,409 [IPC Server handler 46 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322389856419974 bcsId: 0
scm_1       | 2020-06-10 23:56:44,409 [IPC Server handler 46 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322388629651588 bcsId: 0
scm_1       | 2020-06-10 23:57:05,087 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:57:05,090 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:57:05,392 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:57:05,420 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:57:05,524 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:57:05,541 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:57:08,306 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:57:08,308 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:57:35,095 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:57:35,111 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:57:35,410 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:57:35,421 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:57:35,533 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:57:35,543 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:58:05,093 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:58:05,100 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:58:05,414 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:58:05,430 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:58:05,532 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:58:05,542 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:58:13,252 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:58:13,254 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-10 23:58:26,719 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-10 23:58:26,720 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-06-10 23:58:30,282 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:58:30,291 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-10 23:58:35,112 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:58:35,125 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:58:35,393 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:58:35,396 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:58:35,522 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:58:35,527 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:59:05,094 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:59:05,100 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:59:05,386 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:59:05,404 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:59:05,535 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:59:05,546 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:59:05,679 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:59:05,681 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:59:30,424 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:59:30,429 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:59:35,086 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:59:35,113 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2020-06-10 23:57:37,348 [IPC Server handler 98 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access volume /fstest317/null/null
om_1        | 2020-06-10 23:57:39,094 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:39,105 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:41,088 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:41,105 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:43,333 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:43,348 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:45,616 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:45,627 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:45,891 [IPC Server handler 46 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket /fstest317/bk1/null
om_1        | 2020-06-10 23:57:47,653 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:47,664 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:49,791 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:49,803 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:51,775 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:51,785 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:52,103 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:52,113 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:57:54,335 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:57:54,352 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:58:13,232 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:58:13,244 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:58:16,644 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:58:16,652 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:58:16,907 [IPC Server handler 30 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:s3v for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-10 23:58:17,760 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 2cc95e95cc233da8556424b15b3e7398e2427969795162947dfa71e49dde8639
om_1        | 2020-06-10 23:58:17,768 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-10 23:58:17,790 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:58:18,724 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 2cc95e95cc233da8556424b15b3e7398e2427969795162947dfa71e49dde8639
om_1        | 2020-06-10 23:58:18,724 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-10 23:58:18,739 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:58:20,544 [Socket Reader #1 for port 9862] ERROR security.OzoneDelegationTokenSecretManager: Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20200610T235820Z
om_1        | 20200610/us-west-1/s3/aws4_request
om_1        | 4f10b6f740f310080273f0cd1a26da62fb87e2a910fa29b3797054025368c914, signature=59d460d5063cb512fa5af91462138452fffb4c3d613ff33904acae3f67866929, awsAccessKeyId=dlfknslnfslf, omServiceId=null
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3AuthInfo(OzoneDelegationTokenSecretManager.java:455)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:403)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:2115)
scm_1       | 2020-06-10 23:59:35,402 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:59:35,409 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:59:35,524 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:59:35,532 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-10 23:59:44,438 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-10 23:59:44,443 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-10 23:59:44,444 [IPC Server handler 9 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 1 blocks
scm_1       | 2020-06-10 23:59:44,444 [IPC Server handler 9 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322404871700618 bcsId: 0
scm_1       | 2020-06-11 00:00:03,132 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:00:03,139 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-11 00:00:05,096 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:00:05,116 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:00:05,404 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:00:05,425 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:00:05,532 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:00:05,552 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:00:17,738 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:00:17,740 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-11 00:00:26,720 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-11 00:00:26,720 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-06-11 00:00:31,323 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:00:31,331 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-11 00:00:35,075 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:00:35,080 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:00:35,406 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:00:35,409 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:00:35,527 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:00:35,533 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:00:44,479 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:00:44,484 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-11 00:00:44,486 [IPC Server handler 27 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 2 blocks
scm_1       | 2020-06-11 00:00:44,486 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322403249750152 bcsId: 0
scm_1       | 2020-06-11 00:00:44,487 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322403793109129 bcsId: 0
scm_1       | 2020-06-11 00:00:49,711 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2020-06-11 00:01:02,784 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:01:02,793 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-11 00:01:05,094 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:01:05,122 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:01:05,396 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Jun 10, 2020 11:58:20 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:2092)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1984)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1926)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2724)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2526)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2275)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1394)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1250)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
om_1        | 2020-06-10 23:58:20,547 [Socket Reader #1 for port 9862] WARN ipc.Server: Auth failed for 172.26.0.7:58582:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20200610T235820Z
om_1        | 20200610/us-west-1/s3/aws4_request
om_1        | 4f10b6f740f310080273f0cd1a26da62fb87e2a910fa29b3797054025368c914, signature=59d460d5063cb512fa5af91462138452fffb4c3d613ff33904acae3f67866929, awsAccessKeyId=dlfknslnfslf, omServiceId=null)
om_1        | 2020-06-10 23:58:20,924 [Socket Reader #1 for port 9862] ERROR security.OzoneDelegationTokenSecretManager: Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20200610T235820Z
om_1        | 20200610/us-west-1/s3/aws4_request
om_1        | 4f10b6f740f310080273f0cd1a26da62fb87e2a910fa29b3797054025368c914, signature=59d460d5063cb512fa5af91462138452fffb4c3d613ff33904acae3f67866929, awsAccessKeyId=dlfknslnfslf, omServiceId=null
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3AuthInfo(OzoneDelegationTokenSecretManager.java:455)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:403)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:2115)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:2092)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1984)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1926)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2724)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2526)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2275)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1394)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1250)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
om_1        | 2020-06-10 23:58:20,924 [Socket Reader #1 for port 9862] WARN ipc.Server: Auth failed for 172.26.0.7:58586:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20200610T235820Z
om_1        | 20200610/us-west-1/s3/aws4_request
om_1        | 4f10b6f740f310080273f0cd1a26da62fb87e2a910fa29b3797054025368c914, signature=59d460d5063cb512fa5af91462138452fffb4c3d613ff33904acae3f67866929, awsAccessKeyId=dlfknslnfslf, omServiceId=null)
om_1        | 2020-06-10 23:58:22,328 [Socket Reader #1 for port 9862] ERROR security.OzoneDelegationTokenSecretManager: Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20200610T235822Z
om_1        | 20200610/us-west-1/s3/aws4_request
om_1        | 85541cf5a34a6d30c18cda345cb2b86883cfe98f659640d1cef8edcc9a74fc40, signature=f18db4ccb093b03dcbf8240b70ef4673038328c799cf92668fc8f144a3a76538, awsAccessKeyId=dlfknslnfslf, omServiceId=null
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3AuthInfo(OzoneDelegationTokenSecretManager.java:455)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:403)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:2115)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:2092)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1984)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1926)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2724)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2526)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2275)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1394)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1250)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
om_1        | 2020-06-10 23:58:22,328 [Socket Reader #1 for port 9862] WARN ipc.Server: Auth failed for 172.26.0.7:58590:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20200610T235822Z
om_1        | 20200610/us-west-1/s3/aws4_request
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
scm_1       | 2020-06-11 00:01:05,408 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:01:05,531 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:01:05,575 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:01:13,399 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:01:13,401 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-11 00:01:35,092 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:01:35,105 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:01:35,400 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:01:35,415 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:01:35,511 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:01:35,521 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:01:55,745 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:01:55,748 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-11 00:02:05,083 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:02:05,097 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:02:05,416 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:02:05,425 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:02:05,532 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:02:05,539 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:02:26,721 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-11 00:02:26,724 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-06-11 00:02:35,079 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:02:35,099 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:02:35,391 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:02:35,404 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:02:35,518 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:02:35,529 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:02:42,818 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:02:42,819 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-11 00:02:44,496 [IPC Server handler 27 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 5 blocks
scm_1       | 2020-06-11 00:02:44,496 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322415895773343 bcsId: 0,conID: 1 locID: 104322415942762657 bcsId: 0,conID: 1 locID: 104322415896035488 bcsId: 0
scm_1       | 2020-06-11 00:02:44,497 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322414395261075 bcsId: 0
scm_1       | 2020-06-11 00:02:44,497 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322415024668826 bcsId: 0
scm_1       | 2020-06-11 00:02:44,497 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322415461859484 bcsId: 0
scm_1       | 2020-06-11 00:02:44,497 [IPC Server handler 27 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322415674589341 bcsId: 0
scm_1       | 2020-06-11 00:02:55,040 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:02:55,052 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-11 00:03:05,075 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:05,099 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:03:05,382 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:05,398 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:03:05,518 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:05,532 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:03:11,847 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:11,848 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-11 00:03:35,102 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:35,114 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:03:35,386 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:35,399 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:03:35,547 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:35,585 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:03:44,515 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:44,523 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-11 00:03:44,524 [IPC Server handler 39 on default port 9863] INFO server.SCMBlockProtocolServer: SCM is informed by OM to delete 5 blocks
scm_1       | 2020-06-11 00:03:44,524 [IPC Server handler 39 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322419382616237 bcsId: 0
scm_1       | 2020-06-11 00:03:44,525 [IPC Server handler 39 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322419418792110 bcsId: 0
scm_1       | 2020-06-11 00:03:44,525 [IPC Server handler 39 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322418281873578 bcsId: 0
scm_1       | 2020-06-11 00:03:44,525 [IPC Server handler 39 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322418548539563 bcsId: 0
scm_1       | 2020-06-11 00:03:44,526 [IPC Server handler 39 on default port 9863] INFO block.BlockManagerImpl: Deleting blocks conID: 1 locID: 104322418707136684 bcsId: 0
scm_1       | 2020-06-11 00:03:45,881 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:45,899 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-06-11 00:03:46,006 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:46,008 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-11 00:03:48,054 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:48,079 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-06-11 00:03:48,201 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:48,206 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-11 00:03:50,351 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:50,359 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2020-06-11 00:03:50,433 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:50,437 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-11 00:03:50,439 [IPC Server handler 23 on default port 9860] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 0e4f81f7-aef8-47e4-8c46-0cbe4d3a79c9, Nodes: 51d66525-f84b-46be-9310-54df40bdb627{ip: 172.26.0.9, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:STAND_ALONE, Factor:ONE, State:OPEN, leaderId:, CreationTimestamp2020-06-11T00:03:50.438770Z]
scm_1       | 2020-06-11 00:03:58,291 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:58,296 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-11 00:03:58,714 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:58,721 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2020-06-11 00:03:59,959 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:59,966 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:03:59,984 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:248)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:112)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:68)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 104 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235820Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 4f10b6f740f310080273f0cd1a26da62fb87e2a910fa29b3797054025368c914, signature=59d460d5063cb512fa5af91462138452fffb4c3d613ff33904acae3f67866929, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:209)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1003)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:241)
s3g_1       | 	... 113 more
s3g_1       | 
s3g_1       | 
s3g_1       | 23:58:20.936 [qtp1270038388-19] ERROR org.jboss.weld.Bean - WELD-000019: Error destroying an instance org.apache.hadoop.ozone.s3.OzoneClientProducer@1ea45d38 of Managed Bean [class org.apache.hadoop.ozone.s3.OzoneClientProducer] with qualifiers [@Any @Default]
s3g_1       | 2020-06-10 23:58:20,937 [qtp1270038388-19] WARN server.HttpChannel: handleException /bucket-test123 java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 2020-06-10 23:58:20,937 [qtp1270038388-19] WARN server.HttpChannelState: unhandled due to prior sendError
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om_1        | 85541cf5a34a6d30c18cda345cb2b86883cfe98f659640d1cef8edcc9a74fc40, signature=f18db4ccb093b03dcbf8240b70ef4673038328c799cf92668fc8f144a3a76538, awsAccessKeyId=dlfknslnfslf, omServiceId=null)
om_1        | 2020-06-10 23:58:23,114 [Socket Reader #1 for port 9862] ERROR security.OzoneDelegationTokenSecretManager: Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20200610T235823Z
om_1        | 20200610/us-west-1/s3/aws4_request
om_1        | 2384dec37f79ed8489835afd41cd1f261613495a8a4bb80994edb5ced6c9f75f, signature=b4b43b5456b8b418f958e9acdce095826b652c8fa87b010a48268e0f640d237a, awsAccessKeyId=dlfknslnfslf, omServiceId=null
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3AuthInfo(OzoneDelegationTokenSecretManager.java:455)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:403)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:2115)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:2092)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1984)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1926)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2724)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2526)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2275)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1394)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1250)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
om_1        | 2020-06-10 23:58:23,114 [Socket Reader #1 for port 9862] WARN ipc.Server: Auth failed for 172.26.0.7:58594:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20200610T235823Z
om_1        | 20200610/us-west-1/s3/aws4_request
om_1        | 2384dec37f79ed8489835afd41cd1f261613495a8a4bb80994edb5ced6c9f75f, signature=b4b43b5456b8b418f958e9acdce095826b652c8fa87b010a48268e0f640d237a, awsAccessKeyId=dlfknslnfslf, omServiceId=null)
om_1        | 2020-06-10 23:58:28,582 [Socket Reader #1 for port 9862] ERROR security.OzoneDelegationTokenSecretManager: Error while validating S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20200610T235828Z
om_1        | 20200610/us-west-1/s3/aws4_request
om_1        | 55a87f22d237a66a7c510665cf4ac692c899deeef23eae01d1ce75dc7663fd0a, signature=53a0954a905b5b5fc8f47c2801fa197c18da8d75359e16d6e2d319c5b6601568, awsAccessKeyId=dlfknslnfslf, omServiceId=null
om_1        | org.apache.hadoop.ozone.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId dlfknslnfslf
om_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3AuthInfo(OzoneDelegationTokenSecretManager.java:455)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:403)
om_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:56)
om_1        | 	at org.apache.hadoop.security.token.SecretManager.retriableRetrievePassword(SecretManager.java:91)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.getPassword(SaslRpcServer.java:277)
om_1        | 	at org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle(SaslRpcServer.java:304)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.validateClientResponse(DigestMD5Server.java:589)
om_1        | 	at java.security.sasl/com.sun.security.sasl.digest.DigestMD5Server.evaluateResponse(DigestMD5Server.java:244)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslToken(Server.java:2115)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processSaslMessage(Server.java:2092)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslProcess(Server.java:1984)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess(Server.java:1926)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processRpcOutOfBandRequest(Server.java:2724)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:2526)
om_1        | 	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2275)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1394)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1250)
om_1        | 	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
om_1        | 2020-06-10 23:58:28,583 [Socket Reader #1 for port 9862] WARN ipc.Server: Auth failed for 172.26.0.7:58618:null (DIGEST-MD5: IO error acquiring password) with true cause: (No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
om_1        | 20200610T235828Z
om_1        | 20200610/us-west-1/s3/aws4_request
om_1        | 55a87f22d237a66a7c510665cf4ac692c899deeef23eae01d1ce75dc7663fd0a, signature=53a0954a905b5b5fc8f47c2801fa197c18da8d75359e16d6e2d319c5b6601568, awsAccessKeyId=dlfknslnfslf, omServiceId=null)
om_1        | 2020-06-10 23:58:30,255 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:58:30,275 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:58:34,025 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:58:34,034 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:58:36,145 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:58:36,155 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om_1        | 2020-06-10 23:58:45,117 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:58:45,141 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:58:45,395 [IPC Server handler 45 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:fstest for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-10 23:58:47,884 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:58:47,896 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:58:48,145 [IPC Server handler 23 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:fstest2 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-10 23:58:49,901 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:58:49,913 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:58:51,877 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:58:51,887 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:58:52,004 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:58:52,012 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:58:53,900 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:58:53,910 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:58:56,063 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:58:56,087 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:58:58,589 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:58:58,607 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:00,826 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:00,838 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:02,828 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:02,836 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:05,341 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:05,352 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:08,851 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:08,862 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:11,146 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:11,157 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:13,620 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:13,628 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:17,250 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:17,259 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:20,069 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:20,102 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:22,646 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:22,664 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:25,099 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:25,113 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:27,668 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:27,685 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:30,092 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:30,110 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:33,838 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:33,879 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:36,356 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:36,369 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:38,662 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:38,674 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:42,113 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:42,130 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:44,281 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:44,305 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:46,658 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:46,674 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:48,814 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:48,825 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:51,351 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:51,361 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:51,931 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:51,945 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:53,544 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:53,552 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:56,302 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:56,318 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-10 23:59:58,456 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-10 23:59:58,464 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:00:00,755 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:00:00,765 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:00:02,830 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:00:02,838 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:00:06,673 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:00:06,687 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:00:10,247 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:00:10,262 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:00:12,581 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:00:12,593 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:00:14,902 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:00:14,916 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:00:17,298 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:00:17,308 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:00:21,084 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:00:21,100 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:00:24,872 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:00:24,884 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:00:28,884 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:00:28,902 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:00:31,164 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:00:31,180 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:00:33,735 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:00:33,745 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:00:37,185 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:00:37,202 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:00:52,010 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:00:52,028 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:02,764 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:01:02,772 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:06,244 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:01:06,259 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:06,546 [IPC Server handler 12 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:testuser/s3g@EXAMPLE.COM volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:01:08,748 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:01:08,763 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:12,031 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:01:12,043 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:12,281 [IPC Server handler 44 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:testuser/s3g@EXAMPLE.COM volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm_1       | 2020-06-11 00:04:00,015 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:04:00,017 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:04:00,024 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:04:00,032 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-11 00:04:00,077 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:04:26,726 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor ONE. Exception: Cannot create pipeline of factor 1 using 0 nodes. Used 3 nodes. Healthy nodes 3
scm_1       | 2020-06-11 00:04:26,726 [RatisPipelineUtilsThread] ERROR pipeline.SCMPipelineManager: Failed to create pipeline of type RATIS and factor THREE. Exception: Pipeline creation failed because nodes are engaged in other pipelines and every node can only be engaged in max 2 pipelines. Required 3. Found 0
scm_1       | 2020-06-11 00:04:29,953 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:04:29,965 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:04:29,968 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:04:29,971 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:04:30,007 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:04:30,016 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:04:59,972 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:04:59,984 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:04:59,995 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/29984dc17d72@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:05:00,016 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/e740903365c7@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:05:00,023 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:05:00,044 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/7ed8bbd12868@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2020-06-11 00:05:02,623 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:05:02,625 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2020-06-11 00:05:03,064 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS)
scm_1       | 2020-06-11 00:05:03,066 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:01:12,846 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:12,847 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:12,853 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:13,346 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:13,347 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:13,351 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:15,766 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:15,767 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:15,769 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:16,330 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:16,331 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:16,338 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:16,805 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:16,805 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:16,810 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:17,278 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:17,279 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:17,283 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:19,718 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:01:19,735 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:22,991 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:01:23,001 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:23,232 [IPC Server handler 1 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:testuser/s3g@EXAMPLE.COM volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:01:23,787 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:23,787 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:23,795 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:24,460 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:24,460 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:24,477 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:24,963 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:24,963 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:24,972 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:24,981 [IPC Server handler 57 on default port 9862] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-95372 in volume:s3v
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:186)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:01:25,453 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:25,454 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:25,459 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:27,958 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:01:27,978 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:31,445 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:01:31,459 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:31,704 [IPC Server handler 7 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:testuser/s3g@EXAMPLE.COM volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:01:32,299 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:32,300 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:32,301 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:32,769 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:32,769 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:32,773 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:33,253 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:33,253 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:33,258 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:33,270 [IPC Server handler 98 on default port 9862] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket doesn't exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:121)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 45 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 72 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:248)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:112)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:68)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 104 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235820Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 4f10b6f740f310080273f0cd1a26da62fb87e2a910fa29b3797054025368c914, signature=59d460d5063cb512fa5af91462138452fffb4c3d613ff33904acae3f67866929, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:209)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1003)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:241)
s3g_1       | 	... 113 more
s3g_1       | 2020-06-10 23:58:22,322 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-10 23:58:22,336 [qtp1270038388-18] WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235822Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 85541cf5a34a6d30c18cda345cb2b86883cfe98f659640d1cef8edcc9a74fc40, signature=f18db4ccb093b03dcbf8240b70ef4673038328c799cf92668fc8f144a3a76538, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 2020-06-10 23:58:22,336 [qtp1270038388-18] ERROR client.OzoneClientFactory: Couldn't create RpcClient protocol exception: 
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235822Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 85541cf5a34a6d30c18cda345cb2b86883cfe98f659640d1cef8edcc9a74fc40, signature=f18db4ccb093b03dcbf8240b70ef4673038328c799cf92668fc8f144a3a76538, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:209)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1003)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:112)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:68)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:01:35,699 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:01:35,712 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:39,120 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:01:39,130 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:39,385 [IPC Server handler 0 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:testuser/s3g@EXAMPLE.COM volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:01:39,938 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:39,938 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:39,942 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:40,424 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:40,425 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:40,427 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:40,891 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:40,892 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:40,898 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:43,194 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:01:43,211 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:46,503 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:01:46,515 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:46,807 [IPC Server handler 39 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:testuser/s3g@EXAMPLE.COM volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:01:47,256 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:47,256 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:47,261 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:47,723 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:47,723 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:47,726 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:49,966 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:01:49,980 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:52,951 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:01:52,967 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:53,290 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:01:53,298 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:53,586 [IPC Server handler 18 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:testuser/s3g@EXAMPLE.COM volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:01:54,115 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:54,117 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:54,118 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:54,587 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:54,588 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:54,592 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:55,121 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:55,123 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:55,124 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:55,715 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:55,716 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:55,718 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
om_1        | 2020-06-11 00:01:56,653 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:56,654 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:56,657 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:57,413 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:57,413 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:57,416 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:58,038 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:58,038 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:58,043 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:58,813 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:58,813 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:58,818 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:59,389 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:59,390 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:59,395 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:01:59,899 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:01:59,899 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:01:59,911 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:00,689 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:00,690 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:00,691 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:01,247 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:01,247 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:01,250 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:01,833 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:01,834 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:01,847 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:02,435 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:02,435 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:02,441 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:02,453 [IPC Server handler 18 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-99386/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om_1        | 2020-06-11 00:02:02,453 [IPC Server handler 18 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey2 in Volume/Bucket s3v/bucket-99386
om_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: s3vbucket: bucket-99386key: multipartKey2
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:241)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:02:02,474 [IPC Server handler 18 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s3v"
om_1        |   bucketName: "bucket-99386"
om_1        |   keyName: "multipartKey2"
om_1        |   multipartUploadID: "5feb5ae2-6a70-4aef-83f1-51328b5089d6-104322414719664282"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "testuser/s3g@EXAMPLE.COM"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   acls {
om_1        |     type: GROUP
om_1        |     name: "root"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1591833722452
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 1
om_1        |   partName: "/s3v/bucket-99386/multipartKey2104322414756429979"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "/s3v/bucket-99386/multipartKey2104322414795489436"
om_1        | }
om_1        | 
om_1        | 2020-06-11 00:02:02,946 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:02,946 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:02,951 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:03,497 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:03,500 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:03,503 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:03,516 [IPC Server handler 24 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-99386/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om_1        | partName: "etag1"
om_1        | , partNumber: 2
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2020-06-11 00:02:03,517 [IPC Server handler 24 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s3v/bucket-99386
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-99386key: multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:181)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:02:03,518 [IPC Server handler 24 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s3v"
om_1        |   bucketName: "bucket-99386"
om_1        |   keyName: "multipartKey3"
om_1        |   multipartUploadID: "90c5a1a7-f04b-4bdf-9c4f-fea2ca284e5c-104322414868299933"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "testuser/s3g@EXAMPLE.COM"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   acls {
om_1        |     type: GROUP
om_1        |     name: "root"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1591833723516
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 1
om_1        |   partName: "etag1"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "etag2"
om_1        | }
om_1        | 
om_1        | 2020-06-11 00:02:03,978 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:03,978 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:03,982 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:03,995 [IPC Server handler 65 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-99386/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om_1        | partName: "etag1"
om_1        | , partNumber: 1
om_1        | partName: "etag2"
om_1        | ]
om_1        | 2020-06-11 00:02:03,997 [IPC Server handler 65 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s3v/bucket-99386
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-99386key: multipartKey3
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:181)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Jun 10, 2020 11:58:22 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.enterprise.inject.CreationException
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:02:03,998 [IPC Server handler 65 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s3v"
om_1        |   bucketName: "bucket-99386"
om_1        |   keyName: "multipartKey3"
om_1        |   multipartUploadID: "90c5a1a7-f04b-4bdf-9c4f-fea2ca284e5c-104322414868299933"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "testuser/s3g@EXAMPLE.COM"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   acls {
om_1        |     type: GROUP
om_1        |     name: "root"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1591833723995
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "etag1"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 1
om_1        |   partName: "etag2"
om_1        | }
om_1        | 
om_1        | 2020-06-11 00:02:04,536 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:04,536 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:04,538 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:05,332 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:05,333 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:05,337 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:06,161 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:06,161 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:06,163 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:06,747 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:06,748 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:06,749 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:06,757 [IPC Server handler 4 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s3v/bucket-99386
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-99386key: multipartKey3. Provided Part info is { etag1, 1}, where as OM has partName /s3v/bucket-99386/multipartKey3104322414971715742
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:223)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:02:06,758 [IPC Server handler 4 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s3v"
om_1        |   bucketName: "bucket-99386"
om_1        |   keyName: "multipartKey3"
om_1        |   multipartUploadID: "90c5a1a7-f04b-4bdf-9c4f-fea2ca284e5c-104322414868299933"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "testuser/s3g@EXAMPLE.COM"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   acls {
om_1        |     type: GROUP
om_1        |     name: "root"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1591833726757
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 1
om_1        |   partName: "etag1"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "etag2"
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:248)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:112)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:68)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 104 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235822Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 85541cf5a34a6d30c18cda345cb2b86883cfe98f659640d1cef8edcc9a74fc40, signature=f18db4ccb093b03dcbf8240b70ef4673038328c799cf92668fc8f144a3a76538, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:209)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1003)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:241)
s3g_1       | 	... 113 more
s3g_1       | 
s3g_1       | 
s3g_1       | 23:58:22.343 [qtp1270038388-18] ERROR org.jboss.weld.Bean - WELD-000019: Error destroying an instance org.apache.hadoop.ozone.s3.OzoneClientProducer@4a9a2811 of Managed Bean [class org.apache.hadoop.ozone.s3.OzoneClientProducer] with qualifiers [@Any @Default]
s3g_1       | 2020-06-10 23:58:22,343 [qtp1270038388-18] WARN server.HttpChannel: handleException /bucket-test123 java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 2020-06-10 23:58:22,343 [qtp1270038388-18] WARN server.HttpChannelState: unhandled due to prior sendError
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
om_1        | }
om_1        | 
om_1        | 2020-06-11 00:02:07,234 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:07,235 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:07,241 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:07,249 [IPC Server handler 98 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s3v/bucket-99386
om_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-99386key: multipartKey3. Provided Part info is { etag2, 2}, where as OM has partName /s3v/bucket-99386/multipartKey3104322415024013471
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:223)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:02:07,250 [IPC Server handler 98 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s3v"
om_1        |   bucketName: "bucket-99386"
om_1        |   keyName: "multipartKey3"
om_1        |   multipartUploadID: "90c5a1a7-f04b-4bdf-9c4f-fea2ca284e5c-104322414868299933"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "testuser/s3g@EXAMPLE.COM"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   acls {
om_1        |     type: GROUP
om_1        |     name: "root"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1591833727249
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 1
om_1        |   partName: "/s3v/bucket-99386/multipartKey3104322414971715742"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "etag2"
om_1        | }
om_1        | 
om_1        | 2020-06-11 00:02:07,709 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:07,709 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:07,710 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:07,720 [IPC Server handler 60 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-99386/multipartKey3
om_1        | 2020-06-11 00:02:07,721 [IPC Server handler 60 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: multipartKey3 in Volume/Bucket s3v/bucket-99386
om_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-99386key: multipartKey3because parts are in Invalid order.
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:02:07,722 [IPC Server handler 60 on default port 9862] ERROR multipart.S3MultipartUploadCompleteRequest: Unrecognized Result for S3MultipartUploadCommitRequest: keyArgs {
om_1        |   volumeName: "s3v"
om_1        |   bucketName: "bucket-99386"
om_1        |   keyName: "multipartKey3"
om_1        |   multipartUploadID: "90c5a1a7-f04b-4bdf-9c4f-fea2ca284e5c-104322414868299933"
om_1        |   acls {
om_1        |     type: USER
om_1        |     name: "testuser/s3g@EXAMPLE.COM"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   acls {
om_1        |     type: GROUP
om_1        |     name: "root"
om_1        |     rights: "\200"
om_1        |     aclScope: ACCESS
om_1        |   }
om_1        |   modificationTime: 1591833727720
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 4
om_1        |   partName: "/s3v/bucket-99386/multipartKey3104322414971715742"
om_1        | }
om_1        | partsList {
om_1        |   partNumber: 2
om_1        |   partName: "etag2"
om_1        | }
om_1        | 
om_1        | 2020-06-11 00:02:08,195 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:08,196 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:08,203 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:08,672 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:08,672 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:08,673 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:09,334 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:09,334 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:09,336 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:09,875 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:09,875 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:09,876 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:10,354 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:10,354 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:10,355 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:10,369 [IPC Server handler 19 on default port 9862] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName multipartKey5 in VolumeName/Bucket s3v/bucket-99386
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-99386key: multipartKey5
om_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:120)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:02:10,371 [IPC Server handler 19 on default port 9862] ERROR multipart.S3MultipartUploadAbortRequest: Unrecognized Result for S3MultipartUploadAbortRequest: keyArgs {
om_1        |   volumeName: "s3v"
om_1        |   bucketName: "bucket-99386"
om_1        |   keyName: "multipartKey5"
om_1        |   multipartUploadID: "random"
om_1        |   modificationTime: 1591833730368
om_1        | }
om_1        | 
om_1        | 2020-06-11 00:02:10,838 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:10,838 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:10,841 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:10,849 [IPC Server handler 77 on default port 9862] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-99386, KeymultipartKey. Exception:{}
om_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:372)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:314)
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:215)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:02:11,339 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:11,340 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:11,343 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:11,953 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:11,954 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:11,954 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:15,251 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:15,251 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:15,253 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:15,871 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:15,872 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:15,877 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:16,498 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:16,498 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:16,503 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:17,050 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:17,050 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:17,051 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:17,565 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:17,566 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:17,572 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:18,247 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:18,249 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:18,250 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:18,558 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:18,558 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:18,567 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:18,608 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:18,608 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:18,613 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:18,625 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:18,625 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:18,634 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:19,776 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:19,776 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:19,779 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:20,271 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:20,271 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:20,272 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:20,325 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:20,330 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:20,336 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:20,337 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:20,338 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:20,340 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:20,343 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:20,351 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:20,358 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:21,364 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:21,365 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:21,365 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:22,081 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:22,082 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:22,082 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:22,825 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:22,825 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:22,826 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:23,341 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:23,342 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:23,348 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:26,737 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:26,737 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:26,740 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:27,222 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:27,222 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:27,232 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:28,060 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:28,060 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:28,061 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:29,072 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:29,072 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:29,074 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:29,611 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:29,611 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:29,615 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:30,764 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:30,764 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:30,765 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:32,488 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:32,488 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:32,491 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:32,961 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:32,961 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:32,962 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:33,734 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:33,735 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:33,735 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:34,311 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:34,311 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:34,323 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:34,830 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:34,831 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:34,834 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:37,280 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:02:37,295 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:40,931 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:02:40,942 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:41,246 [IPC Server handler 3 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:testuser/s3g@EXAMPLE.COM volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:02:41,870 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:41,870 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:41,872 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:42,333 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:42,333 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:42,338 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:42,800 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:42,800 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:42,801 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:43,335 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:43,335 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:43,349 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:43,823 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:43,824 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:43,825 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:44,421 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:44,422 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:44,425 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:44,894 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:44,895 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:44,900 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:45,490 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:45,490 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:45,491 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:45,959 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:45,960 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:45,960 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:46,438 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:46,438 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:46,439 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:46,902 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:46,903 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:46,905 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:47,361 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:47,363 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:47,367 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:49,627 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:02:49,641 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:53,037 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:02:53,048 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:53,237 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:02:53,248 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:53,493 [IPC Server handler 4 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:testuser/s3g@EXAMPLE.COM volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:02:54,519 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:54,519 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:54,520 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:55,016 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:55,017 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:55,017 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:55,613 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:55,613 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:55,614 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:56,105 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:56,106 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:56,113 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:57,213 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:57,214 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:57,215 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:57,688 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:57,689 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:57,691 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:58,152 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:58,152 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:58,158 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:58,611 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:58,611 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:58,618 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:59,115 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:59,115 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:59,117 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:02:59,709 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:02:59,709 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:02:59,710 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:00,180 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:00,181 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:00,181 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:00,615 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:00,616 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:00,616 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:01,065 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:01,066 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:01,067 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:01,536 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:01,536 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:01,537 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:03,174 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:03,174 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:03,177 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:03,627 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:03,627 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:03,635 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:04,071 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:04,071 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:04,072 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:04,536 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:04,536 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:04,537 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:05,024 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 45 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om_1        | 2020-06-11 00:03:05,024 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:05,025 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:07,215 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:03:07,234 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:10,511 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:03:10,520 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:10,805 [IPC Server handler 75 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:testuser/s3g@EXAMPLE.COM volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:03:11,346 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:11,346 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:11,348 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:11,832 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:11,832 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:11,834 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:12,395 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:12,395 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:12,396 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:12,919 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:12,920 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:12,920 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:13,453 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:13,453 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:13,454 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:13,921 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:13,922 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:13,930 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:13,961 [IPC Server handler 4 on default port 9862] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-69958, Keymultidelete/f4. Exception:{}
om_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:130)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:03:14,423 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:14,423 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:14,424 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:16,590 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:03:16,603 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:20,135 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:03:20,148 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:20,398 [IPC Server handler 26 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:testuser/s3g@EXAMPLE.COM volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:03:20,943 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 72 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:248)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:112)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:68)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 104 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235822Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 85541cf5a34a6d30c18cda345cb2b86883cfe98f659640d1cef8edcc9a74fc40, signature=f18db4ccb093b03dcbf8240b70ef4673038328c799cf92668fc8f144a3a76538, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:209)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1003)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:241)
s3g_1       | 	... 113 more
s3g_1       | 2020-06-10 23:58:23,107 [qtp1270038388-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
om_1        | 2020-06-11 00:03:20,943 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:20,948 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:21,449 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:21,450 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:21,450 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:21,990 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:21,991 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:21,991 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:22,449 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:22,450 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:22,450 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:22,931 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:22,931 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:22,937 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:23,397 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:23,397 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:23,397 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:23,909 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:23,910 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:23,916 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1       | 2020-06-10 23:58:23,115 [qtp1270038388-19] WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235823Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 2384dec37f79ed8489835afd41cd1f261613495a8a4bb80994edb5ced6c9f75f, signature=b4b43b5456b8b418f958e9acdce095826b652c8fa87b010a48268e0f640d237a, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 2020-06-10 23:58:23,116 [qtp1270038388-19] ERROR client.OzoneClientFactory: Couldn't create RpcClient protocol exception: 
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235823Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 2384dec37f79ed8489835afd41cd1f261613495a8a4bb80994edb5ced6c9f75f, signature=b4b43b5456b8b418f958e9acdce095826b652c8fa87b010a48268e0f640d237a, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:209)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1003)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:112)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:68)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
om_1        | 2020-06-11 00:03:24,453 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:24,453 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:24,459 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:24,953 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:24,953 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:24,961 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:25,463 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:25,464 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:25,466 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:25,984 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:25,985 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:25,986 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:26,512 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:26,512 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:26,513 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:27,005 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:27,006 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:27,007 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:27,504 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:27,504 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:27,510 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:28,006 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:28,006 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:28,007 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:28,507 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:28,508 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:28,510 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:29,038 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:29,038 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:29,043 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:29,569 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:29,569 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:29,574 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:30,123 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:30,123 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:30,124 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:30,618 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:30,618 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:30,623 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:31,117 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:31,117 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:31,119 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:33,416 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:03:33,427 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:36,946 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:03:36,960 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:37,178 [IPC Server handler 95 on default port 9862] ERROR volume.OMVolumeCreateRequest: Volume creation failed for user:testuser/s3g@EXAMPLE.COM volume:s3v
om_1        | VOLUME_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Volume already exists
om_1        | 	at org.apache.hadoop.ozone.om.request.volume.OMVolumeCreateRequest.validateAndUpdateCache(OMVolumeCreateRequest.java:174)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:224)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:145)
om_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:74)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:113)
om_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om_1        | 2020-06-11 00:03:37,743 [Socket Reader #1 for port 9862] INFO security.AWSV4AuthValidator: 59d698f20362616502db31890f17a9d37e68d4334c1e3ca2036bf5523853021c
om_1        | 2020-06-11 00:03:37,743 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN)
om_1        | 2020-06-11 00:03:37,748 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/s3g@EXAMPLE.COM (auth:TOKEN) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:54,028 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:03:54,034 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:58,268 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:03:58,280 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:03:58,612 [IPC Server handler 70 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-16968 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-11 00:04:54,096 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:04:54,102 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:05:02,602 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS)
om_1        | 2020-06-11 00:05:02,617 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2020-06-11 00:05:02,923 [IPC Server handler 64 on default port 9862] INFO volume.OMVolumeCreateRequest: created volume:vol-0-18084 for user:testuser/scm@EXAMPLE.COM
om_1        | 2020-06-11 00:05:08,518 [qtp1916139819-131] INFO om.OMDBCheckpointServlet: Received request to obtain OM DB checkpoint snapshot
om_1        | 2020-06-11 00:05:08,686 [qtp1916139819-131] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1591833908518 in 167 milliseconds
om_1        | 2020-06-11 00:05:08,693 [qtp1916139819-131] INFO om.OMDBCheckpointServlet: Time taken to write the checkpoint to response output stream: 6 milliseconds
om_1        | 2020-06-11 00:05:08,693 [qtp1916139819-131] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/rdb_rdb_checkpoint_1591833908518
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Jun 10, 2020 11:58:23 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:248)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:112)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:68)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 104 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235823Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 2384dec37f79ed8489835afd41cd1f261613495a8a4bb80994edb5ced6c9f75f, signature=b4b43b5456b8b418f958e9acdce095826b652c8fa87b010a48268e0f640d237a, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:209)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1003)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:241)
s3g_1       | 	... 113 more
s3g_1       | 
s3g_1       | 
s3g_1       | 23:58:23.119 [qtp1270038388-19] ERROR org.jboss.weld.Bean - WELD-000019: Error destroying an instance org.apache.hadoop.ozone.s3.OzoneClientProducer@490bd5ac of Managed Bean [class org.apache.hadoop.ozone.s3.OzoneClientProducer] with qualifiers [@Any @Default]
s3g_1       | 2020-06-10 23:58:23,120 [qtp1270038388-19] WARN server.HttpChannel: handleException /bucket-test123 java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 2020-06-10 23:58:23,120 [qtp1270038388-19] WARN server.HttpChannelState: unhandled due to prior sendError
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 45 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 72 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:248)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:112)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:68)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 104 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235823Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 2384dec37f79ed8489835afd41cd1f261613495a8a4bb80994edb5ced6c9f75f, signature=b4b43b5456b8b418f958e9acdce095826b652c8fa87b010a48268e0f640d237a, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:209)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1003)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:241)
s3g_1       | 	... 113 more
s3g_1       | 2020-06-10 23:58:28,575 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-10 23:58:28,583 [qtp1270038388-18] WARN ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235828Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 55a87f22d237a66a7c510665cf4ac692c899deeef23eae01d1ce75dc7663fd0a, signature=53a0954a905b5b5fc8f47c2801fa197c18da8d75359e16d6e2d319c5b6601568, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 2020-06-10 23:58:28,584 [qtp1270038388-18] ERROR client.OzoneClientFactory: Couldn't create RpcClient protocol exception: 
s3g_1       | org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235828Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 55a87f22d237a66a7c510665cf4ac692c899deeef23eae01d1ce75dc7663fd0a, signature=53a0954a905b5b5fc8f47c2801fa197c18da8d75359e16d6e2d319c5b6601568, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:209)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1003)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:241)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:112)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:68)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Jun 10, 2020 11:58:28 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1       | MultiException stack 1 of 1
s3g_1       | javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:248)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:112)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:68)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 104 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235828Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 55a87f22d237a66a7c510665cf4ac692c899deeef23eae01d1ce75dc7663fd0a, signature=53a0954a905b5b5fc8f47c2801fa197c18da8d75359e16d6e2d319c5b6601568, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:209)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1003)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:241)
s3g_1       | 	... 113 more
s3g_1       | 
s3g_1       | 
s3g_1       | 23:58:28.588 [qtp1270038388-18] ERROR org.jboss.weld.Bean - WELD-000019: Error destroying an instance org.apache.hadoop.ozone.s3.OzoneClientProducer@77913af1 of Managed Bean [class org.apache.hadoop.ozone.s3.OzoneClientProducer] with qualifiers [@Any @Default]
s3g_1       | 2020-06-10 23:58:28,588 [qtp1270038388-18] WARN server.HttpChannel: handleException /bucket-test123 java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 2020-06-10 23:58:28,589 [qtp1270038388-18] WARN server.HttpChannelState: unhandled due to prior sendError
s3g_1       | javax.servlet.ServletException: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:162)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: javax.servlet.ServletException: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:432)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	... 17 more
s3g_1       | Caused by: A MultiException has 1 exceptions.  They are:
s3g_1       | 1. javax.enterprise.inject.CreationException
s3g_1       | 
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:494)
s3g_1       | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:70)
s3g_1       | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2126)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:777)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:740)
s3g_1       | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:710)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:184)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:54)
s3g_1       | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:129)
s3g_1       | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:284)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:75)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:110)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:113)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:93)
s3g_1       | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:62)
s3g_1       | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:197)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:269)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	... 45 more
s3g_1       | Caused by: javax.enterprise.inject.CreationException
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
s3g_1       | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1       | 	at java.base/java.lang.Class.newInstance(Class.java:584)
s3g_1       | 	at org.jboss.weld.security.NewInstanceAction.run(NewInstanceAction.java:33)
s3g_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:40)
s3g_1       | 	at org.jboss.weld.injection.Exceptions.rethrowException(Exceptions.java:78)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:96)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1       | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1       | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1       | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1       | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1       | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1       | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1       | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1       | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1       | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:873)
s3g_1       | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1       | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1       | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1       | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1       | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1       | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:151)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:93)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:127)
s3g_1       | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:70)
s3g_1       | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:77)
s3g_1       | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:153)
s3g_1       | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:487)
s3g_1       | 	... 72 more
s3g_1       | Caused by: java.io.IOException: Couldn't create RpcClient protocol
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:248)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:224)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getRpcClient(OzoneClientFactory.java:145)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getClient(OzoneClientProducer.java:112)
s3g_1       | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.createClient(OzoneClientProducer.java:68)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1       | 	... 104 more
s3g_1       | Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): No S3 secret found for S3 identifier:OzoneToken owner=dlfknslnfslf, renewer=, realUser=, issueDate=0, maxDate=0, sequenceNumber=0, masterKeyId=0, strToSign=AWS4-HMAC-SHA256
s3g_1       | 20200610T235828Z
s3g_1       | 20200610/us-west-1/s3/aws4_request
s3g_1       | 55a87f22d237a66a7c510665cf4ac692c899deeef23eae01d1ce75dc7663fd0a, signature=53a0954a905b5b5fc8f47c2801fa197c18da8d75359e16d6e2d319c5b6601568, awsAccessKeyId=dlfknslnfslf, omServiceId=null
s3g_1       | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
s3g_1       | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
s3g_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
s3g_1       | 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
s3g_1       | 	at com.sun.proxy.$Proxy88.submitRequest(Unknown Source)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:86)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:209)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceInfo(OzoneManagerProtocolClientSideTranslatorPB.java:1003)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.<init>(RpcClient.java:173)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneClientFactory.getClientProtocol(OzoneClientFactory.java:241)
s3g_1       | 	... 113 more
s3g_1       | 2020-06-11 00:01:12,835 [qtp1270038388-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:12,861 [qtp1270038388-15] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-42681, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-11 00:01:12,871 [qtp1270038388-15] INFO endpoint.BucketEndpoint: Location is /bucket-42681
s3g_1       | 2020-06-11 00:01:13,337 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:14,282 [qtp1270038388-18] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1       | 2020-06-11 00:01:14,335 [qtp1270038388-18] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1       | 2020-06-11 00:01:14,335 [qtp1270038388-18] INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
s3g_1       | 2020-06-11 00:01:14,336 [qtp1270038388-18] WARN impl.MetricsSystemImpl: Sink prometheus already exists!
s3g_1       | 2020-06-11 00:01:15,750 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:16,324 [qtp1270038388-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:16,799 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:17,272 [qtp1270038388-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:23,782 [qtp1270038388-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:23,802 [qtp1270038388-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-94298, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-11 00:01:23,987 [qtp1270038388-19] INFO endpoint.BucketEndpoint: Location is /bucket-94298
s3g_1       | 2020-06-11 00:01:24,451 [qtp1270038388-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:24,486 [qtp1270038388-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-95372, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-11 00:01:24,494 [qtp1270038388-19] INFO endpoint.BucketEndpoint: Location is /bucket-95372
s3g_1       | 2020-06-11 00:01:24,956 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:24,979 [qtp1270038388-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-95372, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-11 00:01:24,988 [qtp1270038388-18] INFO endpoint.BucketEndpoint: Location is /bucket-95372
s3g_1       | 2020-06-11 00:01:25,442 [qtp1270038388-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:25,467 [qtp1270038388-19] ERROR endpoint.BucketEndpoint: Error in Create Bucket Request for bucket: bucket_1
s3g_1       | INVALID_BUCKET_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Bucket or Volume name has an unsupported character : _
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.verifyBucketName(RpcClient.java:469)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:419)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:410)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneVolume.createBucket(OzoneVolume.java:213)
s3g_1       | 	at org.apache.hadoop.ozone.client.ObjectStore.createS3Bucket(ObjectStore.java:118)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.createS3Bucket(EndpointBase.java:96)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:205)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-11 00:01:32,294 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:32,307 [qtp1270038388-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-31961, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-11 00:01:32,316 [qtp1270038388-18] INFO endpoint.BucketEndpoint: Location is /bucket-31961
s3g_1       | 2020-06-11 00:01:32,764 [qtp1270038388-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:33,245 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:39,933 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:39,951 [qtp1270038388-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-40785, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-11 00:01:39,962 [qtp1270038388-18] INFO endpoint.BucketEndpoint: Location is /bucket-40785
s3g_1       | 2020-06-11 00:01:40,418 [qtp1270038388-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:40,886 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:40,905 [qtp1270038388-18] ERROR endpoint.BucketEndpoint: Exception occurred in headBucket
s3g_1       | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:107)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:72)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:253)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-11 00:01:47,251 [qtp1270038388-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:47,266 [qtp1270038388-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-42419, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-11 00:01:47,276 [qtp1270038388-19] INFO endpoint.BucketEndpoint: Location is /bucket-42419
s3g_1       | 2020-06-11 00:01:47,718 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:54,110 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:54,124 [qtp1270038388-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-99386, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-11 00:01:54,136 [qtp1270038388-20] INFO endpoint.BucketEndpoint: Location is /bucket-99386
s3g_1       | 2020-06-11 00:01:54,583 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:55,116 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:55,706 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:56,646 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:57,403 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:58,031 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:58,805 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:59,385 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:01:59,894 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:00,685 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:01,243 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:01,826 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:02,430 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:02,475 [qtp1270038388-18] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-99386, , key: multipartKey2
s3g_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: Entity too small: volume: s3vbucket: bucket-99386key: multipartKey2
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:884)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:900)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-11 00:02:02,930 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:03,493 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:03,529 [qtp1270038388-18] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-99386, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-99386key: multipartKey3
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:884)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:900)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-11 00:02:03,973 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:04,003 [qtp1270038388-18] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-99386, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-99386key: multipartKey3
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:884)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:900)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-11 00:02:04,529 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:05,325 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:06,157 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:06,742 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:06,765 [qtp1270038388-18] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-99386, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-99386key: multipartKey3. Provided Part info is { etag1, 1}, where as OM has partName /s3v/bucket-99386/multipartKey3104322414971715742
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:884)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:900)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-11 00:02:07,230 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:07,255 [qtp1270038388-18] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-99386, , key: multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-99386key: multipartKey3. Provided Part info is { etag2, 2}, where as OM has partName /s3v/bucket-99386/multipartKey3104322415024013471
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:884)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:900)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-11 00:02:07,705 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:07,728 [qtp1270038388-18] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-99386, , key: multipartKey3
s3g_1       | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3vbucket: bucket-99386key: multipartKey3because parts are in Invalid order.
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:589)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:884)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:900)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:446)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:476)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsyncServlet.service(ServletHolder.java:1395)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:755)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1617)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1596)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1640)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:545)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:590)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1607)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1297)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:485)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1577)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1212)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:500)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:547)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:270)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-06-11 00:02:08,185 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:08,666 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:09,328 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:09,868 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:10,348 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:10,833 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:11,330 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:11,947 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:15,245 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:15,867 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:16,493 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:17,044 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:17,559 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:18,242 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:18,550 [qtp1270038388-20] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:18,583 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:18,604 [qtp1270038388-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:19,358 [qtp1270038388-20] WARN io.KeyOutputStream: Encountered exception java.io.IOException: Unexpected Storage Container Exception: java.util.concurrent.CompletionException: java.util.concurrent.CompletionException: org.apache.ratis.protocol.StateMachineException: org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Block token verification failed. Fail to find any token (empty or null.) on the pipeline Pipeline[ Id: e8e97232-1ec5-4e87-b560-d686c3ce217f, Nodes: 51d66525-f84b-46be-9310-54df40bdb627{ip: 172.26.0.9, host: ozonesecure_datanode_1.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}6ece063b-e1a0-4363-8e78-5ecf0377c4b0{ip: 172.26.0.10, host: ozonesecure_datanode_3.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}41410284-0e36-4425-9317-2f8ae5197d6c{ip: 172.26.0.2, host: ozonesecure_datanode_2.ozonesecure_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:6ece063b-e1a0-4363-8e78-5ecf0377c4b0, CreationTimestamp2020-06-10T23:50:41.044Z]. The last committed block length is 0, uncommitted data length is 8388608 retry count 0
s3g_1       | 2020-06-11 00:02:19,359 [qtp1270038388-20] INFO io.BlockOutputStreamEntryPool: Allocating block with ExcludeList {datanodes = [], containerIds = [], pipelineIds = [PipelineID=e8e97232-1ec5-4e87-b560-d686c3ce217f]}
s3g_1       | 2020-06-11 00:02:19,769 [qtp1270038388-21] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:20,267 [qtp1270038388-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:20,320 [qtp1270038388-21] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:20,324 [qtp1270038388-19] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:20,329 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:21,360 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:22,075 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:22,820 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:23,337 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:26,733 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:27,218 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:28,049 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:29,064 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:29,604 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:30,757 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:32,484 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:32,956 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:33,728 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:34,307 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:34,825 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:41,865 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:41,876 [qtp1270038388-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-32471, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-11 00:02:41,885 [qtp1270038388-17] INFO endpoint.BucketEndpoint: Location is /bucket-32471
s3g_1       | 2020-06-11 00:02:42,329 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:42,342 [qtp1270038388-18] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-86167, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-11 00:02:42,349 [qtp1270038388-18] INFO endpoint.BucketEndpoint: Location is /destbucket-86167
s3g_1       | 2020-06-11 00:02:42,796 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:43,331 [qtp1270038388-18] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:43,819 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:44,417 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:44,891 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:45,486 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:45,953 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:46,430 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:46,898 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:47,357 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:54,515 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:54,524 [qtp1270038388-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-84293, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-11 00:02:54,534 [qtp1270038388-17] INFO endpoint.BucketEndpoint: Location is /bucket-84293
s3g_1       | 2020-06-11 00:02:55,004 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:55,608 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:56,102 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:57,209 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:57,684 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:58,145 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:58,607 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:59,111 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:02:59,705 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:00,176 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:00,611 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:01,061 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:01,530 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:03,170 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:03,623 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:04,067 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:04,533 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:05,020 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:11,342 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:11,355 [qtp1270038388-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-69958, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-11 00:03:11,366 [qtp1270038388-22] INFO endpoint.BucketEndpoint: Location is /bucket-69958
s3g_1       | 2020-06-11 00:03:11,828 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:12,389 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:12,913 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:13,448 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:13,917 [qtp1270038388-17] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:14,419 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:20,939 [qtp1270038388-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:20,968 [qtp1270038388-15] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-28416, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-11 00:03:20,978 [qtp1270038388-15] INFO endpoint.BucketEndpoint: Location is /bucket-28416
s3g_1       | 2020-06-11 00:03:21,446 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:21,976 [qtp1270038388-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:22,446 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:22,926 [qtp1270038388-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:23,393 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:23,902 [qtp1270038388-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:24,449 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:24,949 [qtp1270038388-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:25,460 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:25,975 [qtp1270038388-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:26,507 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:27,002 [qtp1270038388-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:27,500 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:28,003 [qtp1270038388-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:28,504 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:29,034 [qtp1270038388-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:29,565 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:30,119 [qtp1270038388-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:30,615 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:31,113 [qtp1270038388-15] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:37,740 [qtp1270038388-22] INFO s3.AWSV4SignatureProcessor: Initializing request header parser
s3g_1       | 2020-06-11 00:03:37,751 [qtp1270038388-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-84079, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-06-11 00:03:37,762 [qtp1270038388-22] INFO endpoint.BucketEndpoint: Location is /bucket-84079
