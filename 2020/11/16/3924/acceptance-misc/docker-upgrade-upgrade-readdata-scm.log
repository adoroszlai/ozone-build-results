Attaching to upgrade_scm_1, upgrade_s3g_1, upgrade_dn3_1, upgrade_om_1, upgrade_dn1_1, upgrade_dn2_1, upgrade_recon_1
dn2_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
dn2_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn2_1    | 2020-11-16 13:37:43,589 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn2_1    | /************************************************************
dn2_1    | STARTUP_MSG: Starting HddsDatanodeService
dn2_1    | STARTUP_MSG:   host = ff71737d310f/10.9.0.12
dn2_1    | STARTUP_MSG:   args = []
dn2_1    | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
dn2_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
dn2_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/787e5b6247912eb5f19ffb2f6dc0b82380b77d37 ; compiled by 'runner' on 2020-11-16T12:42Z
dn2_1    | STARTUP_MSG:   java = 11.0.7
dn2_1    | ************************************************************/
dn2_1    | 2020-11-16 13:37:43,642 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn2_1    | 2020-11-16 13:37:45,381 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn2_1    | 2020-11-16 13:37:45,970 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn2_1    | 2020-11-16 13:37:46,782 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn2_1    | 2020-11-16 13:37:46,783 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn2_1    | 2020-11-16 13:37:47,700 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:ff71737d310f ip:10.9.0.12
dn2_1    | 2020-11-16 13:37:48,562 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 8192 at 2020-11-16T13:37:30.054Z
dn2_1    | 2020-11-16 13:37:48,593 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 14727258112
dn2_1    | 2020-11-16 13:37:48,599 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn2_1    | 2020-11-16 13:37:48,624 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn2_1    | 2020-11-16 13:37:48,745 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn2_1    | 2020-11-16 13:37:48,967 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn2_1    | 2020-11-16 13:37:48,971 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn2_1    | 2020-11-16 13:37:48,971 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
dn2_1    | 2020-11-16 13:37:55,477 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn2_1    | 2020-11-16 13:37:55,704 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
dn2_1    | 2020-11-16 13:37:56,085 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
dn2_1    | 2020-11-16 13:37:56,112 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn2_1    | 2020-11-16 13:37:56,113 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2020-11-16 13:37:56,113 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn2_1    | 2020-11-16 13:37:56,114 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn2_1    | 2020-11-16 13:37:57,669 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2020-11-16 13:37:57,714 [main] INFO impl.RaftServerProxy: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: found a subdirectory /data/metadata/ratis/d48b93e3-afae-4915-a84b-c976ad8bd76d
dn2_1    | 2020-11-16 13:37:57,771 [main] INFO impl.RaftServerProxy: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: addNew group-C976AD8BD76D:[] returns group-C976AD8BD76D:java.util.concurrent.CompletableFuture@60325987[Not completed]
dn2_1    | 2020-11-16 13:37:57,771 [main] INFO impl.RaftServerProxy: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: found a subdirectory /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2
dn2_1    | 2020-11-16 13:37:57,771 [main] INFO impl.RaftServerProxy: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: addNew group-52E326379EE2:[] returns group-52E326379EE2:java.util.concurrent.CompletableFuture@2f37f1f9[Not completed]
dn2_1    | 2020-11-16 13:37:57,773 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn2_1    | 2020-11-16 13:37:58,081 [pool-19-thread-1] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: new RaftServerImpl for group-C976AD8BD76D:[] with ContainerStateMachine:uninitialized
dn2_1    | 2020-11-16 13:37:58,082 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2020-11-16 13:37:58,100 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2020-11-16 13:37:58,110 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
dn2_1    | 2020-11-16 13:37:58,121 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
dn2_1    | 2020-11-16 13:37:58,121 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2020-11-16 13:37:58,198 [pool-19-thread-1] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn2_1    | 2020-11-16 13:37:58,199 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2020-11-16 13:37:58,228 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2020-11-16 13:37:58,339 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d48b93e3-afae-4915-a84b-c976ad8bd76d/in_use.lock acquired by nodename 6@ff71737d310f
dn2_1    | 2020-11-16 13:37:58,650 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-C976AD8BD76D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn2_1    | 2020-11-16 13:37:58,687 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2020-11-16 13:37:58,727 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2020-11-16 13:37:58,749 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2020-11-16 13:37:58,750 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn2_1    | 2020-11-16 13:37:58,869 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D
dn2_1    | 2020-11-16 13:37:58,955 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2020-11-16 13:37:58,957 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2020-11-16 13:37:59,042 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn2_1    | 2020-11-16 13:37:59,106 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2020-11-16 13:37:59,170 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/d48b93e3-afae-4915-a84b-c976ad8bd76d
dn2_1    | 2020-11-16 13:37:59,191 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn2_1    | 2020-11-16 13:37:59,196 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2020-11-16 13:37:59,216 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2020-11-16 13:37:59,218 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2020-11-16 13:37:59,246 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2020-11-16 13:37:59,259 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2020-11-16 13:37:59,264 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2020-11-16 13:37:59,269 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2020-11-16 13:37:59,287 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2020-11-16 13:37:59,338 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2020-11-16 13:37:59,424 [main] INFO util.log: Logging initialized @20887ms to org.eclipse.jetty.util.log.Slf4jLog
dn2_1    | 2020-11-16 13:38:00,053 [pool-19-thread-1] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D: set configuration 0: [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0], old=null at 0
dn2_1    | 2020-11-16 13:38:00,080 [pool-19-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/d48b93e3-afae-4915-a84b-c976ad8bd76d/current/log_inprogress_0
dn2_1    | 2020-11-16 13:38:00,132 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
dn2_1    | 2020-11-16 13:38:00,132 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn2_1    | 2020-11-16 13:38:00,574 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn2_1    | 2020-11-16 13:38:00,592 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn2_1    | 2020-11-16 13:38:00,637 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn2_1    | 2020-11-16 13:38:00,657 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn2_1    | 2020-11-16 13:38:00,657 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn2_1    | 2020-11-16 13:38:00,657 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn2_1    | 2020-11-16 13:38:00,705 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2020-11-16 13:38:00,715 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2020-11-16 13:38:00,721 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2020-11-16 13:38:00,731 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2020-11-16 13:38:00,732 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2020-11-16 13:38:00,975 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D
dn2_1    | 2020-11-16 13:38:01,038 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D
dn2_1    | 2020-11-16 13:38:01,109 [pool-19-thread-1] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: new RaftServerImpl for group-52E326379EE2:[] with ContainerStateMachine:uninitialized
dn2_1    | 2020-11-16 13:38:01,109 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2020-11-16 13:38:01,110 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2020-11-16 13:38:01,164 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
dn2_1    | 2020-11-16 13:38:01,164 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
dn2_1    | 2020-11-16 13:38:01,165 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2020-11-16 13:38:01,165 [pool-19-thread-1] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn2_1    | 2020-11-16 13:38:01,165 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2020-11-16 13:38:01,166 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2020-11-16 13:38:01,175 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2/in_use.lock acquired by nodename 6@ff71737d310f
dn2_1    | 2020-11-16 13:38:01,176 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-52E326379EE2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn2_1    | 2020-11-16 13:38:01,179 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2020-11-16 13:38:01,179 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2020-11-16 13:38:01,180 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2020-11-16 13:38:01,180 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2
dn2_1    | 2020-11-16 13:38:01,180 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2020-11-16 13:38:01,183 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2020-11-16 13:38:01,197 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn2_1    | 2020-11-16 13:38:01,199 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
dn2_1    | 2020-11-16 13:38:01,197 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2020-11-16 13:38:01,215 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2
dn2_1    | 2020-11-16 13:38:01,215 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn2_1    | 2020-11-16 13:38:01,215 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2020-11-16 13:38:01,215 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2020-11-16 13:38:01,215 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2020-11-16 13:38:01,216 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2020-11-16 13:38:01,216 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2020-11-16 13:38:01,216 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2020-11-16 13:38:01,216 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2020-11-16 13:38:01,216 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2020-11-16 13:38:01,217 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2020-11-16 13:38:01,220 [pool-19-thread-1] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2: set configuration 0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null at 0
dn2_1    | 2020-11-16 13:38:01,273 [pool-19-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2/current/log_inprogress_0
dn2_1    | 2020-11-16 13:38:01,347 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
dn2_1    | 2020-11-16 13:38:01,347 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn2_1    | 2020-11-16 13:38:01,364 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2020-11-16 13:38:01,367 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2020-11-16 13:38:01,367 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2020-11-16 13:38:01,367 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2020-11-16 13:38:01,368 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2020-11-16 13:38:01,368 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2
dn2_1    | 2020-11-16 13:38:01,368 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2
dn2_1    | 2020-11-16 13:38:01,617 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn2_1    | 2020-11-16 13:38:01,621 [main] INFO server.session: No SessionScavenger set, using defaults
dn2_1    | 2020-11-16 13:38:01,648 [main] INFO server.session: node0 Scavenging every 660000ms
dn2_1    | 2020-11-16 13:38:01,724 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2f3166a{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn2_1    | 2020-11-16 13:38:01,730 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4b76aa5a{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn2_1    | 2020-11-16 13:38:02,316 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3c6c4689{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-15255260993674446118/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn2_1    | 2020-11-16 13:38:02,397 [main] INFO server.AbstractConnector: Started ServerConnector@5984feef{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn2_1    | 2020-11-16 13:38:02,398 [main] INFO server.Server: Started @23860ms
dn2_1    | 2020-11-16 13:38:02,411 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn2_1    | 2020-11-16 13:38:02,418 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn2_1    | 2020-11-16 13:38:02,427 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn2_1    | 2020-11-16 13:38:02,502 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@d570e4f] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn2_1    | 2020-11-16 13:38:02,779 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.15:9891
dn2_1    | 2020-11-16 13:38:05,696 [EndpointStateMachine task thread for recon/10.9.0.15:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.15:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2020-11-16 13:38:05,734 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
dn2_1    | java.net.SocketTimeoutException: Call From ff71737d310f/10.9.0.12 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.12:53768 remote=scm/10.9.0.17:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn2_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn2_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
dn2_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
dn2_1    | 	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn2_1    | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.12:53768 remote=scm/10.9.0.17:9861]
dn3_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
dn3_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn3_1    | 2020-11-16 13:37:44,644 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn3_1    | /************************************************************
dn3_1    | STARTUP_MSG: Starting HddsDatanodeService
dn3_1    | STARTUP_MSG:   host = d1cf08a8030b/10.9.0.13
dn3_1    | STARTUP_MSG:   args = []
dn3_1    | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
dn3_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
dn3_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/787e5b6247912eb5f19ffb2f6dc0b82380b77d37 ; compiled by 'runner' on 2020-11-16T12:42Z
dn3_1    | STARTUP_MSG:   java = 11.0.7
dn3_1    | ************************************************************/
dn3_1    | 2020-11-16 13:37:44,678 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn3_1    | 2020-11-16 13:37:46,413 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn3_1    | 2020-11-16 13:37:46,972 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn3_1    | 2020-11-16 13:37:47,811 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn3_1    | 2020-11-16 13:37:47,811 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn3_1    | 2020-11-16 13:37:48,856 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:d1cf08a8030b ip:10.9.0.13
dn3_1    | 2020-11-16 13:37:49,429 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 8192 at 2020-11-16T13:37:30.029Z
dn3_1    | 2020-11-16 13:37:49,444 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 14727258112
dn3_1    | 2020-11-16 13:37:49,456 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn3_1    | 2020-11-16 13:37:49,508 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn3_1    | 2020-11-16 13:37:49,622 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn3_1    | 2020-11-16 13:37:49,867 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn3_1    | 2020-11-16 13:37:51,306 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn3_1    | 2020-11-16 13:37:51,309 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 1s
dn3_1    | 2020-11-16 13:37:58,816 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn3_1    | 2020-11-16 13:37:59,178 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
dn3_1    | 2020-11-16 13:37:59,767 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
dn3_1    | 2020-11-16 13:37:59,771 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn3_1    | 2020-11-16 13:37:59,773 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2020-11-16 13:37:59,775 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn3_1    | 2020-11-16 13:37:59,777 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2020-11-16 13:38:00,693 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2020-11-16 13:38:00,700 [main] INFO impl.RaftServerProxy: 38c1c219-c9e2-4898-90d7-f000768b0cf3: found a subdirectory /data/metadata/ratis/078fbcbb-0c1b-4852-9c3c-73dafe3709bc
dn3_1    | 2020-11-16 13:38:00,734 [main] INFO impl.RaftServerProxy: 38c1c219-c9e2-4898-90d7-f000768b0cf3: addNew group-73DAFE3709BC:[] returns group-73DAFE3709BC:java.util.concurrent.CompletableFuture@4a67b4ec[Not completed]
dn3_1    | 2020-11-16 13:38:00,743 [main] INFO impl.RaftServerProxy: 38c1c219-c9e2-4898-90d7-f000768b0cf3: found a subdirectory /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2
dn3_1    | 2020-11-16 13:38:00,743 [main] INFO impl.RaftServerProxy: 38c1c219-c9e2-4898-90d7-f000768b0cf3: addNew group-52E326379EE2:[] returns group-52E326379EE2:java.util.concurrent.CompletableFuture@10643593[Not completed]
dn3_1    | 2020-11-16 13:38:00,744 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn3_1    | 2020-11-16 13:38:00,889 [pool-22-thread-1] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3: new RaftServerImpl for group-73DAFE3709BC:[] with ContainerStateMachine:uninitialized
dn3_1    | 2020-11-16 13:38:00,919 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2020-11-16 13:38:00,919 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2020-11-16 13:38:00,923 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
dn3_1    | 2020-11-16 13:38:00,924 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
dn3_1    | 2020-11-16 13:38:00,924 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2020-11-16 13:38:00,982 [pool-22-thread-1] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn3_1    | 2020-11-16 13:38:00,987 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2020-11-16 13:38:01,015 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2020-11-16 13:38:01,109 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/078fbcbb-0c1b-4852-9c3c-73dafe3709bc/in_use.lock acquired by nodename 6@d1cf08a8030b
dn3_1    | 2020-11-16 13:38:01,740 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-73DAFE3709BC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn3_1    | 2020-11-16 13:38:01,753 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn3_1    | 2020-11-16 13:38:01,787 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn3_1    | 2020-11-16 13:38:01,858 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn3_1    | 2020-11-16 13:38:01,862 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2020-11-16 13:38:01,950 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC
dn3_1    | 2020-11-16 13:38:02,032 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn3_1    | 2020-11-16 13:38:02,042 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2020-11-16 13:38:02,052 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2020-11-16 13:38:02,211 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2020-11-16 13:38:02,288 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/078fbcbb-0c1b-4852-9c3c-73dafe3709bc
dn3_1    | 2020-11-16 13:38:02,291 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn1_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
dn1_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn1_1    | 2020-11-16 13:37:39,578 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn1_1    | /************************************************************
dn1_1    | STARTUP_MSG: Starting HddsDatanodeService
dn1_1    | STARTUP_MSG:   host = 5c4e0b586e9d/10.9.0.11
dn1_1    | STARTUP_MSG:   args = []
dn1_1    | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
dn1_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
dn1_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/787e5b6247912eb5f19ffb2f6dc0b82380b77d37 ; compiled by 'runner' on 2020-11-16T12:42Z
dn1_1    | STARTUP_MSG:   java = 11.0.7
dn1_1    | ************************************************************/
dn1_1    | 2020-11-16 13:37:39,720 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn1_1    | 2020-11-16 13:37:41,529 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn1_1    | 2020-11-16 13:37:41,933 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn1_1    | 2020-11-16 13:37:42,868 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn1_1    | 2020-11-16 13:37:42,868 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn1_1    | 2020-11-16 13:37:43,821 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:5c4e0b586e9d ip:10.9.0.11
dn1_1    | 2020-11-16 13:37:44,619 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 8192 at 2020-11-16T13:37:30.023Z
dn1_1    | 2020-11-16 13:37:44,654 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 14727258112
dn1_1    | 2020-11-16 13:37:44,669 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn1_1    | 2020-11-16 13:37:44,687 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn1_1    | 2020-11-16 13:37:44,766 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn1_1    | 2020-11-16 13:37:45,068 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn1_1    | 2020-11-16 13:37:45,069 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn1_1    | 2020-11-16 13:37:45,075 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
dn1_1    | 2020-11-16 13:37:52,652 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn1_1    | 2020-11-16 13:37:52,878 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
dn1_1    | 2020-11-16 13:37:53,370 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
dn1_1    | 2020-11-16 13:37:53,396 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn1_1    | 2020-11-16 13:37:53,397 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2020-11-16 13:37:53,401 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn1_1    | 2020-11-16 13:37:53,409 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn1_1    | 2020-11-16 13:37:54,963 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2020-11-16 13:37:54,997 [main] INFO impl.RaftServerProxy: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: found a subdirectory /data/metadata/ratis/d027eed2-0c03-475b-ba10-f2956286da88
dn1_1    | 2020-11-16 13:37:55,088 [main] INFO impl.RaftServerProxy: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: addNew group-F2956286DA88:[] returns group-F2956286DA88:java.util.concurrent.CompletableFuture@60325987[Not completed]
dn1_1    | 2020-11-16 13:37:55,088 [main] INFO impl.RaftServerProxy: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: found a subdirectory /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2
dn1_1    | 2020-11-16 13:37:55,088 [main] INFO impl.RaftServerProxy: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: addNew group-52E326379EE2:[] returns group-52E326379EE2:java.util.concurrent.CompletableFuture@2f37f1f9[Not completed]
dn1_1    | 2020-11-16 13:37:55,090 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn1_1    | 2020-11-16 13:37:55,280 [pool-19-thread-1] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: new RaftServerImpl for group-F2956286DA88:[] with ContainerStateMachine:uninitialized
dn1_1    | 2020-11-16 13:37:55,299 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2020-11-16 13:37:55,341 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2020-11-16 13:37:55,342 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
dn1_1    | 2020-11-16 13:37:55,342 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
dn1_1    | 2020-11-16 13:37:55,348 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2020-11-16 13:37:55,402 [pool-19-thread-1] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn1_1    | 2020-11-16 13:37:55,403 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2020-11-16 13:37:55,409 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2020-11-16 13:37:55,560 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d027eed2-0c03-475b-ba10-f2956286da88/in_use.lock acquired by nodename 6@5c4e0b586e9d
dn1_1    | 2020-11-16 13:37:55,886 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-F2956286DA88: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn1_1    | 2020-11-16 13:37:55,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn1_1    | 2020-11-16 13:37:55,947 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2020-11-16 13:37:55,977 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2020-11-16 13:37:56,023 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88
dn1_1    | 2020-11-16 13:37:56,158 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn1_1    | 2020-11-16 13:37:56,265 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2020-11-16 13:37:56,289 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2020-11-16 13:37:56,439 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2020-11-16 13:37:56,543 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/d027eed2-0c03-475b-ba10-f2956286da88
dn1_1    | 2020-11-16 13:37:56,545 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn1_1    | 2020-11-16 13:37:56,551 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2020-11-16 13:37:56,556 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn2_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn2_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
dn2_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn2_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
dn2_1    | 2020-11-16 13:38:06,642 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn2_1    | 2020-11-16 13:38:06,666 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn2_1    | 2020-11-16 13:38:06,668 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7 at port 9858
dn2_1    | 2020-11-16 13:38:06,704 [EndpointStateMachine task thread for recon/10.9.0.15:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn2_1    | java.net.SocketTimeoutException: Call From ff71737d310f/10.9.0.12 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.12:60926 remote=recon/10.9.0.15:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn2_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn2_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
dn2_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
dn2_1    | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn2_1    | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.12:60926 remote=recon/10.9.0.15:9891]
dn2_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn2_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn2_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
dn2_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn2_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
dn2_1    | 2020-11-16 13:38:06,728 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2: start as a follower, conf=0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null
dn2_1    | 2020-11-16 13:38:06,732 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2: changes role from      null to FOLLOWER at term 1 for startAsFollower
dn2_1    | 2020-11-16 13:38:06,736 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RoleInfo: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: start FollowerState
dn2_1    | 2020-11-16 13:38:06,755 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D: start as a follower, conf=0: [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0], old=null
dn2_1    | 2020-11-16 13:38:06,759 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D: changes role from      null to FOLLOWER at term 1 for startAsFollower
dn2_1    | 2020-11-16 13:38:06,759 [ForkJoinPool.commonPool-worker-3] INFO impl.RoleInfo: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: start FollowerState
dn2_1    | 2020-11-16 13:38:06,766 [ForkJoinPool.commonPool-worker-3] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C976AD8BD76D,id=6df31ac2-2c4c-45a9-a39c-cce0d698a1e7
dn2_1    | 2020-11-16 13:38:06,784 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-52E326379EE2,id=6df31ac2-2c4c-45a9-a39c-cce0d698a1e7
dn2_1    | 2020-11-16 13:38:06,802 [ForkJoinPool.commonPool-worker-3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D
dn1_1    | 2020-11-16 13:37:56,569 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2020-11-16 13:37:56,548 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn1_1    | 2020-11-16 13:37:56,582 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2020-11-16 13:37:56,583 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2020-11-16 13:37:56,587 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2020-11-16 13:37:56,591 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2020-11-16 13:37:56,595 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2020-11-16 13:37:56,801 [main] INFO util.log: Logging initialized @20391ms to org.eclipse.jetty.util.log.Slf4jLog
dn1_1    | 2020-11-16 13:37:56,855 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2020-11-16 13:37:57,653 [pool-19-thread-1] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88: set configuration 0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0], old=null at 0
dn1_1    | 2020-11-16 13:37:57,665 [pool-19-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/d027eed2-0c03-475b-ba10-f2956286da88/current/log_inprogress_0
dn1_1    | 2020-11-16 13:37:57,711 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
dn1_1    | 2020-11-16 13:37:57,717 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn1_1    | 2020-11-16 13:37:58,194 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn1_1    | 2020-11-16 13:37:58,261 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn1_1    | 2020-11-16 13:37:58,272 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2020-11-16 13:37:58,301 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2020-11-16 13:37:58,302 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2020-11-16 13:37:58,304 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2020-11-16 13:37:58,305 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2020-11-16 13:37:58,317 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn1_1    | 2020-11-16 13:37:58,348 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn1_1    | 2020-11-16 13:37:58,362 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn1_1    | 2020-11-16 13:37:58,363 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn1_1    | 2020-11-16 13:37:58,492 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88
dn1_1    | 2020-11-16 13:37:58,575 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88
dn1_1    | 2020-11-16 13:37:58,609 [pool-19-thread-1] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: new RaftServerImpl for group-52E326379EE2:[] with ContainerStateMachine:uninitialized
dn1_1    | 2020-11-16 13:37:58,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2020-11-16 13:37:58,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2020-11-16 13:37:58,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
dn1_1    | 2020-11-16 13:37:58,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
dn1_1    | 2020-11-16 13:37:58,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2020-11-16 13:37:58,623 [pool-19-thread-1] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn1_1    | 2020-11-16 13:37:58,623 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2020-11-16 13:37:58,624 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2020-11-16 13:37:58,636 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2/in_use.lock acquired by nodename 6@5c4e0b586e9d
dn1_1    | 2020-11-16 13:37:58,637 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-52E326379EE2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn1_1    | 2020-11-16 13:37:58,637 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn1_1    | 2020-11-16 13:37:58,637 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2020-11-16 13:37:58,637 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2020-11-16 13:37:58,637 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2
dn1_1    | 2020-11-16 13:37:58,637 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2020-11-16 13:37:58,638 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2020-11-16 13:37:58,638 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2020-11-16 13:37:58,638 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2
dn1_1    | 2020-11-16 13:37:58,638 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn1_1    | 2020-11-16 13:37:58,657 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2020-11-16 13:37:58,657 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2020-11-16 13:37:58,657 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2020-11-16 13:38:02,295 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2020-11-16 13:38:02,313 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2020-11-16 13:38:02,322 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2020-11-16 13:38:02,323 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2020-11-16 13:38:02,336 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2020-11-16 13:38:02,349 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2020-11-16 13:38:02,354 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2020-11-16 13:38:02,356 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2020-11-16 13:38:02,390 [main] INFO util.log: Logging initialized @22224ms to org.eclipse.jetty.util.log.Slf4jLog
dn3_1    | 2020-11-16 13:38:02,461 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2020-11-16 13:38:02,684 [pool-22-thread-1] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC: set configuration 0: [38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null at 0
dn3_1    | 2020-11-16 13:38:02,717 [pool-22-thread-1] INFO segmented.LogSegment: Successfully read 4 entries from segment file /data/metadata/ratis/078fbcbb-0c1b-4852-9c3c-73dafe3709bc/current/log_inprogress_0
dn3_1    | 2020-11-16 13:38:02,759 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 3
dn3_1    | 2020-11-16 13:38:02,762 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn3_1    | 2020-11-16 13:38:03,084 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn3_1    | 2020-11-16 13:38:03,093 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn3_1    | 2020-11-16 13:38:03,127 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn3_1    | 2020-11-16 13:38:03,139 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn3_1    | 2020-11-16 13:38:03,139 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn3_1    | 2020-11-16 13:38:03,139 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn3_1    | 2020-11-16 13:38:03,400 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn3_1    | 2020-11-16 13:38:03,401 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
dn3_1    | 2020-11-16 13:38:03,462 [pool-22-thread-1] INFO raftlog.RaftLog: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-SegmentedRaftLog: commitIndex: updateToMax old=-1, new=2, updated? true
dn3_1    | 2020-11-16 13:38:03,471 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2020-11-16 13:38:03,476 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2020-11-16 13:38:03,477 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2020-11-16 13:38:03,478 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn3_1    | 2020-11-16 13:38:03,481 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2020-11-16 13:38:03,583 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn3_1    | 2020-11-16 13:38:03,583 [main] INFO server.session: No SessionScavenger set, using defaults
dn3_1    | 2020-11-16 13:38:03,584 [main] INFO server.session: node0 Scavenging every 600000ms
dn3_1    | 2020-11-16 13:38:03,601 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC
dn3_1    | 2020-11-16 13:38:03,609 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6242ae3b{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn3_1    | 2020-11-16 13:38:03,622 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@53a7a60c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn3_1    | 2020-11-16 13:38:03,625 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC
dn3_1    | 2020-11-16 13:38:03,699 [pool-22-thread-1] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3: new RaftServerImpl for group-52E326379EE2:[] with ContainerStateMachine:uninitialized
dn3_1    | 2020-11-16 13:38:03,699 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2020-11-16 13:38:03,699 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2020-11-16 13:38:03,699 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpcslowness.timeout = 300s (custom)
dn3_1    | 2020-11-16 13:38:03,699 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
dn3_1    | 2020-11-16 13:38:03,699 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2020-11-16 13:38:03,699 [pool-22-thread-1] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn3_1    | 2020-11-16 13:38:03,699 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2020-11-16 13:38:03,699 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2020-11-16 13:38:03,721 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2/in_use.lock acquired by nodename 6@d1cf08a8030b
dn3_1    | 2020-11-16 13:38:03,723 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-52E326379EE2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn3_1    | 2020-11-16 13:38:03,723 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn3_1    | 2020-11-16 13:38:03,723 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn3_1    | 2020-11-16 13:38:03,723 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2020-11-16 13:38:03,723 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2
dn3_1    | 2020-11-16 13:38:03,723 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2020-11-16 13:38:03,723 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2020-11-16 13:38:03,724 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2020-11-16 13:38:03,729 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2
dn3_1    | 2020-11-16 13:38:03,729 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn3_1    | 2020-11-16 13:38:03,729 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2020-11-16 13:38:03,730 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2020-11-16 13:38:03,730 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2020-11-16 13:38:03,730 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2020-11-16 13:38:03,732 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2020-11-16 13:38:03,733 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2020-11-16 13:38:03,740 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2020-11-16 13:38:03,740 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2020-11-16 13:38:03,742 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2020-11-16 13:38:03,756 [pool-22-thread-1] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2: set configuration 0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null at 0
dn3_1    | 2020-11-16 13:38:03,759 [pool-22-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2/current/log_inprogress_0
dn3_1    | 2020-11-16 13:38:03,763 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
dn3_1    | 2020-11-16 13:38:03,770 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn3_1    | 2020-11-16 13:38:03,773 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2020-11-16 13:38:03,773 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2020-11-16 13:38:03,774 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2020-11-16 13:38:03,774 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn3_1    | 2020-11-16 13:38:03,775 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2020-11-16 13:38:03,775 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2
dn3_1    | 2020-11-16 13:38:03,776 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2
dn3_1    | 2020-11-16 13:38:04,195 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3e906375{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-3618551021094143175/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn3_1    | 2020-11-16 13:38:04,232 [main] INFO server.AbstractConnector: Started ServerConnector@2440022a{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn3_1    | 2020-11-16 13:38:04,234 [main] INFO server.Server: Started @24070ms
dn3_1    | 2020-11-16 13:38:04,239 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn3_1    | 2020-11-16 13:38:04,239 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn3_1    | 2020-11-16 13:38:04,245 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn3_1    | 2020-11-16 13:38:04,272 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7a9072bd] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn3_1    | 2020-11-16 13:38:04,545 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.15:9891
dn3_1    | 2020-11-16 13:38:06,646 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn3_1    | 2020-11-16 13:38:06,656 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn3_1    | 2020-11-16 13:38:06,657 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 38c1c219-c9e2-4898-90d7-f000768b0cf3 at port 9858
dn3_1    | 2020-11-16 13:38:06,669 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2: start as a follower, conf=0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null
dn3_1    | 2020-11-16 13:38:06,680 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC: start as a follower, conf=0: [38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null
dn3_1    | 2020-11-16 13:38:06,683 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2: changes role from      null to FOLLOWER at term 1 for startAsFollower
dn3_1    | 2020-11-16 13:38:06,685 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RoleInfo: 38c1c219-c9e2-4898-90d7-f000768b0cf3: start FollowerState
dn3_1    | 2020-11-16 13:38:06,687 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC: changes role from      null to FOLLOWER at term 1 for startAsFollower
dn3_1    | 2020-11-16 13:38:06,687 [ForkJoinPool.commonPool-worker-3] INFO impl.RoleInfo: 38c1c219-c9e2-4898-90d7-f000768b0cf3: start FollowerState
dn3_1    | 2020-11-16 13:38:06,704 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-52E326379EE2,id=38c1c219-c9e2-4898-90d7-f000768b0cf3
dn3_1    | 2020-11-16 13:38:06,707 [ForkJoinPool.commonPool-worker-3] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-73DAFE3709BC,id=38c1c219-c9e2-4898-90d7-f000768b0cf3
dn3_1    | 2020-11-16 13:38:06,714 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2
dn2_1    | 2020-11-16 13:38:06,798 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2
dn2_1    | 2020-11-16 13:38:06,869 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerProxy: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: start RPC server
dn2_1    | 2020-11-16 13:38:07,161 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO server.GrpcService: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
dn2_1    | 2020-11-16 13:38:11,897 [Thread-22] INFO impl.FollowerState: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-FollowerState: change to CANDIDATE, lastRpcTime:5137ms, electionTimeout:5137ms
dn2_1    | 2020-11-16 13:38:11,898 [Thread-22] INFO impl.RoleInfo: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: shutdown FollowerState
dn2_1    | 2020-11-16 13:38:11,898 [Thread-22] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn2_1    | 2020-11-16 13:38:11,900 [Thread-22] INFO impl.RoleInfo: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: start LeaderElection
dn2_1    | 2020-11-16 13:38:11,981 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO impl.LeaderElection: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1: begin an election at term 2 for 0: [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0], old=null
dn2_1    | 2020-11-16 13:38:11,984 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO impl.RoleInfo: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: shutdown LeaderElection
dn2_1    | 2020-11-16 13:38:11,984 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
dn2_1    | 2020-11-16 13:38:11,986 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C976AD8BD76D with new leaderId: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7
dn2_1    | 2020-11-16 13:38:11,994 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D: change Leader from null to 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7 at term 2 for becomeLeader, leader elected after 13300ms
dn2_1    | 2020-11-16 13:38:11,997 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn2_1    | 2020-11-16 13:38:12,000 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn2_1    | 2020-11-16 13:38:12,002 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D
dn2_1    | 2020-11-16 13:38:12,005 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2020-11-16 13:38:12,064 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
dn2_1    | 2020-11-16 13:38:12,046 [Thread-21] INFO impl.FollowerState: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-FollowerState: change to CANDIDATE, lastRpcTime:5310ms, electionTimeout:5200ms
dn2_1    | 2020-11-16 13:38:12,068 [Thread-21] INFO impl.RoleInfo: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: shutdown FollowerState
dn2_1    | 2020-11-16 13:38:12,071 [Thread-21] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn2_1    | 2020-11-16 13:38:12,071 [Thread-21] INFO impl.RoleInfo: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: start LeaderElection
dn2_1    | 2020-11-16 13:38:12,098 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-LeaderElection2] INFO impl.LeaderElection: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-LeaderElection2: begin an election at term 2 for 0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null
dn2_1    | 2020-11-16 13:38:12,122 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn2_1    | 2020-11-16 13:38:12,123 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn2_1    | 2020-11-16 13:38:12,123 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn2_1    | 2020-11-16 13:38:12,173 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO impl.RoleInfo: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: start LeaderState
dn2_1    | 2020-11-16 13:38:12,258 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
dn2_1    | 2020-11-16 13:38:12,297 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/d48b93e3-afae-4915-a84b-c976ad8bd76d/current/log_inprogress_0 to /data/metadata/ratis/d48b93e3-afae-4915-a84b-c976ad8bd76d/current/log_0-0
dn2_1    | 2020-11-16 13:38:12,306 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-LeaderElection1] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D: set configuration 1: [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0], old=null at 1
dn2_1    | 2020-11-16 13:38:12,360 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-C976AD8BD76D-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d48b93e3-afae-4915-a84b-c976ad8bd76d/current/log_inprogress_1
dn2_1    | 2020-11-16 13:38:12,901 [grpc-default-executor-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.6df31ac2-2c4c-45a9-a39c-cce0d698a1e7
dn2_1    | 2020-11-16 13:38:12,903 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.6df31ac2-2c4c-45a9-a39c-cce0d698a1e7
dn2_1    | 2020-11-16 13:38:13,013 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-LeaderElection2] INFO impl.LeaderElection: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-LeaderElection2: Election REJECTED; received 2 response(s) [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7<-adb8fb61-c6db-4e1a-bc0f-9493e4c21274#0:FAIL-t2, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7<-38c1c219-c9e2-4898-90d7-f000768b0cf3#0:FAIL-t2] and 0 exception(s); 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2:t2, leader=null, voted=6df31ac2-2c4c-45a9-a39c-cce0d698a1e7, raftlog=6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-SegmentedRaftLog:OPENED:c-1,f0,i0, conf=0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null
dn2_1    | 2020-11-16 13:38:13,014 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-LeaderElection2] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
dn2_1    | 2020-11-16 13:38:13,014 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-LeaderElection2] INFO impl.RoleInfo: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: shutdown LeaderElection
dn2_1    | 2020-11-16 13:38:13,015 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-LeaderElection2] INFO impl.RoleInfo: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: start FollowerState
dn2_1    | 2020-11-16 13:38:18,106 [grpc-default-executor-1] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2: changes role from  FOLLOWER to FOLLOWER at term 3 for recognizeCandidate:38c1c219-c9e2-4898-90d7-f000768b0cf3
dn2_1    | 2020-11-16 13:38:18,107 [grpc-default-executor-1] INFO impl.RoleInfo: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: shutdown FollowerState
dn2_1    | 2020-11-16 13:38:18,108 [Thread-32] INFO impl.FollowerState: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
dn2_1    | 2020-11-16 13:38:18,108 [grpc-default-executor-1] INFO impl.RoleInfo: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7: start FollowerState
dn2_1    | 2020-11-16 13:38:18,109 [grpc-default-executor-1] INFO impl.RaftServerImpl:  FOLLOWER 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2:t3, leader=null, voted=null, raftlog=6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-SegmentedRaftLog:OPENED:c-1,f0,i0, conf=0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null RUNNING priority:0 candidate:38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0 candidatePriority:0 compare:0
dn2_1    | 2020-11-16 13:38:18,188 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-52E326379EE2 with new leaderId: 38c1c219-c9e2-4898-90d7-f000768b0cf3
dn2_1    | 2020-11-16 13:38:18,188 [grpc-default-executor-1] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2: change Leader from null to 38c1c219-c9e2-4898-90d7-f000768b0cf3 at term 3 for appendEntries, leader elected after 17008ms
dn2_1    | 2020-11-16 13:38:18,214 [grpc-default-executor-1] INFO impl.RaftServerImpl: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2: set configuration 1: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null at 1
dn2_1    | 2020-11-16 13:38:18,215 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
dn2_1    | 2020-11-16 13:38:18,215 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2/current/log_inprogress_0 to /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2/current/log_0-0
dn2_1    | 2020-11-16 13:38:18,219 [6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7@group-52E326379EE2-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2/current/log_inprogress_1
dn1_1    | 2020-11-16 13:37:58,657 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2020-11-16 13:37:58,659 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2020-11-16 13:37:58,659 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2020-11-16 13:37:58,660 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2020-11-16 13:37:58,660 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2020-11-16 13:37:58,711 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2020-11-16 13:37:58,712 [pool-19-thread-1] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2: set configuration 0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null at 0
dn1_1    | 2020-11-16 13:37:58,713 [pool-19-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2/current/log_inprogress_0
dn1_1    | 2020-11-16 13:37:58,723 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
dn1_1    | 2020-11-16 13:37:58,723 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn1_1    | 2020-11-16 13:37:58,729 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2020-11-16 13:37:58,729 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2020-11-16 13:37:58,729 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2020-11-16 13:37:58,729 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2020-11-16 13:37:58,729 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2020-11-16 13:37:58,729 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2
dn1_1    | 2020-11-16 13:37:58,730 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2
dn1_1    | 2020-11-16 13:37:58,813 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn1_1    | 2020-11-16 13:37:58,820 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
dn1_1    | 2020-11-16 13:37:58,988 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn1_1    | 2020-11-16 13:37:58,999 [main] INFO server.session: No SessionScavenger set, using defaults
dn1_1    | 2020-11-16 13:37:59,001 [main] INFO server.session: node0 Scavenging every 660000ms
dn1_1    | 2020-11-16 13:37:59,106 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@869d87c{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn1_1    | 2020-11-16 13:37:59,113 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@414f13fc{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn1_1    | 2020-11-16 13:37:59,838 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3a1706e1{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-9423346957665054602/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn1_1    | 2020-11-16 13:37:59,904 [main] INFO server.AbstractConnector: Started ServerConnector@60c73e58{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn1_1    | 2020-11-16 13:37:59,908 [main] INFO server.Server: Started @23497ms
dn1_1    | 2020-11-16 13:37:59,952 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn1_1    | 2020-11-16 13:37:59,952 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn1_1    | 2020-11-16 13:37:59,962 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn1_1    | 2020-11-16 13:38:00,096 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3e54d92] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn1_1    | 2020-11-16 13:38:00,563 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.15:9891
dn1_1    | 2020-11-16 13:38:03,344 [EndpointStateMachine task thread for recon/10.9.0.15:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.15:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn1_1    | 2020-11-16 13:38:03,381 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
dn1_1    | java.net.SocketTimeoutException: Call From 5c4e0b586e9d/10.9.0.11 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.11:36310 remote=scm/10.9.0.17:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn1_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn1_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn1_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn1_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn1_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
dn1_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
dn1_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
dn1_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
dn1_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
dn1_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
dn1_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
dn1_1    | 	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
dn1_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn1_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
dn1_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn1_1    | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.11:36310 remote=scm/10.9.0.17:9861]
dn1_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn1_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn1_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn1_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn1_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
dn1_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn1_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
dn1_1    | 2020-11-16 13:38:04,345 [EndpointStateMachine task thread for recon/10.9.0.15:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.15:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn1_1    | 2020-11-16 13:38:05,346 [EndpointStateMachine task thread for recon/10.9.0.15:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.15:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn1_1    | 2020-11-16 13:38:06,156 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn1_1    | 2020-11-16 13:38:06,159 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn1_1    | 2020-11-16 13:38:06,159 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis adb8fb61-c6db-4e1a-bc0f-9493e4c21274 at port 9858
dn1_1    | 2020-11-16 13:38:06,183 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2: start as a follower, conf=0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null
dn1_1    | 2020-11-16 13:38:06,184 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2: changes role from      null to FOLLOWER at term 1 for startAsFollower
dn1_1    | 2020-11-16 13:38:06,185 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RoleInfo: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: start FollowerState
dn1_1    | 2020-11-16 13:38:06,201 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-52E326379EE2,id=adb8fb61-c6db-4e1a-bc0f-9493e4c21274
dn1_1    | 2020-11-16 13:38:06,211 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88: start as a follower, conf=0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0], old=null
dn1_1    | 2020-11-16 13:38:06,212 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88: changes role from      null to FOLLOWER at term 1 for startAsFollower
dn1_1    | 2020-11-16 13:38:06,211 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2
dn1_1    | 2020-11-16 13:38:06,216 [ForkJoinPool.commonPool-worker-3] INFO impl.RoleInfo: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: start FollowerState
dn1_1    | 2020-11-16 13:38:06,235 [ForkJoinPool.commonPool-worker-3] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F2956286DA88,id=adb8fb61-c6db-4e1a-bc0f-9493e4c21274
dn1_1    | 2020-11-16 13:38:06,251 [ForkJoinPool.commonPool-worker-3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88
dn1_1    | 2020-11-16 13:38:06,253 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerProxy: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: start RPC server
dn1_1    | 2020-11-16 13:38:06,361 [EndpointStateMachine task thread for recon/10.9.0.15:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn1_1    | java.net.SocketTimeoutException: Call From 5c4e0b586e9d/10.9.0.11 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.11:42926 remote=recon/10.9.0.15:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn1_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn1_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn1_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn1_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn1_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
dn1_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
dn1_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
dn1_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
dn1_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
dn1_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
dn1_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
dn1_1    | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
dn1_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn1_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
dn1_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn1_1    | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.11:42926 remote=recon/10.9.0.15:9891]
dn1_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
om_1     | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1     | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1     | 2020-11-16 13:37:44,468 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1     | /************************************************************
om_1     | STARTUP_MSG: Starting OzoneManager
om_1     | STARTUP_MSG:   host = 07dc987833e3/10.9.0.14
om_1     | STARTUP_MSG:   args = []
om_1     | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
recon_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
recon_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1  | 2020-11-16 13:37:39,548 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1  | /************************************************************
recon_1  | STARTUP_MSG: Starting ReconServer
recon_1  | STARTUP_MSG:   host = 360110d17ee0/10.9.0.15
recon_1  | STARTUP_MSG:   args = []
recon_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
recon_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-reconcodegen-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.27.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.27.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-1.1.0-SNAPSHOT.jar
recon_1  | STARTUP_MSG:   build = https://github.com/apache/ozone.git/787e5b6247912eb5f19ffb2f6dc0b82380b77d37 ; compiled by 'runner' on 2020-11-16T12:42Z
recon_1  | STARTUP_MSG:   java = 11.0.7
recon_1  | ************************************************************/
recon_1  | 2020-11-16 13:37:39,647 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1  | WARNING: An illegal reflective access operation has occurred
recon_1  | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
recon_1  | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
recon_1  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1  | WARNING: All illegal access operations will be denied in a future release
recon_1  | 2020-11-16 13:37:42,956 [main] INFO recon.ReconRestServletModule: rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1  | 2020-11-16 13:37:44,823 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1  | 2020-11-16 13:37:45,232 [main] INFO impl.ReconContainerDBProvider: Last known container-key DB : /data/metadata/recon/recon-container-key.db_1605533805753
recon_1  | 2020-11-16 13:37:46,381 [main] INFO persistence.DerbyDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1  | 2020-11-16 13:37:52,084 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1  | 2020-11-16 13:37:54,546 [main] INFO persistence.DerbyDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1  | 2020-11-16 13:37:54,705 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1  | 2020-11-16 13:37:54,715 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1  | 2020-11-16 13:38:00,135 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1  | 2020-11-16 13:38:00,275 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
recon_1  | 2020-11-16 13:38:00,301 [main] INFO util.log: Logging initialized @23428ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1  | 2020-11-16 13:38:00,760 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1  | 2020-11-16 13:38:00,798 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1  | 2020-11-16 13:38:00,835 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1  | 2020-11-16 13:38:00,837 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
recon_1  | 2020-11-16 13:38:00,855 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
recon_1  | 2020-11-16 13:38:00,855 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
recon_1  | 2020-11-16 13:38:01,478 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1  | 2020-11-16 13:38:02,653 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1  | 2020-11-16 13:38:02,711 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1  | 2020-11-16 13:38:02,769 [main] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
recon_1  | 2020-11-16 13:38:02,769 [main] INFO ozone.OmUtils: No OzoneManager ServiceID configured.
recon_1  | 2020-11-16 13:38:03,377 [main] INFO Configuration.deprecation: No unit for ozone.recon.om.connection.request.timeout(5000) assuming MILLISECONDS
recon_1  | 2020-11-16 13:38:03,879 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2020-11-16 13:38:04,228 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2020-11-16 13:38:04,274 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@773eca84
recon_1  | 2020-11-16 13:38:04,300 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1  | 2020-11-16 13:38:04,449 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om_1     | STARTUP_MSG:   build = https://github.com/apache/ozone.git/787e5b6247912eb5f19ffb2f6dc0b82380b77d37 ; compiled by 'runner' on 2020-11-16T12:42Z
om_1     | STARTUP_MSG:   java = 11.0.7
om_1     | ************************************************************/
om_1     | 2020-11-16 13:37:44,494 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1     | 2020-11-16 13:37:51,989 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1     | 2020-11-16 13:37:52,277 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.9.0.14:9862
om_1     | 2020-11-16 13:37:52,291 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1     | 2020-11-16 13:37:52,303 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1     | 2020-11-16 13:37:52,397 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1     | 2020-11-16 13:37:54,966 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-11-16 13:37:55,967 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-11-16 13:37:56,968 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-11-16 13:37:57,969 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-11-16 13:37:58,969 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-11-16 13:37:59,970 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-11-16 13:38:00,971 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-11-16 13:38:01,972 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-11-16 13:38:07,764 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1     | 2020-11-16 13:38:08,081 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om_1     | 2020-11-16 13:38:08,085 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om_1     | 2020-11-16 13:38:08,119 [main] INFO db.RDBStore: Found the following extra column families in existing DB : [s3Table]
om_1     | 2020-11-16 13:38:08,357 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
om_1     | 2020-11-16 13:38:08,409 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1     | 2020-11-16 13:38:08,484 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1     | 2020-11-16 13:38:08,749 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1     | 2020-11-16 13:38:08,823 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1     | 2020-11-16 13:38:08,823 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1     | 2020-11-16 13:38:08,874 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/10.9.0.14:9862
om_1     | 2020-11-16 13:38:08,966 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1     | 2020-11-16 13:38:08,966 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1     | 2020-11-16 13:38:09,009 [Listener at om/9862] INFO util.log: Logging initialized @30361ms to org.eclipse.jetty.util.log.Slf4jLog
om_1     | 2020-11-16 13:38:09,151 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1     | 2020-11-16 13:38:09,154 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1     | 2020-11-16 13:38:09,166 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1     | 2020-11-16 13:38:09,176 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1     | 2020-11-16 13:38:09,176 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1     | 2020-11-16 13:38:09,176 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1     | 2020-11-16 13:38:09,276 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1     | 2020-11-16 13:38:09,278 [Listener at om/9862] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
om_1     | 2020-11-16 13:38:09,375 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1     | 2020-11-16 13:38:09,375 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1     | 2020-11-16 13:38:09,384 [Listener at om/9862] INFO server.session: node0 Scavenging every 600000ms
om_1     | 2020-11-16 13:38:09,441 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@107bfcb2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1     | 2020-11-16 13:38:09,443 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@61a91c9b{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1     | 2020-11-16 13:38:09,835 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@60bb7995{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-1_1_0-SNAPSHOT_jar-_-any-15476949381555353802/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1     | 2020-11-16 13:38:09,884 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@1e236278{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om_1     | 2020-11-16 13:38:09,884 [Listener at om/9862] INFO server.Server: Started @31237ms
om_1     | 2020-11-16 13:38:09,902 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1     | 2020-11-16 13:38:09,902 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1     | 2020-11-16 13:38:09,916 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1     | 2020-11-16 13:38:09,922 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1     | 2020-11-16 13:38:09,994 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1     | 2020-11-16 13:38:10,009 [Listener at om/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om_1     | 2020-11-16 13:38:10,029 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7ed3df3b] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn1_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn1_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn1_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn1_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
dn1_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn1_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
dn1_1    | 2020-11-16 13:38:06,553 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO server.GrpcService: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
dn1_1    | 2020-11-16 13:38:11,220 [Thread-21] INFO impl.FollowerState: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-FollowerState: change to CANDIDATE, lastRpcTime:5035ms, electionTimeout:5008ms
dn1_1    | 2020-11-16 13:38:11,221 [Thread-21] INFO impl.RoleInfo: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: shutdown FollowerState
dn1_1    | 2020-11-16 13:38:11,221 [Thread-21] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn1_1    | 2020-11-16 13:38:11,223 [Thread-21] INFO impl.RoleInfo: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: start LeaderElection
dn1_1    | 2020-11-16 13:38:11,239 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-LeaderElection1] INFO impl.LeaderElection: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-LeaderElection1: begin an election at term 2 for 0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null
dn1_1    | 2020-11-16 13:38:11,431 [Thread-22] INFO impl.FollowerState: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-FollowerState: change to CANDIDATE, lastRpcTime:5215ms, electionTimeout:5176ms
dn1_1    | 2020-11-16 13:38:11,439 [Thread-22] INFO impl.RoleInfo: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: shutdown FollowerState
dn1_1    | 2020-11-16 13:38:11,439 [Thread-22] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn1_1    | 2020-11-16 13:38:11,440 [Thread-22] INFO impl.RoleInfo: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: start LeaderElection
dn1_1    | 2020-11-16 13:38:11,475 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO impl.LeaderElection: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2: begin an election at term 2 for 0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0], old=null
dn1_1    | 2020-11-16 13:38:11,477 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO impl.RoleInfo: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: shutdown LeaderElection
dn1_1    | 2020-11-16 13:38:11,478 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
dn1_1    | 2020-11-16 13:38:11,478 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F2956286DA88 with new leaderId: adb8fb61-c6db-4e1a-bc0f-9493e4c21274
dn1_1    | 2020-11-16 13:38:11,479 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88: change Leader from null to adb8fb61-c6db-4e1a-bc0f-9493e4c21274 at term 2 for becomeLeader, leader elected after 15583ms
dn1_1    | 2020-11-16 13:38:11,494 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn1_1    | 2020-11-16 13:38:11,494 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn1_1    | 2020-11-16 13:38:11,497 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88
dn1_1    | 2020-11-16 13:38:11,508 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn1_1    | 2020-11-16 13:38:11,509 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
dn1_1    | 2020-11-16 13:38:11,536 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn1_1    | 2020-11-16 13:38:11,538 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn1_1    | 2020-11-16 13:38:11,539 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn1_1    | 2020-11-16 13:38:11,571 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO impl.RoleInfo: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: start LeaderState
dn1_1    | 2020-11-16 13:38:11,623 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
dn1_1    | 2020-11-16 13:38:11,645 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/d027eed2-0c03-475b-ba10-f2956286da88/current/log_inprogress_0 to /data/metadata/ratis/d027eed2-0c03-475b-ba10-f2956286da88/current/log_0-0
dn1_1    | 2020-11-16 13:38:11,714 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-LeaderElection2] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88: set configuration 1: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0], old=null at 1
dn1_1    | 2020-11-16 13:38:11,733 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-F2956286DA88-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d027eed2-0c03-475b-ba10-f2956286da88/current/log_inprogress_1
dn1_1    | 2020-11-16 13:38:12,907 [grpc-default-executor-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.adb8fb61-c6db-4e1a-bc0f-9493e4c21274
s3g_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
s3g_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1    | 2020-11-16 13:37:43,565 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1    | 2020-11-16 13:37:43,591 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
s3g_1    | 2020-11-16 13:37:43,682 [main] INFO util.log: Logging initialized @6232ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1    | 2020-11-16 13:37:44,391 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1    | 2020-11-16 13:37:44,586 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1    | 2020-11-16 13:37:44,633 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1    | 2020-11-16 13:37:44,655 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g_1    | 2020-11-16 13:37:44,659 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1    | 2020-11-16 13:37:44,659 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1    | 2020-11-16 13:37:44,984 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1    | /************************************************************
s3g_1    | STARTUP_MSG: Starting Gateway
s3g_1    | STARTUP_MSG:   host = 20995342fd66/10.9.0.16
s3g_1    | STARTUP_MSG:   args = []
s3g_1    | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
dn3_1    | 2020-11-16 13:38:06,714 [ForkJoinPool.commonPool-worker-3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC
dn3_1    | 2020-11-16 13:38:06,749 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerProxy: 38c1c219-c9e2-4898-90d7-f000768b0cf3: start RPC server
dn3_1    | 2020-11-16 13:38:07,130 [RatisApplyTransactionExecutor 1] WARN helpers.ChunkUtils: Duplicate write chunk request. Chunk overwrite without explicit request. ChunkInfo{chunkName='105220265957195776_chunk_1, offset=0, len=17540}
dn3_1    | 2020-11-16 13:38:07,130 [RatisApplyTransactionExecutor 1] WARN impl.FilePerChunkStrategy: ChunkFile already exists /data/hdds/hdds/bd3792ed-84db-4436-86f9-89808a254442/current/containerDir0/1/chunks/105220265957195776_chunk_1
dn3_1    | 2020-11-16 13:38:07,248 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO server.GrpcService: 38c1c219-c9e2-4898-90d7-f000768b0cf3: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
dn3_1    | 2020-11-16 13:38:07,574 [EndpointStateMachine task thread for recon/10.9.0.15:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn3_1    | java.net.SocketTimeoutException: Call From d1cf08a8030b/10.9.0.13 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.13:33596 remote=recon/10.9.0.15:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn3_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn3_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn3_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn3_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn3_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
dn3_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
dn3_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
dn3_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
dn3_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
dn3_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
dn3_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
dn3_1    | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
dn3_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn3_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn3_1    | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.13:33596 remote=recon/10.9.0.15:9891]
dn3_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn3_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn3_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn3_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn3_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
dn3_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn3_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
dn3_1    | 2020-11-16 13:38:11,756 [Thread-19] INFO impl.FollowerState: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-FollowerState: change to CANDIDATE, lastRpcTime:5071ms, electionTimeout:5054ms
dn3_1    | 2020-11-16 13:38:11,756 [Thread-19] INFO impl.RoleInfo: 38c1c219-c9e2-4898-90d7-f000768b0cf3: shutdown FollowerState
dn3_1    | 2020-11-16 13:38:11,756 [Thread-19] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn3_1    | 2020-11-16 13:38:11,758 [Thread-19] INFO impl.RoleInfo: 38c1c219-c9e2-4898-90d7-f000768b0cf3: start LeaderElection
dn3_1    | 2020-11-16 13:38:11,805 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection1] INFO impl.LeaderElection: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection1: begin an election at term 2 for 0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null
dn3_1    | 2020-11-16 13:38:11,911 [Thread-20] INFO impl.FollowerState: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-FollowerState: change to CANDIDATE, lastRpcTime:5224ms, electionTimeout:5192ms
dn3_1    | 2020-11-16 13:38:11,912 [Thread-20] INFO impl.RoleInfo: 38c1c219-c9e2-4898-90d7-f000768b0cf3: shutdown FollowerState
dn3_1    | 2020-11-16 13:38:11,912 [Thread-20] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn3_1    | 2020-11-16 13:38:11,913 [Thread-20] INFO impl.RoleInfo: 38c1c219-c9e2-4898-90d7-f000768b0cf3: start LeaderElection
dn3_1    | 2020-11-16 13:38:11,954 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO impl.LeaderElection: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2: begin an election at term 2 for 0: [38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null
dn3_1    | 2020-11-16 13:38:11,963 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO impl.RoleInfo: 38c1c219-c9e2-4898-90d7-f000768b0cf3: shutdown LeaderElection
dn3_1    | 2020-11-16 13:38:11,964 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
dn3_1    | 2020-11-16 13:38:11,964 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-73DAFE3709BC with new leaderId: 38c1c219-c9e2-4898-90d7-f000768b0cf3
dn1_1    | 2020-11-16 13:38:12,979 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-LeaderElection1] INFO impl.LeaderElection: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-LeaderElection1: Election REJECTED; received 2 response(s) [adb8fb61-c6db-4e1a-bc0f-9493e4c21274<-6df31ac2-2c4c-45a9-a39c-cce0d698a1e7#0:FAIL-t2, adb8fb61-c6db-4e1a-bc0f-9493e4c21274<-38c1c219-c9e2-4898-90d7-f000768b0cf3#0:FAIL-t2] and 0 exception(s); adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2:t2, leader=null, voted=adb8fb61-c6db-4e1a-bc0f-9493e4c21274, raftlog=adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-SegmentedRaftLog:OPENED:c-1,f0,i0, conf=0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null
dn1_1    | 2020-11-16 13:38:12,982 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-LeaderElection1] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
dn1_1    | 2020-11-16 13:38:12,982 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-LeaderElection1] INFO impl.RoleInfo: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: shutdown LeaderElection
dn1_1    | 2020-11-16 13:38:12,982 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-LeaderElection1] INFO impl.RoleInfo: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: start FollowerState
dn1_1    | 2020-11-16 13:38:18,099 [grpc-default-executor-1] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2: changes role from  FOLLOWER to FOLLOWER at term 3 for recognizeCandidate:38c1c219-c9e2-4898-90d7-f000768b0cf3
dn1_1    | 2020-11-16 13:38:18,099 [grpc-default-executor-1] INFO impl.RoleInfo: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: shutdown FollowerState
dn1_1    | 2020-11-16 13:38:18,099 [grpc-default-executor-1] INFO impl.RoleInfo: adb8fb61-c6db-4e1a-bc0f-9493e4c21274: start FollowerState
dn1_1    | 2020-11-16 13:38:18,099 [Thread-34] INFO impl.FollowerState: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
dn1_1    | 2020-11-16 13:38:18,104 [grpc-default-executor-1] INFO impl.RaftServerImpl:  FOLLOWER adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2:t3, leader=null, voted=null, raftlog=adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-SegmentedRaftLog:OPENED:c-1,f0,i0, conf=0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null RUNNING priority:0 candidate:38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0 candidatePriority:0 compare:0
dn1_1    | 2020-11-16 13:38:18,175 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-52E326379EE2 with new leaderId: 38c1c219-c9e2-4898-90d7-f000768b0cf3
dn1_1    | 2020-11-16 13:38:18,175 [grpc-default-executor-1] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2: change Leader from null to 38c1c219-c9e2-4898-90d7-f000768b0cf3 at term 3 for appendEntries, leader elected after 19537ms
dn1_1    | 2020-11-16 13:38:18,244 [grpc-default-executor-1] INFO impl.RaftServerImpl: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2: set configuration 1: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null at 1
dn1_1    | 2020-11-16 13:38:18,247 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
dn1_1    | 2020-11-16 13:38:18,254 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2/current/log_inprogress_0 to /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2/current/log_0-0
dn1_1    | 2020-11-16 13:38:18,262 [adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: adb8fb61-c6db-4e1a-bc0f-9493e4c21274@group-52E326379EE2-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2/current/log_inprogress_1
s3g_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.27.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.10.3.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar
s3g_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/787e5b6247912eb5f19ffb2f6dc0b82380b77d37 ; compiled by 'runner' on 2020-11-16T12:42Z
s3g_1    | STARTUP_MSG:   java = 11.0.7
s3g_1    | ************************************************************/
s3g_1    | 2020-11-16 13:37:45,021 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1    | 2020-11-16 13:37:45,252 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1    | 2020-11-16 13:37:45,314 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1    | 2020-11-16 13:37:45,340 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
s3g_1    | 2020-11-16 13:37:45,784 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1    | 2020-11-16 13:37:45,792 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1    | 2020-11-16 13:37:45,796 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1    | 2020-11-16 13:37:45,907 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4808bc9b{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1    | 2020-11-16 13:37:45,919 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7de62196{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1    | WARNING: An illegal reflective access operation has occurred
s3g_1    | WARNING: Illegal reflective access by org.jboss.classfilewriter.ClassFile$1 (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int)
s3g_1    | WARNING: Please consider reporting this to the maintainers of org.jboss.classfilewriter.ClassFile$1
s3g_1    | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1    | WARNING: All illegal access operations will be denied in a future release
s3g_1    | Nov 16, 2020 1:38:01 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1    | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1    | 
s3g_1    | 2020-11-16 13:38:02,015 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6282b9f5{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-1_1_0-SNAPSHOT_jar-_-any-3739267927057342217/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1    | 2020-11-16 13:38:02,088 [main] INFO server.AbstractConnector: Started ServerConnector@7354b8c5{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1    | 2020-11-16 13:38:02,091 [main] INFO server.Server: Started @24642ms
s3g_1    | 2020-11-16 13:38:02,103 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
recon_1  | 2020-11-16 13:38:04,557 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1  | 2020-11-16 13:38:04,589 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1  | 2020-11-16 13:38:04,591 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1  | 2020-11-16 13:38:04,668 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1  | 2020-11-16 13:38:04,743 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1  | 2020-11-16 13:38:04,777 [Listener at 0.0.0.0/9891] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
recon_1  | 2020-11-16 13:38:04,846 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1  | 2020-11-16 13:38:04,849 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1  | 2020-11-16 13:38:04,958 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1  | 2020-11-16 13:38:04,992 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1  | 2020-11-16 13:38:04,992 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1  | 2020-11-16 13:38:05,279 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1  | 2020-11-16 13:38:05,281 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
recon_1  | 2020-11-16 13:38:05,358 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1  | 2020-11-16 13:38:05,358 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1  | 2020-11-16 13:38:05,369 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1  | 2020-11-16 13:38:05,397 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@327e5be5{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1  | 2020-11-16 13:38:05,398 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4978777f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1  | 2020-11-16 13:38:08,781 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3a6b94b6{recon,/,file:///tmp/jetty-0_0_0_0-9888-hadoop-ozone-recon-1_1_0-SNAPSHOT_jar-_-any-16647347696866171938/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-1.1.0-SNAPSHOT.jar!/webapps/recon}
recon_1  | 2020-11-16 13:38:08,801 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@5099c59b{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1  | 2020-11-16 13:38:08,805 [Listener at 0.0.0.0/9891] INFO server.Server: Started @31932ms
recon_1  | 2020-11-16 13:38:08,812 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1  | 2020-11-16 13:38:08,812 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1  | 2020-11-16 13:38:08,942 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1  | 2020-11-16 13:38:08,942 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1  | 2020-11-16 13:38:08,951 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1  | 2020-11-16 13:38:08,956 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1  | 2020-11-16 13:38:08,956 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1  | 2020-11-16 13:38:08,959 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2020-11-16 13:38:08,959 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1  | 2020-11-16 13:38:08,962 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1  | 2020-11-16 13:38:09,215 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 4 pipelines from SCM.
recon_1  | 2020-11-16 13:38:09,215 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1  | 2020-11-16 13:38:09,216 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=078fbcbb-0c1b-4852-9c3c-73dafe3709bc from SCM.
recon_1  | 2020-11-16 13:38:09,228 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 078fbcbb-0c1b-4852-9c3c-73dafe3709bc, Nodes: 38c1c219-c9e2-4898-90d7-f000768b0cf3{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:38c1c219-c9e2-4898-90d7-f000768b0cf3, CreationTimestamp2020-11-16T13:37:51.321Z]
recon_1  | 2020-11-16 13:38:09,232 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=d027eed2-0c03-475b-ba10-f2956286da88 from SCM.
recon_1  | 2020-11-16 13:38:09,233 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: d027eed2-0c03-475b-ba10-f2956286da88, Nodes: adb8fb61-c6db-4e1a-bc0f-9493e4c21274{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:adb8fb61-c6db-4e1a-bc0f-9493e4c21274, CreationTimestamp2020-11-16T13:37:51.523Z]
recon_1  | 2020-11-16 13:38:09,233 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=d48b93e3-afae-4915-a84b-c976ad8bd76d from SCM.
recon_1  | 2020-11-16 13:38:09,234 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: d48b93e3-afae-4915-a84b-c976ad8bd76d, Nodes: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:6df31ac2-2c4c-45a9-a39c-cce0d698a1e7, CreationTimestamp2020-11-16T13:37:51.550Z]
recon_1  | 2020-11-16 13:38:09,234 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=0bd52ee0-c9d9-4277-ae53-52e326379ee2 from SCM.
recon_1  | 2020-11-16 13:38:09,235 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 0bd52ee0-c9d9-4277-ae53-52e326379ee2, Nodes: 38c1c219-c9e2-4898-90d7-f000768b0cf3{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}6df31ac2-2c4c-45a9-a39c-cce0d698a1e7{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}adb8fb61-c6db-4e1a-bc0f-9493e4c21274{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-11-16T13:37:51.493Z]
recon_1  | 2020-11-16 13:38:09,237 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1  | 2020-11-16 13:38:09,246 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1  | 2020-11-16 13:38:09,337 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
dn3_1    | 2020-11-16 13:38:11,975 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC: change Leader from null to 38c1c219-c9e2-4898-90d7-f000768b0cf3 at term 2 for becomeLeader, leader elected after 10211ms
dn3_1    | 2020-11-16 13:38:11,979 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn3_1    | 2020-11-16 13:38:11,984 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2020-11-16 13:38:11,986 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC
dn3_1    | 2020-11-16 13:38:12,003 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2020-11-16 13:38:12,009 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
dn3_1    | 2020-11-16 13:38:12,060 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn3_1    | 2020-11-16 13:38:12,063 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn3_1    | 2020-11-16 13:38:12,067 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn3_1    | 2020-11-16 13:38:12,121 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO impl.RoleInfo: 38c1c219-c9e2-4898-90d7-f000768b0cf3: start LeaderState
dn3_1    | 2020-11-16 13:38:12,191 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-SegmentedRaftLogWorker: Rolling segment log-0_3 to index:3
dn3_1    | 2020-11-16 13:38:12,212 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/078fbcbb-0c1b-4852-9c3c-73dafe3709bc/current/log_inprogress_0 to /data/metadata/ratis/078fbcbb-0c1b-4852-9c3c-73dafe3709bc/current/log_0-3
dn3_1    | 2020-11-16 13:38:12,244 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/078fbcbb-0c1b-4852-9c3c-73dafe3709bc/current/log_inprogress_4
dn3_1    | 2020-11-16 13:38:12,251 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC-LeaderElection2] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-73DAFE3709BC: set configuration 4: [38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null at 4
dn3_1    | 2020-11-16 13:38:12,872 [grpc-default-executor-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.38c1c219-c9e2-4898-90d7-f000768b0cf3
dn3_1    | 2020-11-16 13:38:12,988 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection1] INFO impl.LeaderElection: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection1: Election REJECTED; received 2 response(s) [38c1c219-c9e2-4898-90d7-f000768b0cf3<-adb8fb61-c6db-4e1a-bc0f-9493e4c21274#0:FAIL-t2, 38c1c219-c9e2-4898-90d7-f000768b0cf3<-6df31ac2-2c4c-45a9-a39c-cce0d698a1e7#0:FAIL-t2] and 0 exception(s); 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2:t2, leader=null, voted=38c1c219-c9e2-4898-90d7-f000768b0cf3, raftlog=38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-SegmentedRaftLog:OPENED:c-1,f0,i0, conf=0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null
dn3_1    | 2020-11-16 13:38:12,989 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection1] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
dn3_1    | 2020-11-16 13:38:12,989 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection1] INFO impl.RoleInfo: 38c1c219-c9e2-4898-90d7-f000768b0cf3: shutdown LeaderElection
dn3_1    | 2020-11-16 13:38:12,990 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection1] INFO impl.RoleInfo: 38c1c219-c9e2-4898-90d7-f000768b0cf3: start FollowerState
dn3_1    | 2020-11-16 13:38:18,063 [Thread-31] INFO impl.FollowerState: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-FollowerState: change to CANDIDATE, lastRpcTime:5072ms, electionTimeout:5061ms
dn3_1    | 2020-11-16 13:38:18,063 [Thread-31] INFO impl.RoleInfo: 38c1c219-c9e2-4898-90d7-f000768b0cf3: shutdown FollowerState
dn3_1    | 2020-11-16 13:38:18,063 [Thread-31] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
dn3_1    | 2020-11-16 13:38:18,064 [Thread-31] INFO impl.RoleInfo: 38c1c219-c9e2-4898-90d7-f000768b0cf3: start LeaderElection
dn3_1    | 2020-11-16 13:38:18,085 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO impl.LeaderElection: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3: begin an election at term 3 for 0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null
dn3_1    | 2020-11-16 13:38:18,115 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO impl.LeaderElection: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3: Election PASSED; received 1 response(s) [38c1c219-c9e2-4898-90d7-f000768b0cf3<-adb8fb61-c6db-4e1a-bc0f-9493e4c21274#0:OK-t3] and 0 exception(s); 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2:t3, leader=null, voted=38c1c219-c9e2-4898-90d7-f000768b0cf3, raftlog=38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-SegmentedRaftLog:OPENED:c-1,f0,i0, conf=0: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null
dn3_1    | 2020-11-16 13:38:18,115 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO impl.RoleInfo: 38c1c219-c9e2-4898-90d7-f000768b0cf3: shutdown LeaderElection
dn3_1    | 2020-11-16 13:38:18,115 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
dn3_1    | 2020-11-16 13:38:18,115 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-52E326379EE2 with new leaderId: 38c1c219-c9e2-4898-90d7-f000768b0cf3
dn3_1    | 2020-11-16 13:38:18,116 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2: change Leader from null to 38c1c219-c9e2-4898-90d7-f000768b0cf3 at term 3 for becomeLeader, leader elected after 14392ms
dn3_1    | 2020-11-16 13:38:18,116 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn3_1    | 2020-11-16 13:38:18,116 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2020-11-16 13:38:18,116 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2
dn3_1    | 2020-11-16 13:38:18,116 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2020-11-16 13:38:18,116 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
dn3_1    | 2020-11-16 13:38:18,117 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn3_1    | 2020-11-16 13:38:18,117 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn3_1    | 2020-11-16 13:38:18,117 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn3_1    | 2020-11-16 13:38:18,120 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn3_1    | 2020-11-16 13:38:18,120 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2020-11-16 13:38:18,121 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn3_1    | 2020-11-16 13:38:18,136 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn3_1    | 2020-11-16 13:38:18,137 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2020-11-16 13:38:18,137 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2020-11-16 13:38:18,138 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2
dn3_1    | 2020-11-16 13:38:18,141 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn3_1    | 2020-11-16 13:38:18,141 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2020-11-16 13:38:18,141 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn3_1    | 2020-11-16 13:38:18,141 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn3_1    | 2020-11-16 13:38:18,141 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2020-11-16 13:38:18,141 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2020-11-16 13:38:18,144 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO impl.RoleInfo: 38c1c219-c9e2-4898-90d7-f000768b0cf3: start LeaderState
dn3_1    | 2020-11-16 13:38:18,144 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
dn3_1    | 2020-11-16 13:38:18,146 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2/current/log_inprogress_0 to /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2/current/log_0-0
dn3_1    | 2020-11-16 13:38:18,147 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0bd52ee0-c9d9-4277-ae53-52e326379ee2/current/log_inprogress_1
dn3_1    | 2020-11-16 13:38:18,151 [38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2-LeaderElection3] INFO impl.RaftServerImpl: 38c1c219-c9e2-4898-90d7-f000768b0cf3@group-52E326379EE2: set configuration 1: [adb8fb61-c6db-4e1a-bc0f-9493e4c21274:10.9.0.11:9858:0, 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7:10.9.0.12:9858:0, 38c1c219-c9e2-4898-90d7-f000768b0cf3:10.9.0.13:9858:0], old=null at 1
recon_1  | 2020-11-16 13:38:09,467 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1  | 2020-11-16 13:38:09,467 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1  | 2020-11-16 13:38:09,524 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1  | 2020-11-16 13:38:09,524 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1  | 2020-11-16 13:38:09,540 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
recon_1  | 2020-11-16 13:38:09,541 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 59 milliseconds.
recon_1  | 2020-11-16 13:38:09,703 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 166 milliseconds to process 0 existing database records.
recon_1  | 2020-11-16 13:38:09,747 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 24 milliseconds for processing 0 containers.
recon_1  | 2020-11-16 13:38:09,972 [IPC Server handler 5 on default port 9891] WARN ipc.Server: IPC Server handler 5 on default port 9891, call Call#4 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.12:60946: output error
recon_1  | 2020-11-16 13:38:09,972 [IPC Server handler 4 on default port 9891] WARN ipc.Server: IPC Server handler 4 on default port 9891, call Call#3 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.12:60938: output error
recon_1  | 2020-11-16 13:38:09,972 [IPC Server handler 7 on default port 9891] WARN ipc.Server: IPC Server handler 7 on default port 9891, call Call#7 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.11:42946: output error
recon_1  | 2020-11-16 13:38:09,972 [IPC Server handler 2 on default port 9891] WARN ipc.Server: IPC Server handler 2 on default port 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.12:60926: output error
recon_1  | 2020-11-16 13:38:09,972 [IPC Server handler 8 on default port 9891] WARN ipc.Server: IPC Server handler 8 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.13:33604: output error
recon_1  | 2020-11-16 13:38:09,973 [IPC Server handler 1 on default port 9891] WARN ipc.Server: IPC Server handler 1 on default port 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.11:42926: output error
recon_1  | 2020-11-16 13:38:09,974 [IPC Server handler 3 on default port 9891] WARN ipc.Server: IPC Server handler 3 on default port 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.13:33596: output error
recon_1  | 2020-11-16 13:38:09,988 [IPC Server handler 6 on default port 9891] WARN ipc.Server: IPC Server handler 6 on default port 9891, call Call#4 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.11:42932: output error
recon_1  | 2020-11-16 13:38:09,988 [IPC Server handler 9 on default port 9891] WARN ipc.Server: IPC Server handler 9 on default port 9891, call Call#5 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.11:42942: output error
recon_1  | 2020-11-16 13:38:09,989 [IPC Server handler 5 on default port 9891] INFO ipc.Server: IPC Server handler 5 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-11-16 13:38:09,990 [IPC Server handler 4 on default port 9891] INFO ipc.Server: IPC Server handler 4 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-11-16 13:38:09,992 [IPC Server handler 7 on default port 9891] INFO ipc.Server: IPC Server handler 7 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-11-16 13:38:09,992 [IPC Server handler 2 on default port 9891] INFO ipc.Server: IPC Server handler 2 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-11-16 13:38:09,992 [IPC Server handler 8 on default port 9891] INFO ipc.Server: IPC Server handler 8 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-11-16 13:38:09,992 [IPC Server handler 3 on default port 9891] INFO ipc.Server: IPC Server handler 3 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-11-16 13:38:09,992 [IPC Server handler 6 on default port 9891] INFO ipc.Server: IPC Server handler 6 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-11-16 13:38:09,990 [IPC Server handler 9 on default port 9891] INFO ipc.Server: IPC Server handler 9 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-11-16 13:38:09,996 [IPC Server handler 1 on default port 9891] INFO ipc.Server: IPC Server handler 1 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-11-16 13:38:11,495 [IPC Server handler 5 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/adb8fb61-c6db-4e1a-bc0f-9493e4c21274
recon_1  | 2020-11-16 13:38:11,505 [IPC Server handler 5 on default port 9891] INFO node.SCMNodeManager: Registered Data node : adb8fb61-c6db-4e1a-bc0f-9493e4c21274{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
recon_1  | 2020-11-16 13:38:11,507 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node adb8fb61-c6db-4e1a-bc0f-9493e4c21274 to Node DB.
recon_1  | 2020-11-16 13:38:11,523 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=0bd52ee0-c9d9-4277-ae53-52e326379ee2 reported by adb8fb61-c6db-4e1a-bc0f-9493e4c21274{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
recon_1  | 2020-11-16 13:38:12,012 [IPC Server handler 11 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/38c1c219-c9e2-4898-90d7-f000768b0cf3
recon_1  | 2020-11-16 13:38:12,013 [IPC Server handler 11 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 38c1c219-c9e2-4898-90d7-f000768b0cf3{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
recon_1  | 2020-11-16 13:38:12,013 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 38c1c219-c9e2-4898-90d7-f000768b0cf3 to Node DB.
recon_1  | 2020-11-16 13:38:12,014 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=0bd52ee0-c9d9-4277-ae53-52e326379ee2 reported by 38c1c219-c9e2-4898-90d7-f000768b0cf3{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
recon_1  | 2020-11-16 13:38:12,014 [EventQueue-ContainerReportForReconContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from upgrade_dn3_1.upgrade_net.
recon_1  | 2020-11-16 13:38:12,040 [IPC Server handler 10 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/6df31ac2-2c4c-45a9-a39c-cce0d698a1e7
recon_1  | 2020-11-16 13:38:12,040 [IPC Server handler 10 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
recon_1  | 2020-11-16 13:38:12,040 [EventQueue-ContainerReportForReconContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1  | 2020-11-16 13:38:12,053 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7 to Node DB.
recon_1  | 2020-11-16 13:38:12,040 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=0bd52ee0-c9d9-4277-ae53-52e326379ee2 reported by 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
recon_1  | 2020-11-16 13:38:18,130 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=0bd52ee0-c9d9-4277-ae53-52e326379ee2 reported by 38c1c219-c9e2-4898-90d7-f000768b0cf3{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
recon_1  | 2020-11-16 13:38:18,130 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 0bd52ee0-c9d9-4277-ae53-52e326379ee2, Nodes: 38c1c219-c9e2-4898-90d7-f000768b0cf3{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}6df31ac2-2c4c-45a9-a39c-cce0d698a1e7{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}adb8fb61-c6db-4e1a-bc0f-9493e4c21274{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:38c1c219-c9e2-4898-90d7-f000768b0cf3, CreationTimestamp2020-11-16T13:37:51.493Z] moved to OPEN state
scm_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1    | 2020-11-16 13:37:43,918 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1    | /************************************************************
scm_1    | STARTUP_MSG: Starting StorageContainerManager
scm_1    | STARTUP_MSG:   host = 418af6b1f512/10.9.0.17
scm_1    | STARTUP_MSG:   args = []
scm_1    | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
scm_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT-tests.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-11689cd-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar
scm_1    | STARTUP_MSG:   build = https://github.com/apache/ozone.git/787e5b6247912eb5f19ffb2f6dc0b82380b77d37 ; compiled by 'runner' on 2020-11-16T12:42Z
scm_1    | STARTUP_MSG:   java = 11.0.7
scm_1    | ************************************************************/
scm_1    | 2020-11-16 13:37:43,961 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1    | 2020-11-16 13:37:44,874 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2020-11-16 13:37:46,554 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2020-11-16 13:37:47,705 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@7ac296f6
scm_1    | 2020-11-16 13:37:47,730 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1    | 2020-11-16 13:37:49,193 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1    | 2020-11-16 13:37:50,469 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1    | 2020-11-16 13:37:50,862 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.DefaultLeaderChoosePolicy
scm_1    | 2020-11-16 13:37:51,321 [main] INFO pipeline.SCMPipelineManager: Found pipeline in old format key : PipelineID=078fbcbb-0c1b-4852-9c3c-73dafe3709bc
scm_1    | 2020-11-16 13:37:51,467 [main] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 078fbcbb-0c1b-4852-9c3c-73dafe3709bc, Nodes: 38c1c219-c9e2-4898-90d7-f000768b0cf3{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-11-16T13:37:51.321661Z]
scm_1    | 2020-11-16 13:37:51,493 [main] INFO pipeline.SCMPipelineManager: Found pipeline in old format key : PipelineID=0bd52ee0-c9d9-4277-ae53-52e326379ee2
scm_1    | 2020-11-16 13:37:51,495 [main] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 0bd52ee0-c9d9-4277-ae53-52e326379ee2, Nodes: 38c1c219-c9e2-4898-90d7-f000768b0cf3{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}6df31ac2-2c4c-45a9-a39c-cce0d698a1e7{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}adb8fb61-c6db-4e1a-bc0f-9493e4c21274{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-11-16T13:37:51.493568Z]
scm_1    | 2020-11-16 13:37:51,523 [main] INFO pipeline.SCMPipelineManager: Found pipeline in old format key : PipelineID=d027eed2-0c03-475b-ba10-f2956286da88
scm_1    | 2020-11-16 13:37:51,524 [main] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: d027eed2-0c03-475b-ba10-f2956286da88, Nodes: adb8fb61-c6db-4e1a-bc0f-9493e4c21274{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-11-16T13:37:51.523536Z]
scm_1    | 2020-11-16 13:37:51,550 [main] INFO pipeline.SCMPipelineManager: Found pipeline in old format key : PipelineID=d48b93e3-afae-4915-a84b-c976ad8bd76d
scm_1    | 2020-11-16 13:37:51,555 [main] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: d48b93e3-afae-4915-a84b-c976ad8bd76d, Nodes: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-11-16T13:37:51.550731Z]
scm_1    | 2020-11-16 13:37:51,765 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm_1    | 2020-11-16 13:37:52,396 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 1, healthy pipeline threshold count is 1
scm_1    | 2020-11-16 13:37:52,404 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 1, pipeline's with at least one datanode reported threshold count is 1
scm_1    | 2020-11-16 13:38:01,100 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2020-11-16 13:38:01,383 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1    | 2020-11-16 13:38:01,759 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2020-11-16 13:38:01,775 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1    | 2020-11-16 13:38:01,900 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2020-11-16 13:38:01,913 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1    | 2020-11-16 13:38:02,084 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1    | 2020-11-16 13:38:02,091 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1    | 2020-11-16 13:38:02,366 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @25092ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1    | 2020-11-16 13:38:03,360 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1    | 2020-11-16 13:38:03,468 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1    | 2020-11-16 13:38:03,486 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1    | 2020-11-16 13:38:03,517 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1    | 2020-11-16 13:38:03,532 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1    | 2020-11-16 13:38:03,535 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1    | 2020-11-16 13:38:03,769 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1    | 2020-11-16 13:38:04,117 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1    | 2020-11-16 13:38:04,315 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1    | 2020-11-16 13:38:04,316 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1    | 2020-11-16 13:38:04,854 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1    | 2020-11-16 13:38:04,855 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1    | 2020-11-16 13:38:04,931 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1    | 2020-11-16 13:38:05,228 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1    | 2020-11-16 13:38:05,230 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1    | 2020-11-16 13:38:05,234 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1    | 2020-11-16 13:38:05,234 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1    | 2020-11-16 13:38:05,409 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1    | 2020-11-16 13:38:05,410 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1    | 2020-11-16 13:38:05,410 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1    | 2020-11-16 13:38:05,411 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1    | 2020-11-16 13:38:05,622 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1    | 2020-11-16 13:38:05,626 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
scm_1    | 2020-11-16 13:38:05,755 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1    | 2020-11-16 13:38:05,755 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1    | 2020-11-16 13:38:05,757 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1    | 2020-11-16 13:38:05,811 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@23202c31{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1    | 2020-11-16 13:38:05,813 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@35dd9ed3{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1    | 2020-11-16 13:38:05,981 [IPC Server handler 1 on default port 9861] WARN ipc.Server: IPC Server handler 1 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.11:36310: output error
scm_1    | 2020-11-16 13:38:05,981 [IPC Server handler 2 on default port 9861] WARN ipc.Server: IPC Server handler 2 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.12:53768: output error
scm_1    | 2020-11-16 13:38:06,005 [IPC Server handler 0 on default port 9861] WARN ipc.Server: IPC Server handler 0 on default port 9861, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.11:36324: output error
scm_1    | 2020-11-16 13:38:06,025 [IPC Server handler 1 on default port 9861] INFO ipc.Server: IPC Server handler 1 on default port 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1    | 2020-11-16 13:38:06,031 [IPC Server handler 2 on default port 9861] INFO ipc.Server: IPC Server handler 2 on default port 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1    | 2020-11-16 13:38:06,031 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1    | 2020-11-16 13:38:06,730 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@ae202c6{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-1_1_0-SNAPSHOT_jar-_-any-18187762687357494306/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar!/webapps/scm}
scm_1    | 2020-11-16 13:38:06,806 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@116a2108{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm_1    | 2020-11-16 13:38:06,810 [Listener at 0.0.0.0/9860] INFO server.Server: Started @29550ms
scm_1    | 2020-11-16 13:38:06,828 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1    | 2020-11-16 13:38:06,831 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1    | 2020-11-16 13:38:06,843 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1    | 2020-11-16 13:38:06,897 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2e869098] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1    | 2020-11-16 13:38:08,144 [IPC Server handler 42 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/adb8fb61-c6db-4e1a-bc0f-9493e4c21274
scm_1    | 2020-11-16 13:38:08,148 [IPC Server handler 42 on default port 9861] INFO node.SCMNodeManager: Registered Data node : adb8fb61-c6db-4e1a-bc0f-9493e4c21274{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
scm_1    | 2020-11-16 13:38:08,162 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1    | 2020-11-16 13:38:08,163 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1    | 2020-11-16 13:38:08,192 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: d027eed2-0c03-475b-ba10-f2956286da88, Nodes: adb8fb61-c6db-4e1a-bc0f-9493e4c21274{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:adb8fb61-c6db-4e1a-bc0f-9493e4c21274, CreationTimestamp2020-11-16T13:37:51.523536Z] moved to OPEN state
scm_1    | 2020-11-16 13:38:08,203 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 1
scm_1    | 2020-11-16 13:38:08,209 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2020-11-16 13:38:08,302 [IPC Server handler 41 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/38c1c219-c9e2-4898-90d7-f000768b0cf3
scm_1    | 2020-11-16 13:38:08,303 [IPC Server handler 41 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 38c1c219-c9e2-4898-90d7-f000768b0cf3{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
scm_1    | 2020-11-16 13:38:08,306 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1    | 2020-11-16 13:38:08,310 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1    | 2020-11-16 13:38:08,313 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 078fbcbb-0c1b-4852-9c3c-73dafe3709bc, Nodes: 38c1c219-c9e2-4898-90d7-f000768b0cf3{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:38c1c219-c9e2-4898-90d7-f000768b0cf3, CreationTimestamp2020-11-16T13:37:51.321661Z] moved to OPEN state
scm_1    | 2020-11-16 13:38:08,319 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2020-11-16 13:38:08,319 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 1
scm_1    | 2020-11-16 13:38:08,536 [IPC Server handler 64 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/6df31ac2-2c4c-45a9-a39c-cce0d698a1e7
scm_1    | 2020-11-16 13:38:08,537 [IPC Server handler 64 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
scm_1    | 2020-11-16 13:38:08,539 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1    | 2020-11-16 13:38:08,539 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: d48b93e3-afae-4915-a84b-c976ad8bd76d, Nodes: 6df31ac2-2c4c-45a9-a39c-cce0d698a1e7{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:6df31ac2-2c4c-45a9-a39c-cce0d698a1e7, CreationTimestamp2020-11-16T13:37:51.550731Z] moved to OPEN state
scm_1    | 2020-11-16 13:38:08,539 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1    | 2020-11-16 13:38:08,542 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1    | 2020-11-16 13:38:08,542 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1    | 2020-11-16 13:38:08,542 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 1
scm_1    | 2020-11-16 13:38:08,553 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2020-11-16 13:38:18,124 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 0bd52ee0-c9d9-4277-ae53-52e326379ee2, Nodes: 38c1c219-c9e2-4898-90d7-f000768b0cf3{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}6df31ac2-2c4c-45a9-a39c-cce0d698a1e7{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}adb8fb61-c6db-4e1a-bc0f-9493e4c21274{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:38c1c219-c9e2-4898-90d7-f000768b0cf3, CreationTimestamp2020-11-16T13:37:51.493568Z] moved to OPEN state
scm_1    | 2020-11-16 13:38:18,124 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 1
scm_1    | 2020-11-16 13:38:18,124 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1    | 2020-11-16 13:38:18,126 [EventQueue-OpenPipelineForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1    | 2020-11-16 13:38:18,127 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1    | 2020-11-16 13:38:18,127 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1    | 2020-11-16 13:38:18,127 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
