Attaching to upgrade_dn1_1, upgrade_dn3_1, upgrade_om_1, upgrade_s3g_1, upgrade_dn2_1, upgrade_recon_1, upgrade_scm_1
dn1_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
dn1_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn1_1    | 2020-12-08 15:25:12,501 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn1_1    | /************************************************************
dn1_1    | STARTUP_MSG: Starting HddsDatanodeService
dn1_1    | STARTUP_MSG:   host = a4822ae6317d/10.9.0.11
dn1_1    | STARTUP_MSG:   args = []
dn1_1    | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
dn1_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
dn1_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/c215b110d945df61bcd82bad9f31d421c3d12abb ; compiled by 'runner' on 2020-12-08T14:26Z
dn1_1    | STARTUP_MSG:   java = 11.0.7
dn1_1    | ************************************************************/
dn1_1    | 2020-12-08 15:25:12,553 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn1_1    | 2020-12-08 15:25:14,513 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn1_1    | 2020-12-08 15:25:15,050 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn1_1    | 2020-12-08 15:25:16,170 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn1_1    | 2020-12-08 15:25:16,170 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn1_1    | 2020-12-08 15:25:16,993 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:a4822ae6317d ip:10.9.0.11
dn1_1    | 2020-12-08 15:25:17,766 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 8192 at 2020-12-08T15:24:58.967Z
dn1_1    | 2020-12-08 15:25:17,806 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 14727258112
dn1_1    | 2020-12-08 15:25:17,808 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn1_1    | 2020-12-08 15:25:17,843 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn1_1    | 2020-12-08 15:25:17,996 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn1_1    | 2020-12-08 15:25:18,245 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn1_1    | 2020-12-08 15:25:19,751 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn1_1    | 2020-12-08 15:25:19,751 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 1s
dn1_1    | 2020-12-08 15:25:26,683 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn1_1    | 2020-12-08 15:25:27,221 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
dn1_1    | 2020-12-08 15:25:27,833 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
dn1_1    | 2020-12-08 15:25:27,841 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn1_1    | 2020-12-08 15:25:27,844 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2020-12-08 15:25:27,850 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn1_1    | 2020-12-08 15:25:27,854 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn1_1    | 2020-12-08 15:25:28,980 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn1_1    | 2020-12-08 15:25:29,129 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2020-12-08 15:25:29,172 [main] INFO impl.RaftServerProxy: 25c58bfd-4348-494a-9b09-a4dec9a92dee: found a subdirectory /data/metadata/ratis/8ed7bd94-023f-45a0-8cfb-9d505c79c0d2
dn1_1    | 2020-12-08 15:25:29,202 [main] INFO impl.RaftServerProxy: 25c58bfd-4348-494a-9b09-a4dec9a92dee: addNew group-9D505C79C0D2:[] returns group-9D505C79C0D2:java.util.concurrent.CompletableFuture@30e9ca13[Not completed]
dn1_1    | 2020-12-08 15:25:29,204 [main] INFO impl.RaftServerProxy: 25c58bfd-4348-494a-9b09-a4dec9a92dee: found a subdirectory /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df
dn1_1    | 2020-12-08 15:25:29,204 [main] INFO impl.RaftServerProxy: 25c58bfd-4348-494a-9b09-a4dec9a92dee: addNew group-ADFD663A93DF:[] returns group-ADFD663A93DF:java.util.concurrent.CompletableFuture@46185a1b[Not completed]
dn1_1    | 2020-12-08 15:25:29,205 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn1_1    | 2020-12-08 15:25:29,408 [pool-22-thread-1] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee: new RaftServerImpl for group-9D505C79C0D2:[] with ContainerStateMachine:uninitialized
dn1_1    | 2020-12-08 15:25:29,441 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2020-12-08 15:25:29,442 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2020-12-08 15:25:29,442 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2020-12-08 15:25:29,444 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2020-12-08 15:25:29,445 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
dn1_1    | 2020-12-08 15:25:29,446 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2020-12-08 15:25:29,494 [pool-22-thread-1] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn1_1    | 2020-12-08 15:25:29,516 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2020-12-08 15:25:29,535 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2020-12-08 15:25:29,594 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/8ed7bd94-023f-45a0-8cfb-9d505c79c0d2/in_use.lock acquired by nodename 6@a4822ae6317d
dn1_1    | 2020-12-08 15:25:29,791 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-9D505C79C0D2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn1_1    | 2020-12-08 15:25:29,791 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn1_1    | 2020-12-08 15:25:29,967 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2020-12-08 15:25:29,977 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2020-12-08 15:25:30,142 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2
dn1_1    | 2020-12-08 15:25:30,167 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn1_1    | 2020-12-08 15:25:30,242 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2020-12-08 15:25:30,323 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2020-12-08 15:25:30,405 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn1_1    | 2020-12-08 15:25:30,469 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2020-12-08 15:25:30,606 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/8ed7bd94-023f-45a0-8cfb-9d505c79c0d2
dn1_1    | 2020-12-08 15:25:30,638 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn2_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
dn2_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn2_1    | 2020-12-08 15:25:09,398 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn2_1    | /************************************************************
dn2_1    | STARTUP_MSG: Starting HddsDatanodeService
dn2_1    | STARTUP_MSG:   host = 754ac15d7f19/10.9.0.12
dn2_1    | STARTUP_MSG:   args = []
dn2_1    | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
dn2_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
dn1_1    | 2020-12-08 15:25:30,638 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2020-12-08 15:25:30,650 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2020-12-08 15:25:30,674 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2020-12-08 15:25:30,692 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2020-12-08 15:25:30,702 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2020-12-08 15:25:30,702 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2020-12-08 15:25:30,722 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2020-12-08 15:25:30,726 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2020-12-08 15:25:30,874 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2020-12-08 15:25:30,919 [main] INFO util.log: Logging initialized @23296ms to org.eclipse.jetty.util.log.Slf4jLog
dn1_1    | 2020-12-08 15:25:31,245 [pool-22-thread-1] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2: set configuration 0: [25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null at 0
dn1_1    | 2020-12-08 15:25:31,293 [pool-22-thread-1] INFO segmented.LogSegment: Successfully read 4 entries from segment file /data/metadata/ratis/8ed7bd94-023f-45a0-8cfb-9d505c79c0d2/current/log_inprogress_0
dn1_1    | 2020-12-08 15:25:31,324 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 3
dn1_1    | 2020-12-08 15:25:31,330 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn1_1    | 2020-12-08 15:25:31,758 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn1_1    | 2020-12-08 15:25:31,776 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn1_1    | 2020-12-08 15:25:31,811 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn1_1    | 2020-12-08 15:25:31,827 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn1_1    | 2020-12-08 15:25:31,829 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn1_1    | 2020-12-08 15:25:31,829 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn1_1    | 2020-12-08 15:25:32,017 [pool-22-thread-1] INFO raftlog.RaftLog: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-SegmentedRaftLog: commitIndex: updateToMax old=-1, new=2, updated? true
dn1_1    | 2020-12-08 15:25:32,029 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2020-12-08 15:25:32,035 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2020-12-08 15:25:32,040 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2020-12-08 15:25:32,043 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2020-12-08 15:25:32,045 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2020-12-08 15:25:32,034 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn1_1    | 2020-12-08 15:25:32,048 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
dn1_1    | 2020-12-08 15:25:32,161 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2
dn1_1    | 2020-12-08 15:25:32,167 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2
dn1_1    | 2020-12-08 15:25:32,239 [pool-22-thread-1] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee: new RaftServerImpl for group-ADFD663A93DF:[] with ContainerStateMachine:uninitialized
dn1_1    | 2020-12-08 15:25:32,258 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2020-12-08 15:25:32,258 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2020-12-08 15:25:32,259 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2020-12-08 15:25:32,273 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2020-12-08 15:25:32,274 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
dn1_1    | 2020-12-08 15:25:32,274 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2020-12-08 15:25:32,274 [pool-22-thread-1] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn1_1    | 2020-12-08 15:25:32,274 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2020-12-08 15:25:32,282 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2020-12-08 15:25:32,288 [pool-22-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df/in_use.lock acquired by nodename 6@a4822ae6317d
dn1_1    | 2020-12-08 15:25:32,288 [pool-22-thread-1] INFO ratis.ContainerStateMachine: group-ADFD663A93DF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn1_1    | 2020-12-08 15:25:32,293 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn1_1    | 2020-12-08 15:25:32,293 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn1_1    | 2020-12-08 15:25:32,293 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2020-12-08 15:25:32,294 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF
dn1_1    | 2020-12-08 15:25:32,294 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2020-12-08 15:25:32,294 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2020-12-08 15:25:32,295 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2020-12-08 15:25:32,296 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: new 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df
dn1_1    | 2020-12-08 15:25:32,296 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn1_1    | 2020-12-08 15:25:32,296 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2020-12-08 15:25:32,298 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2020-12-08 15:25:32,299 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2020-12-08 15:25:32,309 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2020-12-08 15:25:32,311 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2020-12-08 15:25:32,311 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2020-12-08 15:25:32,312 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2020-12-08 15:25:32,313 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2020-12-08 15:25:32,316 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2020-12-08 15:25:32,317 [pool-22-thread-1] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF: set configuration 0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null at 0
dn1_1    | 2020-12-08 15:25:32,310 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn1_1    | 2020-12-08 15:25:32,322 [main] INFO server.session: No SessionScavenger set, using defaults
dn1_1    | 2020-12-08 15:25:32,323 [main] INFO server.session: node0 Scavenging every 600000ms
dn1_1    | 2020-12-08 15:25:32,325 [pool-22-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df/current/log_inprogress_0
dn1_1    | 2020-12-08 15:25:32,330 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
dn1_1    | 2020-12-08 15:25:32,331 [pool-22-thread-1] INFO segmented.SegmentedRaftLogWorker: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn1_1    | 2020-12-08 15:25:32,349 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2020-12-08 15:25:32,350 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2020-12-08 15:25:32,351 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2020-12-08 15:25:32,353 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn1_1    | 2020-12-08 15:25:32,358 [pool-22-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2020-12-08 15:25:32,358 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF
dn1_1    | 2020-12-08 15:25:32,359 [pool-22-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF
dn1_1    | 2020-12-08 15:25:32,373 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@fb2e3fd{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn1_1    | 2020-12-08 15:25:32,377 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5a50d9fc{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn1_1    | 2020-12-08 15:25:32,707 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1220ef43{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-6807383709460663200/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn1_1    | 2020-12-08 15:25:32,727 [main] INFO server.AbstractConnector: Started ServerConnector@4c361f63{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn1_1    | 2020-12-08 15:25:32,739 [main] INFO server.Server: Started @25116ms
dn1_1    | 2020-12-08 15:25:32,750 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn1_1    | 2020-12-08 15:25:32,750 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn1_1    | 2020-12-08 15:25:32,756 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn1_1    | 2020-12-08 15:25:32,884 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@75cc1672] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn1_1    | 2020-12-08 15:25:33,286 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.15:9891
dn1_1    | 2020-12-08 15:25:36,143 [EndpointStateMachine task thread for recon/10.9.0.15:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn1_1    | java.net.SocketTimeoutException: Call From a4822ae6317d/10.9.0.11 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.11:36206 remote=recon/10.9.0.15:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn1_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn1_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn1_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn1_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn1_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
dn1_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
dn1_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
dn1_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
dn1_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
dn1_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
dn1_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
dn1_1    | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
dn1_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn1_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
dn1_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
om_1     | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om_1     | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1     | 2020-12-08 15:25:13,541 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1     | /************************************************************
om_1     | STARTUP_MSG: Starting OzoneManager
om_1     | STARTUP_MSG:   host = a1780e94dd4f/10.9.0.14
om_1     | STARTUP_MSG:   args = []
om_1     | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
dn2_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/c215b110d945df61bcd82bad9f31d421c3d12abb ; compiled by 'runner' on 2020-12-08T14:26Z
dn2_1    | STARTUP_MSG:   java = 11.0.7
dn2_1    | ************************************************************/
dn2_1    | 2020-12-08 15:25:09,454 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn2_1    | 2020-12-08 15:25:11,254 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn2_1    | 2020-12-08 15:25:11,863 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn2_1    | 2020-12-08 15:25:12,761 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn2_1    | 2020-12-08 15:25:12,761 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn2_1    | 2020-12-08 15:25:13,543 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:754ac15d7f19 ip:10.9.0.12
dn2_1    | 2020-12-08 15:25:14,339 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 8192 at 2020-12-08T15:24:58.929Z
dn2_1    | 2020-12-08 15:25:14,361 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 14727258112
dn2_1    | 2020-12-08 15:25:14,374 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn2_1    | 2020-12-08 15:25:14,402 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn2_1    | 2020-12-08 15:25:14,564 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn2_1    | 2020-12-08 15:25:14,808 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn2_1    | 2020-12-08 15:25:14,818 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn2_1    | 2020-12-08 15:25:14,825 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
dn2_1    | 2020-12-08 15:25:22,278 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn2_1    | 2020-12-08 15:25:22,500 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
dn2_1    | 2020-12-08 15:25:22,909 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
dn2_1    | 2020-12-08 15:25:22,935 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn2_1    | 2020-12-08 15:25:22,945 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2020-12-08 15:25:22,953 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn2_1    | 2020-12-08 15:25:22,954 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn2_1    | 2020-12-08 15:25:24,609 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn2_1    | 2020-12-08 15:25:24,669 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2020-12-08 15:25:24,722 [main] INFO impl.RaftServerProxy: 892026bc-38f3-4f54-afde-0054a2964852: found a subdirectory /data/metadata/ratis/febfc757-4270-4628-a832-ce73ee770a85
dn2_1    | 2020-12-08 15:25:24,771 [main] INFO impl.RaftServerProxy: 892026bc-38f3-4f54-afde-0054a2964852: addNew group-CE73EE770A85:[] returns group-CE73EE770A85:java.util.concurrent.CompletableFuture@227a47[Not completed]
dn2_1    | 2020-12-08 15:25:24,771 [main] INFO impl.RaftServerProxy: 892026bc-38f3-4f54-afde-0054a2964852: found a subdirectory /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df
dn2_1    | 2020-12-08 15:25:24,772 [main] INFO impl.RaftServerProxy: 892026bc-38f3-4f54-afde-0054a2964852: addNew group-ADFD663A93DF:[] returns group-ADFD663A93DF:java.util.concurrent.CompletableFuture@9596ce8[Not completed]
dn2_1    | 2020-12-08 15:25:24,772 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn2_1    | 2020-12-08 15:25:25,092 [pool-19-thread-1] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852: new RaftServerImpl for group-CE73EE770A85:[] with ContainerStateMachine:uninitialized
dn2_1    | 2020-12-08 15:25:25,167 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2020-12-08 15:25:25,180 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2020-12-08 15:25:25,180 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2020-12-08 15:25:25,201 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2020-12-08 15:25:25,203 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
dn2_1    | 2020-12-08 15:25:25,204 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2020-12-08 15:25:25,304 [pool-19-thread-1] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn2_1    | 2020-12-08 15:25:25,305 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2020-12-08 15:25:25,330 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2020-12-08 15:25:25,501 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/febfc757-4270-4628-a832-ce73ee770a85/in_use.lock acquired by nodename 6@754ac15d7f19
dn2_1    | 2020-12-08 15:25:25,748 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-CE73EE770A85: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn2_1    | 2020-12-08 15:25:25,748 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2020-12-08 15:25:25,792 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2020-12-08 15:25:25,852 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2020-12-08 15:25:25,890 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn2_1    | 2020-12-08 15:25:25,914 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85
dn2_1    | 2020-12-08 15:25:26,038 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2020-12-08 15:25:26,040 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2020-12-08 15:25:26,134 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn2_1    | 2020-12-08 15:25:26,168 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2020-12-08 15:25:26,222 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/febfc757-4270-4628-a832-ce73ee770a85
dn2_1    | 2020-12-08 15:25:26,230 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn2_1    | 2020-12-08 15:25:26,230 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2020-12-08 15:25:26,234 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2020-12-08 15:25:26,241 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2020-12-08 15:25:26,253 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2020-12-08 15:25:26,258 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2020-12-08 15:25:26,267 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2020-12-08 15:25:26,267 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2020-12-08 15:25:26,318 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2020-12-08 15:25:26,422 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2020-12-08 15:25:26,468 [main] INFO util.log: Logging initialized @20763ms to org.eclipse.jetty.util.log.Slf4jLog
dn2_1    | 2020-12-08 15:25:27,123 [pool-19-thread-1] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85: set configuration 0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:], old=null at 0
dn2_1    | 2020-12-08 15:25:27,149 [pool-19-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/febfc757-4270-4628-a832-ce73ee770a85/current/log_inprogress_0
dn2_1    | 2020-12-08 15:25:27,220 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
dn2_1    | 2020-12-08 15:25:27,222 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn2_1    | 2020-12-08 15:25:27,799 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2020-12-08 15:25:27,805 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2020-12-08 15:25:27,814 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2020-12-08 15:25:27,829 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2020-12-08 15:25:27,832 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2020-12-08 15:25:27,882 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn2_1    | 2020-12-08 15:25:27,887 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn2_1    | 2020-12-08 15:25:27,919 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn2_1    | 2020-12-08 15:25:27,935 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn2_1    | 2020-12-08 15:25:27,949 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn2_1    | 2020-12-08 15:25:27,950 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn2_1    | 2020-12-08 15:25:27,986 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85
dn2_1    | 2020-12-08 15:25:28,034 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn1_1    | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.11:36206 remote=recon/10.9.0.15:9891]
dn1_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn1_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn1_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn1_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn1_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
dn1_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn1_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
dn1_1    | 2020-12-08 15:25:36,160 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn1_1    | 2020-12-08 15:25:36,189 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn1_1    | 2020-12-08 15:25:36,193 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 25c58bfd-4348-494a-9b09-a4dec9a92dee at port 9858
dn1_1    | 2020-12-08 15:25:36,343 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF: start as a follower, conf=0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null
dn1_1    | 2020-12-08 15:25:36,346 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF: changes role from      null to FOLLOWER at term 1 for startAsFollower
dn1_1    | 2020-12-08 15:25:36,347 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RoleInfo: 25c58bfd-4348-494a-9b09-a4dec9a92dee: start 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-FollowerState
dn1_1    | 2020-12-08 15:25:36,378 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-ADFD663A93DF,id=25c58bfd-4348-494a-9b09-a4dec9a92dee
dn1_1    | 2020-12-08 15:25:36,421 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2: start as a follower, conf=0: [25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null
dn1_1    | 2020-12-08 15:25:36,379 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF
dn1_1    | 2020-12-08 15:25:36,428 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2: changes role from      null to FOLLOWER at term 1 for startAsFollower
dn1_1    | 2020-12-08 15:25:36,428 [ForkJoinPool.commonPool-worker-3] INFO impl.RoleInfo: 25c58bfd-4348-494a-9b09-a4dec9a92dee: start 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-FollowerState
dn1_1    | 2020-12-08 15:25:36,432 [ForkJoinPool.commonPool-worker-3] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9D505C79C0D2,id=25c58bfd-4348-494a-9b09-a4dec9a92dee
dn1_1    | 2020-12-08 15:25:36,452 [ForkJoinPool.commonPool-worker-3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2
dn1_1    | 2020-12-08 15:25:36,491 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerProxy: 25c58bfd-4348-494a-9b09-a4dec9a92dee: start RPC server
dn1_1    | 2020-12-08 15:25:36,844 [RatisApplyTransactionExecutor 1] WARN helpers.ChunkUtils: Duplicate write chunk request. Chunk overwrite without explicit request. ChunkInfo{chunkName='105345259427659776_chunk_1, offset=0, len=17540}
dn1_1    | 2020-12-08 15:25:36,856 [RatisApplyTransactionExecutor 1] WARN impl.FilePerChunkStrategy: ChunkFile already exists /data/hdds/hdds/ed9b649e-aca1-46de-b3a6-782bf132b41f/current/containerDir0/1/chunks/105345259427659776_chunk_1
dn1_1    | 2020-12-08 15:25:36,967 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO server.GrpcService: 25c58bfd-4348-494a-9b09-a4dec9a92dee: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
dn1_1    | 2020-12-08 15:25:37,005 [org.apache.ratis.server.JvmPauseMonitor@7095e32c-Monitor] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn1_1    | 2020-12-08 15:25:37,008 [org.apache.ratis.server.JvmPauseMonitor@7095e32c-Monitor] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn1_1    | 2020-12-08 15:25:37,024 [org.apache.ratis.server.JvmPauseMonitor@7095e32c-Monitor] INFO server.JvmPauseMonitor: Starting Ratis JVM pause monitor
dn1_1    | 2020-12-08 15:25:41,479 [Thread-19] INFO impl.FollowerState: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-FollowerState: change to CANDIDATE, lastRpcTime:5132ms, electionTimeout:5083ms
dn1_1    | 2020-12-08 15:25:41,480 [Thread-19] INFO impl.RoleInfo: 25c58bfd-4348-494a-9b09-a4dec9a92dee: shutdown 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-FollowerState
dn1_1    | 2020-12-08 15:25:41,480 [Thread-19] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn1_1    | 2020-12-08 15:25:41,482 [Thread-19] INFO impl.RoleInfo: 25c58bfd-4348-494a-9b09-a4dec9a92dee: start 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection1
dn1_1    | 2020-12-08 15:25:41,505 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection1] INFO impl.LeaderElection: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection1: begin an election at term 2 for 0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null
dn1_1    | 2020-12-08 15:25:41,636 [Thread-20] INFO impl.FollowerState: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-FollowerState: change to CANDIDATE, lastRpcTime:5207ms, electionTimeout:5151ms
dn1_1    | 2020-12-08 15:25:41,644 [Thread-20] INFO impl.RoleInfo: 25c58bfd-4348-494a-9b09-a4dec9a92dee: shutdown 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-FollowerState
dn1_1    | 2020-12-08 15:25:41,644 [Thread-20] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn1_1    | 2020-12-08 15:25:41,644 [Thread-20] INFO impl.RoleInfo: 25c58bfd-4348-494a-9b09-a4dec9a92dee: start 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2
om_1     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om_1     | STARTUP_MSG:   build = https://github.com/apache/ozone/c215b110d945df61bcd82bad9f31d421c3d12abb ; compiled by 'runner' on 2020-12-08T14:26Z
om_1     | STARTUP_MSG:   java = 11.0.7
om_1     | ************************************************************/
om_1     | 2020-12-08 15:25:13,564 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1     | 2020-12-08 15:25:21,390 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1     | 2020-12-08 15:25:21,750 [main] INFO ha.OMHANodeDetails: Configuration either no ozone.om.address set. Falling back to the default OM address om/10.9.0.14:9862
om_1     | 2020-12-08 15:25:21,750 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1     | 2020-12-08 15:25:21,781 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1     | 2020-12-08 15:25:21,921 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1     | 2020-12-08 15:25:24,619 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-08 15:25:25,633 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-08 15:25:26,634 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-08 15:25:27,639 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-08 15:25:28,640 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-08 15:25:29,641 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-08 15:25:30,642 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-08 15:25:31,646 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-08 15:25:32,647 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-08 15:25:33,647 [main] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-08 15:25:38,047 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1     | 2020-12-08 15:25:38,309 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om_1     | 2020-12-08 15:25:38,311 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om_1     | 2020-12-08 15:25:38,351 [main] INFO db.RDBStore: Found the following extra column families in existing DB : [s3Table]
om_1     | 2020-12-08 15:25:38,541 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
om_1     | 2020-12-08 15:25:38,653 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1     | 2020-12-08 15:25:38,670 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1     | 2020-12-08 15:25:38,951 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1     | 2020-12-08 15:25:39,093 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1     | 2020-12-08 15:25:39,094 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om_1     | 2020-12-08 15:25:39,173 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/10.9.0.14:9862
om_1     | 2020-12-08 15:25:39,281 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1     | 2020-12-08 15:25:39,284 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om_1     | 2020-12-08 15:25:39,326 [Listener at om/9862] INFO util.log: Logging initialized @31565ms to org.eclipse.jetty.util.log.Slf4jLog
om_1     | 2020-12-08 15:25:39,547 [Listener at om/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1     | 2020-12-08 15:25:39,571 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1     | 2020-12-08 15:25:39,586 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1     | 2020-12-08 15:25:39,588 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1     | 2020-12-08 15:25:39,592 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om_1     | 2020-12-08 15:25:39,592 [Listener at om/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om_1     | 2020-12-08 15:25:39,707 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1     | 2020-12-08 15:25:39,714 [Listener at om/9862] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
om_1     | 2020-12-08 15:25:39,941 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1     | 2020-12-08 15:25:39,944 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
om_1     | 2020-12-08 15:25:39,952 [Listener at om/9862] INFO server.session: node0 Scavenging every 660000ms
om_1     | 2020-12-08 15:25:39,993 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68ed3f30{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1     | 2020-12-08 15:25:39,998 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@58015e56{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn2_1    | 2020-12-08 15:25:28,120 [pool-19-thread-1] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852: new RaftServerImpl for group-ADFD663A93DF:[] with ContainerStateMachine:uninitialized
dn2_1    | 2020-12-08 15:25:28,170 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2020-12-08 15:25:28,193 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2020-12-08 15:25:28,194 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2020-12-08 15:25:28,194 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2020-12-08 15:25:28,194 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
dn2_1    | 2020-12-08 15:25:28,195 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2020-12-08 15:25:28,195 [pool-19-thread-1] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn2_1    | 2020-12-08 15:25:28,196 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2020-12-08 15:25:28,196 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2020-12-08 15:25:28,216 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df/in_use.lock acquired by nodename 6@754ac15d7f19
dn2_1    | 2020-12-08 15:25:28,217 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-ADFD663A93DF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn2_1    | 2020-12-08 15:25:28,217 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn2_1    | 2020-12-08 15:25:28,217 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn2_1    | 2020-12-08 15:25:28,217 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2020-12-08 15:25:28,217 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF
dn2_1    | 2020-12-08 15:25:28,217 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2020-12-08 15:25:28,217 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2020-12-08 15:25:28,218 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2020-12-08 15:25:28,218 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df
dn2_1    | 2020-12-08 15:25:28,221 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn2_1    | 2020-12-08 15:25:28,221 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2020-12-08 15:25:28,221 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2020-12-08 15:25:28,222 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
om_1     | 2020-12-08 15:25:40,239 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4b960b5b{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-1_1_0-SNAPSHOT_jar-_-any-3538747782335642257/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/ozoneManager}
om_1     | 2020-12-08 15:25:40,260 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@43bdaa1b{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om_1     | 2020-12-08 15:25:40,260 [Listener at om/9862] INFO server.Server: Started @32499ms
om_1     | 2020-12-08 15:25:40,280 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om_1     | 2020-12-08 15:25:40,285 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1     | 2020-12-08 15:25:40,301 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1     | 2020-12-08 15:25:40,303 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1     | 2020-12-08 15:25:40,304 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1     | 2020-12-08 15:25:40,465 [Listener at om/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om_1     | 2020-12-08 15:25:40,475 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@ffd4cba] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn2_1    | 2020-12-08 15:25:28,222 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2020-12-08 15:25:28,222 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2020-12-08 15:25:28,222 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2020-12-08 15:25:28,222 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2020-12-08 15:25:28,222 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2020-12-08 15:25:28,223 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2020-12-08 15:25:28,296 [pool-19-thread-1] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF: set configuration 0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null at 0
dn2_1    | 2020-12-08 15:25:28,302 [pool-19-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df/current/log_inprogress_0
dn2_1    | 2020-12-08 15:25:28,321 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
dn2_1    | 2020-12-08 15:25:28,322 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn2_1    | 2020-12-08 15:25:28,328 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2020-12-08 15:25:28,333 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2020-12-08 15:25:28,362 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2020-12-08 15:25:28,362 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn2_1    | 2020-12-08 15:25:28,362 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2020-12-08 15:25:28,362 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF
dn2_1    | 2020-12-08 15:25:28,363 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF
dn2_1    | 2020-12-08 15:25:28,426 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn2_1    | 2020-12-08 15:25:28,430 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
dn2_1    | 2020-12-08 15:25:28,799 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn2_1    | 2020-12-08 15:25:28,806 [main] INFO server.session: No SessionScavenger set, using defaults
dn2_1    | 2020-12-08 15:25:28,807 [main] INFO server.session: node0 Scavenging every 600000ms
dn2_1    | 2020-12-08 15:25:28,941 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@11eed657{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn2_1    | 2020-12-08 15:25:28,974 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6415f61e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn2_1    | 2020-12-08 15:25:29,852 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@73c3cd09{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-3086106147024788047/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn2_1    | 2020-12-08 15:25:29,937 [main] INFO server.AbstractConnector: Started ServerConnector@42a0501e{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn2_1    | 2020-12-08 15:25:29,938 [main] INFO server.Server: Started @24233ms
dn2_1    | 2020-12-08 15:25:29,953 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn2_1    | 2020-12-08 15:25:29,954 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn2_1    | 2020-12-08 15:25:29,959 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn2_1    | 2020-12-08 15:25:30,102 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4b11f53e] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn2_1    | 2020-12-08 15:25:30,640 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.15:9891
dn2_1    | 2020-12-08 15:25:33,239 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2020-12-08 15:25:33,288 [EndpointStateMachine task thread for recon/10.9.0.15:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.15:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2020-12-08 15:25:34,289 [EndpointStateMachine task thread for recon/10.9.0.15:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.15:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2020-12-08 15:25:34,312 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
dn2_1    | java.net.SocketTimeoutException: Call From 754ac15d7f19/10.9.0.12 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.12:43748 remote=scm/10.9.0.17:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn2_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn2_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
dn2_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
dn2_1    | 	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn1_1    | 2020-12-08 15:25:41,665 [org.apache.ratis.server.JvmPauseMonitor@7095e32c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 86ms
dn1_1    | GC pool 'ParNew' had collection(s): count=1 time=88ms
dn1_1    | 2020-12-08 15:25:41,676 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO impl.LeaderElection: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2: begin an election at term 2 for 0: [25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null
dn1_1    | 2020-12-08 15:25:41,681 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO impl.RoleInfo: 25c58bfd-4348-494a-9b09-a4dec9a92dee: shutdown 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2
dn1_1    | 2020-12-08 15:25:41,681 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
dn1_1    | 2020-12-08 15:25:41,681 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-9D505C79C0D2 with new leaderId: 25c58bfd-4348-494a-9b09-a4dec9a92dee
dn1_1    | 2020-12-08 15:25:41,685 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2: change Leader from null to 25c58bfd-4348-494a-9b09-a4dec9a92dee at term 2 for becomeLeader, leader elected after 11890ms
dn1_1    | 2020-12-08 15:25:41,717 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn1_1    | 2020-12-08 15:25:41,721 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn1_1    | 2020-12-08 15:25:41,722 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2
dn1_1    | 2020-12-08 15:25:41,730 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn1_1    | 2020-12-08 15:25:41,734 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
dn1_1    | 2020-12-08 15:25:41,773 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn1_1    | 2020-12-08 15:25:41,773 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn1_1    | 2020-12-08 15:25:41,774 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn1_1    | 2020-12-08 15:25:41,815 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO impl.RoleInfo: 25c58bfd-4348-494a-9b09-a4dec9a92dee: start 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderState
dn1_1    | 2020-12-08 15:25:41,886 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-SegmentedRaftLogWorker: Rolling segment log-0_3 to index:3
dn1_1    | 2020-12-08 15:25:41,906 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/8ed7bd94-023f-45a0-8cfb-9d505c79c0d2/current/log_inprogress_0 to /data/metadata/ratis/8ed7bd94-023f-45a0-8cfb-9d505c79c0d2/current/log_0-3
dn1_1    | 2020-12-08 15:25:41,954 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-LeaderElection2] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2: set configuration 4: [25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null at 4
dn1_1    | 2020-12-08 15:25:41,955 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-9D505C79C0D2-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8ed7bd94-023f-45a0-8cfb-9d505c79c0d2/current/log_inprogress_4
dn1_1    | 2020-12-08 15:25:42,618 [grpc-default-executor-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.25c58bfd-4348-494a-9b09-a4dec9a92dee
dn1_1    | 2020-12-08 15:25:42,673 [org.apache.ratis.server.JvmPauseMonitor@7095e32c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8ms
dn1_1    | GC pool 'ParNew' had collection(s): count=1 time=88ms
dn1_1    | 2020-12-08 15:25:43,121 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection1] INFO impl.LeaderElection: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection1: Election REJECTED; received 2 response(s) [25c58bfd-4348-494a-9b09-a4dec9a92dee<-892026bc-38f3-4f54-afde-0054a2964852#0:FAIL-t2, 25c58bfd-4348-494a-9b09-a4dec9a92dee<-054abb01-b57b-42ea-aff7-3bb87eb3dd27#0:FAIL-t2] and 0 exception(s); 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF:t2, leader=null, voted=25c58bfd-4348-494a-9b09-a4dec9a92dee, raftlog=25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-SegmentedRaftLog:OPENED:c-1,f0,i0, conf=0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null
dn1_1    | 2020-12-08 15:25:43,122 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection1] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
dn1_1    | 2020-12-08 15:25:43,123 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection1] INFO impl.RoleInfo: 25c58bfd-4348-494a-9b09-a4dec9a92dee: shutdown 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection1
dn1_1    | 2020-12-08 15:25:43,123 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection1] INFO impl.RoleInfo: 25c58bfd-4348-494a-9b09-a4dec9a92dee: start 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-FollowerState
dn1_1    | 2020-12-08 15:25:48,208 [Thread-33] INFO impl.FollowerState: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-FollowerState: change to CANDIDATE, lastRpcTime:5084ms, electionTimeout:5067ms
dn1_1    | 2020-12-08 15:25:48,208 [Thread-33] INFO impl.RoleInfo: 25c58bfd-4348-494a-9b09-a4dec9a92dee: shutdown 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-FollowerState
dn1_1    | 2020-12-08 15:25:48,208 [Thread-33] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
dn1_1    | 2020-12-08 15:25:48,209 [Thread-33] INFO impl.RoleInfo: 25c58bfd-4348-494a-9b09-a4dec9a92dee: start 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection3
dn3_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
dn3_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
dn3_1    | 2020-12-08 15:25:10,731 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
dn3_1    | /************************************************************
dn3_1    | STARTUP_MSG: Starting HddsDatanodeService
dn3_1    | STARTUP_MSG:   host = ed8969a89b71/10.9.0.13
dn3_1    | STARTUP_MSG:   args = []
dn3_1    | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
dn1_1    | 2020-12-08 15:25:48,210 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection3] INFO impl.LeaderElection: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection3: begin an election at term 3 for 0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null
dn1_1    | 2020-12-08 15:25:48,300 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection3] INFO impl.LeaderElection: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection3: Election REJECTED; received 2 response(s) [25c58bfd-4348-494a-9b09-a4dec9a92dee<-892026bc-38f3-4f54-afde-0054a2964852#0:FAIL-t3, 25c58bfd-4348-494a-9b09-a4dec9a92dee<-054abb01-b57b-42ea-aff7-3bb87eb3dd27#0:FAIL-t3] and 0 exception(s); 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF:t3, leader=null, voted=25c58bfd-4348-494a-9b09-a4dec9a92dee, raftlog=25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-SegmentedRaftLog:OPENED:c-1,f0,i0, conf=0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null
dn1_1    | 2020-12-08 15:25:48,301 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection3] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF: changes role from CANDIDATE to FOLLOWER at term 3 for DISCOVERED_A_NEW_TERM
dn1_1    | 2020-12-08 15:25:48,301 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection3] INFO impl.RoleInfo: 25c58bfd-4348-494a-9b09-a4dec9a92dee: shutdown 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection3
dn1_1    | 2020-12-08 15:25:48,301 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-LeaderElection3] INFO impl.RoleInfo: 25c58bfd-4348-494a-9b09-a4dec9a92dee: start 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-FollowerState
dn1_1    | 2020-12-08 15:25:48,341 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-ADFD663A93DF with new leaderId: 054abb01-b57b-42ea-aff7-3bb87eb3dd27
dn1_1    | 2020-12-08 15:25:48,342 [grpc-default-executor-1] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF: change Leader from null to 054abb01-b57b-42ea-aff7-3bb87eb3dd27 at term 3 for appendEntries, leader elected after 16047ms
dn1_1    | 2020-12-08 15:25:48,420 [grpc-default-executor-1] INFO impl.RaftServerImpl: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF: set configuration 1: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null at 1
dn1_1    | 2020-12-08 15:25:48,428 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
dn1_1    | 2020-12-08 15:25:48,434 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df/current/log_inprogress_0 to /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df/current/log_0-0
dn1_1    | 2020-12-08 15:25:48,445 [25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 25c58bfd-4348-494a-9b09-a4dec9a92dee@group-ADFD663A93DF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df/current/log_inprogress_1
s3g_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
s3g_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1    | 2020-12-08 15:25:11,990 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1    | 2020-12-08 15:25:12,005 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
s3g_1    | 2020-12-08 15:25:12,162 [main] INFO util.log: Logging initialized @6067ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1    | 2020-12-08 15:25:12,798 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1    | 2020-12-08 15:25:12,948 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1    | 2020-12-08 15:25:12,967 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1    | 2020-12-08 15:25:12,993 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g_1    | 2020-12-08 15:25:12,996 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1    | 2020-12-08 15:25:12,996 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1    | 2020-12-08 15:25:13,276 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1    | /************************************************************
s3g_1    | STARTUP_MSG: Starting Gateway
s3g_1    | STARTUP_MSG:   host = be2f9be17154/10.9.0.16
s3g_1    | STARTUP_MSG:   args = []
s3g_1    | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
dn3_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
dn3_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/c215b110d945df61bcd82bad9f31d421c3d12abb ; compiled by 'runner' on 2020-12-08T14:26Z
dn3_1    | STARTUP_MSG:   java = 11.0.7
dn3_1    | ************************************************************/
dn3_1    | 2020-12-08 15:25:10,770 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
dn3_1    | 2020-12-08 15:25:12,709 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn3_1    | 2020-12-08 15:25:13,274 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
dn3_1    | 2020-12-08 15:25:14,137 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn3_1    | 2020-12-08 15:25:14,138 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
dn3_1    | 2020-12-08 15:25:14,864 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:ed8969a89b71 ip:10.9.0.13
dn3_1    | 2020-12-08 15:25:15,543 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info found in /data/hdds/scmUsed: 8192 at 2020-12-08T15:24:58.837Z
dn3_1    | 2020-12-08 15:25:15,555 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 14727258112
dn3_1    | 2020-12-08 15:25:15,559 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
dn3_1    | 2020-12-08 15:25:15,599 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
dn3_1    | 2020-12-08 15:25:15,731 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
dn3_1    | 2020-12-08 15:25:15,992 [Thread-3] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
dn3_1    | 2020-12-08 15:25:15,993 [Thread-3] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
dn3_1    | 2020-12-08 15:25:15,997 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
dn3_1    | 2020-12-08 15:25:23,011 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn3_1    | 2020-12-08 15:25:23,358 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
dn3_1    | 2020-12-08 15:25:23,841 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
dn3_1    | 2020-12-08 15:25:23,847 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn3_1    | 2020-12-08 15:25:23,854 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2020-12-08 15:25:23,859 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn3_1    | 2020-12-08 15:25:23,872 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2020-12-08 15:25:25,235 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
dn3_1    | 2020-12-08 15:25:25,384 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2020-12-08 15:25:25,430 [main] INFO impl.RaftServerProxy: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: found a subdirectory /data/metadata/ratis/c6d30633-727c-4874-8a43-de6535ef93f5
dn3_1    | 2020-12-08 15:25:25,506 [main] INFO impl.RaftServerProxy: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: addNew group-DE6535EF93F5:[] returns group-DE6535EF93F5:java.util.concurrent.CompletableFuture@9596ce8[Not completed]
dn3_1    | 2020-12-08 15:25:25,506 [main] INFO impl.RaftServerProxy: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: found a subdirectory /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df
dn3_1    | 2020-12-08 15:25:25,506 [main] INFO impl.RaftServerProxy: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: addNew group-ADFD663A93DF:[] returns group-ADFD663A93DF:java.util.concurrent.CompletableFuture@75ae4a1f[Not completed]
dn3_1    | 2020-12-08 15:25:25,508 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn3_1    | 2020-12-08 15:25:25,795 [pool-19-thread-1] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: new RaftServerImpl for group-DE6535EF93F5:[] with ContainerStateMachine:uninitialized
dn3_1    | 2020-12-08 15:25:25,809 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2020-12-08 15:25:25,824 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2020-12-08 15:25:25,828 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2020-12-08 15:25:25,837 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2020-12-08 15:25:25,840 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
dn3_1    | 2020-12-08 15:25:25,859 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2020-12-08 15:25:25,918 [pool-19-thread-1] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn3_1    | 2020-12-08 15:25:25,934 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2020-12-08 15:25:25,952 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2020-12-08 15:25:26,118 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c6d30633-727c-4874-8a43-de6535ef93f5/in_use.lock acquired by nodename 6@ed8969a89b71
dn3_1    | 2020-12-08 15:25:26,449 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-DE6535EF93F5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn3_1    | 2020-12-08 15:25:26,473 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn3_1    | 2020-12-08 15:25:26,485 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn3_1    | 2020-12-08 15:25:26,528 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2020-12-08 15:25:26,595 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5
dn3_1    | 2020-12-08 15:25:26,632 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn3_1    | 2020-12-08 15:25:26,724 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2020-12-08 15:25:26,735 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2020-12-08 15:25:26,859 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2020-12-08 15:25:26,932 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
dn3_1    | 2020-12-08 15:25:26,950 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/c6d30633-727c-4874-8a43-de6535ef93f5
dn3_1    | 2020-12-08 15:25:26,958 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn3_1    | 2020-12-08 15:25:26,968 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2020-12-08 15:25:26,986 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2020-12-08 15:25:26,987 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2020-12-08 15:25:26,987 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2020-12-08 15:25:26,988 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2020-12-08 15:25:26,989 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2020-12-08 15:25:26,998 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2020-12-08 15:25:27,008 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2020-12-08 15:25:27,132 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2020-12-08 15:25:27,138 [main] INFO util.log: Logging initialized @21023ms to org.eclipse.jetty.util.log.Slf4jLog
dn3_1    | 2020-12-08 15:25:27,719 [pool-19-thread-1] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5: set configuration 0: [054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:], old=null at 0
dn3_1    | 2020-12-08 15:25:27,751 [pool-19-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/c6d30633-727c-4874-8a43-de6535ef93f5/current/log_inprogress_0
dn3_1    | 2020-12-08 15:25:27,824 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
dn3_1    | 2020-12-08 15:25:27,849 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn3_1    | 2020-12-08 15:25:28,402 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn3_1    | 2020-12-08 15:25:28,433 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
dn3_1    | 2020-12-08 15:25:28,520 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn3_1    | 2020-12-08 15:25:28,570 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn3_1    | 2020-12-08 15:25:28,581 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
dn3_1    | 2020-12-08 15:25:28,582 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
dn3_1    | 2020-12-08 15:25:29,114 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2020-12-08 15:25:29,119 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2020-12-08 15:25:29,137 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2020-12-08 15:25:29,146 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn3_1    | 2020-12-08 15:25:29,146 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2020-12-08 15:25:29,186 [main] INFO http.HttpServer2: Jetty bound to port 9882
dn3_1    | 2020-12-08 15:25:29,188 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
dn3_1    | 2020-12-08 15:25:29,331 [main] INFO server.session: DefaultSessionIdManager workerName=node0
dn3_1    | 2020-12-08 15:25:29,331 [main] INFO server.session: No SessionScavenger set, using defaults
dn3_1    | 2020-12-08 15:25:29,332 [main] INFO server.session: node0 Scavenging every 660000ms
dn3_1    | 2020-12-08 15:25:29,402 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@708f018e{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn3_1    | 2020-12-08 15:25:29,403 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@334ebcaa{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
dn3_1    | 2020-12-08 15:25:29,426 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5
dn3_1    | 2020-12-08 15:25:29,431 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5
dn3_1    | 2020-12-08 15:25:29,616 [pool-19-thread-1] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: new RaftServerImpl for group-ADFD663A93DF:[] with ContainerStateMachine:uninitialized
dn3_1    | 2020-12-08 15:25:29,650 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2020-12-08 15:25:29,654 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2020-12-08 15:25:29,662 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2020-12-08 15:25:29,667 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2020-12-08 15:25:29,671 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
dn3_1    | 2020-12-08 15:25:29,695 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2020-12-08 15:25:29,695 [pool-19-thread-1] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
dn3_1    | 2020-12-08 15:25:29,712 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2020-12-08 15:25:29,713 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2020-12-08 15:25:29,734 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df/in_use.lock acquired by nodename 6@ed8969a89b71
dn3_1    | 2020-12-08 15:25:29,735 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-ADFD663A93DF: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn3_1    | 2020-12-08 15:25:29,746 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
dn3_1    | 2020-12-08 15:25:29,756 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
dn3_1    | 2020-12-08 15:25:29,761 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2020-12-08 15:25:29,761 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF
recon_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
recon_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1  | 2020-12-08 15:25:11,432 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1  | /************************************************************
recon_1  | STARTUP_MSG: Starting ReconServer
recon_1  | STARTUP_MSG:   host = c67399e29b6a/10.9.0.15
recon_1  | STARTUP_MSG:   args = []
recon_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
recon_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-reconcodegen-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.27.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.27.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.5.RELEASE.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.27.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-1.1.0-SNAPSHOT.jar
recon_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/c215b110d945df61bcd82bad9f31d421c3d12abb ; compiled by 'runner' on 2020-12-08T14:26Z
recon_1  | STARTUP_MSG:   java = 11.0.7
recon_1  | ************************************************************/
recon_1  | 2020-12-08 15:25:11,495 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1  | WARNING: An illegal reflective access operation has occurred
recon_1  | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
recon_1  | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
recon_1  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1  | WARNING: All illegal access operations will be denied in a future release
recon_1  | 2020-12-08 15:25:15,286 [main] INFO recon.ReconRestServletModule: rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1  | 2020-12-08 15:25:16,954 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1  | 2020-12-08 15:25:17,286 [main] INFO impl.ReconContainerDBProvider: Last known container-key DB : /data/metadata/recon/recon-container-key.db_1607441055894
recon_1  | 2020-12-08 15:25:18,488 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1  | 2020-12-08 15:25:24,674 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1  | 2020-12-08 15:25:27,318 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1  | 2020-12-08 15:25:27,459 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1  | 2020-12-08 15:25:27,460 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1  | 2020-12-08 15:25:31,861 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1  | 2020-12-08 15:25:31,947 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
recon_1  | 2020-12-08 15:25:31,997 [main] INFO util.log: Logging initialized @24284ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1  | 2020-12-08 15:25:32,286 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1  | 2020-12-08 15:25:32,297 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1  | 2020-12-08 15:25:32,307 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1  | 2020-12-08 15:25:32,311 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
recon_1  | 2020-12-08 15:25:32,311 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
recon_1  | 2020-12-08 15:25:32,312 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
recon_1  | 2020-12-08 15:25:32,592 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1  | 2020-12-08 15:25:33,270 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1  | 2020-12-08 15:25:33,288 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1  | 2020-12-08 15:25:33,355 [main] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
recon_1  | 2020-12-08 15:25:33,355 [main] INFO ozone.OmUtils: No OzoneManager ServiceID configured.
recon_1  | 2020-12-08 15:25:33,723 [main] INFO Configuration.deprecation: No unit for ozone.recon.om.connection.request.timeout(5000) assuming MILLISECONDS
recon_1  | 2020-12-08 15:25:34,152 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2020-12-08 15:25:34,359 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2020-12-08 15:25:34,382 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@44641d6c
recon_1  | 2020-12-08 15:25:34,385 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1  | 2020-12-08 15:25:34,527 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2020-12-08 15:25:34,604 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1  | 2020-12-08 15:25:34,688 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn2_1    | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.12:43748 remote=scm/10.9.0.17:9861]
dn2_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn2_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn2_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
dn2_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn2_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
dn2_1    | 2020-12-08 15:25:35,290 [EndpointStateMachine task thread for recon/10.9.0.15:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.15:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn2_1    | 2020-12-08 15:25:36,115 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState: Error in executing end point task.
dn2_1    | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:450)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:230)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:407)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn2_1    | Caused by: java.util.concurrent.TimeoutException
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn2_1    | 	... 1 more
dn2_1    | 2020-12-08 15:25:36,234 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn2_1    | 2020-12-08 15:25:36,248 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn2_1    | 2020-12-08 15:25:36,249 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 892026bc-38f3-4f54-afde-0054a2964852 at port 9858
dn2_1    | 2020-12-08 15:25:36,266 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF: start as a follower, conf=0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null
dn2_1    | 2020-12-08 15:25:36,267 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF: changes role from      null to FOLLOWER at term 1 for startAsFollower
dn2_1    | 2020-12-08 15:25:36,268 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RoleInfo: 892026bc-38f3-4f54-afde-0054a2964852: start 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-FollowerState
dn2_1    | 2020-12-08 15:25:36,290 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-ADFD663A93DF,id=892026bc-38f3-4f54-afde-0054a2964852
dn2_1    | 2020-12-08 15:25:36,292 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF
dn2_1    | 2020-12-08 15:25:36,295 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85: start as a follower, conf=0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:], old=null
dn2_1    | 2020-12-08 15:25:36,295 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85: changes role from      null to FOLLOWER at term 1 for startAsFollower
dn2_1    | 2020-12-08 15:25:36,296 [ForkJoinPool.commonPool-worker-3] INFO impl.RoleInfo: 892026bc-38f3-4f54-afde-0054a2964852: start 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-FollowerState
dn2_1    | 2020-12-08 15:25:36,308 [EndpointStateMachine task thread for recon/10.9.0.15:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn2_1    | java.net.SocketTimeoutException: Call From 754ac15d7f19/10.9.0.12 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.12:41984 remote=recon/10.9.0.15:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn2_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn2_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.27.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.10.3.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar
s3g_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/c215b110d945df61bcd82bad9f31d421c3d12abb ; compiled by 'runner' on 2020-12-08T14:26Z
s3g_1    | STARTUP_MSG:   java = 11.0.7
s3g_1    | ************************************************************/
s3g_1    | 2020-12-08 15:25:13,318 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1    | 2020-12-08 15:25:13,628 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1    | 2020-12-08 15:25:13,685 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1    | 2020-12-08 15:25:13,695 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
s3g_1    | 2020-12-08 15:25:14,194 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1    | 2020-12-08 15:25:14,201 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1    | 2020-12-08 15:25:14,207 [main] INFO server.session: node0 Scavenging every 660000ms
s3g_1    | 2020-12-08 15:25:14,350 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4c5ae43b{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1    | 2020-12-08 15:25:14,377 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@747f281{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1    | WARNING: An illegal reflective access operation has occurred
s3g_1    | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1    | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1    | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1    | WARNING: All illegal access operations will be denied in a future release
s3g_1    | Dec 08, 2020 3:25:30 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1    | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1    | 
s3g_1    | 2020-12-08 15:25:31,059 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@126f8f24{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-1_1_0-SNAPSHOT_jar-_-any-17160442300912989071/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1    | 2020-12-08 15:25:31,122 [main] INFO server.AbstractConnector: Started ServerConnector@6736fa8d{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1    | 2020-12-08 15:25:31,123 [main] INFO server.Server: Started @25029ms
s3g_1    | 2020-12-08 15:25:31,135 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
scm_1    | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1    | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1    | 2020-12-08 15:25:16,703 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1    | /************************************************************
scm_1    | STARTUP_MSG: Starting StorageContainerManager
scm_1    | STARTUP_MSG:   host = 0d8117e73079/10.9.0.17
scm_1    | STARTUP_MSG:   args = []
scm_1    | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
scm_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar
dn3_1    | 2020-12-08 15:25:29,763 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2020-12-08 15:25:29,763 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2020-12-08 15:25:29,764 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2020-12-08 15:25:29,782 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df
dn3_1    | 2020-12-08 15:25:29,791 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
dn3_1    | 2020-12-08 15:25:29,792 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2020-12-08 15:25:29,797 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2020-12-08 15:25:29,798 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2020-12-08 15:25:29,798 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2020-12-08 15:25:29,798 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2020-12-08 15:25:29,801 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2020-12-08 15:25:29,805 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2020-12-08 15:25:29,806 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2020-12-08 15:25:29,806 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2020-12-08 15:25:29,830 [pool-19-thread-1] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF: set configuration 0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null at 0
dn3_1    | 2020-12-08 15:25:29,859 [pool-19-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df/current/log_inprogress_0
dn3_1    | 2020-12-08 15:25:29,862 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
dn3_1    | 2020-12-08 15:25:29,865 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
dn3_1    | 2020-12-08 15:25:29,922 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2020-12-08 15:25:29,922 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2020-12-08 15:25:29,923 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2020-12-08 15:25:29,923 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
dn3_1    | 2020-12-08 15:25:29,939 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2020-12-08 15:25:29,939 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF
dn3_1    | 2020-12-08 15:25:29,940 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF
dn3_1    | 2020-12-08 15:25:30,333 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4a8a0099{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-7700484039630569086/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
dn3_1    | 2020-12-08 15:25:30,412 [main] INFO server.AbstractConnector: Started ServerConnector@6aa3bfc{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
dn3_1    | 2020-12-08 15:25:30,423 [main] INFO server.Server: Started @24308ms
dn3_1    | 2020-12-08 15:25:30,432 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
dn3_1    | 2020-12-08 15:25:30,441 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
dn3_1    | 2020-12-08 15:25:30,453 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn3_1    | 2020-12-08 15:25:30,604 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@103fa3f] INFO util.JvmPauseMonitor: Starting JVM pause monitor
dn3_1    | 2020-12-08 15:25:31,045 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/10.9.0.15:9891
dn3_1    | 2020-12-08 15:25:33,805 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/10.9.0.17:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn3_1    | 2020-12-08 15:25:33,809 [EndpointStateMachine task thread for recon/10.9.0.15:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.15:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn3_1    | 2020-12-08 15:25:34,810 [EndpointStateMachine task thread for recon/10.9.0.15:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/10.9.0.15:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
dn3_1    | 2020-12-08 15:25:34,829 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
dn3_1    | java.net.SocketTimeoutException: Call From ed8969a89b71/10.9.0.13 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.13:37732 remote=scm/10.9.0.17:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn3_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn3_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn3_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn3_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn3_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
dn3_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
dn3_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
dn3_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
dn3_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
dn3_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
dn3_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
dn3_1    | 	at com.sun.proxy.$Proxy37.submitRequest(Unknown Source)
recon_1  | 2020-12-08 15:25:34,699 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1  | 2020-12-08 15:25:34,719 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1  | 2020-12-08 15:25:34,755 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1  | 2020-12-08 15:25:34,795 [Listener at 0.0.0.0/9891] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
recon_1  | 2020-12-08 15:25:34,848 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1  | 2020-12-08 15:25:34,851 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1  | 2020-12-08 15:25:35,000 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1  | 2020-12-08 15:25:35,119 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1  | 2020-12-08 15:25:35,120 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1  | 2020-12-08 15:25:35,625 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1  | 2020-12-08 15:25:35,630 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
recon_1  | 2020-12-08 15:25:35,756 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1  | 2020-12-08 15:25:35,765 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1  | 2020-12-08 15:25:35,766 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
recon_1  | 2020-12-08 15:25:35,837 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@664212ab{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1  | 2020-12-08 15:25:35,840 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1ba467c2{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1  | 2020-12-08 15:25:39,229 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@612290d{recon,/,file:///tmp/jetty-0_0_0_0-9888-hadoop-ozone-recon-1_1_0-SNAPSHOT_jar-_-any-11711153836967829869/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-1.1.0-SNAPSHOT.jar!/webapps/recon}
recon_1  | 2020-12-08 15:25:39,260 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@1536ea40{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1  | 2020-12-08 15:25:39,261 [Listener at 0.0.0.0/9891] INFO server.Server: Started @31548ms
recon_1  | 2020-12-08 15:25:39,263 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1  | 2020-12-08 15:25:39,265 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1  | 2020-12-08 15:25:39,275 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1  | 2020-12-08 15:25:39,276 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1  | 2020-12-08 15:25:39,300 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1  | 2020-12-08 15:25:39,327 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1  | 2020-12-08 15:25:39,329 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1  | 2020-12-08 15:25:39,329 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2020-12-08 15:25:39,329 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1  | 2020-12-08 15:25:39,332 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1  | 2020-12-08 15:25:39,873 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 4 pipelines from SCM.
recon_1  | 2020-12-08 15:25:39,879 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1  | 2020-12-08 15:25:39,883 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=febfc757-4270-4628-a832-ce73ee770a85 from SCM.
recon_1  | 2020-12-08 15:25:39,921 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: febfc757-4270-4628-a832-ce73ee770a85, Nodes: 892026bc-38f3-4f54-afde-0054a2964852{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:892026bc-38f3-4f54-afde-0054a2964852, CreationTimestamp2020-12-08T15:25:24.339Z]
recon_1  | 2020-12-08 15:25:39,932 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=c6d30633-727c-4874-8a43-de6535ef93f5 from SCM.
recon_1  | 2020-12-08 15:25:39,935 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: c6d30633-727c-4874-8a43-de6535ef93f5, Nodes: 054abb01-b57b-42ea-aff7-3bb87eb3dd27{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:054abb01-b57b-42ea-aff7-3bb87eb3dd27, CreationTimestamp2020-12-08T15:25:24.338Z]
recon_1  | 2020-12-08 15:25:39,935 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=8ed7bd94-023f-45a0-8cfb-9d505c79c0d2 from SCM.
recon_1  | 2020-12-08 15:25:39,936 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 8ed7bd94-023f-45a0-8cfb-9d505c79c0d2, Nodes: 25c58bfd-4348-494a-9b09-a4dec9a92dee{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:25c58bfd-4348-494a-9b09-a4dec9a92dee, CreationTimestamp2020-12-08T15:25:24.315Z]
recon_1  | 2020-12-08 15:25:39,936 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=6618c38d-5b72-4334-a134-adfd663a93df from SCM.
recon_1  | 2020-12-08 15:25:39,940 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 6618c38d-5b72-4334-a134-adfd663a93df, Nodes: 892026bc-38f3-4f54-afde-0054a2964852{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}054abb01-b57b-42ea-aff7-3bb87eb3dd27{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}25c58bfd-4348-494a-9b09-a4dec9a92dee{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-12-08T15:25:24.159Z]
recon_1  | 2020-12-08 15:25:39,942 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1  | 2020-12-08 15:25:39,952 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1  | 2020-12-08 15:25:39,961 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1  | 2020-12-08 15:25:40,111 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1  | 2020-12-08 15:25:40,111 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1  | 2020-12-08 15:25:40,178 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
recon_1  | 2020-12-08 15:25:40,183 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 53 milliseconds.
recon_1  | 2020-12-08 15:25:40,195 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1  | 2020-12-08 15:25:40,206 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1  | 2020-12-08 15:25:40,322 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 107 milliseconds to process 0 existing database records.
recon_1  | 2020-12-08 15:25:40,340 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 18 milliseconds for processing 0 containers.
recon_1  | 2020-12-08 15:25:40,490 [IPC Server handler 4 on default port 9891] WARN ipc.Server: IPC Server handler 4 on default port 9891, call Call#3 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.13:33930: output error
recon_1  | 2020-12-08 15:25:40,491 [IPC Server handler 11 on default port 9891] WARN ipc.Server: IPC Server handler 11 on default port 9891, call Call#6 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.13:33950: output error
recon_1  | 2020-12-08 15:25:40,491 [IPC Server handler 7 on default port 9891] WARN ipc.Server: IPC Server handler 7 on default port 9891, call Call#5 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.12:42006: output error
recon_1  | 2020-12-08 15:25:40,498 [IPC Server handler 0 on default port 9891] WARN ipc.Server: IPC Server handler 0 on default port 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.13:33916: output error
recon_1  | 2020-12-08 15:25:40,498 [IPC Server handler 3 on default port 9891] WARN ipc.Server: IPC Server handler 3 on default port 9891, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.11:36206: output error
recon_1  | 2020-12-08 15:25:40,491 [IPC Server handler 8 on default port 9891] WARN ipc.Server: IPC Server handler 8 on default port 9891, call Call#5 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.13:33942: output error
recon_1  | 2020-12-08 15:25:40,490 [IPC Server handler 5 on default port 9891] WARN ipc.Server: IPC Server handler 5 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.11:36228: output error
recon_1  | 2020-12-08 15:25:40,498 [IPC Server handler 10 on default port 9891] WARN ipc.Server: IPC Server handler 10 on default port 9891, call Call#7 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.12:42008: output error
recon_1  | 2020-12-08 15:25:40,498 [IPC Server handler 2 on default port 9891] WARN ipc.Server: IPC Server handler 2 on default port 9891, call Call#4 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.12:41998: output error
recon_1  | 2020-12-08 15:25:40,499 [IPC Server handler 6 on default port 9891] WARN ipc.Server: IPC Server handler 6 on default port 9891, call Call#3 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.11:36236: output error
recon_1  | 2020-12-08 15:25:40,512 [IPC Server handler 4 on default port 9891] INFO ipc.Server: IPC Server handler 4 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1    | STARTUP_MSG:   build = https://github.com/apache/ozone/c215b110d945df61bcd82bad9f31d421c3d12abb ; compiled by 'runner' on 2020-12-08T14:26Z
scm_1    | STARTUP_MSG:   java = 11.0.7
scm_1    | ************************************************************/
scm_1    | 2020-12-08 15:25:16,834 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1    | 2020-12-08 15:25:18,211 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2020-12-08 15:25:20,128 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2020-12-08 15:25:20,970 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@6bb4dd34
scm_1    | 2020-12-08 15:25:20,975 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1    | 2020-12-08 15:25:22,360 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1    | 2020-12-08 15:25:23,652 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1    | 2020-12-08 15:25:23,806 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.DefaultLeaderChoosePolicy
scm_1    | 2020-12-08 15:25:24,159 [main] INFO pipeline.SCMPipelineManager: Found pipeline in old format key : PipelineID=6618c38d-5b72-4334-a134-adfd663a93df
scm_1    | 2020-12-08 15:25:24,310 [main] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 6618c38d-5b72-4334-a134-adfd663a93df, Nodes: 892026bc-38f3-4f54-afde-0054a2964852{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}054abb01-b57b-42ea-aff7-3bb87eb3dd27{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}25c58bfd-4348-494a-9b09-a4dec9a92dee{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-12-08T15:25:24.159006Z]
scm_1    | 2020-12-08 15:25:24,315 [main] INFO pipeline.SCMPipelineManager: Found pipeline in old format key : PipelineID=8ed7bd94-023f-45a0-8cfb-9d505c79c0d2
scm_1    | 2020-12-08 15:25:24,337 [main] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 8ed7bd94-023f-45a0-8cfb-9d505c79c0d2, Nodes: 25c58bfd-4348-494a-9b09-a4dec9a92dee{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-12-08T15:25:24.315288Z]
scm_1    | 2020-12-08 15:25:24,338 [main] INFO pipeline.SCMPipelineManager: Found pipeline in old format key : PipelineID=c6d30633-727c-4874-8a43-de6535ef93f5
scm_1    | 2020-12-08 15:25:24,339 [main] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: c6d30633-727c-4874-8a43-de6535ef93f5, Nodes: 054abb01-b57b-42ea-aff7-3bb87eb3dd27{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-12-08T15:25:24.338410Z]
scm_1    | 2020-12-08 15:25:24,339 [main] INFO pipeline.SCMPipelineManager: Found pipeline in old format key : PipelineID=febfc757-4270-4628-a832-ce73ee770a85
scm_1    | 2020-12-08 15:25:24,341 [main] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: febfc757-4270-4628-a832-ce73ee770a85, Nodes: 892026bc-38f3-4f54-afde-0054a2964852{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-12-08T15:25:24.339657Z]
scm_1    | 2020-12-08 15:25:24,518 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm_1    | 2020-12-08 15:25:25,162 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1    | 2020-12-08 15:25:25,178 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1    | 2020-12-08 15:25:32,808 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2020-12-08 15:25:32,884 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1    | 2020-12-08 15:25:32,982 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2020-12-08 15:25:32,985 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1    | 2020-12-08 15:25:33,003 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2020-12-08 15:25:33,004 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1    | 2020-12-08 15:25:33,046 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1    | 2020-12-08 15:25:33,047 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1    | 2020-12-08 15:25:33,109 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @26507ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1    | 2020-12-08 15:25:33,359 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1    | 2020-12-08 15:25:33,508 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1    | 2020-12-08 15:25:33,550 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1    | 2020-12-08 15:25:33,556 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1    | 2020-12-08 15:25:33,560 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1    | 2020-12-08 15:25:33,560 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1    | 2020-12-08 15:25:33,701 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1    | 2020-12-08 15:25:33,849 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1    | 2020-12-08 15:25:34,030 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
dn3_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn3_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn3_1    | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.13:37732 remote=scm/10.9.0.17:9861]
dn3_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn3_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn3_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn3_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn3_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
dn3_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn3_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
dn3_1    | 2020-12-08 15:25:35,814 [EndpointStateMachine task thread for recon/10.9.0.15:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn3_1    | java.net.SocketTimeoutException: Call From ed8969a89b71/10.9.0.13 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.13:33916 remote=recon/10.9.0.15:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn3_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn3_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn3_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn3_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn3_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
dn3_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
dn3_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
dn3_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
dn3_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
dn3_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
dn3_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
dn3_1    | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
dn3_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn3_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn3_1    | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.13:33916 remote=recon/10.9.0.15:9891]
dn3_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn3_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn3_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn3_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn3_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
dn3_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn3_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
dn3_1    | 2020-12-08 15:25:36,614 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState: Error in executing end point task.
dn3_1    | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:450)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:230)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:407)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn3_1    | Caused by: java.util.concurrent.TimeoutException
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1    | 2020-12-08 15:25:34,040 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1    | 2020-12-08 15:25:34,512 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1    | 2020-12-08 15:25:34,513 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1    | 2020-12-08 15:25:34,521 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1    | 2020-12-08 15:25:34,668 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1    | 2020-12-08 15:25:34,672 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1    | 2020-12-08 15:25:34,676 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1    | 2020-12-08 15:25:34,677 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1    | 2020-12-08 15:25:34,793 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1    | 2020-12-08 15:25:34,798 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1    | 2020-12-08 15:25:34,809 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1    | 2020-12-08 15:25:34,809 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1    | 2020-12-08 15:25:34,927 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1    | 2020-12-08 15:25:34,943 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
scm_1    | 2020-12-08 15:25:35,239 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1    | 2020-12-08 15:25:35,243 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1    | 2020-12-08 15:25:35,253 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1    | 2020-12-08 15:25:35,339 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1d61c6dc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1    | 2020-12-08 15:25:35,358 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@26f7cdf8{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1    | 2020-12-08 15:25:35,956 [IPC Server handler 3 on default port 9861] WARN ipc.Server: IPC Server handler 3 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.12:43748: output error
scm_1    | 2020-12-08 15:25:35,957 [IPC Server handler 1 on default port 9861] WARN ipc.Server: IPC Server handler 1 on default port 9861, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.13:37744: output error
scm_1    | 2020-12-08 15:25:35,958 [IPC Server handler 4 on default port 9861] WARN ipc.Server: IPC Server handler 4 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.13:37732: output error
scm_1    | 2020-12-08 15:25:35,958 [IPC Server handler 0 on default port 9861] WARN ipc.Server: IPC Server handler 0 on default port 9861, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.12:43762: output error
scm_1    | 2020-12-08 15:25:36,009 [IPC Server handler 1 on default port 9861] INFO ipc.Server: IPC Server handler 1 on default port 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1    | 2020-12-08 15:25:36,009 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1    | 2020-12-08 15:25:36,009 [IPC Server handler 4 on default port 9861] INFO ipc.Server: IPC Server handler 4 on default port 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	... 1 more
dn3_1    | 2020-12-08 15:25:36,738 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
dn3_1    | 2020-12-08 15:25:36,748 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
dn3_1    | 2020-12-08 15:25:36,752 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 054abb01-b57b-42ea-aff7-3bb87eb3dd27 at port 9858
dn3_1    | 2020-12-08 15:25:36,832 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF: start as a follower, conf=0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null
dn3_1    | 2020-12-08 15:25:36,833 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF: changes role from      null to FOLLOWER at term 1 for startAsFollower
dn3_1    | 2020-12-08 15:25:36,841 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RoleInfo: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: start 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-FollowerState
dn3_1    | 2020-12-08 15:25:36,878 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5: start as a follower, conf=0: [054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:], old=null
dn3_1    | 2020-12-08 15:25:36,886 [ForkJoinPool.commonPool-worker-3] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5: changes role from      null to FOLLOWER at term 1 for startAsFollower
dn3_1    | 2020-12-08 15:25:36,889 [ForkJoinPool.commonPool-worker-3] INFO impl.RoleInfo: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: start 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-FollowerState
dn3_1    | 2020-12-08 15:25:36,899 [ForkJoinPool.commonPool-worker-3] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DE6535EF93F5,id=054abb01-b57b-42ea-aff7-3bb87eb3dd27
dn3_1    | 2020-12-08 15:25:36,900 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-ADFD663A93DF,id=054abb01-b57b-42ea-aff7-3bb87eb3dd27
dn3_1    | 2020-12-08 15:25:36,902 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF
dn3_1    | 2020-12-08 15:25:36,906 [ForkJoinPool.commonPool-worker-3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5
dn3_1    | 2020-12-08 15:25:36,919 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerProxy: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: start RPC server
dn3_1    | 2020-12-08 15:25:37,137 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO server.GrpcService: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
dn3_1    | 2020-12-08 15:25:37,167 [org.apache.ratis.server.JvmPauseMonitor@3956c6bb-Monitor] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn3_1    | 2020-12-08 15:25:37,202 [org.apache.ratis.server.JvmPauseMonitor@3956c6bb-Monitor] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn3_1    | 2020-12-08 15:25:37,286 [org.apache.ratis.server.JvmPauseMonitor@3956c6bb-Monitor] INFO server.JvmPauseMonitor: Starting Ratis JVM pause monitor
dn3_1    | 2020-12-08 15:25:37,795 [org.apache.ratis.server.JvmPauseMonitor@3956c6bb-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
dn3_1    | No GCs detected
dn3_1    | 2020-12-08 15:25:42,081 [Thread-22] INFO impl.FollowerState: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-FollowerState: change to CANDIDATE, lastRpcTime:5246ms, electionTimeout:5188ms
dn3_1    | 2020-12-08 15:25:42,085 [Thread-22] INFO impl.RoleInfo: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: shutdown 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-FollowerState
dn3_1    | 2020-12-08 15:25:42,085 [Thread-22] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn3_1    | 2020-12-08 15:25:42,093 [Thread-24] INFO impl.FollowerState: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-FollowerState: change to CANDIDATE, lastRpcTime:5204ms, electionTimeout:5195ms
dn3_1    | 2020-12-08 15:25:42,094 [Thread-24] INFO impl.RoleInfo: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: shutdown 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-FollowerState
dn3_1    | 2020-12-08 15:25:42,094 [Thread-22] INFO impl.RoleInfo: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: start 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection1
dn3_1    | 2020-12-08 15:25:42,094 [Thread-24] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn3_1    | 2020-12-08 15:25:42,095 [Thread-24] INFO impl.RoleInfo: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: start 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2
dn3_1    | 2020-12-08 15:25:42,144 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO impl.LeaderElection: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2: begin an election at term 2 for 0: [054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:], old=null
dn3_1    | 2020-12-08 15:25:42,145 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO impl.RoleInfo: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: shutdown 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2
dn3_1    | 2020-12-08 15:25:42,146 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
dn3_1    | 2020-12-08 15:25:42,146 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-DE6535EF93F5 with new leaderId: 054abb01-b57b-42ea-aff7-3bb87eb3dd27
dn3_1    | 2020-12-08 15:25:42,149 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5: change Leader from null to 054abb01-b57b-42ea-aff7-3bb87eb3dd27 at term 2 for becomeLeader, leader elected after 15673ms
dn3_1    | 2020-12-08 15:25:42,152 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection1] INFO impl.LeaderElection: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection1: begin an election at term 2 for 0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null
recon_1  | 2020-12-08 15:25:40,513 [IPC Server handler 6 on default port 9891] INFO ipc.Server: IPC Server handler 6 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-12-08 15:25:40,513 [IPC Server handler 2 on default port 9891] INFO ipc.Server: IPC Server handler 2 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1    | 2020-12-08 15:25:36,009 [IPC Server handler 3 on default port 9861] INFO ipc.Server: IPC Server handler 3 on default port 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1    | 2020-12-08 15:25:36,301 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@340a8894{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-1_1_0-SNAPSHOT_jar-_-any-16159392639217072988/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar!/webapps/scm}
scm_1    | 2020-12-08 15:25:36,398 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@60acd609{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm_1    | 2020-12-08 15:25:36,398 [Listener at 0.0.0.0/9860] INFO server.Server: Started @29797ms
scm_1    | 2020-12-08 15:25:36,400 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1    | 2020-12-08 15:25:36,411 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1    | 2020-12-08 15:25:36,427 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1    | 2020-12-08 15:25:36,470 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4993febc] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1    | 2020-12-08 15:25:38,162 [IPC Server handler 18 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/892026bc-38f3-4f54-afde-0054a2964852
scm_1    | 2020-12-08 15:25:38,164 [IPC Server handler 18 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 892026bc-38f3-4f54-afde-0054a2964852{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2020-12-08 15:25:38,177 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1    | 2020-12-08 15:25:38,186 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1    | 2020-12-08 15:25:38,202 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1    | 2020-12-08 15:25:38,210 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: febfc757-4270-4628-a832-ce73ee770a85, Nodes: 892026bc-38f3-4f54-afde-0054a2964852{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:892026bc-38f3-4f54-afde-0054a2964852, CreationTimestamp2020-12-08T15:25:24.339657Z] moved to OPEN state
scm_1    | 2020-12-08 15:25:38,222 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2020-12-08 15:25:38,638 [IPC Server handler 19 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/054abb01-b57b-42ea-aff7-3bb87eb3dd27
scm_1    | 2020-12-08 15:25:38,639 [IPC Server handler 19 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 054abb01-b57b-42ea-aff7-3bb87eb3dd27{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2020-12-08 15:25:38,641 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1    | 2020-12-08 15:25:38,645 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1    | 2020-12-08 15:25:38,653 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1    | 2020-12-08 15:25:38,661 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: c6d30633-727c-4874-8a43-de6535ef93f5, Nodes: 054abb01-b57b-42ea-aff7-3bb87eb3dd27{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:054abb01-b57b-42ea-aff7-3bb87eb3dd27, CreationTimestamp2020-12-08T15:25:24.338410Z] moved to OPEN state
scm_1    | 2020-12-08 15:25:38,661 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2020-12-08 15:25:38,978 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/25c58bfd-4348-494a-9b09-a4dec9a92dee
scm_1    | 2020-12-08 15:25:38,979 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 25c58bfd-4348-494a-9b09-a4dec9a92dee{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1    | 2020-12-08 15:25:38,982 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1    | 2020-12-08 15:25:38,982 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1    | 2020-12-08 15:25:38,982 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1    | 2020-12-08 15:25:38,982 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
dn2_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
dn2_1    | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn2_1    | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.12:41984 remote=recon/10.9.0.15:9891]
dn2_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn2_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn2_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
dn2_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn2_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
dn2_1    | 2020-12-08 15:25:36,308 [ForkJoinPool.commonPool-worker-3] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CE73EE770A85,id=892026bc-38f3-4f54-afde-0054a2964852
dn2_1    | 2020-12-08 15:25:36,334 [ForkJoinPool.commonPool-worker-3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85
dn2_1    | 2020-12-08 15:25:36,336 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO impl.RaftServerProxy: 892026bc-38f3-4f54-afde-0054a2964852: start RPC server
dn2_1    | 2020-12-08 15:25:36,558 [EndpointStateMachine task thread for scm/10.9.0.17:9861 - 0 ] INFO server.GrpcService: 892026bc-38f3-4f54-afde-0054a2964852: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
dn2_1    | 2020-12-08 15:25:36,596 [org.apache.ratis.server.JvmPauseMonitor@3e2f64d2-Monitor] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
dn2_1    | 2020-12-08 15:25:36,596 [org.apache.ratis.server.JvmPauseMonitor@3e2f64d2-Monitor] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
dn2_1    | 2020-12-08 15:25:36,635 [org.apache.ratis.server.JvmPauseMonitor@3e2f64d2-Monitor] INFO server.JvmPauseMonitor: Starting Ratis JVM pause monitor
dn2_1    | 2020-12-08 15:25:38,116 [Datanode State Machine Thread - 0] ERROR datanode.RunningDatanodeState: Error in executing end point task.
dn2_1    | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:191)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:231)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:450)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:230)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:407)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn2_1    | Caused by: java.util.concurrent.TimeoutException
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:149)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn2_1    | 	... 1 more
dn2_1    | 2020-12-08 15:25:38,152 [org.apache.ratis.server.JvmPauseMonitor@3e2f64d2-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
dn2_1    | No GCs detected
dn2_1    | 2020-12-08 15:25:41,319 [Thread-21] INFO impl.FollowerState: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-FollowerState: change to CANDIDATE, lastRpcTime:5051ms, electionTimeout:5001ms
dn2_1    | 2020-12-08 15:25:41,320 [Thread-21] INFO impl.RoleInfo: 892026bc-38f3-4f54-afde-0054a2964852: shutdown 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-FollowerState
dn2_1    | 2020-12-08 15:25:41,323 [Thread-21] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn2_1    | 2020-12-08 15:25:41,325 [Thread-21] INFO impl.RoleInfo: 892026bc-38f3-4f54-afde-0054a2964852: start 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-LeaderElection1
dn2_1    | 2020-12-08 15:25:41,377 [892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-LeaderElection1] INFO impl.LeaderElection: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-LeaderElection1: begin an election at term 2 for 0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null
dn3_1    | 2020-12-08 15:25:42,174 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn3_1    | 2020-12-08 15:25:42,174 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2020-12-08 15:25:42,175 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5
dn3_1    | 2020-12-08 15:25:42,196 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2020-12-08 15:25:42,210 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
dn3_1    | 2020-12-08 15:25:42,260 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn3_1    | 2020-12-08 15:25:42,300 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn3_1    | 2020-12-08 15:25:42,312 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn3_1    | 2020-12-08 15:25:42,331 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO impl.RoleInfo: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: start 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderState
dn3_1    | 2020-12-08 15:25:42,396 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
dn3_1    | 2020-12-08 15:25:42,412 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/c6d30633-727c-4874-8a43-de6535ef93f5/current/log_inprogress_0 to /data/metadata/ratis/c6d30633-727c-4874-8a43-de6535ef93f5/current/log_0-0
dn3_1    | 2020-12-08 15:25:42,486 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-LeaderElection2] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5: set configuration 1: [054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:], old=null at 1
dn3_1    | 2020-12-08 15:25:42,487 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-DE6535EF93F5-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c6d30633-727c-4874-8a43-de6535ef93f5/current/log_inprogress_1
dn3_1    | 2020-12-08 15:25:42,814 [org.apache.ratis.server.JvmPauseMonitor@3956c6bb-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
dn3_1    | GC pool 'ParNew' had collection(s): count=1 time=31ms
dn3_1    | 2020-12-08 15:25:43,040 [grpc-default-executor-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.054abb01-b57b-42ea-aff7-3bb87eb3dd27
dn3_1    | 2020-12-08 15:25:43,172 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection1] INFO impl.LeaderElection: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection1: Election REJECTED; received 2 response(s) [054abb01-b57b-42ea-aff7-3bb87eb3dd27<-892026bc-38f3-4f54-afde-0054a2964852#0:FAIL-t2, 054abb01-b57b-42ea-aff7-3bb87eb3dd27<-25c58bfd-4348-494a-9b09-a4dec9a92dee#0:FAIL-t2] and 0 exception(s); 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF:t2, leader=null, voted=054abb01-b57b-42ea-aff7-3bb87eb3dd27, raftlog=054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-SegmentedRaftLog:OPENED:c-1,f0,i0, conf=0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null
dn3_1    | 2020-12-08 15:25:43,175 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection1] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
dn3_1    | 2020-12-08 15:25:43,175 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection1] INFO impl.RoleInfo: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: shutdown 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection1
dn3_1    | 2020-12-08 15:25:43,177 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection1] INFO impl.RoleInfo: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: start 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-FollowerState
dn3_1    | 2020-12-08 15:25:48,198 [Thread-35] INFO impl.FollowerState: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-FollowerState: change to CANDIDATE, lastRpcTime:5022ms, electionTimeout:5016ms
dn3_1    | 2020-12-08 15:25:48,198 [Thread-35] INFO impl.RoleInfo: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: shutdown 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-FollowerState
dn3_1    | 2020-12-08 15:25:48,198 [Thread-35] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
dn3_1    | 2020-12-08 15:25:48,198 [Thread-35] INFO impl.RoleInfo: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: start 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3
dn3_1    | 2020-12-08 15:25:48,200 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO impl.LeaderElection: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3: begin an election at term 3 for 0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null
dn3_1    | 2020-12-08 15:25:48,229 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO impl.LeaderElection: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3: Election PASSED; received 1 response(s) [054abb01-b57b-42ea-aff7-3bb87eb3dd27<-892026bc-38f3-4f54-afde-0054a2964852#0:OK-t3] and 0 exception(s); 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF:t3, leader=null, voted=054abb01-b57b-42ea-aff7-3bb87eb3dd27, raftlog=054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-SegmentedRaftLog:OPENED:c-1,f0,i0, conf=0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null
dn3_1    | 2020-12-08 15:25:48,230 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO impl.RoleInfo: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: shutdown 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3
dn3_1    | 2020-12-08 15:25:48,230 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
dn3_1    | 2020-12-08 15:25:48,230 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-ADFD663A93DF with new leaderId: 054abb01-b57b-42ea-aff7-3bb87eb3dd27
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-12-08 15:25:40,513 [IPC Server handler 10 on default port 9891] INFO ipc.Server: IPC Server handler 10 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-12-08 15:25:40,513 [IPC Server handler 5 on default port 9891] INFO ipc.Server: IPC Server handler 5 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-12-08 15:25:40,513 [IPC Server handler 8 on default port 9891] INFO ipc.Server: IPC Server handler 8 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-12-08 15:25:40,513 [IPC Server handler 7 on default port 9891] INFO ipc.Server: IPC Server handler 7 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-12-08 15:25:40,513 [IPC Server handler 11 on default port 9891] INFO ipc.Server: IPC Server handler 11 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1    | 2020-12-08 15:25:38,983 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1    | 2020-12-08 15:25:38,998 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 8ed7bd94-023f-45a0-8cfb-9d505c79c0d2, Nodes: 25c58bfd-4348-494a-9b09-a4dec9a92dee{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:25c58bfd-4348-494a-9b09-a4dec9a92dee, CreationTimestamp2020-12-08T15:25:24.315288Z] moved to OPEN state
scm_1    | 2020-12-08 15:25:38,999 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2020-12-08 15:25:42,260 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1    | 2020-12-08 15:25:42,262 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1    | 2020-12-08 15:25:42,262 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2020-12-08 15:25:42,263 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2020-12-08 15:25:42,897 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1    | 2020-12-08 15:25:42,897 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2020-12-08 15:25:48,246 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1    | 2020-12-08 15:25:48,256 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2020-12-08 15:25:48,256 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 6618c38d-5b72-4334-a134-adfd663a93df, Nodes: 892026bc-38f3-4f54-afde-0054a2964852{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}054abb01-b57b-42ea-aff7-3bb87eb3dd27{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}25c58bfd-4348-494a-9b09-a4dec9a92dee{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:054abb01-b57b-42ea-aff7-3bb87eb3dd27, CreationTimestamp2020-12-08T15:25:24.159006Z] moved to OPEN state
scm_1    | 2020-12-08 15:25:48,264 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1    | 2020-12-08 15:25:48,264 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1    | 2020-12-08 15:25:48,267 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1    | 2020-12-08 15:25:48,267 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
dn3_1    | 2020-12-08 15:25:48,231 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF: change Leader from null to 054abb01-b57b-42ea-aff7-3bb87eb3dd27 at term 3 for becomeLeader, leader elected after 18486ms
dn3_1    | 2020-12-08 15:25:48,231 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn3_1    | 2020-12-08 15:25:48,231 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2020-12-08 15:25:48,233 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF
dn3_1    | 2020-12-08 15:25:48,242 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2020-12-08 15:25:48,243 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
dn3_1    | 2020-12-08 15:25:48,243 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn3_1    | 2020-12-08 15:25:48,243 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn3_1    | 2020-12-08 15:25:48,244 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn3_1    | 2020-12-08 15:25:48,250 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn3_1    | 2020-12-08 15:25:48,251 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2020-12-08 15:25:48,252 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn3_1    | 2020-12-08 15:25:48,254 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn3_1    | 2020-12-08 15:25:48,256 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2020-12-08 15:25:48,256 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2020-12-08 15:25:48,257 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF
dn3_1    | 2020-12-08 15:25:48,260 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn3_1    | 2020-12-08 15:25:48,274 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2020-12-08 15:25:48,274 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
dn3_1    | 2020-12-08 15:25:48,274 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn3_1    | 2020-12-08 15:25:48,277 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2020-12-08 15:25:48,277 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2020-12-08 15:25:48,280 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO impl.RoleInfo: 054abb01-b57b-42ea-aff7-3bb87eb3dd27: start 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderState
dn3_1    | 2020-12-08 15:25:48,284 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
dn3_1    | 2020-12-08 15:25:48,287 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df/current/log_inprogress_0 to /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df/current/log_0-0
dn3_1    | 2020-12-08 15:25:48,289 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df/current/log_inprogress_1
dn3_1    | 2020-12-08 15:25:48,296 [054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-LeaderElection3] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF: set configuration 1: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null at 1
dn3_1    | 2020-12-08 15:25:48,296 [grpc-default-executor-1] INFO impl.RaftServerImpl: 054abb01-b57b-42ea-aff7-3bb87eb3dd27@group-ADFD663A93DF-   LEADER: Withhold vote from candidate 25c58bfd-4348-494a-9b09-a4dec9a92dee with term 3. State: leader=054abb01-b57b-42ea-aff7-3bb87eb3dd27, term=3, lastRpcElapsed=null
dn2_1    | 2020-12-08 15:25:41,520 [Thread-22] INFO impl.FollowerState: 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-FollowerState: change to CANDIDATE, lastRpcTime:5224ms, electionTimeout:5158ms
dn2_1    | 2020-12-08 15:25:41,544 [Thread-22] INFO impl.RoleInfo: 892026bc-38f3-4f54-afde-0054a2964852: shutdown 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-FollowerState
dn2_1    | 2020-12-08 15:25:41,545 [Thread-22] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
dn2_1    | 2020-12-08 15:25:41,545 [Thread-22] INFO impl.RoleInfo: 892026bc-38f3-4f54-afde-0054a2964852: start 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2
dn2_1    | 2020-12-08 15:25:41,575 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO impl.LeaderElection: 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2: begin an election at term 2 for 0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:], old=null
dn2_1    | 2020-12-08 15:25:41,585 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO impl.RoleInfo: 892026bc-38f3-4f54-afde-0054a2964852: shutdown 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2
dn2_1    | 2020-12-08 15:25:41,585 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
dn2_1    | 2020-12-08 15:25:41,586 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CE73EE770A85 with new leaderId: 892026bc-38f3-4f54-afde-0054a2964852
dn2_1    | 2020-12-08 15:25:41,587 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85: change Leader from null to 892026bc-38f3-4f54-afde-0054a2964852 at term 2 for becomeLeader, leader elected after 15837ms
dn2_1    | 2020-12-08 15:25:41,628 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
dn2_1    | 2020-12-08 15:25:41,629 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
dn2_1    | 2020-12-08 15:25:41,630 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85
dn2_1    | 2020-12-08 15:25:41,643 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2020-12-08 15:25:41,662 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
dn2_1    | 2020-12-08 15:25:41,679 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
dn2_1    | 2020-12-08 15:25:41,681 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
dn2_1    | 2020-12-08 15:25:41,687 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
dn2_1    | 2020-12-08 15:25:41,735 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO impl.RoleInfo: 892026bc-38f3-4f54-afde-0054a2964852: start 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderState
dn2_1    | 2020-12-08 15:25:41,818 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
dn2_1    | 2020-12-08 15:25:41,891 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/febfc757-4270-4628-a832-ce73ee770a85/current/log_inprogress_0 to /data/metadata/ratis/febfc757-4270-4628-a832-ce73ee770a85/current/log_0-0
dn2_1    | 2020-12-08 15:25:41,922 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-LeaderElection2] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85: set configuration 1: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:], old=null at 1
dn2_1    | 2020-12-08 15:25:41,957 [892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 892026bc-38f3-4f54-afde-0054a2964852@group-CE73EE770A85-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/febfc757-4270-4628-a832-ce73ee770a85/current/log_inprogress_1
dn2_1    | 2020-12-08 15:25:42,630 [grpc-default-executor-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.892026bc-38f3-4f54-afde-0054a2964852
dn2_1    | 2020-12-08 15:25:43,124 [892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-LeaderElection1] INFO impl.LeaderElection: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-LeaderElection1: Election REJECTED; received 2 response(s) [892026bc-38f3-4f54-afde-0054a2964852<-25c58bfd-4348-494a-9b09-a4dec9a92dee#0:FAIL-t2, 892026bc-38f3-4f54-afde-0054a2964852<-054abb01-b57b-42ea-aff7-3bb87eb3dd27#0:FAIL-t2] and 0 exception(s); 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF:t2, leader=null, voted=892026bc-38f3-4f54-afde-0054a2964852, raftlog=892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-SegmentedRaftLog:OPENED:c-1,f0,i0, conf=0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null
dn2_1    | 2020-12-08 15:25:43,124 [892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-LeaderElection1] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
dn2_1    | 2020-12-08 15:25:43,125 [892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-LeaderElection1] INFO impl.RoleInfo: 892026bc-38f3-4f54-afde-0054a2964852: shutdown 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-LeaderElection1
dn2_1    | 2020-12-08 15:25:43,125 [892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-LeaderElection1] INFO impl.RoleInfo: 892026bc-38f3-4f54-afde-0054a2964852: start 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-FollowerState
dn2_1    | 2020-12-08 15:25:48,214 [grpc-default-executor-1] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF: changes role from  FOLLOWER to FOLLOWER at term 3 for recognizeCandidate:054abb01-b57b-42ea-aff7-3bb87eb3dd27
dn2_1    | 2020-12-08 15:25:48,217 [grpc-default-executor-1] INFO impl.RoleInfo: 892026bc-38f3-4f54-afde-0054a2964852: shutdown 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-FollowerState
dn2_1    | 2020-12-08 15:25:48,217 [grpc-default-executor-1] INFO impl.RoleInfo: 892026bc-38f3-4f54-afde-0054a2964852: start 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-FollowerState
dn2_1    | 2020-12-08 15:25:48,217 [Thread-35] INFO impl.FollowerState: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-FollowerState was interrupted: {}
dn2_1    | java.lang.InterruptedException: sleep interrupted
dn2_1    | 	at java.base/java.lang.Thread.sleep(Native Method)
dn2_1    | 	at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:250)
dn2_1    | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:116)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
dn2_1    | 2020-12-08 15:25:48,218 [grpc-default-executor-1] INFO impl.RaftServerImpl:  FOLLOWER 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF:t3, leader=null, voted=null, raftlog=892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-SegmentedRaftLog:OPENED:c-1,f0,i0, conf=0: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null RUNNING priority:0 candidate:054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream: candidatePriority:0 compare:0
dn2_1    | 2020-12-08 15:25:48,328 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-ADFD663A93DF with new leaderId: 054abb01-b57b-42ea-aff7-3bb87eb3dd27
dn2_1    | 2020-12-08 15:25:48,328 [grpc-default-executor-1] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF: change Leader from null to 054abb01-b57b-42ea-aff7-3bb87eb3dd27 at term 3 for appendEntries, leader elected after 20111ms
dn2_1    | 2020-12-08 15:25:48,376 [grpc-default-executor-1] INFO impl.RaftServerImpl: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF: set configuration 1: [892026bc-38f3-4f54-afde-0054a2964852|rpc:10.9.0.12:9858|dataStream:, 054abb01-b57b-42ea-aff7-3bb87eb3dd27|rpc:10.9.0.13:9858|dataStream:, 25c58bfd-4348-494a-9b09-a4dec9a92dee|rpc:10.9.0.11:9858|dataStream:], old=null at 1
dn2_1    | 2020-12-08 15:25:48,382 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
dn2_1    | 2020-12-08 15:25:48,396 [892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df/current/log_inprogress_0 to /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df/current/log_0-0
dn2_1    | 2020-12-08 15:25:48,398 [892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 892026bc-38f3-4f54-afde-0054a2964852@group-ADFD663A93DF-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6618c38d-5b72-4334-a134-adfd663a93df/current/log_inprogress_1
dn2_1    | 2020-12-08 15:25:56,669 [org.apache.ratis.server.JvmPauseMonitor@3e2f64d2-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
dn2_1    | GC pool 'ParNew' had collection(s): count=1 time=43ms
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-12-08 15:25:40,513 [IPC Server handler 3 on default port 9891] INFO ipc.Server: IPC Server handler 3 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-12-08 15:25:40,515 [IPC Server handler 0 on default port 9891] INFO ipc.Server: IPC Server handler 0 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-12-08 15:25:40,520 [IPC Server handler 1 on default port 9891] WARN ipc.Server: IPC Server handler 1 on default port 9891, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.12:41984: output error
recon_1  | 2020-12-08 15:25:40,520 [IPC Server handler 1 on default port 9891] INFO ipc.Server: IPC Server handler 1 on default port 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
recon_1  | 2020-12-08 15:25:41,622 [IPC Server handler 12 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/892026bc-38f3-4f54-afde-0054a2964852
recon_1  | 2020-12-08 15:25:41,624 [IPC Server handler 12 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 892026bc-38f3-4f54-afde-0054a2964852{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2020-12-08 15:25:41,634 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 892026bc-38f3-4f54-afde-0054a2964852 to Node DB.
recon_1  | 2020-12-08 15:25:41,650 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=6618c38d-5b72-4334-a134-adfd663a93df reported by 892026bc-38f3-4f54-afde-0054a2964852{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2020-12-08 15:25:41,696 [IPC Server handler 13 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/25c58bfd-4348-494a-9b09-a4dec9a92dee
recon_1  | 2020-12-08 15:25:41,696 [IPC Server handler 13 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 25c58bfd-4348-494a-9b09-a4dec9a92dee{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2020-12-08 15:25:41,697 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 25c58bfd-4348-494a-9b09-a4dec9a92dee to Node DB.
recon_1  | 2020-12-08 15:25:41,697 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=6618c38d-5b72-4334-a134-adfd663a93df reported by 25c58bfd-4348-494a-9b09-a4dec9a92dee{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2020-12-08 15:25:41,698 [EventQueue-ContainerReportForReconContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from upgrade_dn1_1.upgrade_net.
recon_1  | 2020-12-08 15:25:41,753 [EventQueue-ContainerReportForReconContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1  | 2020-12-08 15:25:42,175 [IPC Server handler 3 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/054abb01-b57b-42ea-aff7-3bb87eb3dd27
recon_1  | 2020-12-08 15:25:42,176 [IPC Server handler 3 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 054abb01-b57b-42ea-aff7-3bb87eb3dd27{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2020-12-08 15:25:42,176 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 054abb01-b57b-42ea-aff7-3bb87eb3dd27 to Node DB.
recon_1  | 2020-12-08 15:25:42,178 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=6618c38d-5b72-4334-a134-adfd663a93df reported by 054abb01-b57b-42ea-aff7-3bb87eb3dd27{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2020-12-08 15:25:48,245 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline THREE PipelineID=6618c38d-5b72-4334-a134-adfd663a93df reported by 054abb01-b57b-42ea-aff7-3bb87eb3dd27{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1  | 2020-12-08 15:25:48,246 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 6618c38d-5b72-4334-a134-adfd663a93df, Nodes: 892026bc-38f3-4f54-afde-0054a2964852{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}054abb01-b57b-42ea-aff7-3bb87eb3dd27{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}25c58bfd-4348-494a-9b09-a4dec9a92dee{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:054abb01-b57b-42ea-aff7-3bb87eb3dd27, CreationTimestamp2020-12-08T15:25:24.159Z] moved to OPEN state
